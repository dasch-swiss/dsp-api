{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"Readme/","text":"DSP-API Documentation This folder contains the sources to the DSP-API part of documentation published under https://docs.dasch.swiss/ and managed by DSP-DOCS repository. Build and serve the docs locally Documentation can be build by invoking the following make commands from the project root directory: make docs-install-requirements: ## install requirements make docs-build # build the documentation make docs-serve # serve it locally Prerequisites You will need Graphviz . On macOS: ```shell brew install graphviz ``` On Linux, use your distribution's package manager.","title":"DSP-API Documentation"},{"location":"Readme/#dsp-api-documentation","text":"This folder contains the sources to the DSP-API part of documentation published under https://docs.dasch.swiss/ and managed by DSP-DOCS repository.","title":"DSP-API Documentation"},{"location":"Readme/#build-and-serve-the-docs-locally","text":"Documentation can be build by invoking the following make commands from the project root directory: make docs-install-requirements: ## install requirements make docs-build # build the documentation make docs-serve # serve it locally","title":"Build and serve the docs locally"},{"location":"Readme/#prerequisites","text":"You will need Graphviz . On macOS: ```shell brew install graphviz ``` On Linux, use your distribution's package manager.","title":"Prerequisites"},{"location":"01-introduction/example-project/","text":"An Example Project This section introduces some of the basic concepts involved in creating ontologies for DSP projects, by means of a relatively simple example project. Before reading this document, it will be helpful to have some familiarity with the basic concepts explained in knora-base. DSP-API comes with two example projects, called incunabula and images-demo . Here we will consider the incunabula example, which is a reduced version of a real research project on early printed books. It is designed to store an image of each page of each book, as well as RDF data about books, pages, their contents, and relationships between them. At the moment, only the RDF data is provided in the example project, not the images. The incunabula ontology is in the file incunabula-onto.ttl , and its data is in the file incunabula-demo-data.ttl . Both these files are in a standard RDF file format called Turtle . The DSP-API distribution includes sample scripts (in the webapi/scripts directory) for importing these files directly into different triplestores. If you are starting a new project from scratch, you can adapt these scripts to import your ontology (and any existing RDF data) into your triplestore for use with DSP-API. The syntax of Turtle is fairly simple: it is basically a sequence of triples. We will consider some details of Turtle syntax as we go along. The Incunabula Ontology Here we will just focus on some of the main aspects of the ontology. An ontology file typically begins by defining prefixes for the IRIs of other ontologies that will be referred to. First there are some prefixes for ontologies that are very commonly used in RDF: @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix xsd: <http://www.w3.org/2001/XMLSchema#> . @prefix foaf: <http://xmlns.com/foaf/0.1/> . @prefix dcterms: <http://purl.org/dc/terms/> . The rdf , rdfs , and owl ontologies contain basic properties that are used to define ontology entities. The xsd ontology contains definitions of literal data types such as string and integer . (For more information about these ontologies, see the references in knora-base.) The foaf ontology contains classes and properties for representing people. The dcterms ontology represents Dublin Core metadata. Then we define prefixes for DSP ontologies: @prefix knora-base: <http://www.knora.org/ontology/knora-base#> . @prefix salsah-gui: <http://www.knora.org/ontology/salsah-gui#> . The knora-base ontology contains DSP-API's core abstractions, and is described in knora-base. The salsah-gui ontology includes properties that DSP projects must use to enable SALSAH, DSP-API's generic virtual research environment. For convenience, we can use the empty prefix to refer to the incunabula ontology itself: @prefix : <http://www.knora.org/ontology/0803/incunabula#> . However, outside the ontology file, it would make more sense to define an incunabula prefix to refer to the incunabula ontology. Properties All the content produced by a DSP project must be stored in Knora resources (see incunabula-resource-classes ). Resources have properties that point to different parts of their contents; for example, the incunabula project contains books, which have properties like title . Every property that poitns to a DSP value must be a subproperty of knora-base:hasValue , and every property that points to another Knora resource must be a subproperty of knora-base:hasLinkTo . Here is the definition of the incunabula:title property: :title rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:hasValue, dcterms:title ; rdfs:label \"Titel\"@de , \"Titre\"@fr , \"Titolo\"@it , \"Title\"@en ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue ; salsah-gui:guiElement salsah-gui:SimpleText ; salsah-gui:guiAttribute \"size=80\" , \"maxlength=255\" . The definition of incunabula:title consists of a list of triples, all of which have :title as their subject. To avoid repeating :title for each triple, Turtle syntax allows us to use a semicolon ( ; ) to separate triples that have the same subject. Moreover, some triples also have the same predicate; a comma ( , ) is used to avoid repeating the predicate. The definition of :title says: rdf:type owl:ObjectProperty : It is an owl:ObjectProperty . There are two kinds of OWL properties: object properties and datatype properties. Object properties point to objects, which have IRIs and can have their own properties. Datatype properties point to literal values, such as strings and integers. rdfs:subPropertyOf knora-base:hasValue, dcterms:title : It is a subproperty of knora-base:hasValue and dcterms:title . Since the objects of this property will be Knora values, it must be a subproperty of knora-base:hasValue . To facilitate searches, we have also chosen to make it a subproperty of dcterms:title . In the DSP-API v2, if you do a search for resources that have a certain dcterms:title , and there is a resource with a matching incunabula:title , the search results could include that resource. rdfs:label \"Titel\"@de , etc.: It has the specified labels in various languages. These are needed, for example, by user interfaces, to prompt the user to enter a value. knora-base:subjectClassConstraint :book : The subject of the property must be an incunabula:book . knora-base:objectClassConstraint knora-base:TextValue : The object of this property must be a knora-base:TextValue (which is a subclass of knora-base:Value ). salsah-gui:guiElement salsah-gui:SimpleText : When SALSAH asks a user to enter a value for this property, it should use a simple text field. salsah-gui:guiAttribute \"size=80\" , \"maxlength=255\" : The SALSAH text field for entering a value for this property should be 80 characters wide, and should accept at most 255 characters. The incunabula ontology contains several other property definitions that are basically similar. Note that different subclasses of Value are used. For example, incunabula:pubdate , which represents the publication date of a book, points to a knora-base:DateValue . The DateValue class stores a date range, with a specified degree of precision and a preferred calendar system for display. A property can point to a Knora resource instead of to a Knora value. For example, in the incunabula ontology, there are resources representing pages and books, and each page is part of some book. This relationship is expressed using the property incunabula:partOf : :partOf rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:isPartOf ; rdfs:label \"ist ein Teil von\"@de , \"est un part de\"@fr , \"e una parte di\"@it , \"is a part of\"@en ; rdfs:comment \"\"\"Diese Property bezeichnet eine Verbindung zu einer anderen Resource, in dem ausgesagt wird, dass die vorliegende Resource ein integraler Teil der anderen Resource ist. Zum Beispiel ist eine Buchseite ein integraler Bestandteil genau eines Buches.\"\"\"@de ; knora-base:subjectClassConstraint :page ; knora-base:objectClassConstraint :book ; salsah-gui:guiElement salsah-gui:Searchbox . The key things to notice here are: rdfs:subPropertyOf knora-base:isPartOf : The knora-base ontology provides a generic isPartOf property to express part-whole relationships. A project may use knora-base:isPartOf directly, however creating a subproperty such as incunabula:partOf will allow to customize the property further, e.g. by giving it a more descriptive label. It is important to note that knora-base:isPartOf is a subproperty of knora-base:hasLinkTo . Any property that points to a knora-base:Resource must be a subproperty of knora-base:hasLinkTo . Such a property is called a link property . knora-base:objectClassConstraint :book : The object of this property must be a member of the class incunabula:book , which, as we will see below, is a subclass of knora-base:Resource . salsah-gui:guiElement salsah-gui:Searchbox : When SALSAH prompts a user to select the book that a page is part of, it should provide a search box enabling the user to find the desired book. Because incunabula:partOf is a link property, it must always accompanied by a link value property , which enables Knora to store metadata about each link that is created with the link property. This metadata includes the date and time when the link was created, its owner, the permissions it grants, and whether it has been deleted. Storing this metadata allows Knora to authorise users to see or modify the link, as well as to query a previous state of a repository in which a deleted link had not yet been deleted. (The ability to query previous states of a repository is planned for DSP-API version 2.) The name of a link property and its link value property must be related by the following naming convention: to determine the name of the link value property, add the word Value to the name of the link property. Hence, the incunabula ontology defines the property partOfValue : :partOfValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:isPartOfValue ; knora-base:subjectClassConstraint :page ; knora-base:objectClassConstraint knora-base:LinkValue . As a link value property, incunabula:partOfValue must point to a knora-base:LinkValue . The LinkValue class is an RDF reification of a triple (in this case, the triple that links a page to a book). For more details about this, see knora-base-linkvalue. Note that the property incunabula:hasAuthor points to a knora-base:TextValue , because the incunabula project represents authors simply by their names. A more complex project could represent each author as a resource, in which case incunabula:hasAuthor would need to be a subproperty of knora-base:hasLinkTo . Resource Classes The two main resource classes in the incunabula ontology are book and page . Here is incunabula:book : :book rdf:type owl:Class ; rdfs:subClassOf knora-base:Resource , [ rdf:type owl:Restriction ; owl:onProperty :title ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasAuthor ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :publisher ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"3\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :publoc ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"4\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :pubdate ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :location ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"6\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :url ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"7\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :description ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :physical_desc ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"9\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :note ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :citation ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :book_comment ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"12\"^^xsd:nonNegativeInteger ] ; knora-base:resourceIcon \"book.gif\" ; rdfs:label \"Buch\"@de , \"Livre\"@fr , \"Libro\"@it , \"Book\"@en ; rdfs:comment \"\"\"Diese Resource-Klasse beschreibt ein Buch\"\"\"@de . Like every Knora resource class, incunabula:book is a subclass of knora-base:Resource . It is also a subclass of a number of other classes of type owl:Restriction , which are defined in square brackets, using Turtle's syntax for anonymous blank nodes. Each owl:Restriction specifies a cardinality for a property that is allowed in resources of type incunabula:book . A cardinality is indeed a kind of restriction: it means that a resource of this type may have, or must have, a certain number of instances of the specified property. For example, incunabula:book has cardinalities saying that a book must have at least one title and at most one publication date. In the DSP-API version 1, the word 'occurrence' is used instead of 'cardinality'. The OWL cardinalities supported by Knora are described in OWL Cardinalities . Note that incunabula:book specifies a cardinality of owl:minCardinality 0 on the property incunabula:hasAuthor . At first glance, this might seem as if it serves no purpose, since it says that the property is optional and can have any number of instances. You may be wondering whether this cardinality could simply be omitted from the definition of incunabula:book . However, Knora requires every property of a resource to have some cardinality in the resource's class. This is because Knora uses the cardinalities to determine which properties are possible for instances of the class, and the DSP-API relies on this information. If there was no cardinality for incunabula:hasAuthor , Knora would not allow a book to have an author. Each owl:Restriction specifying a cardinality can include the predicate salsah-gui:guiOrder , which tells the SALSAH GUI the order the properties should be displayed in. Here is the definition of incunabula:page : :page rdf:type owl:Class ; rdfs:subClassOf knora-base:StillImageRepresentation , [ rdf:type owl:Restriction ; owl:onProperty :pagenum ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :partOfValue ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :partOf ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :seqnum ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"3\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :description ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :citation ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :page_comment ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"6\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :origname ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"7\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasLeftSidebandValue ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasLeftSideband ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasRightSidebandValue ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"11\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasRightSideband ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"11\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :transcription ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"12\"^^xsd:nonNegativeInteger ] ; knora-base:resourceIcon \"page.gif\" ; rdfs:label \"Seite\"@de , \"Page\"@fr , \"Page\"@en ; rdfs:comment \"\"\"Eine Seite ist ein Teil eines Buchs\"\"\"@de , \"\"\"Une page est une partie d'un livre\"\"\"@fr , \"\"\"A page is a part of a book\"\"\"@en . The incunabula:page class is a subclass of knora-base:StillImageRepresentation , which is a subclass of knora-base:Representation , which is a subclass of knora-base:Resource . The class knora-base:Representation is used for resources that contain metadata about files stored by Knora. Each It has different subclasses that can hold different types of files, including still images, audio, and video files. A given Representation can store metadata about several different files, as long as they are of the same type and are semantically equivalent, e.g. are different versions of the same image with different colorspaces, so that coordinates in one file will work in the other files. In Knora, a subclass inherits the cardinalities defined in its superclasses. Let's look at the class hierarchy of incunabula:page , starting with knora-base:Representation : :Representation rdf:type owl:Class ; rdfs:subClassOf :Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:comment \"A resource that can store one or more FileValues\"@en . This says that a Representation must have at least one instance of the property hasFileValue , which is defined like this: :hasFileValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf :hasValue ; :subjectClassConstraint :Representation ; :objectClassConstraint :FileValue . The subject of hasFileValue must be a Representation , and its object must be a FileValue . There are different subclasses of FileValue for different kinds of files, but we'll skip the details here. This is the definition of knora-base:StillImageRepresentation : :StillImageRepresentation rdf:type owl:Class ; rdfs:subClassOf :Representation , [ rdf:type owl:Restriction ; owl:onProperty :hasStillImageFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:comment \"A resource that can contain two-dimensional still image files\"@en . It must have at least one instance of the property hasStillImageFileValue , which is defined as follows: :hasStillImageFileValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf :hasFileValue ; :subjectClassConstraint :StillImageRepresentation ; :objectClassConstraint :StillImageFileValue . Because hasStillImageFileValue is a subproperty of hasFileValue , the cardinality on hasStillImageFileValue , defined in the subclass StillImageRepresentation , overrides the cardinality on hasFileValue , defined in the superclass Representation . In other words, the more general cardinality in the superclass is replaced by a more specific cardinality in the base class. Since incunabula:page is a subclass of StillImageRepresentation , it inherits the cardinality on hasStillImageFileValue . As a result, a page must have at least one image file attached to it. Here's another example of cardinality inheritance. The class knora-base:Resource has a cardinality for knora-base:seqnum . The idea is that resources of any type could be arranged in some sort of sequence. As we saw above, incunabula:page is a subclass of knora-base:Resource . But incunabula:page has its own cardinality for incunabula:seqnum , which is a subproperty of knora-base:seqnum . Once again, the subclass's cardinality on the subproperty replaces the superclass's cardinality on the superproperty: a page is allowed to have an incunabula:seqnum , but it is not allowed to have a knora-base:seqnum .","title":"An Example Project"},{"location":"01-introduction/example-project/#an-example-project","text":"This section introduces some of the basic concepts involved in creating ontologies for DSP projects, by means of a relatively simple example project. Before reading this document, it will be helpful to have some familiarity with the basic concepts explained in knora-base. DSP-API comes with two example projects, called incunabula and images-demo . Here we will consider the incunabula example, which is a reduced version of a real research project on early printed books. It is designed to store an image of each page of each book, as well as RDF data about books, pages, their contents, and relationships between them. At the moment, only the RDF data is provided in the example project, not the images. The incunabula ontology is in the file incunabula-onto.ttl , and its data is in the file incunabula-demo-data.ttl . Both these files are in a standard RDF file format called Turtle . The DSP-API distribution includes sample scripts (in the webapi/scripts directory) for importing these files directly into different triplestores. If you are starting a new project from scratch, you can adapt these scripts to import your ontology (and any existing RDF data) into your triplestore for use with DSP-API. The syntax of Turtle is fairly simple: it is basically a sequence of triples. We will consider some details of Turtle syntax as we go along.","title":"An Example Project"},{"location":"01-introduction/example-project/#the-incunabula-ontology","text":"Here we will just focus on some of the main aspects of the ontology. An ontology file typically begins by defining prefixes for the IRIs of other ontologies that will be referred to. First there are some prefixes for ontologies that are very commonly used in RDF: @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . @prefix owl: <http://www.w3.org/2002/07/owl#> . @prefix xsd: <http://www.w3.org/2001/XMLSchema#> . @prefix foaf: <http://xmlns.com/foaf/0.1/> . @prefix dcterms: <http://purl.org/dc/terms/> . The rdf , rdfs , and owl ontologies contain basic properties that are used to define ontology entities. The xsd ontology contains definitions of literal data types such as string and integer . (For more information about these ontologies, see the references in knora-base.) The foaf ontology contains classes and properties for representing people. The dcterms ontology represents Dublin Core metadata. Then we define prefixes for DSP ontologies: @prefix knora-base: <http://www.knora.org/ontology/knora-base#> . @prefix salsah-gui: <http://www.knora.org/ontology/salsah-gui#> . The knora-base ontology contains DSP-API's core abstractions, and is described in knora-base. The salsah-gui ontology includes properties that DSP projects must use to enable SALSAH, DSP-API's generic virtual research environment. For convenience, we can use the empty prefix to refer to the incunabula ontology itself: @prefix : <http://www.knora.org/ontology/0803/incunabula#> . However, outside the ontology file, it would make more sense to define an incunabula prefix to refer to the incunabula ontology.","title":"The Incunabula Ontology"},{"location":"01-introduction/example-project/#properties","text":"All the content produced by a DSP project must be stored in Knora resources (see incunabula-resource-classes ). Resources have properties that point to different parts of their contents; for example, the incunabula project contains books, which have properties like title . Every property that poitns to a DSP value must be a subproperty of knora-base:hasValue , and every property that points to another Knora resource must be a subproperty of knora-base:hasLinkTo . Here is the definition of the incunabula:title property: :title rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:hasValue, dcterms:title ; rdfs:label \"Titel\"@de , \"Titre\"@fr , \"Titolo\"@it , \"Title\"@en ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue ; salsah-gui:guiElement salsah-gui:SimpleText ; salsah-gui:guiAttribute \"size=80\" , \"maxlength=255\" . The definition of incunabula:title consists of a list of triples, all of which have :title as their subject. To avoid repeating :title for each triple, Turtle syntax allows us to use a semicolon ( ; ) to separate triples that have the same subject. Moreover, some triples also have the same predicate; a comma ( , ) is used to avoid repeating the predicate. The definition of :title says: rdf:type owl:ObjectProperty : It is an owl:ObjectProperty . There are two kinds of OWL properties: object properties and datatype properties. Object properties point to objects, which have IRIs and can have their own properties. Datatype properties point to literal values, such as strings and integers. rdfs:subPropertyOf knora-base:hasValue, dcterms:title : It is a subproperty of knora-base:hasValue and dcterms:title . Since the objects of this property will be Knora values, it must be a subproperty of knora-base:hasValue . To facilitate searches, we have also chosen to make it a subproperty of dcterms:title . In the DSP-API v2, if you do a search for resources that have a certain dcterms:title , and there is a resource with a matching incunabula:title , the search results could include that resource. rdfs:label \"Titel\"@de , etc.: It has the specified labels in various languages. These are needed, for example, by user interfaces, to prompt the user to enter a value. knora-base:subjectClassConstraint :book : The subject of the property must be an incunabula:book . knora-base:objectClassConstraint knora-base:TextValue : The object of this property must be a knora-base:TextValue (which is a subclass of knora-base:Value ). salsah-gui:guiElement salsah-gui:SimpleText : When SALSAH asks a user to enter a value for this property, it should use a simple text field. salsah-gui:guiAttribute \"size=80\" , \"maxlength=255\" : The SALSAH text field for entering a value for this property should be 80 characters wide, and should accept at most 255 characters. The incunabula ontology contains several other property definitions that are basically similar. Note that different subclasses of Value are used. For example, incunabula:pubdate , which represents the publication date of a book, points to a knora-base:DateValue . The DateValue class stores a date range, with a specified degree of precision and a preferred calendar system for display. A property can point to a Knora resource instead of to a Knora value. For example, in the incunabula ontology, there are resources representing pages and books, and each page is part of some book. This relationship is expressed using the property incunabula:partOf : :partOf rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:isPartOf ; rdfs:label \"ist ein Teil von\"@de , \"est un part de\"@fr , \"e una parte di\"@it , \"is a part of\"@en ; rdfs:comment \"\"\"Diese Property bezeichnet eine Verbindung zu einer anderen Resource, in dem ausgesagt wird, dass die vorliegende Resource ein integraler Teil der anderen Resource ist. Zum Beispiel ist eine Buchseite ein integraler Bestandteil genau eines Buches.\"\"\"@de ; knora-base:subjectClassConstraint :page ; knora-base:objectClassConstraint :book ; salsah-gui:guiElement salsah-gui:Searchbox . The key things to notice here are: rdfs:subPropertyOf knora-base:isPartOf : The knora-base ontology provides a generic isPartOf property to express part-whole relationships. A project may use knora-base:isPartOf directly, however creating a subproperty such as incunabula:partOf will allow to customize the property further, e.g. by giving it a more descriptive label. It is important to note that knora-base:isPartOf is a subproperty of knora-base:hasLinkTo . Any property that points to a knora-base:Resource must be a subproperty of knora-base:hasLinkTo . Such a property is called a link property . knora-base:objectClassConstraint :book : The object of this property must be a member of the class incunabula:book , which, as we will see below, is a subclass of knora-base:Resource . salsah-gui:guiElement salsah-gui:Searchbox : When SALSAH prompts a user to select the book that a page is part of, it should provide a search box enabling the user to find the desired book. Because incunabula:partOf is a link property, it must always accompanied by a link value property , which enables Knora to store metadata about each link that is created with the link property. This metadata includes the date and time when the link was created, its owner, the permissions it grants, and whether it has been deleted. Storing this metadata allows Knora to authorise users to see or modify the link, as well as to query a previous state of a repository in which a deleted link had not yet been deleted. (The ability to query previous states of a repository is planned for DSP-API version 2.) The name of a link property and its link value property must be related by the following naming convention: to determine the name of the link value property, add the word Value to the name of the link property. Hence, the incunabula ontology defines the property partOfValue : :partOfValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf knora-base:isPartOfValue ; knora-base:subjectClassConstraint :page ; knora-base:objectClassConstraint knora-base:LinkValue . As a link value property, incunabula:partOfValue must point to a knora-base:LinkValue . The LinkValue class is an RDF reification of a triple (in this case, the triple that links a page to a book). For more details about this, see knora-base-linkvalue. Note that the property incunabula:hasAuthor points to a knora-base:TextValue , because the incunabula project represents authors simply by their names. A more complex project could represent each author as a resource, in which case incunabula:hasAuthor would need to be a subproperty of knora-base:hasLinkTo .","title":"Properties"},{"location":"01-introduction/example-project/#resource-classes","text":"The two main resource classes in the incunabula ontology are book and page . Here is incunabula:book : :book rdf:type owl:Class ; rdfs:subClassOf knora-base:Resource , [ rdf:type owl:Restriction ; owl:onProperty :title ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasAuthor ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :publisher ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"3\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :publoc ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"4\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :pubdate ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :location ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"6\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :url ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"7\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :description ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :physical_desc ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"9\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :note ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :citation ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :book_comment ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"12\"^^xsd:nonNegativeInteger ] ; knora-base:resourceIcon \"book.gif\" ; rdfs:label \"Buch\"@de , \"Livre\"@fr , \"Libro\"@it , \"Book\"@en ; rdfs:comment \"\"\"Diese Resource-Klasse beschreibt ein Buch\"\"\"@de . Like every Knora resource class, incunabula:book is a subclass of knora-base:Resource . It is also a subclass of a number of other classes of type owl:Restriction , which are defined in square brackets, using Turtle's syntax for anonymous blank nodes. Each owl:Restriction specifies a cardinality for a property that is allowed in resources of type incunabula:book . A cardinality is indeed a kind of restriction: it means that a resource of this type may have, or must have, a certain number of instances of the specified property. For example, incunabula:book has cardinalities saying that a book must have at least one title and at most one publication date. In the DSP-API version 1, the word 'occurrence' is used instead of 'cardinality'. The OWL cardinalities supported by Knora are described in OWL Cardinalities . Note that incunabula:book specifies a cardinality of owl:minCardinality 0 on the property incunabula:hasAuthor . At first glance, this might seem as if it serves no purpose, since it says that the property is optional and can have any number of instances. You may be wondering whether this cardinality could simply be omitted from the definition of incunabula:book . However, Knora requires every property of a resource to have some cardinality in the resource's class. This is because Knora uses the cardinalities to determine which properties are possible for instances of the class, and the DSP-API relies on this information. If there was no cardinality for incunabula:hasAuthor , Knora would not allow a book to have an author. Each owl:Restriction specifying a cardinality can include the predicate salsah-gui:guiOrder , which tells the SALSAH GUI the order the properties should be displayed in. Here is the definition of incunabula:page : :page rdf:type owl:Class ; rdfs:subClassOf knora-base:StillImageRepresentation , [ rdf:type owl:Restriction ; owl:onProperty :pagenum ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :partOfValue ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :partOf ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :seqnum ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"3\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :description ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"2\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :citation ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"5\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :page_comment ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"6\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :origname ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"7\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasLeftSidebandValue ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasLeftSideband ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"10\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasRightSidebandValue ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"11\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasRightSideband ; owl:maxCardinality \"1\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"11\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :transcription ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ; salsah-gui:guiOrder \"12\"^^xsd:nonNegativeInteger ] ; knora-base:resourceIcon \"page.gif\" ; rdfs:label \"Seite\"@de , \"Page\"@fr , \"Page\"@en ; rdfs:comment \"\"\"Eine Seite ist ein Teil eines Buchs\"\"\"@de , \"\"\"Une page est une partie d'un livre\"\"\"@fr , \"\"\"A page is a part of a book\"\"\"@en . The incunabula:page class is a subclass of knora-base:StillImageRepresentation , which is a subclass of knora-base:Representation , which is a subclass of knora-base:Resource . The class knora-base:Representation is used for resources that contain metadata about files stored by Knora. Each It has different subclasses that can hold different types of files, including still images, audio, and video files. A given Representation can store metadata about several different files, as long as they are of the same type and are semantically equivalent, e.g. are different versions of the same image with different colorspaces, so that coordinates in one file will work in the other files. In Knora, a subclass inherits the cardinalities defined in its superclasses. Let's look at the class hierarchy of incunabula:page , starting with knora-base:Representation : :Representation rdf:type owl:Class ; rdfs:subClassOf :Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:comment \"A resource that can store one or more FileValues\"@en . This says that a Representation must have at least one instance of the property hasFileValue , which is defined like this: :hasFileValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf :hasValue ; :subjectClassConstraint :Representation ; :objectClassConstraint :FileValue . The subject of hasFileValue must be a Representation , and its object must be a FileValue . There are different subclasses of FileValue for different kinds of files, but we'll skip the details here. This is the definition of knora-base:StillImageRepresentation : :StillImageRepresentation rdf:type owl:Class ; rdfs:subClassOf :Representation , [ rdf:type owl:Restriction ; owl:onProperty :hasStillImageFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:comment \"A resource that can contain two-dimensional still image files\"@en . It must have at least one instance of the property hasStillImageFileValue , which is defined as follows: :hasStillImageFileValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf :hasFileValue ; :subjectClassConstraint :StillImageRepresentation ; :objectClassConstraint :StillImageFileValue . Because hasStillImageFileValue is a subproperty of hasFileValue , the cardinality on hasStillImageFileValue , defined in the subclass StillImageRepresentation , overrides the cardinality on hasFileValue , defined in the superclass Representation . In other words, the more general cardinality in the superclass is replaced by a more specific cardinality in the base class. Since incunabula:page is a subclass of StillImageRepresentation , it inherits the cardinality on hasStillImageFileValue . As a result, a page must have at least one image file attached to it. Here's another example of cardinality inheritance. The class knora-base:Resource has a cardinality for knora-base:seqnum . The idea is that resources of any type could be arranged in some sort of sequence. As we saw above, incunabula:page is a subclass of knora-base:Resource . But incunabula:page has its own cardinality for incunabula:seqnum , which is a subproperty of knora-base:seqnum . Once again, the subclass's cardinality on the subproperty replaces the superclass's cardinality on the superproperty: a page is allowed to have an incunabula:seqnum , but it is not allowed to have a knora-base:seqnum .","title":"Resource Classes"},{"location":"01-introduction/file-formats/","text":"File Formats in DSP-API Currently, only a limited number of file formats is accepted to be uploaded onto DSP. Some metadata is extracted from the files during the ingest but the file formats are not validated. Only image file formats are currently migrated into another format. Both, the migrated version of the file and the original are kept. The following table shows the accepted file formats: Category Accepted format Converted during ingest? Text, XML 1 TXT, XML, XSL, XSD No Tables CSV, XLS, XLSX No 2D Images JPG, JPEG, JP2, PNG, TIF, TIFF Yes, converted to JPEG 2000 by Sipi Audio MPEG (MP3), WAV No Video MP4 No Office PDF, DOC, DOCX, PPT, PPTX No Archives ZIP, TAR, GZ, Z, TAR.GZ, TGZ, GZIP, 7Z No 1: If your XML files represent text with markup (e.g. TEI/XML ), the recommended approach is to allow Knora to store it as Standoff/RDF .","title":"File Formats in DSP-API"},{"location":"01-introduction/file-formats/#file-formats-in-dsp-api","text":"Currently, only a limited number of file formats is accepted to be uploaded onto DSP. Some metadata is extracted from the files during the ingest but the file formats are not validated. Only image file formats are currently migrated into another format. Both, the migrated version of the file and the original are kept. The following table shows the accepted file formats: Category Accepted format Converted during ingest? Text, XML 1 TXT, XML, XSL, XSD No Tables CSV, XLS, XLSX No 2D Images JPG, JPEG, JP2, PNG, TIF, TIFF Yes, converted to JPEG 2000 by Sipi Audio MPEG (MP3), WAV No Video MP4 No Office PDF, DOC, DOCX, PPT, PPTX No Archives ZIP, TAR, GZ, Z, TAR.GZ, TGZ, GZIP, 7Z No 1: If your XML files represent text with markup (e.g. TEI/XML ), the recommended approach is to allow Knora to store it as Standoff/RDF .","title":"File Formats in DSP-API"},{"location":"01-introduction/standoff-rdf/","text":"Standoff/RDF Text Markup Standoff markup is text markup that is stored separately from the content it describes. DSP-API's Standoff/RDF markup stores content as a simple Unicode string, and represents markup separately as RDF data. This approach has some advantages over commonly used markup systems such as XML: First, XML and other hierarchical markup systems assume that a document is a hierarchy, and have difficulty representing non-hierarchical structures or multiple overlapping hierarchies. Standoff markup can easily represent these structures. Second, markup languages are typically designed to be used in text files. But there is no standard system for searching and linking together many different text files containing markup. It is possible to do this in a non-standard way by using an XML database such as eXist , but this still does not allow for queries that include text as well as non-textual data not stored in XML. By storing markup as RDF, DSP-API can search for markup structures in the same way as it searches for any RDF data structure. This makes it possible to do searches that combine text-related criteria with other sorts of criteria. For example, if persons and events are represented as resources, and texts are represented in Standoff/RDF, a text can contain tags representing links to persons or events. You could then search for a text that mentions a person who lived in the same city as another person who is the author of a text that mentions an event that occurred during a certain time period. In DSP-API's Standoff/RDF, a tag is an RDF entity that is linked to a text value . Each tag points to a substring of the text, and has semantic properties of its own. You can define your own tag classes in your ontology by making subclasses of knora-base:StandoffTag , and attach your own properties to them. You can then search for those properties using DSP-API's search language, Gravsearch . The built-in knora-base and standoff ontologies provide some basic tags that can be reused or extended. These include tags that represent DSP-API data types. For example, knora-base:StandoffDateTag represents a date in exactly the same way as a date value , i.e. as a calendar-independent astronomical date. You can use this tag as-is, or extend it by making a subclass, to represent dates in texts. Gravsearch includes built-in functionality for searching for these data type tags. For example, you can search for text containing a date that falls within a certain date range . DSP-API supports automatic conversion between XML and Standoff/RDF. To make this work, Standoff/RDF stores the order of tags and their hierarchical relationships. You must define an XML-to-Standoff Mapping for your standoff tag classes and properties. Then you can import an XML document into DSP-API, which will store it as Standoff/RDF. The text and markup can then be searched using Gravsearch. When you retrieve the document, DSP-API converts it back to the original XML. To represent overlapping or non-hierarchical markup in exported and imported XML, DSP-API supports CLIX tags. As XML-to-Standoff has proved to be complicated and not very well performing, the use of standoff with custom mappings is discouraged. Improved integration of text with XML mark up, particularly TEI-XML, is in planning.","title":"Standoff/RDF Text Markup"},{"location":"01-introduction/standoff-rdf/#standoffrdf-text-markup","text":"Standoff markup is text markup that is stored separately from the content it describes. DSP-API's Standoff/RDF markup stores content as a simple Unicode string, and represents markup separately as RDF data. This approach has some advantages over commonly used markup systems such as XML: First, XML and other hierarchical markup systems assume that a document is a hierarchy, and have difficulty representing non-hierarchical structures or multiple overlapping hierarchies. Standoff markup can easily represent these structures. Second, markup languages are typically designed to be used in text files. But there is no standard system for searching and linking together many different text files containing markup. It is possible to do this in a non-standard way by using an XML database such as eXist , but this still does not allow for queries that include text as well as non-textual data not stored in XML. By storing markup as RDF, DSP-API can search for markup structures in the same way as it searches for any RDF data structure. This makes it possible to do searches that combine text-related criteria with other sorts of criteria. For example, if persons and events are represented as resources, and texts are represented in Standoff/RDF, a text can contain tags representing links to persons or events. You could then search for a text that mentions a person who lived in the same city as another person who is the author of a text that mentions an event that occurred during a certain time period. In DSP-API's Standoff/RDF, a tag is an RDF entity that is linked to a text value . Each tag points to a substring of the text, and has semantic properties of its own. You can define your own tag classes in your ontology by making subclasses of knora-base:StandoffTag , and attach your own properties to them. You can then search for those properties using DSP-API's search language, Gravsearch . The built-in knora-base and standoff ontologies provide some basic tags that can be reused or extended. These include tags that represent DSP-API data types. For example, knora-base:StandoffDateTag represents a date in exactly the same way as a date value , i.e. as a calendar-independent astronomical date. You can use this tag as-is, or extend it by making a subclass, to represent dates in texts. Gravsearch includes built-in functionality for searching for these data type tags. For example, you can search for text containing a date that falls within a certain date range . DSP-API supports automatic conversion between XML and Standoff/RDF. To make this work, Standoff/RDF stores the order of tags and their hierarchical relationships. You must define an XML-to-Standoff Mapping for your standoff tag classes and properties. Then you can import an XML document into DSP-API, which will store it as Standoff/RDF. The text and markup can then be searched using Gravsearch. When you retrieve the document, DSP-API converts it back to the original XML. To represent overlapping or non-hierarchical markup in exported and imported XML, DSP-API supports CLIX tags. As XML-to-Standoff has proved to be complicated and not very well performing, the use of standoff with custom mappings is discouraged. Improved integration of text with XML mark up, particularly TEI-XML, is in planning.","title":"Standoff/RDF Text Markup"},{"location":"01-introduction/what-is-dsp/","text":"What is DSP and DSP-API (previous Knora)? The DaSCH Service Platform (DSP) is a content management system for the long-term preservation and reuse of humanities data. It is designed to accommodate data with a complex internal structure, including data that could be stored in relational databases. DSP aims to solve key problems in the long-term preservation and reuse of humanities data: First, traditional archives preserve data, but do not facilitate reuse. Typically, only metadata can be searched, not the data itself. You have to first identify an information package that might be of interest, then download it, and only then can you find out what's really in it. This is time-consuming, and makes it impractical to reuse data from many different sources. DSP solves this problem by keeping the data alive. You can query all the data in a DSP repository, not just the metadata. You can import thousands of databases into DSP, and run queries that search through all of them at once. Another problem is that researchers use a multitude of different file formats, many of which are proprietary and quickly become obsolete. It is not practical to maintain all the programs that were used to create and read old files, or even all the operating systems that these programs ran on. Therefore, DSP only accepts a certain number of file formats . Non-binary data is stored as RDF , in a dedicated database called a triplestore. RDF is an open, vendor-independent standard that can express any data structure. Binary media files (images, audio, and video) are converted to a few specialised archival file formats and stored by Sipi , with metadata stored in the triplestore. DSP then makes this data available for reuse via its generic, standards-based application programming interfaces (APIs = DSP-API). A virtual research environment (VRE) can then use these APIs to search, link together, and add to data from different research projects in a unified way. Humanities-Focused Data Storage Each project creates its own data model (or ontology ), describing the types of items it wishes to store, using basic data types defined in Knora's base ontology . This gives projects the freedom to describe their data in a way that makes sense to them, while allowing DSP to support searching and linking across projects. DSP has built-in support for data structures that are commonly needed in humanities data, and that present unique challenges for any type of database storage. Calendar-Independent Dates In the humanities, a date could be based on any sort of calendar (e.g. Gregorian, Julian, Islamic, or Hebrew). The DSP stores dates using a calendar-independent, astronomical representation, and converts between calendars as needed. This makes it possible to search for a date in one calendar, and get search results in other calendars. Flexible, Searchable Text Markup Commonly used text markup systems, such as TEI/XML , have to represent a text as a hierarchy, and therefore have trouble supporting overlapping markup. DSP supports Standoff/RDF markup : the markup is stored as RDF data, separately from the text, allowing for overlapping markup. DSP's RDF-based standoff is designed to support the needs of complex digital critical editions. The DSP can import any XML document (including TEI/XML) for storage as standoff/RDF, and can regenerate the original XML document at any time. Powerful Searches DSP-API provides a search language, Gravsearch , that is designed to meet the needs of humanities researchers. Gravsearch supports DSP-API's humanities-focused data structures, including calendar-independent dates and standoff markup, as well as fast full-text searches. This allows searches to combine text-related criteria with any other criteria. For example, you could search for a text that contains a certain word and also mentions a person who lived in the same city as another person who is the author of a text that mentions an event that occurred during a certain time period. Access Control The RDF standards do not include any concept of permissions. DSP-API's permission system allows project administrators and users to determine who can see or modify each item of data. DSP-API filters search results according to each user's permissions. Data History RDF does not have a concept of data history. DSP-API maintains all previous versions of each item of data. Ordinary searches return only the latest version, but you can obtain and cite an item as it was at any point in the past. Data Consistency RDF triplestores do not implement a standardised way of ensuring the consistency of data in a repository. DSP-API ensures that all data is consistent, conforms the project-specific data models, and meets DSP-API's minimum requirements for interoperability and reusability of data. Linked Open Data DSP-API supports publishing data online as as Linked Open Data , using open standards to allow interoperability between different repositories on the web. Build Your Own Application DSP-API can be used with a general-purpose, browser-based VRE called DSP-APP or SALSAH . Using the DSP-API and DSP-JS and/or DSP-UI , a set of reusable user-interface components, you can also create your own VRE or project-specific web site.","title":"What is DSP?"},{"location":"01-introduction/what-is-dsp/#what-is-dsp-and-dsp-api-previous-knora","text":"The DaSCH Service Platform (DSP) is a content management system for the long-term preservation and reuse of humanities data. It is designed to accommodate data with a complex internal structure, including data that could be stored in relational databases. DSP aims to solve key problems in the long-term preservation and reuse of humanities data: First, traditional archives preserve data, but do not facilitate reuse. Typically, only metadata can be searched, not the data itself. You have to first identify an information package that might be of interest, then download it, and only then can you find out what's really in it. This is time-consuming, and makes it impractical to reuse data from many different sources. DSP solves this problem by keeping the data alive. You can query all the data in a DSP repository, not just the metadata. You can import thousands of databases into DSP, and run queries that search through all of them at once. Another problem is that researchers use a multitude of different file formats, many of which are proprietary and quickly become obsolete. It is not practical to maintain all the programs that were used to create and read old files, or even all the operating systems that these programs ran on. Therefore, DSP only accepts a certain number of file formats . Non-binary data is stored as RDF , in a dedicated database called a triplestore. RDF is an open, vendor-independent standard that can express any data structure. Binary media files (images, audio, and video) are converted to a few specialised archival file formats and stored by Sipi , with metadata stored in the triplestore. DSP then makes this data available for reuse via its generic, standards-based application programming interfaces (APIs = DSP-API). A virtual research environment (VRE) can then use these APIs to search, link together, and add to data from different research projects in a unified way.","title":"What is DSP and DSP-API (previous Knora)?"},{"location":"01-introduction/what-is-dsp/#humanities-focused-data-storage","text":"Each project creates its own data model (or ontology ), describing the types of items it wishes to store, using basic data types defined in Knora's base ontology . This gives projects the freedom to describe their data in a way that makes sense to them, while allowing DSP to support searching and linking across projects. DSP has built-in support for data structures that are commonly needed in humanities data, and that present unique challenges for any type of database storage.","title":"Humanities-Focused Data Storage"},{"location":"01-introduction/what-is-dsp/#calendar-independent-dates","text":"In the humanities, a date could be based on any sort of calendar (e.g. Gregorian, Julian, Islamic, or Hebrew). The DSP stores dates using a calendar-independent, astronomical representation, and converts between calendars as needed. This makes it possible to search for a date in one calendar, and get search results in other calendars.","title":"Calendar-Independent Dates"},{"location":"01-introduction/what-is-dsp/#flexible-searchable-text-markup","text":"Commonly used text markup systems, such as TEI/XML , have to represent a text as a hierarchy, and therefore have trouble supporting overlapping markup. DSP supports Standoff/RDF markup : the markup is stored as RDF data, separately from the text, allowing for overlapping markup. DSP's RDF-based standoff is designed to support the needs of complex digital critical editions. The DSP can import any XML document (including TEI/XML) for storage as standoff/RDF, and can regenerate the original XML document at any time.","title":"Flexible, Searchable Text Markup"},{"location":"01-introduction/what-is-dsp/#powerful-searches","text":"DSP-API provides a search language, Gravsearch , that is designed to meet the needs of humanities researchers. Gravsearch supports DSP-API's humanities-focused data structures, including calendar-independent dates and standoff markup, as well as fast full-text searches. This allows searches to combine text-related criteria with any other criteria. For example, you could search for a text that contains a certain word and also mentions a person who lived in the same city as another person who is the author of a text that mentions an event that occurred during a certain time period.","title":"Powerful Searches"},{"location":"01-introduction/what-is-dsp/#access-control","text":"The RDF standards do not include any concept of permissions. DSP-API's permission system allows project administrators and users to determine who can see or modify each item of data. DSP-API filters search results according to each user's permissions.","title":"Access Control"},{"location":"01-introduction/what-is-dsp/#data-history","text":"RDF does not have a concept of data history. DSP-API maintains all previous versions of each item of data. Ordinary searches return only the latest version, but you can obtain and cite an item as it was at any point in the past.","title":"Data History"},{"location":"01-introduction/what-is-dsp/#data-consistency","text":"RDF triplestores do not implement a standardised way of ensuring the consistency of data in a repository. DSP-API ensures that all data is consistent, conforms the project-specific data models, and meets DSP-API's minimum requirements for interoperability and reusability of data.","title":"Data Consistency"},{"location":"01-introduction/what-is-dsp/#linked-open-data","text":"DSP-API supports publishing data online as as Linked Open Data , using open standards to allow interoperability between different repositories on the web.","title":"Linked Open Data"},{"location":"01-introduction/what-is-dsp/#build-your-own-application","text":"DSP-API can be used with a general-purpose, browser-based VRE called DSP-APP or SALSAH . Using the DSP-API and DSP-JS and/or DSP-UI , a set of reusable user-interface components, you can also create your own VRE or project-specific web site.","title":"Build Your Own Application"},{"location":"02-dsp-ontologies/introduction/","text":"Introduction The DSP ontologies provide a generic framework for describing humanities research data, allowing data from different projects to be combined, augmented, and reused. Resource Description Framework (RDF) DSP-API uses a hierarchy of ontologies based on the Resource Description Framework ( RDF ), RDF Schema ( RDFS ), and the Web Ontology Language ( OWL ). Both RDFS and OWL are expressed in RDF. RDF expresses information as a set of statements (called triples ). A triple consists of a subject, a predicate, and an object: The object may be either a literal value (such as a name or number) or another subject. Thus it is possible to create complex graphs that connect many subjects, like this: In RDF, each subject and predicate has a unique, URL-like identifier called an Internationalized Resource Identifier ( IRI ). Within a given project, IRIs typically differ only in their last component (the \"local part\"), which is often the fragment following a # character. Such IRIs share a long \"prefix\". In Turtle and similar formats for writing RDF, a short prefix label can be defined to represent the long prefix. Then an IRI can be written as a prefix label and a local part, separated by a colon ( : ). For example, if the \"example\" project's long prefix is http://www.example.org/rdf# , and it contains subjects with IRIs like http://www.example.org/rdf#book , we can define the prefix label ex to represent the prefix label, and write prefixed names for IRIs: Built-in Ontologies and User-Created Ontologies To ensure the interoperability of data produced by different projects, each project must describe its data model by creating one or more ontologies that extend Knora's built-in ontologies. The main built-in ontology in Knora is knora-base . Shared Ontologies Knora does not normally allow a project to use classes or properties defined in an ontology that belongs to another project. Each project must be free to change its own ontologies, but this is not possible if they have been used in ontologies or data created by other projects. However, an ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators will not change it in ways that could affect other ontologies or data that are based on it. Specifically, in a shared ontology, existing classes and properties cannot safely be changed, but new ones can be added. (It is not even safe to add an optional cardinality to an existing class, because this could cause subclasses to violate the rule that a class cannot have a cardinality on property P as well as a cardinality on a subproperty of P; see Restrictions on Classes .) A standardisation process for shared ontologies is planned (issue @github #523 ). For more details about shared ontologies, see Shared Ontology IRIs .","title":"Introduction"},{"location":"02-dsp-ontologies/introduction/#introduction","text":"The DSP ontologies provide a generic framework for describing humanities research data, allowing data from different projects to be combined, augmented, and reused.","title":"Introduction"},{"location":"02-dsp-ontologies/introduction/#resource-description-framework-rdf","text":"DSP-API uses a hierarchy of ontologies based on the Resource Description Framework ( RDF ), RDF Schema ( RDFS ), and the Web Ontology Language ( OWL ). Both RDFS and OWL are expressed in RDF. RDF expresses information as a set of statements (called triples ). A triple consists of a subject, a predicate, and an object: The object may be either a literal value (such as a name or number) or another subject. Thus it is possible to create complex graphs that connect many subjects, like this: In RDF, each subject and predicate has a unique, URL-like identifier called an Internationalized Resource Identifier ( IRI ). Within a given project, IRIs typically differ only in their last component (the \"local part\"), which is often the fragment following a # character. Such IRIs share a long \"prefix\". In Turtle and similar formats for writing RDF, a short prefix label can be defined to represent the long prefix. Then an IRI can be written as a prefix label and a local part, separated by a colon ( : ). For example, if the \"example\" project's long prefix is http://www.example.org/rdf# , and it contains subjects with IRIs like http://www.example.org/rdf#book , we can define the prefix label ex to represent the prefix label, and write prefixed names for IRIs:","title":"Resource Description Framework (RDF)"},{"location":"02-dsp-ontologies/introduction/#built-in-ontologies-and-user-created-ontologies","text":"To ensure the interoperability of data produced by different projects, each project must describe its data model by creating one or more ontologies that extend Knora's built-in ontologies. The main built-in ontology in Knora is knora-base .","title":"Built-in Ontologies and User-Created Ontologies"},{"location":"02-dsp-ontologies/introduction/#shared-ontologies","text":"Knora does not normally allow a project to use classes or properties defined in an ontology that belongs to another project. Each project must be free to change its own ontologies, but this is not possible if they have been used in ontologies or data created by other projects. However, an ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators will not change it in ways that could affect other ontologies or data that are based on it. Specifically, in a shared ontology, existing classes and properties cannot safely be changed, but new ones can be added. (It is not even safe to add an optional cardinality to an existing class, because this could cause subclasses to violate the rule that a class cannot have a cardinality on property P as well as a cardinality on a subproperty of P; see Restrictions on Classes .) A standardisation process for shared ontologies is planned (issue @github #523 ). For more details about shared ontologies, see Shared Ontology IRIs .","title":"Shared Ontologies"},{"location":"02-dsp-ontologies/knora-base/","text":"The Knora Base Ontology Overview The Knora base ontology is the main built-in Knora ontology. Each project that uses DSP-API must describe its data model by creating ontologies that extend this ontology. The Knora base ontology is identified by the IRI http://www.knora.org/ontology/knora-base . In the DSP-API documentation in general, it is identified by the prefix knora-base , but for brevity, in this document, we use kb or omit the prefix entirely. The Knora Data Model The Knora data model is based on the observation that, in the humanities, a value or literal is often itself structured and can be highly complex. Moreover, a value may have its own metadata, such as its creation date, information about permissions, and so on. Therefore, the Knora base ontology describes structured value types that can store this type of metadata. In the diagram below, a book ( ex:book2 ) has a title (identified by the predicate ex:title ) and a publication date ( ex:pubdate ), each of which has some metadata. Projects In Knora, each item of data belongs to some particular project. Each project using Knora must define a kb:knoraProject , which has these properties (cardinalities are indicated in parentheses after each property name): projectShortname (1): A short name that can be used to identify the project in configuration files and the like. projectLongname (0-1): The full name of the project. projectShortcode (1): A hexadecimal code that uniquely identifies the project. These codes are assigned to projects by the DaSCH . projectDescription (1-n): A description of the project. belongsToInstitution (0-1): The kb:Institution that the project belongs to. Ontologies and resources are associated with a project by means of the kb:attachedToProject property, as described in Ontologies and Properties of Resource ). Users are associated with a project by means of the kb:isInProject property, as described in Users and Groups . Ontologies Each user-created ontology must be defined as an owl:Ontology with the properties rdfs:label and kb:attachedToProject . Since DSP-API v20 kb:lastModificationDate property is also required. Resources All the content produced by a project (e.g. digitised primary source materials or research data) must be stored in objects that belong to subclasses of kb:Resource , so that Knora can query and update that content. Each project using the Knora base ontology must define its own OWL classes, derived from kb:Resource , to represent the types of data it deals with. A subclass of kb:Resource may additionally be a subclass of any other class, e.g. an industry-standard class such as foaf:Person ; this can facilitate searches across projects. Resources have properties that point to different parts of the content they contain. For example, a resource representing a book could have a property called hasAuthor , pointing to the author of the book. There are two possible kinds of content in a Knora resource: Knora values (see Values ) or links to other resources (see Links Between Resources ). Properties that point to Knora values must be subproperties of kb:hasValue , and properties that point to other resources must be subproperties of kb:hasLinkTo . Either of these two types of properties may also be a subproperty of any other property, e.g. an industry-standard property such as foaf:name ; this can facilitate searches across projects. Each property definition must specify the types that its subjects and objects must belong to (see Constraints on the Types of Property Subjects and Objects for details). Each user-created resource class definition must use OWL cardinality restrictions to specify the properties that resources of that class can have (see OWL Cardinalities for details). Resources are not versioned; only their values are versioned (see Values ). Every resource is required to have an rdfs:label . The object of this property is an xsd:string , rather than a Knora value; hence it is not versioned. A user who has modify permission on a resource (see Authorisation ) can change its label. A resource can be marked as deleted; Knora does this by adding the predicate kb:isDeleted true to the resource. An optional kb:deleteComment may be added to explain why the resource has been marked as deleted. Deleted resources are normally hidden. They cannot be undeleted, because even though resources are not versioned, it is necessary to be able to find out when a resource was deleted. If desired, a new resource can be created by copying data from a deleted resource. Properties of Resource creationDate (1): The time when the resource was created. attachedToUser (1): The user who owns the resource. attachedToProject (1): The project that the resource is part of. lastModificationDate (0-1): A timestamp indicating when the resource (or one of its values) was last modified. seqnum (0-1): The sequence number of the resource, if it is part of an ordered group of resources, such as the pages in a book. isDeleted (1): Indicates whether the resource has been deleted. deleteDate (0-1): If the resource has been deleted, indicates when it was deleted. deleteComment (0-1): If the resource has been deleted, indicates why it was deleted. Resources can have properties that point to other resources; see Links Between Resources . A resource grants permissions to groups of users; see Authorisation . Representations It is not practical to store all data in RDF. In particular, RDF is not a good storage medium for binary data such as images. Therefore, Knora stores such data outside the triplestore, in ordinary files. A resource can have metadata about a file attached to it. The technical term for such a resource in Knora is a Representation . For each file, there is a kb:FileValue in the triplestore containing metadata about the file (see FileValue ). Knora uses Sipi to store files. The Knora APIs provide ways to create file values using Knora and Sipi. A resource that has a file value must belong to one of the subclasses of kb:Representation . Its subclasses include: StillImageRepresentation : A representation containing a still image file. MovingImageRepresentation : A representation containing a video file. AudioRepresentation : A representation containing an audio file. DDDrepresentation : A representation containing a 3D image file. TextRepresentation : A representation containing a formatted text file, such as an XML file. DocumentRepresentation : A representation containing a document (such as a PDF file) that is not a text file. ArchiveRepresentation : A representation containing an archive file (such as a zip archive). These classes can be used directly in data, but it is often better to make subclasses of them, to include metadata about the files being stored. The base class of all these classes is Representation , which is not intended to be used directly. It has this property, which its subclasses override: hasFileValue (1): Points to a file value. There are two ways for a project to design classes for representations. The simpler way is to create a resource class that represents a thing in the world (such as ex:Painting ) and also belongs to a subclass of Representation . This is adequate if the class can have only one type of file attached to it. For example, if paintings are represented only by still images, ex:Painting could be a subclass of StillImageRepresentation . This is the only approach supported in DSP-API v1. The more flexible approach, which is supported by DSP-API v2, is for each ex:Painting to link (using kb:hasRepresentation or a subproperty) to other resources containing files that represent the painting. Each of these other resources can extend a different subclass of Representation . For example, a painting could have a StillImageRepresentation as well as a DDDrepresentation . Standard Resource Classes In general, each project using Knora must define its own subclasses of kb:Resource . However, the Knora base ontology provides some standard subclasses of kb:Resource , which are intended to be used by any project: Region : Represents a region of a Representation (see Representations ). Annotation : Represents an annotation of a resource. The hasComment property points to the text of the annotation, represented as a kb:TextValue . LinkObj : Represents a link that connects two or more resources. A LinkObj has a hasLinkTo property pointing to each resource that it connects, as well as a hasLinkToValue property pointing to a reification of each of these direct links ( see Links Between Resources ). A LinkObj is more complex (and hence less convenient and readable) than a simple direct link, but it has the advantage that it can be annotated using an Annotation . For improved readability, a project can make its own subclasses of LinkObj with specific meanings. Values The Knora base ontology defines a set of OWL classes that are derived from kb:Value and represent different types of structured values found in humanities data. This set of classes may not be extended by user-created ontologies. A value is always part of one particular resource, which points to it using some property derived from hasValue . For example, a user-created ontology could specify a Book class with a property hasSummary (derived from hasValue ), and that property could have a knora-base:objectClassConstraint of TextValue . This would mean that the summary of each book is represented as a TextValue . Knora values are versioned. Existing values are not modified. Instead, a new version of an existing value is created. The new version is linked to the old version via the previousValue property. Since each value version has a different IRI, there is no IRI that can be used to cite the value, such that it will always refer to the latest version of the value. Therefore, the latest version of each value has a separate UUID, as the object of the property valueHasUUID . When a new version of the value is created, this UUID is moved to the new version. This makes it possible to cite the latest version of a value by searching for the UUID. \"Deleting\" a value means marking it with kb:isDeleted . An optional kb:deleteComment may be added to explain why the value has been marked as deleted. Deleted values are normally hidden. Most types of values are marked as deleted without creating a new version of the value. However, link values must be treated as a special case. Before a LinkValue can be marked as deleted, its reference count must be decremented to 0. Therefore, a new version of the LinkValue is made, with a reference count of 0, and it is this new version that is marked as deleted. To simplify the enforcement of ontology constraints, and for consistency with resource updates, no new versions of a deleted value can be made; it is not possible to undelete. Instead, if desired, a new value can be created by copying data from a deleted value. Properties of Value valueCreationDate (1): The date and time when the value was created. attachedToUser (1): The user who owns the value. valueHasString (1): A human-readable string representation of the value's contents, which is available to Knora's full-text search index. valueHasOrder (0-1): A resource may have several properties of the same type with different values (which will be of the same class), and it may be necessary to indicate an order in which these values occur. For example, a book may have several authors which should appear in a defined order. Hence, valueHasOrder , when present, points to an integer literal indicating the order of a given value relative to the other values of the same property. These integers will not necessarily start at any particular number, and will not necessarily be consecutive. previousValue (0-1): The previous version of the value. valueHasUUID (0-1): The UUID that refers to all versions of the value. Only the latest version of the value has this property. isDeleted (1): Indicates whether the value has been deleted. deleteDate (0-1): If the value has been deleted, indicates when it was deleted. deleteComment (0-1): If the value has been deleted, indicates why it was deleted. Each Knora value can grant permissions (see Authorisation ). Subclasses of Value TextValue Represents text, possibly including markup. The text is the object of the valueHasString property. A line break is represented as a Unicode line feed character ( U+000A ). The non-printing Unicode character INFORMATION SEPARATOR TWO (U+001E) can be used to separate words that are separated only by standoff markup (see below), so they are recognised as separate in a full-text search index. Markup is stored using this property: valueHasStandoff (0-n): Points to a standoff markup tag. See Text with Standoff Markup . valueHasMapping (0-1): Points to the mapping used to create the standoff markup and to convert it back to the original XML. See Mapping to Create Standoff From XML . A text value can have a specified language: valueHasLanguage (0-1): An ISO 639-1 code as string specifying the language of the text. DateValue Humanities data includes many different types of dates. In Knora, a date has a specified calendar, and is always represented as a period with start and end points (which may be equal), each of which has a precision ( DAY , MONTH , or YEAR ). For GREGORIAN and JULIAN calendars, an optional ERA indicator term ( BCE , CE , or BC , AD ) can be added to the date, when no era is provided the default era AD will be considered. Internally, the start and end points are stored as two Julian Day Numbers. This calendar-independent representation makes it possible to compare and search for dates regardless of the calendar in which they were entered. Properties: valueHasCalendar (1): The name of the calendar in which the date should be displayed. Currently GREGORIAN , JULIAN , and ISLAMIC civil calendars are supported. valueHasStartJDN (1): The Julian Day Number of the start of the period (an xsd:integer ). valueHasStartPrecision (1): The precision of the start of the period. valueHasEndJDN (1): The Julian Day Number of the end of the period (an xsd:integer ). valueHasEndPrecision (1): The precision of the end of the period. TimeValue A Knora time value represents a precise moment in time in the Gregorian calendar. Since nanosecond precision can be included, it is suitable for use as a timestamp. Properties: valueHasTimeStamp (1): An xsd:dateTimeStamp , stored as an xsd:dateTime (because SPARQL does not support xsd:dateTimeStamp ). IntValue Represents an integer. Property: valueHasInteger (1): An xsd:integer . ColorValue valueHasColor (1): A string representing a color. The string encodes a color as hexadecimal RGB values, e.g. \\#FF0000 . DecimalValue Represents an arbitrary-precision decimal number. Property: valueHasDecimal (1): An xsd:decimal . UriValue Represents a non-Knora URI. Property: valueHasUri (1): An xsd:anyURI . BooleanValue Represents a boolean value. Property: valueHasBoolean (1): An xsd:boolean . GeomValue Represents a geometrical object as a JSON string, using normalized coordinates. Property: valueHasGeometry (1): A JSON string. GeonameValue Represents a geolocation, using the identifiers found at GeoNames . Property: valueHasGeonameCode (1): The identifier of a geographical feature from GeoNames , represented as an xsd:string . IntervalValue Represents a time interval, with precise start and end times on a timeline, e.g. relative to the beginning of an audio or video file. Properties: valueHasIntervalStart (1): An xsd:decimal representing the start of the interval in seconds. valueHasIntervalEnd (1): An xsd:decimal representing the end of the interval in seconds. ListValue Projects often need to define lists or hierarchies of categories that can be assigned to many different resources. Then, for example, a user interface can provide a drop-down menu to allow the user to assign a category to a resource. The ListValue class provides a way to represent these sorts of data structures. It can represent either a flat list or a tree. A ListValue has this property: valueHasListNode (1): Points to a ListNode . Each ListNode can have the following properties: isRootNode (0-1): Set to true if this is the root node. hasSubListNode (0-n): Points to the node's child nodes, if any. hasRootNode (0-1): Points to the root node of the list (absent if isRootNode is true ). listNodePosition (0-1): An integer indicating the node's position in the list of its siblings (absent if isRootNode is true ). listNodeName (0-1): The node's human-readable name (absent if isRootNode is true ). FileValue Knora stores certain kinds of data outside the triplestore, in files (see Representations ). Each digital object that is stored outside the triplestore has associated metadata, which is stored in the triplestore in a kb:FileValue . The base class FileValue , which is not intended to be used directly, has these properties: internalFilename (1): The name of the file as stored by Knora. internalMimeType (1): The MIME type of the file as stored by Knora. originalFilename (0-1): The original name of the file when it was uploaded to the DSP-API server. originalMimeType (0-1): The original MIME type of the file when it was uploaded to the Knora API server. isPreview (0-1): A boolean indicating whether the file is a preview, i.e. a small image representing the contents of the file. A preview is always a StillImageFileValue , regardless of the type of the enclosing Representation . The subclasses of FileValue , which are intended to be used directly in data, include: StillImageFileValue : Contains metadata about a still image file. MovingImageFileValue : Contains metadata about a video file. AudioFileValue : Contains metadata about an audio file. DDDFileValue : Contains metadata about a 3D image file. TextFileValue : Contains metadata about a text file. DocumentFileValue : Contains metadata about a document (such as PDF) that is not a text file. ArchiveFileValue : Contains metadata about an archive (such as zio archive). Each of these classes contains properties that are specific to the type of file it describes. For example, still image files have dimensions, video files have frame rates, and so on. FileValue objects are versioned like other values, and the actual files stored by Knora are also versioned. Version 1 of the DSP-API does not provide a way to retrieve a previous version of a file, but this feature will be added in a subsequent version of the API. LinkValue A LinkValue is an RDF \"reification\" containing metadata about a link between two resources. It is therefore a subclass of rdf:Statement as well as of Value . It has these properties: rdf:subject (1) : The resource that is the source of the link. rdf:predicate (1) : The link property. rdf:object (1) : The resource that is the target of the link. valueHasRefCount (1) : The reference count of the link. This is meaningful when the LinkValue describes resource references in Standoff text markup (see StandoffLinkTag ). Otherwise, the reference count will always be 1 (if the link exists) or 0 (if it has been deleted). For details about how links are created in Knora, see Links Between Resources . ExternalResValue Represents a resource that is not stored in the RDF triplestore managed by Knora, but instead resides in an external repository managed by some other software. The ExternalResValue contains the information that Knora needs in order to access the resource, assuming that a suitable gateway plugin is installed. extResAccessInfo (1) : The location of the repository containing the external resource (e.g. its URL). extResId (1) : The repository-specific ID of the external resource. extResProvider (1) : The name of the external provider of the resource. Links Between Resources A link between two resources is expressed, first of all, as a triple, in which the subject is the resource that is the source of the link, the predicate is a \"link property\" (a subproperty of kb:hasLinkTo ), and the object is the resource that is the target of the link. It is also useful to store metadata about links. For example, Knora needs to know who owns the link, who has permission to modify it, when it was created, and so on. Such metadata cannot simply describe the link property, because then it would refer to that property in general, not to any particular instance in which that property is used to connect two particular resources. To attach metadata to a specific link in RDF, it is necessary to create an RDF \"reification\". A reification makes statements about a particular triple (subject, predicate, object), in this case the triple that expresses the link between the resources. Knora uses reifications of type kb:LinkValue (described in LinkValue to store metadata about links. For example, suppose a project describes paintings that belong to collections. The project can define an ontology as follows (expressed here in Turtle format, and simplified for the purposes of illustration): @prefix kb <http://www.knora.org/ontology/knora-base#> . @prefix : <http://www.knora.org/ontology/paintings#> . :Painting rdf:type owl:Class ; rdfs:subClassOf kb:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasArtist ; owl:cardinality 1 ] , [ rdf:type owl:Restriction ; owl:onProperty :hasTitle ; owl:cardinality 1 ] ; [ rdf:type owl:Restriction ; owl:onProperty :isInCollection ; owl:minCardinality 1 ] ; [ rdf:type owl:Restriction ; owl:onProperty :isInCollectionValue ; owl:minCardinality 1 ] . :Collection rdf:type owl:Class ; rdfs:subClassOf kb:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasCollectionName ; owl:cardinality 1 ] . :hasArtist rdf:type owl:ObjectProperty ; rdfs:label \"Name of artist\" ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:TextValue . :hasTitle rdf:type owl:ObjectProperty ; rdfs:label \"Title of painting\" kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:TextValue . :hasCollectionName rdf:type owl:ObjectProperty ; rdfs:label \"Name of collection\" ; kb:subjectClassConstraint :Collection ; kb:objectClassConstraint kb:TextValue . To link the paintings to the collection, we must add a \"link property\" to the ontology. In this case, the link property will point from a painting to the collection it belongs to. Every link property must be a subproperty of kb:hasLinkTo . :isInCollection rdf:type owl:ObjectProperty ; rdfs:subPropertyOf kb:hasLinkTo ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint :Collection . We must then add a \"link value property\", which will point from a painting to a kb:LinkValue (described in LinkValue ), which will contain metadata about the link between the property and the collection. In particular, the link value specifies the creator of the link, the date when it was created, and the permissions that determine who can view or modify it. The name of the link value property is constructed using a simple naming convention: the word Value is appended to the name of the link property. In this case, since our link property is called :isInCollection , the link value property must be called :isInCollectionValue . Every link value property must be a subproperty of kb:hasLinkToValue . :isInCollectionValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf kb:hasLinkToValue ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:LinkValue . Given this ontology, we can create some RDF data describing a painting and a collection: @prefix paintings <http://www.knora.org/ontology/paintings#> . @prefix data <http://www.knora.org/ontology/paintings/data#> . data:dali_4587 rdf:type paintings:Painting ; paintings:hasTitle data:value_A ; paintings:hasArtist data:value_B . data:value_A rdf:type kb:TextValue ; kb:valueHasString \"The Persistence of Memory\" . data:value_B rdf:type kb:TextValue ; kb:valueHasString \"Salvador Dali\" . data:pompidou rdf:type paintings:Collection ; paintings:hasCollectionName data:value_C . data:value_C rdf:type kb:TextValue ; kb:valueHasString \"Centre Pompidou, Paris\" . We can then state that the painting is in the collection: data:dali_4587 paintings:isInCollection data:pompidou ; paintings:isinCollectionValue data:value_D . data:value_D rdf:type kb:LinkValue ; rdf:subject data:dali_4587 ; rdf:predicate paintings:isInCollection ; rdf:object data:pompidou ; kb:valueHasRefCount 1 . This creates a link ( paintings:isInCollection ) between the painting and the collection, along with a reification containing metadata about the link. We can visualise the result as the following graph: Knora allows a user to see a link if the requesting user has permission to see the source and target resources as well as the kb:LinkValue . Part-Whole-Relations between Resources isPartOf A special case of linked resources are part-of related resources , i.e. a resource consisting of several other resources. In order to create a part-of relation between two resources, the resource that is part of another resource needs to have a property that is either kb:isPartOf or a subproperty thereof. kb:isPartOf itself is a subproperty of kb:hasLinkTo . Same as described above for link properties, a corresponding part-of value property is created automatically. This value property has the same name as the part-of property with Value appended. For example, if in an ontology data a property data:partOf was defined, the corresponding value property would be named data:partOfValue . This newly created property data:partOfValue is defined as a subproperty of kb:isPartOfValue . Part-of relations are recommended for resources of type kb:StillImageRepresentation . In that case, the resource that is part of another resource needs to have a property kb:seqnum or a subproperty thereof, with an integer as value. A client can then use this information to leaf through the parts of the compound resource (p.ex. to leaf through the pages of a book like in this example). isSequenceOf Similar to kb:isPartOf for kb:StillImageRepresentations , part-whole-relations can be defined for resources that have a time dimension by using kb:isSequenceOf . You can use it for video or audio resources that are subtypes of kb:MovingImageRepresentation and kb:AudioRepresentation . kb:isSequenceOf is intended to be used in combination with the property kb:hasSequenceBounds which points to a kb:IntervalValue . This defines the start and end point of the subseqence in relation to the entire audio/video resource as an interval . When the properties are used in this combination, a dedicated behavior in the frontend allows to display the sequences alongside the main resource. There is an important difference between kb:isSequenceOf and kb:isPartOf : For kb:isPartOf , each part is a kb:StillImageRepresentation and the whole consists of multiple such parts. In kb:isSequenceOf on the other hand, the whole is one kb:MovingImageRepresentation or kb:AudioRepresentation . The parts only define which sub-sequence of this representation they are. Text with Standoff Markup DSP-API is designed to be able to store text with markup, which can indicate formatting and structure, as well as the complex observations involved in transcribing handwritten manuscripts. One popular way of representing text in the humanities is to encode it in XML using the Text Encoding Initiative ( TEI ) guidelines. In DSP-API, a TEI/XML document can be stored as a file with attached metadata, but this is not recommended, because it does not allow to perform searches across multiple documents. The recommended way to store text with markup in DSP-API is to use the built-in support for \"standoff\" markup, which is stored separately from the text. This has some advantages over embedded markup such as XML. While XML requires markup to have a hierarchical structure, and does not allow overlapping tags, standoff nodes do not have these limitations (see Using Standoff Properties for Marking-up Historical Documents in the Humanities ). A standoff tag can be attached to any substring in the text by giving its start and end positions. Unlike in corpus linguistics, we do not use any tokenisation resulting in a form of predefined segmentation, which would limit the user's ability to freely annotate any ranges in the text. For example, suppose we have the following text: This sentence has overlapping visual attributes. This would require just two standoff tags: (italic, start=5, end=29) and (bold, start=14, end=36) . Moreover, standoff makes it possible to mark up the same text in different, possibly incompatible ways, allowing for different interpretations without making redundant copies of the text. In the Knora base ontology, any text value can have standoff tags. By representing standoff as RDF triples, DSP-API makes markup searchable across multiple text documents in a repository. For example, if a repository contains documents in which references to persons are indicated in standoff, it is straightforward to find all the documents mentioning a particular person. DSP-API's standoff support is intended to make it possible to convert documents with embedded, hierarchical markup, such as TEI/XML, into RDF standoff and back again, with no data loss, thus bringing the benefits of RDF to existing TEI-encoded documents. In the Knora base ontology, a TextValue can have one or more standoff tags. Each standoff tag indicates the start and end positions of a substring in the text that has a particular attribute. The OWL class kb:StandoffTag , which is the base class of all standoff node classes, has these properties: standoffTagHasStart (1): The index of the first character in the text that has the attribute. standoffTagHasEnd (1): The index of the last character in the text that has the attribute, plus 1. standoffTagHasUUID (1): A UUID identifying this instance and those corresponding to it in later versions of the TextValue it belongs to. The UUID is a means to maintain a reference to a particular range of a text also when new versions are made and standoff tag IRIs change. standoffTagHasOriginalXMLID (0-1): The original ID of the XML element that the standoff tag represents, if any. standoffTagHasStartIndex (1): The start index of the standoff tag. Start indexes are numbered from 0 within the context of a particular text. When several standoff tags share the same start position, they can be nested correctly with this information when transforming them to XML. standoffTagHasEndIndex (1): The end index of the standoff tag. Start indexes are numbered from 0 within the context of a particular text. When several standoff tags share the same end position, they can be nested correctly with this information when transforming them to XML. standoffTagHasStartParent (0-1): Points to the parent standoff tag. This corresponds to the original nesting of tags in XML. If a standoff tag has no parent, it represents the XML root element. If the original XML element is a CLIX tag, it represents the start of a virtual (non syntactical) hierarchy. standoffTagHasEndParent (0-1): Points to the parent standoff tag if the original XML element is a CLIX tag and represents the end of a virtual (non syntactical) hierarchy. The StandoffTag class is not used directly in RDF data; instead, its subclasses are used. A few subclasses are currently provided in standoff-onto.ttl , and more will be added to support TEI semantics. Projects are able to define their own custom standoff tag classes (direct subclasses of StandoffTag or one of the standoff data type classes or subclasses of one of the standoff classes defined in standoff-onto.ttl ). Subclasses of StandoffTag Standoff Data Type Tags Associates data in some Knora value type with a substring in a text. Standoff data type tags are subclasses of ValueBase classes. StandoffLinkTag Indicates that a substring refers to another kb:Resource . See StandoffLinkTag . StandoffInternalReferenceTag Indicates that a substring refers to another standoff tag in the same text value. See Internal Links in a TextValue . StandoffUriTag Indicates that a substring is associated with a URI, which is stored in the same form that is used for kb:UriValue . See UriValue . StandoffDateTag Indicates that a substring represents a date, which is stored in the same form that is used for kb:DateValue . See DateValue . StandoffColorTag Indicates that a substring represents a color, which is stored in the same form that is used for kb:ColorValue . See ColorValue . StandoffIntegerTag Indicates that a substring represents an integer, which is stored in the same form that is used for kb:IntegerValue . See IntValue . StandoffDecimalTag Indicates that a substring represents a number with fractions, which is stored in the same form that is used for kb:DecimalValue . See DecimalValue . StandoffIntervalTag Indicates that a substring represents an interval, which is stored in the same form that is used for kb:IntervalValue . See IntervalValue . StandoffBooleanTag Indicates that a substring represents a Boolean, which is stored in the same form that is used for kb:BooleanValue . See BooleanValue . StandoffTimeTag Indicates that a substring represents a timestamp, which is stored in the same form that is used for kb:TimeValue . See TimeValue . StandoffLinkTag A StandoffLinkTag Indicates that a substring is associated with a Knora resource. For example, if a repository contains resources representing persons, a text could be marked up so that each time a person's name is mentioned, a StandoffLinkTag connects the name to the Knora resource describing that person. It has the following property: standoffTagHasLink (1): The IRI of the resource that is referred to. One of the design goals of the Knora base ontology is to make it easy and efficient to find out which resources contain references to a given resource. Direct links are easier and more efficient to query than indirect links. Therefore, when a text value contains a resource reference in its standoff nodes, Knora automatically creates a direct link between the containing resource and the target resource, along with an RDF reification (a kb:LinkValue ) describing the link, as discussed in Links Between Resources . In this case, the link property is always kb:hasStandoffLinkTo , and the link value property (which points to the LinkValue ) is always kb:hasStandoffLinkToValue . DSP-API automatically updates direct links and reifications for standoff resource references when text values are updated. To do this, it keeps track of the number of text values in each resource that contain at least one standoff reference to a given target resource. It stores this number as the reference count of the LinkValue (see LinkValue ) describing the direct link. Each time this number changes, it makes a new version of the LinkValue , with an updated reference count. When the reference count reaches zero, it removes the direct link and makes a new version of the LinkValue , marked with kb:isDeleted . For example, if data:R1 is a resource with a text value in which the resource data:R2 is referenced, the repository could contain the following triples: data:R1 ex:hasComment data:V1 . data:V1 rdf:type kb:TextValue ; kb:valueHasString \"This link is internal.\" ; kb:valueHasStandoff data:SO1 . data:SO1 rdf:type kb:StandoffLinkTag ; kb:standoffTagHasStart: 5 ; kb:standoffTagHasEnd: 9 ; kb:standoffTagHasLink data:R2 . data:R1 kb:hasStandoffLinkTo data:R2 . data:R1 kb:hasStandoffLinkToValue data:LV1 . data:LV1 rdf:type kb:LinkValue ; rdf:subject data:R1 ; rdf:predicate kb:hasStandoffLinkTo ; rdf:object data:R2 ; kb:valueHasRefCount 1 . The result can be visualized like this: Link values created automatically for resource references in standoff are visible to all users, and the creator of these link values is always kb:SystemUser (see Users and Groups ). The DSP-API server allows a user to see a standoff link if the user has permission to see the source and target resources. Internal Links in a TextValue Internal links in a TextValue can be represented using the data type standoff class StandoffInternalReferenceTag or a subclass of it. It has the following property: standoffTagHasInternalReference (1): Points to a StandoffTag that belongs to the same TextValue . It has an objectClassConstraint of StandoffTag . For links to a kb:Resource , see StandoffLinkTag . Mapping to Create Standoff From XML A mapping allows for the conversion of an XML document to RDF-standoff and back. A mapping defines one-to-one relations between XML elements (with or without a class) and attributes and standoff classes and properties (see XML to Standoff Mapping ). A mapping is represented by a kb:XMLToStandoffMapping which contains one or more kb:MappingElement . A kb:MappingElement maps an XML element (including attributes) to a standoff class and standoff properties. It has the following properties: mappingHasXMLTagname (1): The name of the XML element that is mapped to a standoff class. mappingHasXMLNamespace (1): The XML namespace of the XML element that is mapped to a standoff class. If no namespace is given, noNamespace is used. mappingHasXMLClass (1): The name of the class of the XML element. If it has no class, noClass is used. mappingHasStandoffClass (1): The standoff class the XML element is mapped to. mappingHasXMLAttribute (0-n): Maps XML attributes to standoff properties using MappingXMLAttribute . See below. mappingHasStandoffDataTypeClass (0-1): Indicates the standoff data type class of the standoff class the XML element is mapped to. mappingElementRequiresSeparator (1): Indicates if there should be an invisible word separator inserted after the XML element in the RDF-standoff representation. Once the markup is stripped, text segments that belonged to different elements may be concatenated. A MappingXMLAttribute has the following properties: - mappingHasXMLAttributename : The name of the XML attribute that is mapped to a standoff property. - mappingHasXMLNamespace : The namespace of the XML attribute that is mapped to a standoff property. If no namespace is given, noNamespace is used. - mappingHasStandoffProperty : The standoff property the XML attribute is mapped to. DSP-API includes a standard mapping used by the DSP APP. It has the IRI http://rdfh.ch/standoff/mappings/StandardMapping and defines mappings for a few elements used to write texts with simple markup. Standoff in Digital Editions DSP-API's standoff is designed to make it possible to convert XML documents to standoff and back. One application for this feature is an editing workflow in which an editor works in an XML editor, and the resulting XML documents are converted to standoff and stored in the DSP, where they can be searched and annotated. If an editor wants to correct text that has been imported from XML into standoff, the text can be exported as XML, edited, and imported again. To preserve annotations on standoff tags across edits, each tag can automatically be given a UUID. In a future version of the Knora base ontology, it may be possible to create annotations that point to UUIDs rather than to IRIs. When a text is exported to XML, the UUIDs can be included in the XML. When the edited XML is imported again, it can be converted to new standoff tags with the same UUIDs. Annotations that applied to standoff tags in the previous version of the text will therefore also apply to equivalent tags in the new version. When text is converted from XML into standoff, tags are also given indexes, which are numbered from 0 within the context of a particular text. This makes it possible to order tags that share the same position, and to preserve the hierarchy of the original XML document. An ordinary, hierarchical XML tag is converted to a standoff tag that has one index, as well as the index of its parent tag, if any. The Knora base ontology also supports non-hierarchical markup such as CLIX , which enables overlapping markup to be represented in XML. When non-hierarchical markup is converted to standoff, both the start position and the end position of the standoff tag have indexes and parent indexes. To support these features, a standoff tag can have these additional properties: - standoffTagHasStartIndex (0-1): The index of the start position. - standoffTagHasEndIndex (0-1): The index of the end position, if this is a non-hierarchical tag. - standoffTagHasStartParent (0-1): The IRI of the tag, if any, that contains the start position. - standoffTagHasEndParent (0-1): The IRI of the tag, if any, that contains the end position, if this is a non-hierarchical tag. - standoffTagHasUUID (0-1): A UUID that can be used to annotate a standoff tag that may be present in different versions of a text, or in different layers of a text (such as a diplomatic transcription and an edited critical text). Querying Standoff in SPARQL A future version of DSP-API may provide an API for querying standoff markup. In the meantime, it is possible to query it directly in SPARQL. For example, here is a SPARQL query (using RDFS inference) that finds all the text values that have a standoff date tag referring to Christmas Eve 2016, contained in a StandoffItalicTag : PREFIX knora-base: <http://www.knora.org/ontology/knora-base#> PREFIX standoff: <http://www.knora.org/ontology/standoff#> select * where { ?standoffTag a knora-base:StandoffDateTag . ?standoffTag knora-base:valueHasStartJDN ?dateStart . ?standoffTag knora-base:valueHasEndJDN ?dateEnd . FILTER (2457747 <= ?dateEnd && 2457747 >= ?dateStart) ?standoffTag knora-base:standoffTagHasStartParent ?parent . ?parent a standoff:StandoffItalicTag . ?textValue knora-base:valueHasStandoff ?standoffTag . ?textValue knora-base:valueHasString ?string . ?standoffTag knora-base:standoffTagHasStart ?startPos . ?standoffTag knora-base:standoffTagHasEnd ?endPos . } Authorisation Users and Groups Each Knora user is represented by an object belonging to the class kb:User , which is a subclass of foaf:Person , and has the following properties: userid (1) : A unique identifier that the user must provide when logging in. password (1) : A cryptographic hash of the user's password. email (0-n) : Email addresses belonging to the user. isInProject (0-n) : Projects that the user is a member of. isInGroup (0-n) : user-created groups that the user is a member of. foaf:familyName (1) : The user's family name. foaf:givenName (1) : The user's given name. Knora's concept of access control is that an object (a resource or value) can grant permissions to groups of users (but not to individual users). There are several built-in groups: knora-admin:UnknownUser : Any user who has not logged into Knora is automatically assigned to this group. knora-admin:KnownUser : Any user who has logged into Knora is automatically assigned to this group. knora-admin:ProjectMember : When checking a user's permissions on an object, the user is automatically assigned to this group if she is a member of the project that the object belongs to. knora-admin:Creator : When checking a user's permissions on an object, the user is automatically assigned to this group if he is the creator of the object. knora-admin:ProjectAdmin : When checking a user's permissions on an object, the user is automatically assigned to this group if she is an administrator of the project that the object belongs to. knora-admin:SystemAdmin : The group of Knora system administrators. A user-created ontology can define additional groups, which must belong to the OWL class knora-admin:UserGroup . There is one built-in knora-admin:SystemUser , which is the creator of link values created automatically for resource references in standoff markup (see StandoffLinkTag ). Permissions Each resource or value can grant certain permissions to specified user groups. These permissions are represented as the object of the predicate kb:hasPermissions , which is required on every kb:Resource and on the current version of every kb:Value . The permissions attached to the current version of a value also apply to previous versions of the value. Value versions other than the current one do not have this predicate. The following permissions can be granted: Restricted view permission (RV) Allows a restricted view of the object, e.g. a view of an image with a watermark. View permission (V) Allows an unrestricted view of the object. Having view permission on a resource only affects the user's ability to view information about the resource other than its values. To view a value, she must have view permission on the value itself. Modify permission (M) For values, this permission allows a new version of a value to be created. For resources, this allows the user to create a new value (as opposed to a new version of an existing value), or to change information about the resource other than its values. When he wants to make a new version of a value, his permissions on the containing resource are not relevant. However, when he wants to change the target of a link, the old link must be deleted and a new one created, so he needs modify permission on the resource. Delete permission (D) Allows the item to be marked as deleted. Change rights permission (CR) Allows the permissions granted by the object to be changed. Each permission in the above list implies all lower-numbered permissions. A user's permission level on a particular object is calculated in the following way: Make a list of the groups that the user belongs to, including Creator and/or ProjectMember if applicable. Make a list of the permissions that she can obtain on the object, by iterating over the permissions that the object grants. For each permission, if she is in the specified group, add the specified permission to the list of permissions she can obtain. From the resulting list, select the highest-level permission. If the result is that she would have no permissions, give her whatever permission UnknownUser would have. To view a link between resources, a user needs permission to view the source and target resources. He also needs permission to view the LinkValue representing the link, unless the link property is hasStandoffLinkTo (see StandoffLinkTag ). The format of the object of kb:hasPermissions is as follows: Each permission is represented by the one-letter or two-letter abbreviation given above. Each permission abbreviation is followed by a space, then a comma-separated list of groups that the permission is granted to. The IRIs of built-in groups are shortened using the knora-admin prefix. Multiple permissions are separated by a vertical bar ( | ). For example, if an object grants view permission to unknown and known users, and modify permission to project members, the resulting permission literal would be: V knora-admin:UnknownUser,knora-admin:KnownUser|M knora-admin:ProjectMember Consistency Checking Knora tries to enforce repository consistency by checking constraints that are specified in the Knora base ontology and in user-created ontologies. Three types of consistency rules are enforced: Cardinalities in OWL class definitions must be satisfied. Constraints on the types of the subjects and objects of OWL object properties must be satisfied. A datatype property may not have an empty string as an object. OWL Cardinalities As noted in Resources , each subclass of Resource must use OWL cardinality restrictions to specify the properties it can have. More specifically, a resource is allowed to have a property that is a subproperty of kb:hasValue or kb:hasLinkTo only if the resource's class has some cardinality for that property. Similarly, a value is allowed to have a subproperty of kb:valueHas only if the value's class has some cardinality for that property. Knora supports, and attempts to enforce, the following cardinality constraints: owl:cardinality 1 : A resource of this class must have exactly one instance of the specified property. owl:minCardinality 1 : A resource of this class must have at least one instance of the specified property. owl:maxCardinality 1 : A resource of this class may have zero or one instance of the specified property. owl:minCardinality 0 : A resource of this class may have zero or more instances of the specified property. Knora requires cardinalities to be defined using blank nodes, as in the following example from knora-base : :Representation rdf:type owl:Class ; rdfs:subClassOf :Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] . :StillImageRepresentation rdf:type owl:Class ; rdfs:subClassOf :Representation , [ rdf:type owl:Restriction ; owl:onProperty :hasStillImageFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] . The cardinality of a link property must be the same as the cardinality of the corresponding link value property. Each owl:Restriction may have the predicate salsah-gui:guiOrder to indicate the order in which properties should be displayed in a GUI (see The SALSAH GUI Ontology ). A resource class inherits cardinalities from its superclasses. This follows from the rules of RDFS inference. Also, in Knora, cardinalities in the subclass can override cardinalities that would otherwise be inherited from the superclass. Specifically, if a superclass has a cardinality on a property P, and a subclass has a cardinality on a subproperty of P, the subclass's cardinality overrides the superclass's cardinality. In the example above, hasStillImageFileValue is a subproperty of hasFileValue . Therefore, the cardinality on hasStillImageFileValue overrides (i.e. replaces) the one on hasFileValue . Note that, unlike cardinalities, predicates of properties are not inherited. If :foo rdfs:subPropertyOf :bar , this does not mean that :foo inherits anything from :bar . Any predicates of :foo that are also needed by :bar must be defined explicitly on :bar . This design decision was made because property predicate inheritance is not provided by RDFS inference, and would make it more difficult to check the correctness of ontologies, while providing little practical benefit. For more information about OWL cardinalities, see the OWL 2 Primer . Constraints on the Types of Property Subjects and Objects When a user-created ontology defines a property, it must indicate the types that are allowed as objects (and, if possible, as subjects) of the property. This is done using the following Knora-specific properties: subjectClassConstraint : Specifies the class that subjects of the property must belong to. This constraint is recommended but not required. Knora will attempt to enforce this constraint. objectClassConstraint : If the property is an object property, specifies the class that objects of the property must belong to. Every subproperty of kb:hasValue or a kb:hasLinkTo (i.e. every property of a resource that points to a kb:Value or to another resource) is required to have this constraint, because Knora relies on it to know what type of object to expect for the property. Knora will attempt to enforce this constraint. objectDatatypeConstraint : If the property is a datatype property, specifies the type of literals that can be objects of the property. Knora will not attempt to enforce this constraint, but it is useful for documentation purposes. Note that it is possible for a subproperty to have a more restrictive contraint than its base property, by specifing a subject or object class that is a subclass of the one specified in the base property. However, it is not possible for the subproperty to make the base property's constraint less restrictive. See also Why doesn\u2019t Knora use rdfs:domain and rdfs:range for consistency checking? Consistency Constraint Example A user-created ontology could define consistency constraints as in this simplified example: :book rdf:type owl:Class ; rdfs:subClassOf knora-base:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasTitle ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasAuthor ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ] . :hasTitle rdf:type owl:ObjectProperty ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue . :hasAuthor rdf:type owl:ObjectProperty ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue . Summary of Restrictions on User-Created Ontologies An ontology can refer to a Knora ontology in another project only if the other ontology is built-in or shared (see Shared Ontologies ). Restrictions on Classes Each class must be a subclass of either kb:Resource or kb:StandoffTag , but not both (note that this forbids user-created subclasses of kb:Value ). All the cardinalities that a class defines directly (i.e. does not inherit from kb:Resource ) must be on properties that are defined in the triplestore. Within the cardinalities of a class, there must be a link value property for each link property and vice versa. The cardinality of a link property must be the same as the cardinality of the corresponding link value property. A cardinality on a property with a boolean value must be owl:cardinality 1 or owl:maxCardinality 1 . Each class must be a subclass of all the classes that are subject class constraints of the properties in its cardinalities. If it's a resource class, all its directly defined cardinalities must be on Knora resource properties (subproperties of kb:hasValue or kb:hasLinkTo ), and all its base classes with Knora IRIs must also be resource classes. A cardinality on kb:resourceProperty or kb:hasValue is forbidden. It must also have an rdfs:label . If it's a standoff class, none of its cardinalities may be on Knora resource properties, and all its base classes with Knora IRIs must also be standoff classes. A class cannot have a cardinality on property P as well as a cardinality on a subproperty of P. Restrictions on properties The property's subject class constraint, if provided, must be a subclass of kb:Resource or kb:StandoffTag , and must be a subclass of the subject class constraints of all its base properties. Its object class constraint, if provided, must be a subclass of the object class constraints of all its base properties. If the property is a Knora resource property, it must have an object class constraint and an rdfs:label . It can't be a subproperty of both kb:hasValue and kb:hasLinkTo . It can't be a subproperty of kb:hasFileValue . Each of its base properties that has a Knora IRI must also be a Knora resource property. Standardisation The DaSCH intends to coordinate the standardisation of generally useful entities proposed in user-created ontologies. We envisage a process in which two or more projects would initiate the process by starting a public discussion on proposed entities to be shared. Once a consensus was reached, the DaSCH would publish these entities in a shared ontology ). Knora Ontology Versions The Knora base ontology has the property kb:ontologyVersion , whose object is a string that indicates the deployed version of all the Knora built-in ontologies. This allows the repository update program to determine which repository updates are needed when Knora is upgraded.","title":"The Knora Base Ontology"},{"location":"02-dsp-ontologies/knora-base/#the-knora-base-ontology","text":"","title":"The Knora Base Ontology"},{"location":"02-dsp-ontologies/knora-base/#overview","text":"The Knora base ontology is the main built-in Knora ontology. Each project that uses DSP-API must describe its data model by creating ontologies that extend this ontology. The Knora base ontology is identified by the IRI http://www.knora.org/ontology/knora-base . In the DSP-API documentation in general, it is identified by the prefix knora-base , but for brevity, in this document, we use kb or omit the prefix entirely.","title":"Overview"},{"location":"02-dsp-ontologies/knora-base/#the-knora-data-model","text":"The Knora data model is based on the observation that, in the humanities, a value or literal is often itself structured and can be highly complex. Moreover, a value may have its own metadata, such as its creation date, information about permissions, and so on. Therefore, the Knora base ontology describes structured value types that can store this type of metadata. In the diagram below, a book ( ex:book2 ) has a title (identified by the predicate ex:title ) and a publication date ( ex:pubdate ), each of which has some metadata.","title":"The Knora Data Model"},{"location":"02-dsp-ontologies/knora-base/#projects","text":"In Knora, each item of data belongs to some particular project. Each project using Knora must define a kb:knoraProject , which has these properties (cardinalities are indicated in parentheses after each property name): projectShortname (1): A short name that can be used to identify the project in configuration files and the like. projectLongname (0-1): The full name of the project. projectShortcode (1): A hexadecimal code that uniquely identifies the project. These codes are assigned to projects by the DaSCH . projectDescription (1-n): A description of the project. belongsToInstitution (0-1): The kb:Institution that the project belongs to. Ontologies and resources are associated with a project by means of the kb:attachedToProject property, as described in Ontologies and Properties of Resource ). Users are associated with a project by means of the kb:isInProject property, as described in Users and Groups .","title":"Projects"},{"location":"02-dsp-ontologies/knora-base/#ontologies","text":"Each user-created ontology must be defined as an owl:Ontology with the properties rdfs:label and kb:attachedToProject . Since DSP-API v20 kb:lastModificationDate property is also required.","title":"Ontologies"},{"location":"02-dsp-ontologies/knora-base/#resources","text":"All the content produced by a project (e.g. digitised primary source materials or research data) must be stored in objects that belong to subclasses of kb:Resource , so that Knora can query and update that content. Each project using the Knora base ontology must define its own OWL classes, derived from kb:Resource , to represent the types of data it deals with. A subclass of kb:Resource may additionally be a subclass of any other class, e.g. an industry-standard class such as foaf:Person ; this can facilitate searches across projects. Resources have properties that point to different parts of the content they contain. For example, a resource representing a book could have a property called hasAuthor , pointing to the author of the book. There are two possible kinds of content in a Knora resource: Knora values (see Values ) or links to other resources (see Links Between Resources ). Properties that point to Knora values must be subproperties of kb:hasValue , and properties that point to other resources must be subproperties of kb:hasLinkTo . Either of these two types of properties may also be a subproperty of any other property, e.g. an industry-standard property such as foaf:name ; this can facilitate searches across projects. Each property definition must specify the types that its subjects and objects must belong to (see Constraints on the Types of Property Subjects and Objects for details). Each user-created resource class definition must use OWL cardinality restrictions to specify the properties that resources of that class can have (see OWL Cardinalities for details). Resources are not versioned; only their values are versioned (see Values ). Every resource is required to have an rdfs:label . The object of this property is an xsd:string , rather than a Knora value; hence it is not versioned. A user who has modify permission on a resource (see Authorisation ) can change its label. A resource can be marked as deleted; Knora does this by adding the predicate kb:isDeleted true to the resource. An optional kb:deleteComment may be added to explain why the resource has been marked as deleted. Deleted resources are normally hidden. They cannot be undeleted, because even though resources are not versioned, it is necessary to be able to find out when a resource was deleted. If desired, a new resource can be created by copying data from a deleted resource.","title":"Resources"},{"location":"02-dsp-ontologies/knora-base/#properties-of-resource","text":"creationDate (1): The time when the resource was created. attachedToUser (1): The user who owns the resource. attachedToProject (1): The project that the resource is part of. lastModificationDate (0-1): A timestamp indicating when the resource (or one of its values) was last modified. seqnum (0-1): The sequence number of the resource, if it is part of an ordered group of resources, such as the pages in a book. isDeleted (1): Indicates whether the resource has been deleted. deleteDate (0-1): If the resource has been deleted, indicates when it was deleted. deleteComment (0-1): If the resource has been deleted, indicates why it was deleted. Resources can have properties that point to other resources; see Links Between Resources . A resource grants permissions to groups of users; see Authorisation .","title":"Properties of Resource"},{"location":"02-dsp-ontologies/knora-base/#representations","text":"It is not practical to store all data in RDF. In particular, RDF is not a good storage medium for binary data such as images. Therefore, Knora stores such data outside the triplestore, in ordinary files. A resource can have metadata about a file attached to it. The technical term for such a resource in Knora is a Representation . For each file, there is a kb:FileValue in the triplestore containing metadata about the file (see FileValue ). Knora uses Sipi to store files. The Knora APIs provide ways to create file values using Knora and Sipi. A resource that has a file value must belong to one of the subclasses of kb:Representation . Its subclasses include: StillImageRepresentation : A representation containing a still image file. MovingImageRepresentation : A representation containing a video file. AudioRepresentation : A representation containing an audio file. DDDrepresentation : A representation containing a 3D image file. TextRepresentation : A representation containing a formatted text file, such as an XML file. DocumentRepresentation : A representation containing a document (such as a PDF file) that is not a text file. ArchiveRepresentation : A representation containing an archive file (such as a zip archive). These classes can be used directly in data, but it is often better to make subclasses of them, to include metadata about the files being stored. The base class of all these classes is Representation , which is not intended to be used directly. It has this property, which its subclasses override: hasFileValue (1): Points to a file value. There are two ways for a project to design classes for representations. The simpler way is to create a resource class that represents a thing in the world (such as ex:Painting ) and also belongs to a subclass of Representation . This is adequate if the class can have only one type of file attached to it. For example, if paintings are represented only by still images, ex:Painting could be a subclass of StillImageRepresentation . This is the only approach supported in DSP-API v1. The more flexible approach, which is supported by DSP-API v2, is for each ex:Painting to link (using kb:hasRepresentation or a subproperty) to other resources containing files that represent the painting. Each of these other resources can extend a different subclass of Representation . For example, a painting could have a StillImageRepresentation as well as a DDDrepresentation .","title":"Representations"},{"location":"02-dsp-ontologies/knora-base/#standard-resource-classes","text":"In general, each project using Knora must define its own subclasses of kb:Resource . However, the Knora base ontology provides some standard subclasses of kb:Resource , which are intended to be used by any project: Region : Represents a region of a Representation (see Representations ). Annotation : Represents an annotation of a resource. The hasComment property points to the text of the annotation, represented as a kb:TextValue . LinkObj : Represents a link that connects two or more resources. A LinkObj has a hasLinkTo property pointing to each resource that it connects, as well as a hasLinkToValue property pointing to a reification of each of these direct links ( see Links Between Resources ). A LinkObj is more complex (and hence less convenient and readable) than a simple direct link, but it has the advantage that it can be annotated using an Annotation . For improved readability, a project can make its own subclasses of LinkObj with specific meanings.","title":"Standard Resource Classes"},{"location":"02-dsp-ontologies/knora-base/#values","text":"The Knora base ontology defines a set of OWL classes that are derived from kb:Value and represent different types of structured values found in humanities data. This set of classes may not be extended by user-created ontologies. A value is always part of one particular resource, which points to it using some property derived from hasValue . For example, a user-created ontology could specify a Book class with a property hasSummary (derived from hasValue ), and that property could have a knora-base:objectClassConstraint of TextValue . This would mean that the summary of each book is represented as a TextValue . Knora values are versioned. Existing values are not modified. Instead, a new version of an existing value is created. The new version is linked to the old version via the previousValue property. Since each value version has a different IRI, there is no IRI that can be used to cite the value, such that it will always refer to the latest version of the value. Therefore, the latest version of each value has a separate UUID, as the object of the property valueHasUUID . When a new version of the value is created, this UUID is moved to the new version. This makes it possible to cite the latest version of a value by searching for the UUID. \"Deleting\" a value means marking it with kb:isDeleted . An optional kb:deleteComment may be added to explain why the value has been marked as deleted. Deleted values are normally hidden. Most types of values are marked as deleted without creating a new version of the value. However, link values must be treated as a special case. Before a LinkValue can be marked as deleted, its reference count must be decremented to 0. Therefore, a new version of the LinkValue is made, with a reference count of 0, and it is this new version that is marked as deleted. To simplify the enforcement of ontology constraints, and for consistency with resource updates, no new versions of a deleted value can be made; it is not possible to undelete. Instead, if desired, a new value can be created by copying data from a deleted value.","title":"Values"},{"location":"02-dsp-ontologies/knora-base/#properties-of-value","text":"valueCreationDate (1): The date and time when the value was created. attachedToUser (1): The user who owns the value. valueHasString (1): A human-readable string representation of the value's contents, which is available to Knora's full-text search index. valueHasOrder (0-1): A resource may have several properties of the same type with different values (which will be of the same class), and it may be necessary to indicate an order in which these values occur. For example, a book may have several authors which should appear in a defined order. Hence, valueHasOrder , when present, points to an integer literal indicating the order of a given value relative to the other values of the same property. These integers will not necessarily start at any particular number, and will not necessarily be consecutive. previousValue (0-1): The previous version of the value. valueHasUUID (0-1): The UUID that refers to all versions of the value. Only the latest version of the value has this property. isDeleted (1): Indicates whether the value has been deleted. deleteDate (0-1): If the value has been deleted, indicates when it was deleted. deleteComment (0-1): If the value has been deleted, indicates why it was deleted. Each Knora value can grant permissions (see Authorisation ).","title":"Properties of Value"},{"location":"02-dsp-ontologies/knora-base/#subclasses-of-value","text":"","title":"Subclasses of Value"},{"location":"02-dsp-ontologies/knora-base/#textvalue","text":"Represents text, possibly including markup. The text is the object of the valueHasString property. A line break is represented as a Unicode line feed character ( U+000A ). The non-printing Unicode character INFORMATION SEPARATOR TWO (U+001E) can be used to separate words that are separated only by standoff markup (see below), so they are recognised as separate in a full-text search index. Markup is stored using this property: valueHasStandoff (0-n): Points to a standoff markup tag. See Text with Standoff Markup . valueHasMapping (0-1): Points to the mapping used to create the standoff markup and to convert it back to the original XML. See Mapping to Create Standoff From XML . A text value can have a specified language: valueHasLanguage (0-1): An ISO 639-1 code as string specifying the language of the text.","title":"TextValue"},{"location":"02-dsp-ontologies/knora-base/#datevalue","text":"Humanities data includes many different types of dates. In Knora, a date has a specified calendar, and is always represented as a period with start and end points (which may be equal), each of which has a precision ( DAY , MONTH , or YEAR ). For GREGORIAN and JULIAN calendars, an optional ERA indicator term ( BCE , CE , or BC , AD ) can be added to the date, when no era is provided the default era AD will be considered. Internally, the start and end points are stored as two Julian Day Numbers. This calendar-independent representation makes it possible to compare and search for dates regardless of the calendar in which they were entered. Properties: valueHasCalendar (1): The name of the calendar in which the date should be displayed. Currently GREGORIAN , JULIAN , and ISLAMIC civil calendars are supported. valueHasStartJDN (1): The Julian Day Number of the start of the period (an xsd:integer ). valueHasStartPrecision (1): The precision of the start of the period. valueHasEndJDN (1): The Julian Day Number of the end of the period (an xsd:integer ). valueHasEndPrecision (1): The precision of the end of the period.","title":"DateValue"},{"location":"02-dsp-ontologies/knora-base/#timevalue","text":"A Knora time value represents a precise moment in time in the Gregorian calendar. Since nanosecond precision can be included, it is suitable for use as a timestamp. Properties: valueHasTimeStamp (1): An xsd:dateTimeStamp , stored as an xsd:dateTime (because SPARQL does not support xsd:dateTimeStamp ).","title":"TimeValue"},{"location":"02-dsp-ontologies/knora-base/#intvalue","text":"Represents an integer. Property: valueHasInteger (1): An xsd:integer .","title":"IntValue"},{"location":"02-dsp-ontologies/knora-base/#colorvalue","text":"valueHasColor (1): A string representing a color. The string encodes a color as hexadecimal RGB values, e.g. \\#FF0000 .","title":"ColorValue"},{"location":"02-dsp-ontologies/knora-base/#decimalvalue","text":"Represents an arbitrary-precision decimal number. Property: valueHasDecimal (1): An xsd:decimal .","title":"DecimalValue"},{"location":"02-dsp-ontologies/knora-base/#urivalue","text":"Represents a non-Knora URI. Property: valueHasUri (1): An xsd:anyURI .","title":"UriValue"},{"location":"02-dsp-ontologies/knora-base/#booleanvalue","text":"Represents a boolean value. Property: valueHasBoolean (1): An xsd:boolean .","title":"BooleanValue"},{"location":"02-dsp-ontologies/knora-base/#geomvalue","text":"Represents a geometrical object as a JSON string, using normalized coordinates. Property: valueHasGeometry (1): A JSON string.","title":"GeomValue"},{"location":"02-dsp-ontologies/knora-base/#geonamevalue","text":"Represents a geolocation, using the identifiers found at GeoNames . Property: valueHasGeonameCode (1): The identifier of a geographical feature from GeoNames , represented as an xsd:string .","title":"GeonameValue"},{"location":"02-dsp-ontologies/knora-base/#intervalvalue","text":"Represents a time interval, with precise start and end times on a timeline, e.g. relative to the beginning of an audio or video file. Properties: valueHasIntervalStart (1): An xsd:decimal representing the start of the interval in seconds. valueHasIntervalEnd (1): An xsd:decimal representing the end of the interval in seconds.","title":"IntervalValue"},{"location":"02-dsp-ontologies/knora-base/#listvalue","text":"Projects often need to define lists or hierarchies of categories that can be assigned to many different resources. Then, for example, a user interface can provide a drop-down menu to allow the user to assign a category to a resource. The ListValue class provides a way to represent these sorts of data structures. It can represent either a flat list or a tree. A ListValue has this property: valueHasListNode (1): Points to a ListNode . Each ListNode can have the following properties: isRootNode (0-1): Set to true if this is the root node. hasSubListNode (0-n): Points to the node's child nodes, if any. hasRootNode (0-1): Points to the root node of the list (absent if isRootNode is true ). listNodePosition (0-1): An integer indicating the node's position in the list of its siblings (absent if isRootNode is true ). listNodeName (0-1): The node's human-readable name (absent if isRootNode is true ).","title":"ListValue"},{"location":"02-dsp-ontologies/knora-base/#filevalue","text":"Knora stores certain kinds of data outside the triplestore, in files (see Representations ). Each digital object that is stored outside the triplestore has associated metadata, which is stored in the triplestore in a kb:FileValue . The base class FileValue , which is not intended to be used directly, has these properties: internalFilename (1): The name of the file as stored by Knora. internalMimeType (1): The MIME type of the file as stored by Knora. originalFilename (0-1): The original name of the file when it was uploaded to the DSP-API server. originalMimeType (0-1): The original MIME type of the file when it was uploaded to the Knora API server. isPreview (0-1): A boolean indicating whether the file is a preview, i.e. a small image representing the contents of the file. A preview is always a StillImageFileValue , regardless of the type of the enclosing Representation . The subclasses of FileValue , which are intended to be used directly in data, include: StillImageFileValue : Contains metadata about a still image file. MovingImageFileValue : Contains metadata about a video file. AudioFileValue : Contains metadata about an audio file. DDDFileValue : Contains metadata about a 3D image file. TextFileValue : Contains metadata about a text file. DocumentFileValue : Contains metadata about a document (such as PDF) that is not a text file. ArchiveFileValue : Contains metadata about an archive (such as zio archive). Each of these classes contains properties that are specific to the type of file it describes. For example, still image files have dimensions, video files have frame rates, and so on. FileValue objects are versioned like other values, and the actual files stored by Knora are also versioned. Version 1 of the DSP-API does not provide a way to retrieve a previous version of a file, but this feature will be added in a subsequent version of the API.","title":"FileValue"},{"location":"02-dsp-ontologies/knora-base/#linkvalue","text":"A LinkValue is an RDF \"reification\" containing metadata about a link between two resources. It is therefore a subclass of rdf:Statement as well as of Value . It has these properties: rdf:subject (1) : The resource that is the source of the link. rdf:predicate (1) : The link property. rdf:object (1) : The resource that is the target of the link. valueHasRefCount (1) : The reference count of the link. This is meaningful when the LinkValue describes resource references in Standoff text markup (see StandoffLinkTag ). Otherwise, the reference count will always be 1 (if the link exists) or 0 (if it has been deleted). For details about how links are created in Knora, see Links Between Resources .","title":"LinkValue"},{"location":"02-dsp-ontologies/knora-base/#externalresvalue","text":"Represents a resource that is not stored in the RDF triplestore managed by Knora, but instead resides in an external repository managed by some other software. The ExternalResValue contains the information that Knora needs in order to access the resource, assuming that a suitable gateway plugin is installed. extResAccessInfo (1) : The location of the repository containing the external resource (e.g. its URL). extResId (1) : The repository-specific ID of the external resource. extResProvider (1) : The name of the external provider of the resource.","title":"ExternalResValue"},{"location":"02-dsp-ontologies/knora-base/#links-between-resources","text":"A link between two resources is expressed, first of all, as a triple, in which the subject is the resource that is the source of the link, the predicate is a \"link property\" (a subproperty of kb:hasLinkTo ), and the object is the resource that is the target of the link. It is also useful to store metadata about links. For example, Knora needs to know who owns the link, who has permission to modify it, when it was created, and so on. Such metadata cannot simply describe the link property, because then it would refer to that property in general, not to any particular instance in which that property is used to connect two particular resources. To attach metadata to a specific link in RDF, it is necessary to create an RDF \"reification\". A reification makes statements about a particular triple (subject, predicate, object), in this case the triple that expresses the link between the resources. Knora uses reifications of type kb:LinkValue (described in LinkValue to store metadata about links. For example, suppose a project describes paintings that belong to collections. The project can define an ontology as follows (expressed here in Turtle format, and simplified for the purposes of illustration): @prefix kb <http://www.knora.org/ontology/knora-base#> . @prefix : <http://www.knora.org/ontology/paintings#> . :Painting rdf:type owl:Class ; rdfs:subClassOf kb:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasArtist ; owl:cardinality 1 ] , [ rdf:type owl:Restriction ; owl:onProperty :hasTitle ; owl:cardinality 1 ] ; [ rdf:type owl:Restriction ; owl:onProperty :isInCollection ; owl:minCardinality 1 ] ; [ rdf:type owl:Restriction ; owl:onProperty :isInCollectionValue ; owl:minCardinality 1 ] . :Collection rdf:type owl:Class ; rdfs:subClassOf kb:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasCollectionName ; owl:cardinality 1 ] . :hasArtist rdf:type owl:ObjectProperty ; rdfs:label \"Name of artist\" ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:TextValue . :hasTitle rdf:type owl:ObjectProperty ; rdfs:label \"Title of painting\" kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:TextValue . :hasCollectionName rdf:type owl:ObjectProperty ; rdfs:label \"Name of collection\" ; kb:subjectClassConstraint :Collection ; kb:objectClassConstraint kb:TextValue . To link the paintings to the collection, we must add a \"link property\" to the ontology. In this case, the link property will point from a painting to the collection it belongs to. Every link property must be a subproperty of kb:hasLinkTo . :isInCollection rdf:type owl:ObjectProperty ; rdfs:subPropertyOf kb:hasLinkTo ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint :Collection . We must then add a \"link value property\", which will point from a painting to a kb:LinkValue (described in LinkValue ), which will contain metadata about the link between the property and the collection. In particular, the link value specifies the creator of the link, the date when it was created, and the permissions that determine who can view or modify it. The name of the link value property is constructed using a simple naming convention: the word Value is appended to the name of the link property. In this case, since our link property is called :isInCollection , the link value property must be called :isInCollectionValue . Every link value property must be a subproperty of kb:hasLinkToValue . :isInCollectionValue rdf:type owl:ObjectProperty ; rdfs:subPropertyOf kb:hasLinkToValue ; kb:subjectClassConstraint :Painting ; kb:objectClassConstraint kb:LinkValue . Given this ontology, we can create some RDF data describing a painting and a collection: @prefix paintings <http://www.knora.org/ontology/paintings#> . @prefix data <http://www.knora.org/ontology/paintings/data#> . data:dali_4587 rdf:type paintings:Painting ; paintings:hasTitle data:value_A ; paintings:hasArtist data:value_B . data:value_A rdf:type kb:TextValue ; kb:valueHasString \"The Persistence of Memory\" . data:value_B rdf:type kb:TextValue ; kb:valueHasString \"Salvador Dali\" . data:pompidou rdf:type paintings:Collection ; paintings:hasCollectionName data:value_C . data:value_C rdf:type kb:TextValue ; kb:valueHasString \"Centre Pompidou, Paris\" . We can then state that the painting is in the collection: data:dali_4587 paintings:isInCollection data:pompidou ; paintings:isinCollectionValue data:value_D . data:value_D rdf:type kb:LinkValue ; rdf:subject data:dali_4587 ; rdf:predicate paintings:isInCollection ; rdf:object data:pompidou ; kb:valueHasRefCount 1 . This creates a link ( paintings:isInCollection ) between the painting and the collection, along with a reification containing metadata about the link. We can visualise the result as the following graph: Knora allows a user to see a link if the requesting user has permission to see the source and target resources as well as the kb:LinkValue .","title":"Links Between Resources"},{"location":"02-dsp-ontologies/knora-base/#part-whole-relations-between-resources","text":"","title":"Part-Whole-Relations between Resources"},{"location":"02-dsp-ontologies/knora-base/#ispartof","text":"A special case of linked resources are part-of related resources , i.e. a resource consisting of several other resources. In order to create a part-of relation between two resources, the resource that is part of another resource needs to have a property that is either kb:isPartOf or a subproperty thereof. kb:isPartOf itself is a subproperty of kb:hasLinkTo . Same as described above for link properties, a corresponding part-of value property is created automatically. This value property has the same name as the part-of property with Value appended. For example, if in an ontology data a property data:partOf was defined, the corresponding value property would be named data:partOfValue . This newly created property data:partOfValue is defined as a subproperty of kb:isPartOfValue . Part-of relations are recommended for resources of type kb:StillImageRepresentation . In that case, the resource that is part of another resource needs to have a property kb:seqnum or a subproperty thereof, with an integer as value. A client can then use this information to leaf through the parts of the compound resource (p.ex. to leaf through the pages of a book like in this example).","title":"isPartOf"},{"location":"02-dsp-ontologies/knora-base/#issequenceof","text":"Similar to kb:isPartOf for kb:StillImageRepresentations , part-whole-relations can be defined for resources that have a time dimension by using kb:isSequenceOf . You can use it for video or audio resources that are subtypes of kb:MovingImageRepresentation and kb:AudioRepresentation . kb:isSequenceOf is intended to be used in combination with the property kb:hasSequenceBounds which points to a kb:IntervalValue . This defines the start and end point of the subseqence in relation to the entire audio/video resource as an interval . When the properties are used in this combination, a dedicated behavior in the frontend allows to display the sequences alongside the main resource. There is an important difference between kb:isSequenceOf and kb:isPartOf : For kb:isPartOf , each part is a kb:StillImageRepresentation and the whole consists of multiple such parts. In kb:isSequenceOf on the other hand, the whole is one kb:MovingImageRepresentation or kb:AudioRepresentation . The parts only define which sub-sequence of this representation they are.","title":"isSequenceOf"},{"location":"02-dsp-ontologies/knora-base/#text-with-standoff-markup","text":"DSP-API is designed to be able to store text with markup, which can indicate formatting and structure, as well as the complex observations involved in transcribing handwritten manuscripts. One popular way of representing text in the humanities is to encode it in XML using the Text Encoding Initiative ( TEI ) guidelines. In DSP-API, a TEI/XML document can be stored as a file with attached metadata, but this is not recommended, because it does not allow to perform searches across multiple documents. The recommended way to store text with markup in DSP-API is to use the built-in support for \"standoff\" markup, which is stored separately from the text. This has some advantages over embedded markup such as XML. While XML requires markup to have a hierarchical structure, and does not allow overlapping tags, standoff nodes do not have these limitations (see Using Standoff Properties for Marking-up Historical Documents in the Humanities ). A standoff tag can be attached to any substring in the text by giving its start and end positions. Unlike in corpus linguistics, we do not use any tokenisation resulting in a form of predefined segmentation, which would limit the user's ability to freely annotate any ranges in the text. For example, suppose we have the following text: This sentence has overlapping visual attributes. This would require just two standoff tags: (italic, start=5, end=29) and (bold, start=14, end=36) . Moreover, standoff makes it possible to mark up the same text in different, possibly incompatible ways, allowing for different interpretations without making redundant copies of the text. In the Knora base ontology, any text value can have standoff tags. By representing standoff as RDF triples, DSP-API makes markup searchable across multiple text documents in a repository. For example, if a repository contains documents in which references to persons are indicated in standoff, it is straightforward to find all the documents mentioning a particular person. DSP-API's standoff support is intended to make it possible to convert documents with embedded, hierarchical markup, such as TEI/XML, into RDF standoff and back again, with no data loss, thus bringing the benefits of RDF to existing TEI-encoded documents. In the Knora base ontology, a TextValue can have one or more standoff tags. Each standoff tag indicates the start and end positions of a substring in the text that has a particular attribute. The OWL class kb:StandoffTag , which is the base class of all standoff node classes, has these properties: standoffTagHasStart (1): The index of the first character in the text that has the attribute. standoffTagHasEnd (1): The index of the last character in the text that has the attribute, plus 1. standoffTagHasUUID (1): A UUID identifying this instance and those corresponding to it in later versions of the TextValue it belongs to. The UUID is a means to maintain a reference to a particular range of a text also when new versions are made and standoff tag IRIs change. standoffTagHasOriginalXMLID (0-1): The original ID of the XML element that the standoff tag represents, if any. standoffTagHasStartIndex (1): The start index of the standoff tag. Start indexes are numbered from 0 within the context of a particular text. When several standoff tags share the same start position, they can be nested correctly with this information when transforming them to XML. standoffTagHasEndIndex (1): The end index of the standoff tag. Start indexes are numbered from 0 within the context of a particular text. When several standoff tags share the same end position, they can be nested correctly with this information when transforming them to XML. standoffTagHasStartParent (0-1): Points to the parent standoff tag. This corresponds to the original nesting of tags in XML. If a standoff tag has no parent, it represents the XML root element. If the original XML element is a CLIX tag, it represents the start of a virtual (non syntactical) hierarchy. standoffTagHasEndParent (0-1): Points to the parent standoff tag if the original XML element is a CLIX tag and represents the end of a virtual (non syntactical) hierarchy. The StandoffTag class is not used directly in RDF data; instead, its subclasses are used. A few subclasses are currently provided in standoff-onto.ttl , and more will be added to support TEI semantics. Projects are able to define their own custom standoff tag classes (direct subclasses of StandoffTag or one of the standoff data type classes or subclasses of one of the standoff classes defined in standoff-onto.ttl ).","title":"Text with Standoff Markup"},{"location":"02-dsp-ontologies/knora-base/#subclasses-of-standofftag","text":"","title":"Subclasses of StandoffTag"},{"location":"02-dsp-ontologies/knora-base/#standoff-data-type-tags","text":"Associates data in some Knora value type with a substring in a text. Standoff data type tags are subclasses of ValueBase classes. StandoffLinkTag Indicates that a substring refers to another kb:Resource . See StandoffLinkTag . StandoffInternalReferenceTag Indicates that a substring refers to another standoff tag in the same text value. See Internal Links in a TextValue . StandoffUriTag Indicates that a substring is associated with a URI, which is stored in the same form that is used for kb:UriValue . See UriValue . StandoffDateTag Indicates that a substring represents a date, which is stored in the same form that is used for kb:DateValue . See DateValue . StandoffColorTag Indicates that a substring represents a color, which is stored in the same form that is used for kb:ColorValue . See ColorValue . StandoffIntegerTag Indicates that a substring represents an integer, which is stored in the same form that is used for kb:IntegerValue . See IntValue . StandoffDecimalTag Indicates that a substring represents a number with fractions, which is stored in the same form that is used for kb:DecimalValue . See DecimalValue . StandoffIntervalTag Indicates that a substring represents an interval, which is stored in the same form that is used for kb:IntervalValue . See IntervalValue . StandoffBooleanTag Indicates that a substring represents a Boolean, which is stored in the same form that is used for kb:BooleanValue . See BooleanValue . StandoffTimeTag Indicates that a substring represents a timestamp, which is stored in the same form that is used for kb:TimeValue . See TimeValue .","title":"Standoff Data Type Tags"},{"location":"02-dsp-ontologies/knora-base/#standofflinktag","text":"A StandoffLinkTag Indicates that a substring is associated with a Knora resource. For example, if a repository contains resources representing persons, a text could be marked up so that each time a person's name is mentioned, a StandoffLinkTag connects the name to the Knora resource describing that person. It has the following property: standoffTagHasLink (1): The IRI of the resource that is referred to. One of the design goals of the Knora base ontology is to make it easy and efficient to find out which resources contain references to a given resource. Direct links are easier and more efficient to query than indirect links. Therefore, when a text value contains a resource reference in its standoff nodes, Knora automatically creates a direct link between the containing resource and the target resource, along with an RDF reification (a kb:LinkValue ) describing the link, as discussed in Links Between Resources . In this case, the link property is always kb:hasStandoffLinkTo , and the link value property (which points to the LinkValue ) is always kb:hasStandoffLinkToValue . DSP-API automatically updates direct links and reifications for standoff resource references when text values are updated. To do this, it keeps track of the number of text values in each resource that contain at least one standoff reference to a given target resource. It stores this number as the reference count of the LinkValue (see LinkValue ) describing the direct link. Each time this number changes, it makes a new version of the LinkValue , with an updated reference count. When the reference count reaches zero, it removes the direct link and makes a new version of the LinkValue , marked with kb:isDeleted . For example, if data:R1 is a resource with a text value in which the resource data:R2 is referenced, the repository could contain the following triples: data:R1 ex:hasComment data:V1 . data:V1 rdf:type kb:TextValue ; kb:valueHasString \"This link is internal.\" ; kb:valueHasStandoff data:SO1 . data:SO1 rdf:type kb:StandoffLinkTag ; kb:standoffTagHasStart: 5 ; kb:standoffTagHasEnd: 9 ; kb:standoffTagHasLink data:R2 . data:R1 kb:hasStandoffLinkTo data:R2 . data:R1 kb:hasStandoffLinkToValue data:LV1 . data:LV1 rdf:type kb:LinkValue ; rdf:subject data:R1 ; rdf:predicate kb:hasStandoffLinkTo ; rdf:object data:R2 ; kb:valueHasRefCount 1 . The result can be visualized like this: Link values created automatically for resource references in standoff are visible to all users, and the creator of these link values is always kb:SystemUser (see Users and Groups ). The DSP-API server allows a user to see a standoff link if the user has permission to see the source and target resources.","title":"StandoffLinkTag"},{"location":"02-dsp-ontologies/knora-base/#internal-links-in-a-textvalue","text":"Internal links in a TextValue can be represented using the data type standoff class StandoffInternalReferenceTag or a subclass of it. It has the following property: standoffTagHasInternalReference (1): Points to a StandoffTag that belongs to the same TextValue . It has an objectClassConstraint of StandoffTag . For links to a kb:Resource , see StandoffLinkTag .","title":"Internal Links in a TextValue"},{"location":"02-dsp-ontologies/knora-base/#mapping-to-create-standoff-from-xml","text":"A mapping allows for the conversion of an XML document to RDF-standoff and back. A mapping defines one-to-one relations between XML elements (with or without a class) and attributes and standoff classes and properties (see XML to Standoff Mapping ). A mapping is represented by a kb:XMLToStandoffMapping which contains one or more kb:MappingElement . A kb:MappingElement maps an XML element (including attributes) to a standoff class and standoff properties. It has the following properties: mappingHasXMLTagname (1): The name of the XML element that is mapped to a standoff class. mappingHasXMLNamespace (1): The XML namespace of the XML element that is mapped to a standoff class. If no namespace is given, noNamespace is used. mappingHasXMLClass (1): The name of the class of the XML element. If it has no class, noClass is used. mappingHasStandoffClass (1): The standoff class the XML element is mapped to. mappingHasXMLAttribute (0-n): Maps XML attributes to standoff properties using MappingXMLAttribute . See below. mappingHasStandoffDataTypeClass (0-1): Indicates the standoff data type class of the standoff class the XML element is mapped to. mappingElementRequiresSeparator (1): Indicates if there should be an invisible word separator inserted after the XML element in the RDF-standoff representation. Once the markup is stripped, text segments that belonged to different elements may be concatenated. A MappingXMLAttribute has the following properties: - mappingHasXMLAttributename : The name of the XML attribute that is mapped to a standoff property. - mappingHasXMLNamespace : The namespace of the XML attribute that is mapped to a standoff property. If no namespace is given, noNamespace is used. - mappingHasStandoffProperty : The standoff property the XML attribute is mapped to. DSP-API includes a standard mapping used by the DSP APP. It has the IRI http://rdfh.ch/standoff/mappings/StandardMapping and defines mappings for a few elements used to write texts with simple markup.","title":"Mapping to Create Standoff From XML"},{"location":"02-dsp-ontologies/knora-base/#standoff-in-digital-editions","text":"DSP-API's standoff is designed to make it possible to convert XML documents to standoff and back. One application for this feature is an editing workflow in which an editor works in an XML editor, and the resulting XML documents are converted to standoff and stored in the DSP, where they can be searched and annotated. If an editor wants to correct text that has been imported from XML into standoff, the text can be exported as XML, edited, and imported again. To preserve annotations on standoff tags across edits, each tag can automatically be given a UUID. In a future version of the Knora base ontology, it may be possible to create annotations that point to UUIDs rather than to IRIs. When a text is exported to XML, the UUIDs can be included in the XML. When the edited XML is imported again, it can be converted to new standoff tags with the same UUIDs. Annotations that applied to standoff tags in the previous version of the text will therefore also apply to equivalent tags in the new version. When text is converted from XML into standoff, tags are also given indexes, which are numbered from 0 within the context of a particular text. This makes it possible to order tags that share the same position, and to preserve the hierarchy of the original XML document. An ordinary, hierarchical XML tag is converted to a standoff tag that has one index, as well as the index of its parent tag, if any. The Knora base ontology also supports non-hierarchical markup such as CLIX , which enables overlapping markup to be represented in XML. When non-hierarchical markup is converted to standoff, both the start position and the end position of the standoff tag have indexes and parent indexes. To support these features, a standoff tag can have these additional properties: - standoffTagHasStartIndex (0-1): The index of the start position. - standoffTagHasEndIndex (0-1): The index of the end position, if this is a non-hierarchical tag. - standoffTagHasStartParent (0-1): The IRI of the tag, if any, that contains the start position. - standoffTagHasEndParent (0-1): The IRI of the tag, if any, that contains the end position, if this is a non-hierarchical tag. - standoffTagHasUUID (0-1): A UUID that can be used to annotate a standoff tag that may be present in different versions of a text, or in different layers of a text (such as a diplomatic transcription and an edited critical text).","title":"Standoff in Digital Editions"},{"location":"02-dsp-ontologies/knora-base/#querying-standoff-in-sparql","text":"A future version of DSP-API may provide an API for querying standoff markup. In the meantime, it is possible to query it directly in SPARQL. For example, here is a SPARQL query (using RDFS inference) that finds all the text values that have a standoff date tag referring to Christmas Eve 2016, contained in a StandoffItalicTag : PREFIX knora-base: <http://www.knora.org/ontology/knora-base#> PREFIX standoff: <http://www.knora.org/ontology/standoff#> select * where { ?standoffTag a knora-base:StandoffDateTag . ?standoffTag knora-base:valueHasStartJDN ?dateStart . ?standoffTag knora-base:valueHasEndJDN ?dateEnd . FILTER (2457747 <= ?dateEnd && 2457747 >= ?dateStart) ?standoffTag knora-base:standoffTagHasStartParent ?parent . ?parent a standoff:StandoffItalicTag . ?textValue knora-base:valueHasStandoff ?standoffTag . ?textValue knora-base:valueHasString ?string . ?standoffTag knora-base:standoffTagHasStart ?startPos . ?standoffTag knora-base:standoffTagHasEnd ?endPos . }","title":"Querying Standoff in SPARQL"},{"location":"02-dsp-ontologies/knora-base/#authorisation","text":"","title":"Authorisation"},{"location":"02-dsp-ontologies/knora-base/#users-and-groups","text":"Each Knora user is represented by an object belonging to the class kb:User , which is a subclass of foaf:Person , and has the following properties: userid (1) : A unique identifier that the user must provide when logging in. password (1) : A cryptographic hash of the user's password. email (0-n) : Email addresses belonging to the user. isInProject (0-n) : Projects that the user is a member of. isInGroup (0-n) : user-created groups that the user is a member of. foaf:familyName (1) : The user's family name. foaf:givenName (1) : The user's given name. Knora's concept of access control is that an object (a resource or value) can grant permissions to groups of users (but not to individual users). There are several built-in groups: knora-admin:UnknownUser : Any user who has not logged into Knora is automatically assigned to this group. knora-admin:KnownUser : Any user who has logged into Knora is automatically assigned to this group. knora-admin:ProjectMember : When checking a user's permissions on an object, the user is automatically assigned to this group if she is a member of the project that the object belongs to. knora-admin:Creator : When checking a user's permissions on an object, the user is automatically assigned to this group if he is the creator of the object. knora-admin:ProjectAdmin : When checking a user's permissions on an object, the user is automatically assigned to this group if she is an administrator of the project that the object belongs to. knora-admin:SystemAdmin : The group of Knora system administrators. A user-created ontology can define additional groups, which must belong to the OWL class knora-admin:UserGroup . There is one built-in knora-admin:SystemUser , which is the creator of link values created automatically for resource references in standoff markup (see StandoffLinkTag ).","title":"Users and Groups"},{"location":"02-dsp-ontologies/knora-base/#permissions","text":"Each resource or value can grant certain permissions to specified user groups. These permissions are represented as the object of the predicate kb:hasPermissions , which is required on every kb:Resource and on the current version of every kb:Value . The permissions attached to the current version of a value also apply to previous versions of the value. Value versions other than the current one do not have this predicate. The following permissions can be granted: Restricted view permission (RV) Allows a restricted view of the object, e.g. a view of an image with a watermark. View permission (V) Allows an unrestricted view of the object. Having view permission on a resource only affects the user's ability to view information about the resource other than its values. To view a value, she must have view permission on the value itself. Modify permission (M) For values, this permission allows a new version of a value to be created. For resources, this allows the user to create a new value (as opposed to a new version of an existing value), or to change information about the resource other than its values. When he wants to make a new version of a value, his permissions on the containing resource are not relevant. However, when he wants to change the target of a link, the old link must be deleted and a new one created, so he needs modify permission on the resource. Delete permission (D) Allows the item to be marked as deleted. Change rights permission (CR) Allows the permissions granted by the object to be changed. Each permission in the above list implies all lower-numbered permissions. A user's permission level on a particular object is calculated in the following way: Make a list of the groups that the user belongs to, including Creator and/or ProjectMember if applicable. Make a list of the permissions that she can obtain on the object, by iterating over the permissions that the object grants. For each permission, if she is in the specified group, add the specified permission to the list of permissions she can obtain. From the resulting list, select the highest-level permission. If the result is that she would have no permissions, give her whatever permission UnknownUser would have. To view a link between resources, a user needs permission to view the source and target resources. He also needs permission to view the LinkValue representing the link, unless the link property is hasStandoffLinkTo (see StandoffLinkTag ). The format of the object of kb:hasPermissions is as follows: Each permission is represented by the one-letter or two-letter abbreviation given above. Each permission abbreviation is followed by a space, then a comma-separated list of groups that the permission is granted to. The IRIs of built-in groups are shortened using the knora-admin prefix. Multiple permissions are separated by a vertical bar ( | ). For example, if an object grants view permission to unknown and known users, and modify permission to project members, the resulting permission literal would be: V knora-admin:UnknownUser,knora-admin:KnownUser|M knora-admin:ProjectMember","title":"Permissions"},{"location":"02-dsp-ontologies/knora-base/#consistency-checking","text":"Knora tries to enforce repository consistency by checking constraints that are specified in the Knora base ontology and in user-created ontologies. Three types of consistency rules are enforced: Cardinalities in OWL class definitions must be satisfied. Constraints on the types of the subjects and objects of OWL object properties must be satisfied. A datatype property may not have an empty string as an object.","title":"Consistency Checking"},{"location":"02-dsp-ontologies/knora-base/#owl-cardinalities","text":"As noted in Resources , each subclass of Resource must use OWL cardinality restrictions to specify the properties it can have. More specifically, a resource is allowed to have a property that is a subproperty of kb:hasValue or kb:hasLinkTo only if the resource's class has some cardinality for that property. Similarly, a value is allowed to have a subproperty of kb:valueHas only if the value's class has some cardinality for that property. Knora supports, and attempts to enforce, the following cardinality constraints: owl:cardinality 1 : A resource of this class must have exactly one instance of the specified property. owl:minCardinality 1 : A resource of this class must have at least one instance of the specified property. owl:maxCardinality 1 : A resource of this class may have zero or one instance of the specified property. owl:minCardinality 0 : A resource of this class may have zero or more instances of the specified property. Knora requires cardinalities to be defined using blank nodes, as in the following example from knora-base : :Representation rdf:type owl:Class ; rdfs:subClassOf :Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] . :StillImageRepresentation rdf:type owl:Class ; rdfs:subClassOf :Representation , [ rdf:type owl:Restriction ; owl:onProperty :hasStillImageFileValue ; owl:minCardinality \"1\"^^xsd:nonNegativeInteger ] . The cardinality of a link property must be the same as the cardinality of the corresponding link value property. Each owl:Restriction may have the predicate salsah-gui:guiOrder to indicate the order in which properties should be displayed in a GUI (see The SALSAH GUI Ontology ). A resource class inherits cardinalities from its superclasses. This follows from the rules of RDFS inference. Also, in Knora, cardinalities in the subclass can override cardinalities that would otherwise be inherited from the superclass. Specifically, if a superclass has a cardinality on a property P, and a subclass has a cardinality on a subproperty of P, the subclass's cardinality overrides the superclass's cardinality. In the example above, hasStillImageFileValue is a subproperty of hasFileValue . Therefore, the cardinality on hasStillImageFileValue overrides (i.e. replaces) the one on hasFileValue . Note that, unlike cardinalities, predicates of properties are not inherited. If :foo rdfs:subPropertyOf :bar , this does not mean that :foo inherits anything from :bar . Any predicates of :foo that are also needed by :bar must be defined explicitly on :bar . This design decision was made because property predicate inheritance is not provided by RDFS inference, and would make it more difficult to check the correctness of ontologies, while providing little practical benefit. For more information about OWL cardinalities, see the OWL 2 Primer .","title":"OWL Cardinalities"},{"location":"02-dsp-ontologies/knora-base/#constraints-on-the-types-of-property-subjects-and-objects","text":"When a user-created ontology defines a property, it must indicate the types that are allowed as objects (and, if possible, as subjects) of the property. This is done using the following Knora-specific properties: subjectClassConstraint : Specifies the class that subjects of the property must belong to. This constraint is recommended but not required. Knora will attempt to enforce this constraint. objectClassConstraint : If the property is an object property, specifies the class that objects of the property must belong to. Every subproperty of kb:hasValue or a kb:hasLinkTo (i.e. every property of a resource that points to a kb:Value or to another resource) is required to have this constraint, because Knora relies on it to know what type of object to expect for the property. Knora will attempt to enforce this constraint. objectDatatypeConstraint : If the property is a datatype property, specifies the type of literals that can be objects of the property. Knora will not attempt to enforce this constraint, but it is useful for documentation purposes. Note that it is possible for a subproperty to have a more restrictive contraint than its base property, by specifing a subject or object class that is a subclass of the one specified in the base property. However, it is not possible for the subproperty to make the base property's constraint less restrictive. See also Why doesn\u2019t Knora use rdfs:domain and rdfs:range for consistency checking?","title":"Constraints on the Types of Property Subjects and Objects"},{"location":"02-dsp-ontologies/knora-base/#consistency-constraint-example","text":"A user-created ontology could define consistency constraints as in this simplified example: :book rdf:type owl:Class ; rdfs:subClassOf knora-base:Resource , [ rdf:type owl:Restriction ; owl:onProperty :hasTitle ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ] , [ rdf:type owl:Restriction ; owl:onProperty :hasAuthor ; owl:minCardinality \"0\"^^xsd:nonNegativeInteger ] . :hasTitle rdf:type owl:ObjectProperty ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue . :hasAuthor rdf:type owl:ObjectProperty ; knora-base:subjectClassConstraint :book ; knora-base:objectClassConstraint knora-base:TextValue .","title":"Consistency Constraint Example"},{"location":"02-dsp-ontologies/knora-base/#summary-of-restrictions-on-user-created-ontologies","text":"An ontology can refer to a Knora ontology in another project only if the other ontology is built-in or shared (see Shared Ontologies ).","title":"Summary of Restrictions on User-Created Ontologies"},{"location":"02-dsp-ontologies/knora-base/#restrictions-on-classes","text":"Each class must be a subclass of either kb:Resource or kb:StandoffTag , but not both (note that this forbids user-created subclasses of kb:Value ). All the cardinalities that a class defines directly (i.e. does not inherit from kb:Resource ) must be on properties that are defined in the triplestore. Within the cardinalities of a class, there must be a link value property for each link property and vice versa. The cardinality of a link property must be the same as the cardinality of the corresponding link value property. A cardinality on a property with a boolean value must be owl:cardinality 1 or owl:maxCardinality 1 . Each class must be a subclass of all the classes that are subject class constraints of the properties in its cardinalities. If it's a resource class, all its directly defined cardinalities must be on Knora resource properties (subproperties of kb:hasValue or kb:hasLinkTo ), and all its base classes with Knora IRIs must also be resource classes. A cardinality on kb:resourceProperty or kb:hasValue is forbidden. It must also have an rdfs:label . If it's a standoff class, none of its cardinalities may be on Knora resource properties, and all its base classes with Knora IRIs must also be standoff classes. A class cannot have a cardinality on property P as well as a cardinality on a subproperty of P.","title":"Restrictions on Classes"},{"location":"02-dsp-ontologies/knora-base/#restrictions-on-properties","text":"The property's subject class constraint, if provided, must be a subclass of kb:Resource or kb:StandoffTag , and must be a subclass of the subject class constraints of all its base properties. Its object class constraint, if provided, must be a subclass of the object class constraints of all its base properties. If the property is a Knora resource property, it must have an object class constraint and an rdfs:label . It can't be a subproperty of both kb:hasValue and kb:hasLinkTo . It can't be a subproperty of kb:hasFileValue . Each of its base properties that has a Knora IRI must also be a Knora resource property.","title":"Restrictions on properties"},{"location":"02-dsp-ontologies/knora-base/#standardisation","text":"The DaSCH intends to coordinate the standardisation of generally useful entities proposed in user-created ontologies. We envisage a process in which two or more projects would initiate the process by starting a public discussion on proposed entities to be shared. Once a consensus was reached, the DaSCH would publish these entities in a shared ontology ).","title":"Standardisation"},{"location":"02-dsp-ontologies/knora-base/#knora-ontology-versions","text":"The Knora base ontology has the property kb:ontologyVersion , whose object is a string that indicates the deployed version of all the Knora built-in ontologies. This allows the repository update program to determine which repository updates are needed when Knora is upgraded.","title":"Knora Ontology Versions"},{"location":"02-dsp-ontologies/salsah-gui/","text":"The SALSAH GUI Ontology Overview The SALSAH GUI ontology provides entities that can be used in user-created ontologies to indicate to SALSAH (or to another GUI) how data should be entered and displayed. The SALSAH GUI ontology is identified by the IRI http://www.knora.org/ontology/salsah-gui . In the Knora documentation in general, it is identified by the prefix salsah-gui , but for brevity, we omit the prefix in this document. Properties guiOrder guiOrder can be attached to a cardinality in a resource class, to indicate the order in which properties should be displayed in the GUI. The object is a non-negative integer. For example, a property with guiOrder 0 would be displayed first, followed by a property with guiOrder 1, and so on. guiElement guiElement can be attached to a property definition to indicate which GUI element should be used to enter data for the property. This should be one of the individuals of class Guielement described below. guiAttribute guiAttribute can be attached to a property definition to provide attributes for the GUI element specified in guiElement . The objects of this predicate are written in a DSL with the following syntax: object = attribute name, \"=\", attribute value ; attribute name = identifier ; identifier = letter , { letter } ; attribute value = integer | decimal | percent | string | iri ; percent = integer, \"%\" ; iri = \"<\", string, \">\" ; The attributes used with each GUI element are described below under Individuals . guiAttributeDefinition guiAttributeDefinition is used only in the salsah-gui ontology itself, as a predicate attached to instances of Guielement (see Individuals ), to specify the attributes that can be given as objects of guiAttribute when a given Guielement is used. The objects of this predicate are written in a DSL with the following syntax: object = attribute name, [ \"(required)\" ], \":\", attribute type, [ enumerated values ] ; enumerated values = \"(\", enumerated value, { \"|\", enumerated value } \")\" ; attribute name = identifier ; attribute type = \"integer\" | \"decimal\" | \"percent\" | \"string\" | \"iri\" ; enumerated value = identifier ; identifier = letter , { letter } ; Enumerated values are allowed only if attribute type is string . If enumerated values are provided for an attribute, the attribute value given via guiAttribute must be one of the enumerated values. Classes Guielement The instances of class Guielement are individuals representing GUI elements for data entry. Individuals Colorpicker Colorpicker is a GUI element for selecting a color. A property definition that uses this element may also contain a guiAttribute predicate whose object is a string in the form \"ncolors=N\" , where N is an integer specifying the number of colors to display. Date Date is a GUI element for selecting a date. Geometry Geometry is a GUI element for selecting the geometry of a two-dimensional region. Geonames Geonames is a GUI element for selecting a Geonames identifier. Interval Interval is a GUI element for selecting a time interval in an audio or video recording. List List is a GUI element for selecting an item in a hierarchical list (see ListValue ). A property definition that uses this element must also contain this guiAttribute predicate: \"hlist=<LIST_IRI>\" , where LIST_IRI is the IRI of a knora-base:ListNode that is the root node of a hierarchical list. Pulldown Pulldown is a GUI element for selecting an item in a flat list (see ListValue ) using a pull-down menu. A property definition that uses this element must also contain this guiAttribute predicate: \"hlist=<LIST_IRI>\" , where LIST_IRI is the IRI of a knora-base:ListNode that is the root node of a hierarchical list. Radio Radio is a GUI element for selecting an item in a flat list (see ListValue ) using radio buttons. A property definition that uses this element must also contain this guiAttribute predicate: \"hlist=<LIST_IRI>\" , where LIST_IRI is the IRI of a knora-base:ListNode that is the root node of a hierarchical list. Richtext Richtext is a GUI element for editing multi-line formatted text. Searchbox Searchbox is a GUI element for searching for a resource by matching text in its rdfs:label . For DSP-API v1, a property definition that uses this element may also contain this guiAttribute predicate: \"numprops=N\" , where N is an integer specifying the number of describing properties to be returned for each found resource. For DSP-API v2, the guiAttribute has no effect. SimpleText SimpleText is a GUI element for editing a single line of unformatted text. A property definition that uses this element may also contain a guiAttribute predicate with one or both of the following objects: \"size=N\" , where N is an integer specifying the size of the text field. \"maxlength=N\" , where N is an integer specifying the maximum length of the string to be input. Slider Slider is a GUI element for choosing numerical values using a slider. A property definition that uses this element must also contain a guiAttribute predicate with both of the following objects: \"min=N\" , where N is an integer specifying the minimum value of the input. \"max=N\" , where N is an integer specifying the maximum value of the input. Spinbox Spinbox is a GUI element for choosing numerical values using a spinbox. A property definition that uses this element may also contain a guiAttribute predicate with one or both of the following objects: \"min=N\" , where N is an integer specifying the minimum value of the input. \"max=N\" , where N is an integer specifying the maximum value of the input. Textarea Textarea is a GUI element for editing multi-line unformatted text. A property definition that uses this element may also contain a guiAttribute predicate with one or more of the following objects: \"width=N\" , where N is a percentage of the window width (an integer followed by % ). \"cols=N\" , where N is an integer representing the number of colums in the text entry box. \"rows=N\" , where N is an integer specifying the height of the text entry box in rows. \"wrap=W\" , where W is soft or hard (see wrap ). Checkbox Checkbox is a GUI element for choosing a boolean value using a checkbox. Fileupload Fileupload is a GUI element for uploading a file.","title":"The SALSAH GUI Ontology"},{"location":"02-dsp-ontologies/salsah-gui/#the-salsah-gui-ontology","text":"","title":"The SALSAH GUI Ontology"},{"location":"02-dsp-ontologies/salsah-gui/#overview","text":"The SALSAH GUI ontology provides entities that can be used in user-created ontologies to indicate to SALSAH (or to another GUI) how data should be entered and displayed. The SALSAH GUI ontology is identified by the IRI http://www.knora.org/ontology/salsah-gui . In the Knora documentation in general, it is identified by the prefix salsah-gui , but for brevity, we omit the prefix in this document.","title":"Overview"},{"location":"02-dsp-ontologies/salsah-gui/#properties","text":"","title":"Properties"},{"location":"02-dsp-ontologies/salsah-gui/#guiorder","text":"guiOrder can be attached to a cardinality in a resource class, to indicate the order in which properties should be displayed in the GUI. The object is a non-negative integer. For example, a property with guiOrder 0 would be displayed first, followed by a property with guiOrder 1, and so on.","title":"guiOrder"},{"location":"02-dsp-ontologies/salsah-gui/#guielement","text":"guiElement can be attached to a property definition to indicate which GUI element should be used to enter data for the property. This should be one of the individuals of class Guielement described below.","title":"guiElement"},{"location":"02-dsp-ontologies/salsah-gui/#guiattribute","text":"guiAttribute can be attached to a property definition to provide attributes for the GUI element specified in guiElement . The objects of this predicate are written in a DSL with the following syntax: object = attribute name, \"=\", attribute value ; attribute name = identifier ; identifier = letter , { letter } ; attribute value = integer | decimal | percent | string | iri ; percent = integer, \"%\" ; iri = \"<\", string, \">\" ; The attributes used with each GUI element are described below under Individuals .","title":"guiAttribute"},{"location":"02-dsp-ontologies/salsah-gui/#guiattributedefinition","text":"guiAttributeDefinition is used only in the salsah-gui ontology itself, as a predicate attached to instances of Guielement (see Individuals ), to specify the attributes that can be given as objects of guiAttribute when a given Guielement is used. The objects of this predicate are written in a DSL with the following syntax: object = attribute name, [ \"(required)\" ], \":\", attribute type, [ enumerated values ] ; enumerated values = \"(\", enumerated value, { \"|\", enumerated value } \")\" ; attribute name = identifier ; attribute type = \"integer\" | \"decimal\" | \"percent\" | \"string\" | \"iri\" ; enumerated value = identifier ; identifier = letter , { letter } ; Enumerated values are allowed only if attribute type is string . If enumerated values are provided for an attribute, the attribute value given via guiAttribute must be one of the enumerated values.","title":"guiAttributeDefinition"},{"location":"02-dsp-ontologies/salsah-gui/#classes","text":"","title":"Classes"},{"location":"02-dsp-ontologies/salsah-gui/#guielement_1","text":"The instances of class Guielement are individuals representing GUI elements for data entry.","title":"Guielement"},{"location":"02-dsp-ontologies/salsah-gui/#individuals","text":"","title":"Individuals"},{"location":"02-dsp-ontologies/salsah-gui/#colorpicker","text":"Colorpicker is a GUI element for selecting a color. A property definition that uses this element may also contain a guiAttribute predicate whose object is a string in the form \"ncolors=N\" , where N is an integer specifying the number of colors to display.","title":"Colorpicker"},{"location":"02-dsp-ontologies/salsah-gui/#date","text":"Date is a GUI element for selecting a date.","title":"Date"},{"location":"02-dsp-ontologies/salsah-gui/#geometry","text":"Geometry is a GUI element for selecting the geometry of a two-dimensional region.","title":"Geometry"},{"location":"02-dsp-ontologies/salsah-gui/#geonames","text":"Geonames is a GUI element for selecting a Geonames identifier.","title":"Geonames"},{"location":"02-dsp-ontologies/salsah-gui/#interval","text":"Interval is a GUI element for selecting a time interval in an audio or video recording.","title":"Interval"},{"location":"02-dsp-ontologies/salsah-gui/#list","text":"List is a GUI element for selecting an item in a hierarchical list (see ListValue ). A property definition that uses this element must also contain this guiAttribute predicate: \"hlist=<LIST_IRI>\" , where LIST_IRI is the IRI of a knora-base:ListNode that is the root node of a hierarchical list.","title":"List"},{"location":"02-dsp-ontologies/salsah-gui/#pulldown","text":"Pulldown is a GUI element for selecting an item in a flat list (see ListValue ) using a pull-down menu. A property definition that uses this element must also contain this guiAttribute predicate: \"hlist=<LIST_IRI>\" , where LIST_IRI is the IRI of a knora-base:ListNode that is the root node of a hierarchical list.","title":"Pulldown"},{"location":"02-dsp-ontologies/salsah-gui/#radio","text":"Radio is a GUI element for selecting an item in a flat list (see ListValue ) using radio buttons. A property definition that uses this element must also contain this guiAttribute predicate: \"hlist=<LIST_IRI>\" , where LIST_IRI is the IRI of a knora-base:ListNode that is the root node of a hierarchical list.","title":"Radio"},{"location":"02-dsp-ontologies/salsah-gui/#richtext","text":"Richtext is a GUI element for editing multi-line formatted text.","title":"Richtext"},{"location":"02-dsp-ontologies/salsah-gui/#searchbox","text":"Searchbox is a GUI element for searching for a resource by matching text in its rdfs:label . For DSP-API v1, a property definition that uses this element may also contain this guiAttribute predicate: \"numprops=N\" , where N is an integer specifying the number of describing properties to be returned for each found resource. For DSP-API v2, the guiAttribute has no effect.","title":"Searchbox"},{"location":"02-dsp-ontologies/salsah-gui/#simpletext","text":"SimpleText is a GUI element for editing a single line of unformatted text. A property definition that uses this element may also contain a guiAttribute predicate with one or both of the following objects: \"size=N\" , where N is an integer specifying the size of the text field. \"maxlength=N\" , where N is an integer specifying the maximum length of the string to be input.","title":"SimpleText"},{"location":"02-dsp-ontologies/salsah-gui/#slider","text":"Slider is a GUI element for choosing numerical values using a slider. A property definition that uses this element must also contain a guiAttribute predicate with both of the following objects: \"min=N\" , where N is an integer specifying the minimum value of the input. \"max=N\" , where N is an integer specifying the maximum value of the input.","title":"Slider"},{"location":"02-dsp-ontologies/salsah-gui/#spinbox","text":"Spinbox is a GUI element for choosing numerical values using a spinbox. A property definition that uses this element may also contain a guiAttribute predicate with one or both of the following objects: \"min=N\" , where N is an integer specifying the minimum value of the input. \"max=N\" , where N is an integer specifying the maximum value of the input.","title":"Spinbox"},{"location":"02-dsp-ontologies/salsah-gui/#textarea","text":"Textarea is a GUI element for editing multi-line unformatted text. A property definition that uses this element may also contain a guiAttribute predicate with one or more of the following objects: \"width=N\" , where N is a percentage of the window width (an integer followed by % ). \"cols=N\" , where N is an integer representing the number of colums in the text entry box. \"rows=N\" , where N is an integer specifying the height of the text entry box in rows. \"wrap=W\" , where W is soft or hard (see wrap ).","title":"Textarea"},{"location":"02-dsp-ontologies/salsah-gui/#checkbox","text":"Checkbox is a GUI element for choosing a boolean value using a checkbox.","title":"Checkbox"},{"location":"02-dsp-ontologies/salsah-gui/#fileupload","text":"Fileupload is a GUI element for uploading a file.","title":"Fileupload"},{"location":"03-endpoints/","text":"The Endpoints of DSP-API The endpoints include: DSP-API versions 1 and 2, which are intended to be used by clients for querying, creating and updating data DSP-API admin endpoint, which provides admin functionalities. It is intended to to be used only by DSP-APP and the DSP itself. DSP-API util routes, which provide information about the DSP stack","title":"Index"},{"location":"03-endpoints/#the-endpoints-of-dsp-api","text":"The endpoints include: DSP-API versions 1 and 2, which are intended to be used by clients for querying, creating and updating data DSP-API admin endpoint, which provides admin functionalities. It is intended to to be used only by DSP-APP and the DSP itself. DSP-API util routes, which provide information about the DSP stack","title":"The Endpoints of DSP-API"},{"location":"03-endpoints/api-admin/groups/","text":"Groups Endpoint Endpoint Overview Group Operations: GET: /admin/groups : return all groups GET: /admin/groups/<groupIri> : return single group identified by [IRI] POST: /admin/groups : create a new group PUT: /admin/groups/<groupIri> : update groups's basic information PUT: /admin/groups/<groupIri>/status : update group's status DELETE: /admin/groups/<groupIri> : delete group (set status to false) Member Operations: GET: /admin/groups/<groupIri>/members : return all group members Group Operations Create Group Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission Required information: name (unique inside project), project IRI Optional information: group descriptions Returns information about the newly created group TypeScript Docs: groupFormats - CreateGroupApiRequestV1 POST: /admin/groups BODY: { \"name\": \"NewGroup\", \"descriptions\": [ {\"value\": \"NewGroupDescription\", \"language\": \"en\"}, {\"value\": \"NeueGruppenBeschreibung\", \"language\": \"de\"} ], \"project\": \"http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA\", \"status\": true, \"selfjoin\": false } Additionally, each group can have an optional custom IRI (of @ref: Knora IRI form) specified by the id in the request body as below: { \"id\": \"http://rdfh.ch/groups/00FF/a95UWs71KUklnFOe1rcw1w\", \"name\": \"GroupWithCustomIRI\", \"descriptions\": [{\"value\": \"A new group with a custom IRI\", \"language\": \"en\"}], \"project\": \"http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA\", \"status\": true, \"selfjoin\": false } Update group information Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission / hasProjectRestrictedGroupAdminPermission (for this group) Changeable information: name , descriptions , selfjoin TypeScript Docs: groupFormats - ChangeGroupApiRequestADM PUT: /admin/groups/<groupIri> BODY: { \"name\": \"UpdatedGroupName\", \"descriptions\": [{\"value\": \"UpdatedGroupDescription\", \"language\": \"en\"}], \"selfjoin\": false } Change Group Status: Required permission: SystemAdmin / hasProjectAllAdminPermission Changeable information: status Remark: Deleting a group, removes all members from the group. PUT: /admin/groups/<groupIri>/status BODY: { \"status\": false } Delete Group: Required permission: SystemAdmin / hasProjectAllAdminPermission Remark: The same as changing the groups status to false . To un-delete, set status to true . DELETE: /admin/groups/<groupIri> Example Group Information stored in admin named graph: : <http://rdfh.ch/groups/[shortcode]/[UUID]> rdf:type knora-admin:UserGroup ; knora-admin:groupName \"Name of the group\" ; knora-admin:groupDescriptions \"A description of the group\"@en ; knora-admin:belongsToProject <http://rdfh.ch/projects/[UUID]> ; knora-admin:status \"true\"^^xsd:boolean ; knora-admin:hasSelfJoinEnabled \"false\"^^xsd:boolean . Member Operations Get Group Members Returns all group members Required permission: SystemAdmin / ProjectAdmin GET: /admin/groups/<groupIri>/members","title":"Groups Endpoint"},{"location":"03-endpoints/api-admin/groups/#groups-endpoint","text":"","title":"Groups Endpoint"},{"location":"03-endpoints/api-admin/groups/#endpoint-overview","text":"Group Operations: GET: /admin/groups : return all groups GET: /admin/groups/<groupIri> : return single group identified by [IRI] POST: /admin/groups : create a new group PUT: /admin/groups/<groupIri> : update groups's basic information PUT: /admin/groups/<groupIri>/status : update group's status DELETE: /admin/groups/<groupIri> : delete group (set status to false) Member Operations: GET: /admin/groups/<groupIri>/members : return all group members","title":"Endpoint Overview"},{"location":"03-endpoints/api-admin/groups/#group-operations","text":"","title":"Group Operations"},{"location":"03-endpoints/api-admin/groups/#create-group","text":"Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission Required information: name (unique inside project), project IRI Optional information: group descriptions Returns information about the newly created group TypeScript Docs: groupFormats - CreateGroupApiRequestV1 POST: /admin/groups BODY: { \"name\": \"NewGroup\", \"descriptions\": [ {\"value\": \"NewGroupDescription\", \"language\": \"en\"}, {\"value\": \"NeueGruppenBeschreibung\", \"language\": \"de\"} ], \"project\": \"http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA\", \"status\": true, \"selfjoin\": false } Additionally, each group can have an optional custom IRI (of @ref: Knora IRI form) specified by the id in the request body as below: { \"id\": \"http://rdfh.ch/groups/00FF/a95UWs71KUklnFOe1rcw1w\", \"name\": \"GroupWithCustomIRI\", \"descriptions\": [{\"value\": \"A new group with a custom IRI\", \"language\": \"en\"}], \"project\": \"http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA\", \"status\": true, \"selfjoin\": false }","title":"Create Group"},{"location":"03-endpoints/api-admin/groups/#update-group-information","text":"Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission / hasProjectRestrictedGroupAdminPermission (for this group) Changeable information: name , descriptions , selfjoin TypeScript Docs: groupFormats - ChangeGroupApiRequestADM PUT: /admin/groups/<groupIri> BODY: { \"name\": \"UpdatedGroupName\", \"descriptions\": [{\"value\": \"UpdatedGroupDescription\", \"language\": \"en\"}], \"selfjoin\": false }","title":"Update group information"},{"location":"03-endpoints/api-admin/groups/#change-group-status","text":"Required permission: SystemAdmin / hasProjectAllAdminPermission Changeable information: status Remark: Deleting a group, removes all members from the group. PUT: /admin/groups/<groupIri>/status BODY: { \"status\": false }","title":"Change Group Status:"},{"location":"03-endpoints/api-admin/groups/#delete-group","text":"Required permission: SystemAdmin / hasProjectAllAdminPermission Remark: The same as changing the groups status to false . To un-delete, set status to true . DELETE: /admin/groups/<groupIri> Example Group Information stored in admin named graph: : <http://rdfh.ch/groups/[shortcode]/[UUID]> rdf:type knora-admin:UserGroup ; knora-admin:groupName \"Name of the group\" ; knora-admin:groupDescriptions \"A description of the group\"@en ; knora-admin:belongsToProject <http://rdfh.ch/projects/[UUID]> ; knora-admin:status \"true\"^^xsd:boolean ; knora-admin:hasSelfJoinEnabled \"false\"^^xsd:boolean .","title":"Delete Group:"},{"location":"03-endpoints/api-admin/groups/#member-operations","text":"","title":"Member Operations"},{"location":"03-endpoints/api-admin/groups/#get-group-members","text":"Returns all group members Required permission: SystemAdmin / ProjectAdmin GET: /admin/groups/<groupIri>/members","title":"Get Group Members"},{"location":"03-endpoints/api-admin/introduction/","text":"Introduction: Using the Admin API The DSP Admin API makes it possible to administer projects, users, user groups, permissions, and hierarchical lists. RESTful API The Knora Admin API is a RESTful API that allows for reading and adding of administrative resources from and to Knora and changing their values using HTTP requests. The actual data is submitted as JSON (request and response format). The various HTTP methods are applied according to the widespread practice of RESTful APIs: GET for reading, POST for adding, PUT for changing resources and values, and DELETE to delete resources or values (see Using HTTP Methods for RESTful Services ). Knora IRIs in the Admin API Every resource that is created or hosted by Knora is identified by a unique ID called an Internationalized Resource Identifier ( IRI ). The IRI is required for every API operation to identify the resource in question. A Knora IRI has itself the format of a URL. For some API operations, the IRI has to be URL-encoded (HTTP GET requests). Unlike the DSP-API v2, the admin API uses internal IRIs, i.e. the actual IRIs that are stored in the triplestore (see Knora IRIs ). Admin Path Segment Every request to Admin API includes admin as a path segment, e.g. http://host/admin/users/iri/http%3A%2F%2Frdfh.ch%2Fusers%2Froot . Admin API Response Format If an API request is handled successfully, Knora responds with a 200 HTTP status code. The actual answer from Knora (the representation of the requested resource or information about the executed API operation) is sent in the HTTP body, encoded as JSON. Placeholder host in sample URLs Please note that all the sample URLs used in this documentation contain host as a placeholder. The placeholder host has to be replaced by the actual hostname (and port) of the server the Knora instance is running on. Authentication For all API operations that target at changing resources or values, the client has to provide credentials (username and password) so that the API server can authenticate the user making the request. Credentials can be sent as a part of the HTTP header or as parts of the URL (see Authentication in Knora ). Admin API Endpoints TODO","title":"Introduction"},{"location":"03-endpoints/api-admin/introduction/#introduction-using-the-admin-api","text":"The DSP Admin API makes it possible to administer projects, users, user groups, permissions, and hierarchical lists.","title":"Introduction: Using the Admin API"},{"location":"03-endpoints/api-admin/introduction/#restful-api","text":"The Knora Admin API is a RESTful API that allows for reading and adding of administrative resources from and to Knora and changing their values using HTTP requests. The actual data is submitted as JSON (request and response format). The various HTTP methods are applied according to the widespread practice of RESTful APIs: GET for reading, POST for adding, PUT for changing resources and values, and DELETE to delete resources or values (see Using HTTP Methods for RESTful Services ).","title":"RESTful API"},{"location":"03-endpoints/api-admin/introduction/#knora-iris-in-the-admin-api","text":"Every resource that is created or hosted by Knora is identified by a unique ID called an Internationalized Resource Identifier ( IRI ). The IRI is required for every API operation to identify the resource in question. A Knora IRI has itself the format of a URL. For some API operations, the IRI has to be URL-encoded (HTTP GET requests). Unlike the DSP-API v2, the admin API uses internal IRIs, i.e. the actual IRIs that are stored in the triplestore (see Knora IRIs ).","title":"Knora IRIs in the Admin API"},{"location":"03-endpoints/api-admin/introduction/#admin-path-segment","text":"Every request to Admin API includes admin as a path segment, e.g. http://host/admin/users/iri/http%3A%2F%2Frdfh.ch%2Fusers%2Froot .","title":"Admin Path Segment"},{"location":"03-endpoints/api-admin/introduction/#admin-api-response-format","text":"If an API request is handled successfully, Knora responds with a 200 HTTP status code. The actual answer from Knora (the representation of the requested resource or information about the executed API operation) is sent in the HTTP body, encoded as JSON.","title":"Admin API Response Format"},{"location":"03-endpoints/api-admin/introduction/#placeholder-host-in-sample-urls","text":"Please note that all the sample URLs used in this documentation contain host as a placeholder. The placeholder host has to be replaced by the actual hostname (and port) of the server the Knora instance is running on.","title":"Placeholder host in sample URLs"},{"location":"03-endpoints/api-admin/introduction/#authentication","text":"For all API operations that target at changing resources or values, the client has to provide credentials (username and password) so that the API server can authenticate the user making the request. Credentials can be sent as a part of the HTTP header or as parts of the URL (see Authentication in Knora ).","title":"Authentication"},{"location":"03-endpoints/api-admin/introduction/#admin-api-endpoints","text":"TODO","title":"Admin API Endpoints"},{"location":"03-endpoints/api-admin/lists/","text":"Lists Endpoint Endpoint Overview List Item Operations: GET: /admin/lists[?projectIri=<projectIri>] : return all lists optionally filtered by project GET: /admin/lists/<listItemIri> : return complete list with all children if IRI of the list (i.e. root node) is given If IRI of the child node is given, return the node with its immediate children GET: /admin/lists/infos/<listIri> : return list information (without children) GET: /admin/lists/nodes/<nodeIri> : return list node information (without children) GET: /admin/lists/<listIri>/info : return list basic information (without children) GET: /admin/lists/candelete/<listItemIri> : check if list or its node is unused and can be deleted POST: /admin/lists : create new list POST: /admin/lists/<parentNodeIri> : create new child node under the supplied parent node IRI PUT: /admin/lists/<listItemIri> : update node information (root or child) PUT: /admin/lists/<listItemIri>/name : update the name of the node (root or child) PUT: /admin/lists/<listItemIri>/labels : update labels of the node (root or child) PUT: /admin/lists/<listItemIri>/comments : update comments of the node (root or child) PUT: /admin/lists/<nodeIri>/position : update position of a child node within its current parent or by changing its parent node DELETE: /admin/lists/<listItemIri> : delete a list (i.e. root node) or a child node and all its children, if not used DELETE: /admin/lists/comments/<nodeIri> : delete comments of a node (child only) List Item Operations Get lists Required permission: none Return all lists optionally filtered by project GET: /admin/lists[?projectIri=<projectIri>] Get list Required permission: none Return complete list (or node ) including basic information of the list (or child node), listinfo (or nodeinfo ), and all its children GET: /admin/lists/<listIri> Get list's information Required permission: none Return list information, listinfo (without children). GET: /admin/lists/infos/<listIri> Get list node Information Required permission: none Return node information, nodeinfo , (without children). GET: /admin/lists/nodes/<nodeIri> Get list's information (merged) Required permission: none Return list (or node) basic information, listinfo (or nodeinfo ), without its children GET: /admin/lists/<listIri>/info Check if list node is unused and can be deleted Required permission: none GET: /admin/lists/candelete/<listItemIri> Return simple JSON that confirms if the list node can be deleted { \"canDeleteList\": true, \"listIri\": \"http://rdfh.ch/lists/0801/xxx\" } List (root node or child node with all its children) can be deleted only if it (or one of its children) is not used. Create new list Required permission: SystemAdmin / ProjectAdmin Required fields: projectIri , labels , comments POST: /admin/lists BODY: { \"projectIri\": \"someprojectiri\", \"labels\": [{ \"value\": \"New list\", \"language\": \"en\"}], \"comments\": [] } Additionally, each list can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\", \"name\": \"a new list\", \"labels\": [{ \"value\": \"New list with IRI\", \"language\": \"en\"}], \"comments\": [{ \"value\": \"New comment\", \"language\": \"en\"}] } The response will contain the basic information of the list, listinfo and an empty list of its children, as below: { \"list\": { \"children\": [], \"listinfo\": { \"comments\": [{ \"value\": \"New comment\", \"language\": \"en\"}], \"id\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"isRootNode\": true, \"labels\": [ { \"value\": \"New list with IRI\", \"language\": \"en\" } ], \"name\": \"a new list\", \"projectIri\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" } } } Create new child node Required permission: SystemAdmin / ProjectAdmin Required fields: parentNodeIri , projectIri , labels , Appends a new child node under the supplied nodeIri. If the supplied nodeIri is the listIri, then a new child node is appended to the top level. If a position is given for the new child node, the node will be created and inserted in the specified position, otherwise the node is appended to the end of parent's children. POST: /admin/lists/<parentNodeIri> BODY: { \"parentNodeIri\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\", \"name\": \"a child\", \"labels\": [{ \"value\": \"New List Node\", \"language\": \"en\"}] } Additionally, each child node can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\": \"http://rdfh.ch/lists/0001/8u37MxBVMbX3XQ8-d31x6w\", \"parentNodeIri\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\", \"name\": \"a child\", \"labels\": [{ \"value\": \"New List Node\", \"language\": \"en\"}] } The response will contain the basic information of the node, nodeinfo , as below: { \"nodeinfo\": { \"comments\": [], \"hasRootNode\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"id\": \"http://rdfh.ch/lists/0001/8u37MxBVMbX3XQ8-d31x6w\", \"labels\": [ { \"value\": \"New List Node\", \"language\": \"en\" } ], \"name\": \"a new child\", \"position\": 1 } } The new node can be created and inserted in a specific position which must be given in the payload as shown below. If necessary, according to the given position, the sibling nodes will be shifted. Note that position cannot have a value higher than the number of existing children. { \"parentNodeIri\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\", \"name\": \"Inserted new child\", \"position\": 0, \"labels\": [{ \"value\": \"New List Node\", \"language\": \"en\"}] } In case the new node should be appended to the list of current children, either position: -1 must be given in the payload or the position parameter must be left out of the payload. Update list's or node's information The basic information of a list (or node) such as its labels, comments, name, or all of them can be updated. The parameters that must be updated together with the new value must be given in the JSON body of the request together with the IRI of the list and the IRI of the project it belongs to. Required permission: SystemAdmin / ProjectAdmin Required fields: listIri , projectIri Update list information PUT: /admin/lists/<listIri> BODY: { \"listIri\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\", \"name\": \"new name for the list\", \"labels\": [{ \"value\": \"a new label for the list\", \"language\": \"en\"}], \"comments\": [{ \"value\": \"a new comment for the list\", \"language\": \"en\"}] } The response will contain the basic information of the list, listinfo (or nodeinfo ), without its children, as below: { \"listinfo\": { \"comments\": [ { \"value\": \"a new comment for the list\", \"language\": \"en\" } ], \"id\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"isRootNode\": true, \"labels\": [ { \"value\": \"a new label for the list\", \"language\": \"en\" } ], \"name\": \"new name for the list\", \"projectIri\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" } } If only name of the list must be updated, it can be given as below in the body of the request: { \"listIri\": \"listIri\", \"projectIri\": \"someprojectiri\", \"name\": \"another name\" } Alternatively, basic information name , labels , or comments of the root node (i.e. list) can be updated individually as explained below. Update list or node's name Required permission: SystemAdmin / ProjectAdmin Update name of the list (i.e. root node) or a child node whose IRI is specified by <listItemIri> . PUT: /admin/lists/<listItemIri>/name BODY: The new name of the node must be given in the body of the request as shown below: ```json { \"name\": \"a new name\" } There is no need to specify the project IRI because it is automatically extracted using the given `<listItemIRI>`. ### Update list or node's labels - Required permission: SystemAdmin / ProjectAdmin - Update labels of the list (i.e. root node) or a child node whose IRI is specified by `<listItemIri>`. - PUT: `/admin/lists/<listItemIri>/labels` - BODY: The new set of labels of the node must be given in the body of the request as shown below: ```json { \"labels\": [{\"language\": \"se\", \"value\": \"nya m\u00e4rkningen\"}] } There is no need to specify the project IRI because it is automatically extracted using the given <listItemIRI> . Update list or node's comments Required permission: SystemAdmin / ProjectAdmin Update comments of the list (i.e. root node) or a child node whose IRI is specified by <listItemIri> . PUT: /admin/lists/<listItemIri>/labels BODY: The new set of comments of the node must be given in the body of the request as shown below: ```json { \"comments\": [{\"language\": \"se\", \"value\": \"nya kommentarer\"}] } There is no need to specify the project IRI because it is automatically extracted using the given `<listItemIRI>`. ### Repositioning a child node The position of an existing child node can be updated. The child node can be either repositioned within its current parent node, or can be added to another parent node in a specific position. The IRI of the parent node and the new position of the child node must be given in the request body. If a node is supposed to be repositioned to the end of a parent node's children, give `position: -1`. Suppose a parent node `parentNode1` has five children in positions 0-4, to change the position of its child node `childNode4` from its original position 3 to position 1 the request body should specify the IRI of its parent node and the new position as below: ```json { \"parentNodeIri\": \"<parentNode1-IRI>\", \"position\": 1 } Then the node childNode4 will be put in position 1, and its siblings will be shifted accordingly. The new position given in the request body cannot be the same as the child node's original position. If position: -1 is given, the node will be moved to the end of children list, and its siblings will be shifted to left. In case of repositioning the node within its current parent, the maximum permitted position is the length of its children list, i.e. in this example the highest allowed position is 4. To reposition a child node childNode4 to another parent node parentNode2 in a specific position, for example position: 3 , the IRI of the new parent node and the position the node must be placed within children of parentNode2 must be given as: { \"parentNodeIri\": \"<parentNode2-IRI>\", \"position\": 3 } In this case, the childNode4 is removed from the list of children of its old parent parentNode1 and its old siblings are shifted accordingly. Then the node childNode4 is added to the specified new parent, i.e. parentNode2 , in the given position. The new siblings are shifted accordingly. Note that, the furthest the node can be placed is at the end of the list of the children of parentNode2 . That means if parentNode2 had 3 children with positions 0-2, then childNode4 can be placed in position 0-3 within children of its new parent node. If the position: -1 is given, the node will be appended to the end of new parent's children, and new siblings will not be shifted. Values less than -1 are not permitted for parameter position . Required permission: SystemAdmin / ProjectAdmin Response: returns the updated parent node with all its children. Put /admin/lists/<nodeIri>/position Delete a list or a node An entire list or a single node of it can be completely deleted, if not in use. Before deleting an entire list (i.e. root node), the data and ontologies are checked for any usage of the list or its children. If not in use, the list and all its children are deleted. Similarily, before deleting a single node of a list, it is verified that the node itself and none of its children are used. If not in use, the node and all its children are deleted. Once a node is deleted, its parent node is updated by shifting the remaining child nodes with respect to the position of the deleted node. Required permission: SystemAdmin / ProjectAdmin Response: If the IRI of the list (i.e. root node) is given, the iri of the deleted list with a flag deleted: true is returned. If the IRI of a child node is given, the updated parent node is returned. Delete /admin/lists/<listItemIri> Delete child node comments Performing a DELETE request to route /admin/lists/comments/<nodeIri> deletes the comments of that node. As a response sipmle JSON is returned: { \"commentsDeleted\": true, \"nodeIri\": \"http://rdfh.ch/lists/0801/xxx\" }","title":"Lists Endpoint"},{"location":"03-endpoints/api-admin/lists/#lists-endpoint","text":"","title":"Lists Endpoint"},{"location":"03-endpoints/api-admin/lists/#endpoint-overview","text":"List Item Operations: GET: /admin/lists[?projectIri=<projectIri>] : return all lists optionally filtered by project GET: /admin/lists/<listItemIri> : return complete list with all children if IRI of the list (i.e. root node) is given If IRI of the child node is given, return the node with its immediate children GET: /admin/lists/infos/<listIri> : return list information (without children) GET: /admin/lists/nodes/<nodeIri> : return list node information (without children) GET: /admin/lists/<listIri>/info : return list basic information (without children) GET: /admin/lists/candelete/<listItemIri> : check if list or its node is unused and can be deleted POST: /admin/lists : create new list POST: /admin/lists/<parentNodeIri> : create new child node under the supplied parent node IRI PUT: /admin/lists/<listItemIri> : update node information (root or child) PUT: /admin/lists/<listItemIri>/name : update the name of the node (root or child) PUT: /admin/lists/<listItemIri>/labels : update labels of the node (root or child) PUT: /admin/lists/<listItemIri>/comments : update comments of the node (root or child) PUT: /admin/lists/<nodeIri>/position : update position of a child node within its current parent or by changing its parent node DELETE: /admin/lists/<listItemIri> : delete a list (i.e. root node) or a child node and all its children, if not used DELETE: /admin/lists/comments/<nodeIri> : delete comments of a node (child only)","title":"Endpoint Overview"},{"location":"03-endpoints/api-admin/lists/#list-item-operations","text":"","title":"List Item Operations"},{"location":"03-endpoints/api-admin/lists/#get-lists","text":"Required permission: none Return all lists optionally filtered by project GET: /admin/lists[?projectIri=<projectIri>]","title":"Get lists"},{"location":"03-endpoints/api-admin/lists/#get-list","text":"Required permission: none Return complete list (or node ) including basic information of the list (or child node), listinfo (or nodeinfo ), and all its children GET: /admin/lists/<listIri>","title":"Get list"},{"location":"03-endpoints/api-admin/lists/#get-lists-information","text":"Required permission: none Return list information, listinfo (without children). GET: /admin/lists/infos/<listIri>","title":"Get list's information"},{"location":"03-endpoints/api-admin/lists/#get-list-node-information","text":"Required permission: none Return node information, nodeinfo , (without children). GET: /admin/lists/nodes/<nodeIri>","title":"Get list node Information"},{"location":"03-endpoints/api-admin/lists/#get-lists-information-merged","text":"Required permission: none Return list (or node) basic information, listinfo (or nodeinfo ), without its children GET: /admin/lists/<listIri>/info","title":"Get list's information (merged)"},{"location":"03-endpoints/api-admin/lists/#check-if-list-node-is-unused-and-can-be-deleted","text":"Required permission: none GET: /admin/lists/candelete/<listItemIri> Return simple JSON that confirms if the list node can be deleted { \"canDeleteList\": true, \"listIri\": \"http://rdfh.ch/lists/0801/xxx\" } List (root node or child node with all its children) can be deleted only if it (or one of its children) is not used.","title":"Check if list node is unused and can be deleted"},{"location":"03-endpoints/api-admin/lists/#create-new-list","text":"Required permission: SystemAdmin / ProjectAdmin Required fields: projectIri , labels , comments POST: /admin/lists BODY: { \"projectIri\": \"someprojectiri\", \"labels\": [{ \"value\": \"New list\", \"language\": \"en\"}], \"comments\": [] } Additionally, each list can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\", \"name\": \"a new list\", \"labels\": [{ \"value\": \"New list with IRI\", \"language\": \"en\"}], \"comments\": [{ \"value\": \"New comment\", \"language\": \"en\"}] } The response will contain the basic information of the list, listinfo and an empty list of its children, as below: { \"list\": { \"children\": [], \"listinfo\": { \"comments\": [{ \"value\": \"New comment\", \"language\": \"en\"}], \"id\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"isRootNode\": true, \"labels\": [ { \"value\": \"New list with IRI\", \"language\": \"en\" } ], \"name\": \"a new list\", \"projectIri\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" } } }","title":"Create new list"},{"location":"03-endpoints/api-admin/lists/#create-new-child-node","text":"Required permission: SystemAdmin / ProjectAdmin Required fields: parentNodeIri , projectIri , labels , Appends a new child node under the supplied nodeIri. If the supplied nodeIri is the listIri, then a new child node is appended to the top level. If a position is given for the new child node, the node will be created and inserted in the specified position, otherwise the node is appended to the end of parent's children. POST: /admin/lists/<parentNodeIri> BODY: { \"parentNodeIri\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\", \"name\": \"a child\", \"labels\": [{ \"value\": \"New List Node\", \"language\": \"en\"}] } Additionally, each child node can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\": \"http://rdfh.ch/lists/0001/8u37MxBVMbX3XQ8-d31x6w\", \"parentNodeIri\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\", \"name\": \"a child\", \"labels\": [{ \"value\": \"New List Node\", \"language\": \"en\"}] } The response will contain the basic information of the node, nodeinfo , as below: { \"nodeinfo\": { \"comments\": [], \"hasRootNode\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"id\": \"http://rdfh.ch/lists/0001/8u37MxBVMbX3XQ8-d31x6w\", \"labels\": [ { \"value\": \"New List Node\", \"language\": \"en\" } ], \"name\": \"a new child\", \"position\": 1 } } The new node can be created and inserted in a specific position which must be given in the payload as shown below. If necessary, according to the given position, the sibling nodes will be shifted. Note that position cannot have a value higher than the number of existing children. { \"parentNodeIri\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\", \"name\": \"Inserted new child\", \"position\": 0, \"labels\": [{ \"value\": \"New List Node\", \"language\": \"en\"}] } In case the new node should be appended to the list of current children, either position: -1 must be given in the payload or the position parameter must be left out of the payload.","title":"Create new child node"},{"location":"03-endpoints/api-admin/lists/#update-lists-or-nodes-information","text":"The basic information of a list (or node) such as its labels, comments, name, or all of them can be updated. The parameters that must be updated together with the new value must be given in the JSON body of the request together with the IRI of the list and the IRI of the project it belongs to. Required permission: SystemAdmin / ProjectAdmin Required fields: listIri , projectIri Update list information PUT: /admin/lists/<listIri> BODY: { \"listIri\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"projectIri\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\", \"name\": \"new name for the list\", \"labels\": [{ \"value\": \"a new label for the list\", \"language\": \"en\"}], \"comments\": [{ \"value\": \"a new comment for the list\", \"language\": \"en\"}] } The response will contain the basic information of the list, listinfo (or nodeinfo ), without its children, as below: { \"listinfo\": { \"comments\": [ { \"value\": \"a new comment for the list\", \"language\": \"en\" } ], \"id\": \"http://rdfh.ch/lists/0001/yWQEGXl53Z4C4DYJ-S2c5A\", \"isRootNode\": true, \"labels\": [ { \"value\": \"a new label for the list\", \"language\": \"en\" } ], \"name\": \"new name for the list\", \"projectIri\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" } } If only name of the list must be updated, it can be given as below in the body of the request: { \"listIri\": \"listIri\", \"projectIri\": \"someprojectiri\", \"name\": \"another name\" } Alternatively, basic information name , labels , or comments of the root node (i.e. list) can be updated individually as explained below.","title":"Update list's or node's information"},{"location":"03-endpoints/api-admin/lists/#update-list-or-nodes-name","text":"Required permission: SystemAdmin / ProjectAdmin Update name of the list (i.e. root node) or a child node whose IRI is specified by <listItemIri> . PUT: /admin/lists/<listItemIri>/name BODY: The new name of the node must be given in the body of the request as shown below: ```json { \"name\": \"a new name\" } There is no need to specify the project IRI because it is automatically extracted using the given `<listItemIRI>`. ### Update list or node's labels - Required permission: SystemAdmin / ProjectAdmin - Update labels of the list (i.e. root node) or a child node whose IRI is specified by `<listItemIri>`. - PUT: `/admin/lists/<listItemIri>/labels` - BODY: The new set of labels of the node must be given in the body of the request as shown below: ```json { \"labels\": [{\"language\": \"se\", \"value\": \"nya m\u00e4rkningen\"}] } There is no need to specify the project IRI because it is automatically extracted using the given <listItemIRI> .","title":"Update list or node's name"},{"location":"03-endpoints/api-admin/lists/#update-list-or-nodes-comments","text":"Required permission: SystemAdmin / ProjectAdmin Update comments of the list (i.e. root node) or a child node whose IRI is specified by <listItemIri> . PUT: /admin/lists/<listItemIri>/labels BODY: The new set of comments of the node must be given in the body of the request as shown below: ```json { \"comments\": [{\"language\": \"se\", \"value\": \"nya kommentarer\"}] } There is no need to specify the project IRI because it is automatically extracted using the given `<listItemIRI>`. ### Repositioning a child node The position of an existing child node can be updated. The child node can be either repositioned within its current parent node, or can be added to another parent node in a specific position. The IRI of the parent node and the new position of the child node must be given in the request body. If a node is supposed to be repositioned to the end of a parent node's children, give `position: -1`. Suppose a parent node `parentNode1` has five children in positions 0-4, to change the position of its child node `childNode4` from its original position 3 to position 1 the request body should specify the IRI of its parent node and the new position as below: ```json { \"parentNodeIri\": \"<parentNode1-IRI>\", \"position\": 1 } Then the node childNode4 will be put in position 1, and its siblings will be shifted accordingly. The new position given in the request body cannot be the same as the child node's original position. If position: -1 is given, the node will be moved to the end of children list, and its siblings will be shifted to left. In case of repositioning the node within its current parent, the maximum permitted position is the length of its children list, i.e. in this example the highest allowed position is 4. To reposition a child node childNode4 to another parent node parentNode2 in a specific position, for example position: 3 , the IRI of the new parent node and the position the node must be placed within children of parentNode2 must be given as: { \"parentNodeIri\": \"<parentNode2-IRI>\", \"position\": 3 } In this case, the childNode4 is removed from the list of children of its old parent parentNode1 and its old siblings are shifted accordingly. Then the node childNode4 is added to the specified new parent, i.e. parentNode2 , in the given position. The new siblings are shifted accordingly. Note that, the furthest the node can be placed is at the end of the list of the children of parentNode2 . That means if parentNode2 had 3 children with positions 0-2, then childNode4 can be placed in position 0-3 within children of its new parent node. If the position: -1 is given, the node will be appended to the end of new parent's children, and new siblings will not be shifted. Values less than -1 are not permitted for parameter position . Required permission: SystemAdmin / ProjectAdmin Response: returns the updated parent node with all its children. Put /admin/lists/<nodeIri>/position","title":"Update list or node's comments"},{"location":"03-endpoints/api-admin/lists/#delete-a-list-or-a-node","text":"An entire list or a single node of it can be completely deleted, if not in use. Before deleting an entire list (i.e. root node), the data and ontologies are checked for any usage of the list or its children. If not in use, the list and all its children are deleted. Similarily, before deleting a single node of a list, it is verified that the node itself and none of its children are used. If not in use, the node and all its children are deleted. Once a node is deleted, its parent node is updated by shifting the remaining child nodes with respect to the position of the deleted node. Required permission: SystemAdmin / ProjectAdmin Response: If the IRI of the list (i.e. root node) is given, the iri of the deleted list with a flag deleted: true is returned. If the IRI of a child node is given, the updated parent node is returned. Delete /admin/lists/<listItemIri>","title":"Delete a list or a node"},{"location":"03-endpoints/api-admin/lists/#delete-child-node-comments","text":"Performing a DELETE request to route /admin/lists/comments/<nodeIri> deletes the comments of that node. As a response sipmle JSON is returned: { \"commentsDeleted\": true, \"nodeIri\": \"http://rdfh.ch/lists/0801/xxx\" }","title":"Delete child node comments"},{"location":"03-endpoints/api-admin/overview/","text":"Admin Endpoint For the management of users , projects , and groups , the DSP-API following a resource centric approach, provides three endpoints corresponding to the three classes of objects that they have an effect on, namely: Users Endpoint: http://server:port/admin/users - knora-base:User Projects Endpoint: http://server:port/admin/projects - knora-base:knoraProject Groups Endpoint: http://server:port/admin/groups - knora-base:UserGroup All information regarding users, projects and groups is stored in the http://www.knora.org/admin named graph.","title":"Overview"},{"location":"03-endpoints/api-admin/overview/#admin-endpoint","text":"For the management of users , projects , and groups , the DSP-API following a resource centric approach, provides three endpoints corresponding to the three classes of objects that they have an effect on, namely: Users Endpoint: http://server:port/admin/users - knora-base:User Projects Endpoint: http://server:port/admin/projects - knora-base:knoraProject Groups Endpoint: http://server:port/admin/groups - knora-base:UserGroup All information regarding users, projects and groups is stored in the http://www.knora.org/admin named graph.","title":"Admin Endpoint"},{"location":"03-endpoints/api-admin/permissions/","text":"Permissions Endpoint Permission Operations: Note: For the following operations, the requesting user must be either a systemAdmin or a projectAdmin . Getting Permissions: GET: /admin/permissions/<projectIri> : return all permissions for a project. As a response, the IRI and the type of all permissions of a project are returned. GET: /admin/permissions/ap/<projectIri> : return all administrative permissions for a project. As a response, all administrative_permissions of a project are returned. GET: /admin/permissions/ap/<projectIri>/<groupIri> : return the administrative permissions for a project group. As a response, the administrative_permission defined for the group is returned. GET: /admin/permissions/doap/<projectIri> : return all default object access permissions for a project. As a response, all default_object_acces_permissions of a project are returned. Creating New Administrative Permissions: POST: /admin/permissions/ap : create a new administrative permission. The type of permissions, the project and group to which the permission should be added must be included in the request body, for example: { \"forGroup\":\"http://rdfh.ch/groups/0001/thing-searcher\", \"forProject\":\"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\", \"hasPermissions\":[ { \"additionalInformation\":null, \"name\":\"ProjectAdminGroupAllPermission\", \"permissionCode\":null } ] } In addition, in the body of the request, it is possible to specify a custom IRI (of Knora IRI form) for a permission through the @id attribute which will then be assigned to the permission; otherwise the permission will get a unique random IRI. A custom permission IRI must be http://rdfh.ch/permissions/PROJECT_SHORTCODE/ (where PROJECT_SHORTCODE is the shortcode of the project that the permission belongs to), plus a custom ID string. For example: \"id\": \"http://rdfh.ch/permissions/0001/jKIYuaEUETBcyxpenUwRzQ\", As a response, the created administrative permission and its IRI are returned as below: { \"administrative_permission\": { \"forGroup\": \"http://rdfh.ch/groups/0001/thing-searcher\", \"forProject\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\", \"hasPermissions\": [ { \"additionalInformation\": null, \"name\": \"ProjectAdminGroupAllPermission\", \"permissionCode\": null } ], \"iri\": \"http://rdfh.ch/permissions/0001/mFlyBEiMQtGzwy_hK0M-Ow\" } } hasPermissions contains permission types that must be granted. See the complete description of administrative permission types . In summary, each permission should contain followings: additionalInformation : should be left empty, otherwise will be ignored. name : indicates the type of the permission that can be one of the followings: ProjectAdminAllPermission : gives the user the permission to do anything on project level, i.e. create new groups, modify all existing groups ProjectAdminGroupAllPermission : gives the user the permission to modify group info and group membership on all groups belonging to the project. ProjectAdminGroupRestrictedPermission : gives the user the permission to modify group info and group membership on certain groups belonging to the project. ProjectAdminRightsAllPermission : gives the user the permission to change the permissions on all objects belonging to the project (e.g., default permissions attached to groups and permissions on objects). ProjectResourceCreateAllPermission : gives the permission to create resources inside the project. ProjectResourceCreateRestrictedPermission : gives restricted resource creation permission inside the project. permissionCode : should be left empty, otherwise will be ignored. Note that during the creation of a new project, a default set of administrative permissions are added to its ProjectAdmin and ProjectMember groups (See Default set of permissions for a new project ). Therefore, it is not possible to create new administrative permissions for the ProjectAdmin and ProjectMember groups of a project. However, the default permissions set for these groups can be modified (See update permission ). Creating New Default Object Access Permissions: POST: /admin/permissions/doap : create a new default object access permission. A single instance of knora-admin:DefaultObjectAccessPermission must always reference a project, but can only reference either a group ( knora-admin:forGroup property), a resource class ( knora-admin:forResourceClass ), a property ( knora-admin:forProperty ), or a combination of resource class and property. For example, to create a new default object access permission for a group of a project the request body would be { \"forGroup\":\"http://rdfh.ch/groups/0001/thing-searcher\", \"forProject\":\"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\", \"forProperty\":null, \"forResourceClass\":null, \"hasPermissions\":[ { \"additionalInformation\":\"http://www.knora.org/ontology/knora-admin#ProjectMember\", \"name\":\"D\", \"permissionCode\":7 } ] } hasPermissions contains permission types that must be granted. See a complete description of object access permission types . In summary, each permission should contain followings: additionalInformation : To whom the permission should be granted: project members, known users, unknown users, etc. name : indicates the type of the permission that can be one of the followings. RV : restricted view permission (least privileged) V : view permission M modify permission D : delete permission CR : change rights permission (most privileged) permissionCode : The code assigned to a permission indicating its hierarchical level. These codes are as below: 1 : for restricted view permission (least privileged) 2 : for view permission 6 : for modify permission 7 : for delete permission 8 : for change rights permission (most privileged) Note that, at least either name or permissionCode must be provided. If one is missing, it will be extrapolated from the other. For example, if permissionCode= 1 is given but name was left empty, its value will be set to name = RV . Similar to the previous case a custom IRI can be assigned to a permission specified by the id in the request body. The example below shows the request body to create a new default object access permission with a custom IRI defined for a resource class of a specific project: { \"id\": \"http://rdfh.ch/permissions/00FF/fSw7w1sI5IwDjEfFi1jOeQ\", \"forGroup\":null, \"forProject\":\"http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA\", \"forProperty\":null, \"forResourceClass\":\"http://www.knora.org/ontology/00FF/images#bild\", \"hasPermissions\":[ { \"additionalInformation\":\"http://www.knora.org/ontology/knora-admin#ProjectMember\", \"name\":\"D\", \"permissionCode\":7 } ] } The response contains the newly created permission and its IRI, as: { \"default_object_access_permission\": { \"forGroup\": null, \"forProject\": \"http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA\", \"forProperty\": null, \"forResourceClass\": \"http://www.knora.org/ontology/00FF/images#bild\", \"hasPermissions\": [ { \"additionalInformation\": \"http://www.knora.org/ontology/knora-admin#ProjectMember\", \"name\": \"D\", \"permissionCode\": 7 } ], \"iri\": \"http://rdfh.ch/permissions/00FF/fSw7w1sI5IwDjEfFi1jOeQ\" } } Note that during the creation of a new project, a set of default object access permissions are created for its ProjectAdmin and ProjectMember groups (See Default set of permissions for a new project ). Therefore, it is not possible to create new default object access permissions for the ProjectAdmin and ProjectMember groups of a project. However, the default permissions set for these groups can be modified; see below for more information. Updating a Permission's Group: PUT: /admin/permissions/<permissionIri>/group to change the group for which an administrative or a default object access permission, identified by it IRI <permissionIri> , is defined. The request body must contain the IRI of the new group as below: { \"forGroup\": \"http://www.knora.org/ontology/knora-admin#ProjectMember\" } When updating an administrative permission, its previous forGroup value will be replaced with the new one. When updating a default object access permission, if it originally had a forGroup value defined, it will be replaced with the new group. Otherwise, if the default object access permission was defined for a resource class or a property or the combination of both, the permission will be defined for the newly specified group and its previous forResourceClass and forProperty values will be deleted. Updating a Permission's Scope: PUT: /admin/permissions/<permissionIri>/hasPermissions to change the scope of permissions assigned to an administrative or a default object access permission identified by it IRI, <permissionIri> . The request body must contain the new set of permission types as below: { \"hasPermissions\":[ { \"additionalInformation\":\"http://www.knora.org/ontology/knora-admin#ProjectMember\", \"name\":\"D\", \"permissionCode\":7 } ] } Each permission item given in hasPermissions , must contain the necessary parameters with respect to the type of the permission. For example, if you wish to change the scope of an administrative permission, follow the guidelines for the content of its hasPermissions property. Similarly, if you wish to change the scope of a default object access permission, follow the guidelines given about the content of its hasPermissions property. Updating a Default Object Access Permission's Resource Class: PUT: /admin/permissions/<doap_permissionIri>/resourceClass to change the resource class for which a default object access permission, identified by it IRI <doap_permissionIri> , is defined. This operation is only valid for updating a default object acceess permission. The IRI of the new resource class must be given in the request body as: { \"forResourceClass\": \"http://www.knora.org/ontology/0803/incunabula#book\" } Note that if the default object access permission was originally defined for a group, with this operation, the permission will be defined for the given resource class instead of the group. That means the value of the forGroup will be deleted. Updating a Default Object Access Permission's Property: PUT: /admin/permissions/<doap_permissionIri>/property to change the property for which a default object access permission, identified by it IRI <doap_permissionIri> , is defined. This operation is only valid for updating a default object access permission. The IRI of the new property must be given in the request body as: { \"forProperty\":\"http://www.knora.org/ontology/00FF/images#titel\" } Note that if the default object access permission was originally defined for a group, with this operation, the permission will be defined for the given property instead of the group. That means the value of the forGroup will be deleted. Deleting a permission: DELETE: /admin/permissions/<permissionIri> to delete an administrative, or a default object access permission. The IRI of the permission must be given in encoded form.","title":"Permissions Endpoint"},{"location":"03-endpoints/api-admin/permissions/#permissions-endpoint","text":"","title":"Permissions Endpoint"},{"location":"03-endpoints/api-admin/permissions/#permission-operations","text":"Note: For the following operations, the requesting user must be either a systemAdmin or a projectAdmin .","title":"Permission Operations:"},{"location":"03-endpoints/api-admin/permissions/#getting-permissions","text":"GET: /admin/permissions/<projectIri> : return all permissions for a project. As a response, the IRI and the type of all permissions of a project are returned. GET: /admin/permissions/ap/<projectIri> : return all administrative permissions for a project. As a response, all administrative_permissions of a project are returned. GET: /admin/permissions/ap/<projectIri>/<groupIri> : return the administrative permissions for a project group. As a response, the administrative_permission defined for the group is returned. GET: /admin/permissions/doap/<projectIri> : return all default object access permissions for a project. As a response, all default_object_acces_permissions of a project are returned.","title":"Getting Permissions:"},{"location":"03-endpoints/api-admin/permissions/#creating-new-administrative-permissions","text":"POST: /admin/permissions/ap : create a new administrative permission. The type of permissions, the project and group to which the permission should be added must be included in the request body, for example: { \"forGroup\":\"http://rdfh.ch/groups/0001/thing-searcher\", \"forProject\":\"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\", \"hasPermissions\":[ { \"additionalInformation\":null, \"name\":\"ProjectAdminGroupAllPermission\", \"permissionCode\":null } ] } In addition, in the body of the request, it is possible to specify a custom IRI (of Knora IRI form) for a permission through the @id attribute which will then be assigned to the permission; otherwise the permission will get a unique random IRI. A custom permission IRI must be http://rdfh.ch/permissions/PROJECT_SHORTCODE/ (where PROJECT_SHORTCODE is the shortcode of the project that the permission belongs to), plus a custom ID string. For example: \"id\": \"http://rdfh.ch/permissions/0001/jKIYuaEUETBcyxpenUwRzQ\", As a response, the created administrative permission and its IRI are returned as below: { \"administrative_permission\": { \"forGroup\": \"http://rdfh.ch/groups/0001/thing-searcher\", \"forProject\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\", \"hasPermissions\": [ { \"additionalInformation\": null, \"name\": \"ProjectAdminGroupAllPermission\", \"permissionCode\": null } ], \"iri\": \"http://rdfh.ch/permissions/0001/mFlyBEiMQtGzwy_hK0M-Ow\" } } hasPermissions contains permission types that must be granted. See the complete description of administrative permission types . In summary, each permission should contain followings: additionalInformation : should be left empty, otherwise will be ignored. name : indicates the type of the permission that can be one of the followings: ProjectAdminAllPermission : gives the user the permission to do anything on project level, i.e. create new groups, modify all existing groups ProjectAdminGroupAllPermission : gives the user the permission to modify group info and group membership on all groups belonging to the project. ProjectAdminGroupRestrictedPermission : gives the user the permission to modify group info and group membership on certain groups belonging to the project. ProjectAdminRightsAllPermission : gives the user the permission to change the permissions on all objects belonging to the project (e.g., default permissions attached to groups and permissions on objects). ProjectResourceCreateAllPermission : gives the permission to create resources inside the project. ProjectResourceCreateRestrictedPermission : gives restricted resource creation permission inside the project. permissionCode : should be left empty, otherwise will be ignored. Note that during the creation of a new project, a default set of administrative permissions are added to its ProjectAdmin and ProjectMember groups (See Default set of permissions for a new project ). Therefore, it is not possible to create new administrative permissions for the ProjectAdmin and ProjectMember groups of a project. However, the default permissions set for these groups can be modified (See update permission ).","title":"Creating New Administrative Permissions:"},{"location":"03-endpoints/api-admin/permissions/#creating-new-default-object-access-permissions","text":"POST: /admin/permissions/doap : create a new default object access permission. A single instance of knora-admin:DefaultObjectAccessPermission must always reference a project, but can only reference either a group ( knora-admin:forGroup property), a resource class ( knora-admin:forResourceClass ), a property ( knora-admin:forProperty ), or a combination of resource class and property. For example, to create a new default object access permission for a group of a project the request body would be { \"forGroup\":\"http://rdfh.ch/groups/0001/thing-searcher\", \"forProject\":\"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\", \"forProperty\":null, \"forResourceClass\":null, \"hasPermissions\":[ { \"additionalInformation\":\"http://www.knora.org/ontology/knora-admin#ProjectMember\", \"name\":\"D\", \"permissionCode\":7 } ] } hasPermissions contains permission types that must be granted. See a complete description of object access permission types . In summary, each permission should contain followings: additionalInformation : To whom the permission should be granted: project members, known users, unknown users, etc. name : indicates the type of the permission that can be one of the followings. RV : restricted view permission (least privileged) V : view permission M modify permission D : delete permission CR : change rights permission (most privileged) permissionCode : The code assigned to a permission indicating its hierarchical level. These codes are as below: 1 : for restricted view permission (least privileged) 2 : for view permission 6 : for modify permission 7 : for delete permission 8 : for change rights permission (most privileged) Note that, at least either name or permissionCode must be provided. If one is missing, it will be extrapolated from the other. For example, if permissionCode= 1 is given but name was left empty, its value will be set to name = RV . Similar to the previous case a custom IRI can be assigned to a permission specified by the id in the request body. The example below shows the request body to create a new default object access permission with a custom IRI defined for a resource class of a specific project: { \"id\": \"http://rdfh.ch/permissions/00FF/fSw7w1sI5IwDjEfFi1jOeQ\", \"forGroup\":null, \"forProject\":\"http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA\", \"forProperty\":null, \"forResourceClass\":\"http://www.knora.org/ontology/00FF/images#bild\", \"hasPermissions\":[ { \"additionalInformation\":\"http://www.knora.org/ontology/knora-admin#ProjectMember\", \"name\":\"D\", \"permissionCode\":7 } ] } The response contains the newly created permission and its IRI, as: { \"default_object_access_permission\": { \"forGroup\": null, \"forProject\": \"http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA\", \"forProperty\": null, \"forResourceClass\": \"http://www.knora.org/ontology/00FF/images#bild\", \"hasPermissions\": [ { \"additionalInformation\": \"http://www.knora.org/ontology/knora-admin#ProjectMember\", \"name\": \"D\", \"permissionCode\": 7 } ], \"iri\": \"http://rdfh.ch/permissions/00FF/fSw7w1sI5IwDjEfFi1jOeQ\" } } Note that during the creation of a new project, a set of default object access permissions are created for its ProjectAdmin and ProjectMember groups (See Default set of permissions for a new project ). Therefore, it is not possible to create new default object access permissions for the ProjectAdmin and ProjectMember groups of a project. However, the default permissions set for these groups can be modified; see below for more information.","title":"Creating New Default Object Access Permissions:"},{"location":"03-endpoints/api-admin/permissions/#updating-a-permissions-group","text":"PUT: /admin/permissions/<permissionIri>/group to change the group for which an administrative or a default object access permission, identified by it IRI <permissionIri> , is defined. The request body must contain the IRI of the new group as below: { \"forGroup\": \"http://www.knora.org/ontology/knora-admin#ProjectMember\" } When updating an administrative permission, its previous forGroup value will be replaced with the new one. When updating a default object access permission, if it originally had a forGroup value defined, it will be replaced with the new group. Otherwise, if the default object access permission was defined for a resource class or a property or the combination of both, the permission will be defined for the newly specified group and its previous forResourceClass and forProperty values will be deleted.","title":"Updating a Permission's Group:"},{"location":"03-endpoints/api-admin/permissions/#updating-a-permissions-scope","text":"PUT: /admin/permissions/<permissionIri>/hasPermissions to change the scope of permissions assigned to an administrative or a default object access permission identified by it IRI, <permissionIri> . The request body must contain the new set of permission types as below: { \"hasPermissions\":[ { \"additionalInformation\":\"http://www.knora.org/ontology/knora-admin#ProjectMember\", \"name\":\"D\", \"permissionCode\":7 } ] } Each permission item given in hasPermissions , must contain the necessary parameters with respect to the type of the permission. For example, if you wish to change the scope of an administrative permission, follow the guidelines for the content of its hasPermissions property. Similarly, if you wish to change the scope of a default object access permission, follow the guidelines given about the content of its hasPermissions property.","title":"Updating a Permission's Scope:"},{"location":"03-endpoints/api-admin/permissions/#updating-a-default-object-access-permissions-resource-class","text":"PUT: /admin/permissions/<doap_permissionIri>/resourceClass to change the resource class for which a default object access permission, identified by it IRI <doap_permissionIri> , is defined. This operation is only valid for updating a default object acceess permission. The IRI of the new resource class must be given in the request body as: { \"forResourceClass\": \"http://www.knora.org/ontology/0803/incunabula#book\" } Note that if the default object access permission was originally defined for a group, with this operation, the permission will be defined for the given resource class instead of the group. That means the value of the forGroup will be deleted.","title":"Updating a Default Object Access Permission's Resource Class:"},{"location":"03-endpoints/api-admin/permissions/#updating-a-default-object-access-permissions-property","text":"PUT: /admin/permissions/<doap_permissionIri>/property to change the property for which a default object access permission, identified by it IRI <doap_permissionIri> , is defined. This operation is only valid for updating a default object access permission. The IRI of the new property must be given in the request body as: { \"forProperty\":\"http://www.knora.org/ontology/00FF/images#titel\" } Note that if the default object access permission was originally defined for a group, with this operation, the permission will be defined for the given property instead of the group. That means the value of the forGroup will be deleted.","title":"Updating a Default Object Access Permission's Property:"},{"location":"03-endpoints/api-admin/permissions/#deleting-a-permission","text":"DELETE: /admin/permissions/<permissionIri> to delete an administrative, or a default object access permission. The IRI of the permission must be given in encoded form.","title":"Deleting a permission:"},{"location":"03-endpoints/api-admin/projects/","text":"Projects Endpoint Endpoint Overview Project Operations: GET: /admin/projects : return all projects POST: /admin/projects : create a new project GET: /admin/projects/[iri | shortname | shortcode | uuid]/<identifier> : returns a single project identified either through iri, shortname, shortcode or UUID PUT: /admin/projects/iri/<identifier> : update a project identified by iri DELETE: /admin/projects/iri/<identifier> : update project status to false GET: /admin/projects/iri/<identifier>/AllData : returns a TriG file containing the project's data Project Member Operations: GET: /admin/projects/[iri | shortname | shortcode | uuid]/<identifier>/members : returns all members part of a project identified through iri, shortname, shortcode or UUID Project Admin Member Operations: GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/admin-members : returns all admin members part of a project identified through iri, shortname or shortcode Project Keyword Operations: GET: /admin/projects/Keywords : returns all unique keywords for all projects as a list GET: /admin/projects/iri/<identifier>/Keywords : returns all keywords for a single project Project Restricted View Settings Operations: GET: /admin/projects/iri/<identifier>/RestrictedViewSettings : returns the project's restricted view settings Project Operations Create a new project: Required permission: SystemAdmin Required information: shortcode (unique, 4-digits) shortname (unique; it should be in the form of a xsd:NCNAME and it should be URL safe.) description (collection of descriptions as strings with language tag.) keywords (collection of keywords) status (true, if project is active. false, if project is inactive) selfjoin Optional information: longname, logo Returns information about the newly created project Remark: There are two distinct use cases / payload combination: (1) change ontology and data graph: ontologygraph, datagraph, (2) basic project information: shortcode, shortname, longname, description, keywords, logo, institution, status, selfjoin POST: /admin/projects/ BODY: { \"shortname\": \"newproject\", \"shortcode\": \"3333\", \"longname\": \"project longname\", \"description\": [{\"value\": \"project description\", \"language\": \"en\"}], \"keywords\": [\"test project\"], \"logo\": \"/fu/bar/baz.jpg\", \"status\": true, \"selfjoin\": false } Additionally, each project can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\": \"http://rdfh.ch/projects/9TaSVMUuiRhQsuWHDPr8rw\", \"shortname\": \"newprojectWithIri\", \"shortcode\": \"3333\", \"longname\": \"new project with a custom IRI\", \"description\": [{\"value\": \"a project created with a custom IRI\", \"language\": \"en\"}], \"keywords\": [\"projectWithIRI\"], \"logo\": \"/fu/bar/baz.jpg\", \"status\": true, \"selfjoin\": false } Default set of permissions for a new project: When a new project is created, following default permissions are added to its admins and members: ProjectAdmin group receives an administrative permission to do all project level operations and to create resources within the new project. This administrative permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultApForAdmin ProjectAdmin group also gets a default object access permission to change rights (which includes delete, modify, view, and restricted view permissions) of any entity that belongs to the project. This default object access permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultDoapForAdmin ProjectMember group receives an administrative permission to create resources within the new project. This administrative permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultApForMember ProjectMember group also gets a default object access permission to modify (which includes view and restricted view permissions) of any entity that belongs to the project. This default object access permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultDoapForMember Update project information: Required permission: SystemAdmin / ProjectAdmin Changeable information: shortname, longname, description, keywords, logo, status, selfjoin. The payload must at least contain a new value for one of these properties. TypeScript Docs: projectFormats - ChangeProjectApiRequestV1 PUT: /admin/projects/iri/<projectIri> BODY: { \"shortname\": \"newproject\", \"longname\": \"project longname\", \"description\": [{\"value\": \"a new description\", \"language\": \"en\"}], \"keywords\": [\"a new key\"], \"logo\": \"/fu/bar/baz.jpg\", \"status\": true, \"selfjoin\": false } Delete project (update project status): Required permission: SystemAdmin / ProjectAdmin Remark: The same as updating a project and changing status to false . To un-delete, set status to true . DELETE: /admin/projects/iri/<projectIri> BODY: empty Dump project data: Returns a TriG file containing the project's ontologies, resource data, admin data, and permissions. Required permission: SystemAdmin / ProjectAdmin Required information: project IRI GET: /admin/projects/iri/<identifier>/AllData Project Member Operations Get project members: Required permission: SystemAdmin / ProjectAdmin Required information: project identifier GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/members Project Admin Member Operations Get project members: Required permission: SystemAdmin / ProjectAdmin Required information: project identifier GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/admin-members Restricted View Settings Operations Operates on the following properties: - knora-admin:projectRestrictedViewSize - takes the IIIF size value - knora-admin:projectRestrictedViewWatermark - takes the path to the watermark image. Currently not used. Get the restricted view settings: Required permission: ProjectAdmin Required information: identifier . The identifier can be the project's IRI, shortname or shortcode. GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/RestrictedViewSettings Example Data The following is an example for project information stored in the admin named graph: <http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA> rdf:type knora-admin:knoraProject ; knora-admin:projectShortname \"images\"^^xsd:string ; knora-admin:projectShortcode \"00FF\"^^xsd:string ; knora-admin:projectLongname \"Image Collection Demo\"^^xsd:string ; knora-admin:projectDescription \"A demo project of a collection of images\"@en ; knora-admin:projectKeyword \"images\"^^xsd:string, \"collection\"^^xsd:string ; knora-admin:projectRestrictedViewSize \"!512,512\"^^xsd:string ; knora-admin:projectRestrictedViewWatermark \"path_to_image\"^^xsd:string ; knora-admin:belongsToInstitution <http://rdfh.ch/institutions/dhlab-basel> ; knora-admin:status \"true\"^^xsd:boolean ; knora-admin:hasSelfJoinEnabled \"false\"^^xsd:boolean .","title":"Projects Endpoint"},{"location":"03-endpoints/api-admin/projects/#projects-endpoint","text":"","title":"Projects Endpoint"},{"location":"03-endpoints/api-admin/projects/#endpoint-overview","text":"Project Operations: GET: /admin/projects : return all projects POST: /admin/projects : create a new project GET: /admin/projects/[iri | shortname | shortcode | uuid]/<identifier> : returns a single project identified either through iri, shortname, shortcode or UUID PUT: /admin/projects/iri/<identifier> : update a project identified by iri DELETE: /admin/projects/iri/<identifier> : update project status to false GET: /admin/projects/iri/<identifier>/AllData : returns a TriG file containing the project's data Project Member Operations: GET: /admin/projects/[iri | shortname | shortcode | uuid]/<identifier>/members : returns all members part of a project identified through iri, shortname, shortcode or UUID Project Admin Member Operations: GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/admin-members : returns all admin members part of a project identified through iri, shortname or shortcode Project Keyword Operations: GET: /admin/projects/Keywords : returns all unique keywords for all projects as a list GET: /admin/projects/iri/<identifier>/Keywords : returns all keywords for a single project Project Restricted View Settings Operations: GET: /admin/projects/iri/<identifier>/RestrictedViewSettings : returns the project's restricted view settings","title":"Endpoint Overview"},{"location":"03-endpoints/api-admin/projects/#project-operations","text":"","title":"Project Operations"},{"location":"03-endpoints/api-admin/projects/#create-a-new-project","text":"Required permission: SystemAdmin Required information: shortcode (unique, 4-digits) shortname (unique; it should be in the form of a xsd:NCNAME and it should be URL safe.) description (collection of descriptions as strings with language tag.) keywords (collection of keywords) status (true, if project is active. false, if project is inactive) selfjoin Optional information: longname, logo Returns information about the newly created project Remark: There are two distinct use cases / payload combination: (1) change ontology and data graph: ontologygraph, datagraph, (2) basic project information: shortcode, shortname, longname, description, keywords, logo, institution, status, selfjoin POST: /admin/projects/ BODY: { \"shortname\": \"newproject\", \"shortcode\": \"3333\", \"longname\": \"project longname\", \"description\": [{\"value\": \"project description\", \"language\": \"en\"}], \"keywords\": [\"test project\"], \"logo\": \"/fu/bar/baz.jpg\", \"status\": true, \"selfjoin\": false } Additionally, each project can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\": \"http://rdfh.ch/projects/9TaSVMUuiRhQsuWHDPr8rw\", \"shortname\": \"newprojectWithIri\", \"shortcode\": \"3333\", \"longname\": \"new project with a custom IRI\", \"description\": [{\"value\": \"a project created with a custom IRI\", \"language\": \"en\"}], \"keywords\": [\"projectWithIRI\"], \"logo\": \"/fu/bar/baz.jpg\", \"status\": true, \"selfjoin\": false }","title":"Create a new project:"},{"location":"03-endpoints/api-admin/projects/#default-set-of-permissions-for-a-new-project","text":"When a new project is created, following default permissions are added to its admins and members: ProjectAdmin group receives an administrative permission to do all project level operations and to create resources within the new project. This administrative permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultApForAdmin ProjectAdmin group also gets a default object access permission to change rights (which includes delete, modify, view, and restricted view permissions) of any entity that belongs to the project. This default object access permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultDoapForAdmin ProjectMember group receives an administrative permission to create resources within the new project. This administrative permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultApForMember ProjectMember group also gets a default object access permission to modify (which includes view and restricted view permissions) of any entity that belongs to the project. This default object access permission is retrievable through its IRI: http://rdfh.ch/permissions/[projectShortcode]/defaultDoapForMember","title":"Default set of permissions for a new project:"},{"location":"03-endpoints/api-admin/projects/#update-project-information","text":"Required permission: SystemAdmin / ProjectAdmin Changeable information: shortname, longname, description, keywords, logo, status, selfjoin. The payload must at least contain a new value for one of these properties. TypeScript Docs: projectFormats - ChangeProjectApiRequestV1 PUT: /admin/projects/iri/<projectIri> BODY: { \"shortname\": \"newproject\", \"longname\": \"project longname\", \"description\": [{\"value\": \"a new description\", \"language\": \"en\"}], \"keywords\": [\"a new key\"], \"logo\": \"/fu/bar/baz.jpg\", \"status\": true, \"selfjoin\": false }","title":"Update project information:"},{"location":"03-endpoints/api-admin/projects/#delete-project-update-project-status","text":"Required permission: SystemAdmin / ProjectAdmin Remark: The same as updating a project and changing status to false . To un-delete, set status to true . DELETE: /admin/projects/iri/<projectIri> BODY: empty","title":"Delete project (update project status):"},{"location":"03-endpoints/api-admin/projects/#dump-project-data","text":"Returns a TriG file containing the project's ontologies, resource data, admin data, and permissions. Required permission: SystemAdmin / ProjectAdmin Required information: project IRI GET: /admin/projects/iri/<identifier>/AllData","title":"Dump project data:"},{"location":"03-endpoints/api-admin/projects/#project-member-operations","text":"","title":"Project Member Operations"},{"location":"03-endpoints/api-admin/projects/#get-project-members","text":"Required permission: SystemAdmin / ProjectAdmin Required information: project identifier GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/members","title":"Get project members:"},{"location":"03-endpoints/api-admin/projects/#project-admin-member-operations","text":"","title":"Project Admin Member Operations"},{"location":"03-endpoints/api-admin/projects/#get-project-members_1","text":"Required permission: SystemAdmin / ProjectAdmin Required information: project identifier GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/admin-members","title":"Get project members:"},{"location":"03-endpoints/api-admin/projects/#restricted-view-settings-operations","text":"Operates on the following properties: - knora-admin:projectRestrictedViewSize - takes the IIIF size value - knora-admin:projectRestrictedViewWatermark - takes the path to the watermark image. Currently not used.","title":"Restricted View Settings Operations"},{"location":"03-endpoints/api-admin/projects/#get-the-restricted-view-settings","text":"Required permission: ProjectAdmin Required information: identifier . The identifier can be the project's IRI, shortname or shortcode. GET: /admin/projects/[iri | shortname | shortcode]/<identifier>/RestrictedViewSettings","title":"Get the restricted view settings:"},{"location":"03-endpoints/api-admin/projects/#example-data","text":"The following is an example for project information stored in the admin named graph: <http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA> rdf:type knora-admin:knoraProject ; knora-admin:projectShortname \"images\"^^xsd:string ; knora-admin:projectShortcode \"00FF\"^^xsd:string ; knora-admin:projectLongname \"Image Collection Demo\"^^xsd:string ; knora-admin:projectDescription \"A demo project of a collection of images\"@en ; knora-admin:projectKeyword \"images\"^^xsd:string, \"collection\"^^xsd:string ; knora-admin:projectRestrictedViewSize \"!512,512\"^^xsd:string ; knora-admin:projectRestrictedViewWatermark \"path_to_image\"^^xsd:string ; knora-admin:belongsToInstitution <http://rdfh.ch/institutions/dhlab-basel> ; knora-admin:status \"true\"^^xsd:boolean ; knora-admin:hasSelfJoinEnabled \"false\"^^xsd:boolean .","title":"Example Data"},{"location":"03-endpoints/api-admin/stores/","text":"Stores Endpoint","title":"Stores Endpoint"},{"location":"03-endpoints/api-admin/stores/#stores-endpoint","text":"","title":"Stores Endpoint"},{"location":"03-endpoints/api-admin/users/","text":"Users Endpoint Endpoint Overview User Operations: GET: /admin/users : return all users GET: /admin/users/[iri | email | username]/<identifier> : return single user identified by [IRI | email | username] POST: /admin/users/ : create new user PUT: /admin/users/iri/<userIri>/BasicUserInformation : update user's basic user information PUT: /admin/users/iri/<userIri>/Password : update user's password PUT: /admin/users/iri/<userIri>/Status : update user's status DELETE: /admin/users/iri/<userIri> : delete user (set status to false) User's project membership operations GET: /admin/users/iri/<userIri>/project-memberships : get user's project memberships POST: /admin/users/iri/<userIri>/project-memberships/<projectIri> : add user to project (to ProjectMember group) DELETE: /admin/users/iri/<userIri>/project-memberships/<projectIri> : remove user from project (to ProjectMember group) User's group membership operations GET: /admin/users/iri/<userIri>/project-admin-memberships : get user's ProjectAdmin group memberships POST: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> : add user to ProjectAdmin group DELETE: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> : remove user from ProjectAdmin group GET: /admin/users/iri/<userIri>/group-memberships : get user's normal group memberships POST: /admin/users/iri/<userIri>/group-memberships/<groupIri> : add user to normal group DELETE: /admin/users/iri/<userIri>/group-memberships/<groupIri> : remove user from normal group PUT: /admin/users/iri/<userIri>/SystemAdmin : Add/remove user to/from SystemAdmin group User Operations Get users Required permission: SystemAdmin GET: /admin/users Get user Required permission: SystemAdmin / self: for getting all properties All other users: for getting only the public properties ( givenName and familyName ) GET: /admin/users/[iri | email | username ]/<identifier> Create user Required permission: none, self-registration is allowed Required information: email (unique), given name, family name, password, status, systemAdmin Username restrictions: 4 - 50 characters long Only contains alphanumeric characters, underscore and dot. Underscore and dot can't be at the end or start of a username Underscore or dot can't be used multiple times in a row Returns information about the newly created user TypeScript Docs: userFormats - CreateUserApiRequestV1 POST: /admin/users BODY: { \"email\": \"donald.duck@example.org\", \"givenName\": \"Donald\", \"familyName\": \"Duck\", \"username\": \"donald.duck\", \"password\": \"test\", \"status\": true, \"lang\": \"en\", \"systemAdmin\": false } Additionally, each user can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\" : \"http://rdfh.ch/users/FnjFfIQFVDvI7ex8zSyUyw\", \"email\": \"donald.duck@example.org\", \"givenName\": \"Donald\", \"familyName\": \"Duck\", \"username\": \"donald.duck\", \"password\": \"test\", \"status\": true, \"lang\": \"en\", \"systemAdmin\": false } Update basic user information** Required permission: SystemAdmin / self Changeable information: username, email, given name, family name, password, status, SystemAdmin membership TypeScript Docs: userFormats - ChangeUserApiRequestADM PUT: /admin/users/iri/<userIri>/BasicUserInformation BODY: { \"username\": \"donald.big.duck\", \"email\": \"donald.big.duck@example.org\", \"givenName\": \"Big Donald\", \"familyName\": \"Duckmann\", \"lang\": \"de\" } Update user's password Required permission: SystemAdmin / self Changeable information: password PUT: /admin/users/iri/<userIri>/Password BODY: { \"requesterPassword\": \"test\", \"newPassword\": \"test1234\" } Delete user Required permission: SystemAdmin / self Remark: The same as updating a user and changing status to false . To un-delete, set status to true . PUT: /admin/users/iri/<userIri>/Status BODY: { \"status\": false // true or false } Delete user (-\\update user)** Required permission: SystemAdmin / self Remark: The same as updating a user and changing status to false . To un-delete, set status to true . DELETE: /admin/users/iri/<userIri> BODY: empty User's project membership operations Get user's project memberships GET: /admin/users/iri/<userIri>/project-memberships Add/remove user to/from project Required permission: SystemAdmin / ProjectAdmin / self (if project self-assignment is enabled) Required information: project IRI, user IRI Effects: knora-base:isInProject user property POST / DELETE: /admin/users/iri/<userIri>/project-memberships/<projectIri> BODY: empty Note: When a user is project admin in the same project, his project admin membership will be removed as well. User's group membership operations Get user's project admin memberships GET: /admin/users/iri/<userIri>/project-admin-memberships Add/remove user to/from project admin group Required permission: SystemAdmin / ProjectAdmin Required information: project IRI, user IRI Effects: knora-base:isInProjectAdminGroup user property POST / DELETE: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> BODY: empty Note: In order to add a user to a project admin group, the user needs to be member of that project. Get user's group memberships** GET: /admin/users/iri/<userIri>/group-memberships Add/remove user to/from 'normal' group (not SystemAdmin or ProjectAdmin ) Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission / hasProjectRestrictedGroupAdminPermission (for this group) / User (if group self-assignment is enabled) Required information: group IRI, user IRI Effects: knora-base:isInGroup POST / DELETE: /admin/users/iri/<userIri>/group-memberships/<groupIri> BODY: empty Add/remove user to/from system admin group Required permission: SystemAdmin / self Effects property: knora-base:isInSystemAdminGroup with value true or false PUT: /admin/users/iri/<userIri>/SystemAdmin BODY: { \"systemAdmin\": false } Example Data The following is an example for user information stored in the admin named graph: <http://rdfh.ch/users/c266a56709> rdf:type knora-admin:User ; knora-admin:username \"user01.user1\"^^xsd:string ; knora-admin:email \"user01.user1@example.com\"^^xsd:string ; knora-admin:givenName \"User01\"^^xsd:string ; knora-admin:familyName \"User\"^^xsd:string ; knora-admin:password \"$e0801$FGl9FDIWw+D83OeNPGmD9u2VTqIkJopIQECgmb2DSWQLS0TeKSvYoWAkbEv6KxePPlCI3CP9MmVHuvnWv8/kag==$mlegCYdGXt+ghuo8i0rLjgOiNnGDW604Q5g/v7zwBPU=\"^^xsd:string ; knora-admin:preferredLanguage \"de\"^^xsd:string ; knora-admin:status \"true\"^^xsd:boolean ; knora-admin:isInProject <http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA> ; knora-admin:isInSystemAdminGroup \"false\"^^xsd:boolean ; knora-admin:isInProjectAdminGroup <http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA> .","title":"Users Endpoint"},{"location":"03-endpoints/api-admin/users/#users-endpoint","text":"","title":"Users Endpoint"},{"location":"03-endpoints/api-admin/users/#endpoint-overview","text":"User Operations: GET: /admin/users : return all users GET: /admin/users/[iri | email | username]/<identifier> : return single user identified by [IRI | email | username] POST: /admin/users/ : create new user PUT: /admin/users/iri/<userIri>/BasicUserInformation : update user's basic user information PUT: /admin/users/iri/<userIri>/Password : update user's password PUT: /admin/users/iri/<userIri>/Status : update user's status DELETE: /admin/users/iri/<userIri> : delete user (set status to false) User's project membership operations GET: /admin/users/iri/<userIri>/project-memberships : get user's project memberships POST: /admin/users/iri/<userIri>/project-memberships/<projectIri> : add user to project (to ProjectMember group) DELETE: /admin/users/iri/<userIri>/project-memberships/<projectIri> : remove user from project (to ProjectMember group) User's group membership operations GET: /admin/users/iri/<userIri>/project-admin-memberships : get user's ProjectAdmin group memberships POST: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> : add user to ProjectAdmin group DELETE: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> : remove user from ProjectAdmin group GET: /admin/users/iri/<userIri>/group-memberships : get user's normal group memberships POST: /admin/users/iri/<userIri>/group-memberships/<groupIri> : add user to normal group DELETE: /admin/users/iri/<userIri>/group-memberships/<groupIri> : remove user from normal group PUT: /admin/users/iri/<userIri>/SystemAdmin : Add/remove user to/from SystemAdmin group","title":"Endpoint Overview"},{"location":"03-endpoints/api-admin/users/#user-operations","text":"","title":"User Operations"},{"location":"03-endpoints/api-admin/users/#get-users","text":"Required permission: SystemAdmin GET: /admin/users","title":"Get users"},{"location":"03-endpoints/api-admin/users/#get-user","text":"Required permission: SystemAdmin / self: for getting all properties All other users: for getting only the public properties ( givenName and familyName ) GET: /admin/users/[iri | email | username ]/<identifier>","title":"Get user"},{"location":"03-endpoints/api-admin/users/#create-user","text":"Required permission: none, self-registration is allowed Required information: email (unique), given name, family name, password, status, systemAdmin Username restrictions: 4 - 50 characters long Only contains alphanumeric characters, underscore and dot. Underscore and dot can't be at the end or start of a username Underscore or dot can't be used multiple times in a row Returns information about the newly created user TypeScript Docs: userFormats - CreateUserApiRequestV1 POST: /admin/users BODY: { \"email\": \"donald.duck@example.org\", \"givenName\": \"Donald\", \"familyName\": \"Duck\", \"username\": \"donald.duck\", \"password\": \"test\", \"status\": true, \"lang\": \"en\", \"systemAdmin\": false } Additionally, each user can have an optional custom IRI (of Knora IRI form) specified by the id in the request body as below: { \"id\" : \"http://rdfh.ch/users/FnjFfIQFVDvI7ex8zSyUyw\", \"email\": \"donald.duck@example.org\", \"givenName\": \"Donald\", \"familyName\": \"Duck\", \"username\": \"donald.duck\", \"password\": \"test\", \"status\": true, \"lang\": \"en\", \"systemAdmin\": false }","title":"Create user"},{"location":"03-endpoints/api-admin/users/#update-basic-user-information","text":"Required permission: SystemAdmin / self Changeable information: username, email, given name, family name, password, status, SystemAdmin membership TypeScript Docs: userFormats - ChangeUserApiRequestADM PUT: /admin/users/iri/<userIri>/BasicUserInformation BODY: { \"username\": \"donald.big.duck\", \"email\": \"donald.big.duck@example.org\", \"givenName\": \"Big Donald\", \"familyName\": \"Duckmann\", \"lang\": \"de\" }","title":"Update basic user information**"},{"location":"03-endpoints/api-admin/users/#update-users-password","text":"Required permission: SystemAdmin / self Changeable information: password PUT: /admin/users/iri/<userIri>/Password BODY: { \"requesterPassword\": \"test\", \"newPassword\": \"test1234\" }","title":"Update user's password"},{"location":"03-endpoints/api-admin/users/#delete-user","text":"Required permission: SystemAdmin / self Remark: The same as updating a user and changing status to false . To un-delete, set status to true . PUT: /admin/users/iri/<userIri>/Status BODY: { \"status\": false // true or false }","title":"Delete user"},{"location":"03-endpoints/api-admin/users/#delete-user-update-user","text":"Required permission: SystemAdmin / self Remark: The same as updating a user and changing status to false . To un-delete, set status to true . DELETE: /admin/users/iri/<userIri> BODY: empty","title":"Delete user (-\\update user)**"},{"location":"03-endpoints/api-admin/users/#users-project-membership-operations","text":"","title":"User's project membership operations"},{"location":"03-endpoints/api-admin/users/#get-users-project-memberships","text":"GET: /admin/users/iri/<userIri>/project-memberships","title":"Get user's project memberships"},{"location":"03-endpoints/api-admin/users/#addremove-user-tofrom-project","text":"Required permission: SystemAdmin / ProjectAdmin / self (if project self-assignment is enabled) Required information: project IRI, user IRI Effects: knora-base:isInProject user property POST / DELETE: /admin/users/iri/<userIri>/project-memberships/<projectIri> BODY: empty Note: When a user is project admin in the same project, his project admin membership will be removed as well.","title":"Add/remove user to/from project"},{"location":"03-endpoints/api-admin/users/#users-group-membership-operations","text":"","title":"User's group membership operations"},{"location":"03-endpoints/api-admin/users/#get-users-project-admin-memberships","text":"GET: /admin/users/iri/<userIri>/project-admin-memberships","title":"Get user's project admin memberships"},{"location":"03-endpoints/api-admin/users/#addremove-user-tofrom-project-admin-group","text":"Required permission: SystemAdmin / ProjectAdmin Required information: project IRI, user IRI Effects: knora-base:isInProjectAdminGroup user property POST / DELETE: /admin/users/iri/<userIri>/project-admin-memberships/<projectIri> BODY: empty Note: In order to add a user to a project admin group, the user needs to be member of that project.","title":"Add/remove user to/from project admin group"},{"location":"03-endpoints/api-admin/users/#get-users-group-memberships","text":"GET: /admin/users/iri/<userIri>/group-memberships","title":"Get user's group memberships**"},{"location":"03-endpoints/api-admin/users/#addremove-user-tofrom-normal-group-not-systemadmin-or-projectadmin","text":"Required permission: SystemAdmin / hasProjectAllAdminPermission / hasProjectAllGroupAdminPermission / hasProjectRestrictedGroupAdminPermission (for this group) / User (if group self-assignment is enabled) Required information: group IRI, user IRI Effects: knora-base:isInGroup POST / DELETE: /admin/users/iri/<userIri>/group-memberships/<groupIri> BODY: empty","title":"Add/remove user to/from 'normal' group (not SystemAdmin or ProjectAdmin)"},{"location":"03-endpoints/api-admin/users/#addremove-user-tofrom-system-admin-group","text":"Required permission: SystemAdmin / self Effects property: knora-base:isInSystemAdminGroup with value true or false PUT: /admin/users/iri/<userIri>/SystemAdmin BODY: { \"systemAdmin\": false }","title":"Add/remove user to/from system admin group"},{"location":"03-endpoints/api-admin/users/#example-data","text":"The following is an example for user information stored in the admin named graph: <http://rdfh.ch/users/c266a56709> rdf:type knora-admin:User ; knora-admin:username \"user01.user1\"^^xsd:string ; knora-admin:email \"user01.user1@example.com\"^^xsd:string ; knora-admin:givenName \"User01\"^^xsd:string ; knora-admin:familyName \"User\"^^xsd:string ; knora-admin:password \"$e0801$FGl9FDIWw+D83OeNPGmD9u2VTqIkJopIQECgmb2DSWQLS0TeKSvYoWAkbEv6KxePPlCI3CP9MmVHuvnWv8/kag==$mlegCYdGXt+ghuo8i0rLjgOiNnGDW604Q5g/v7zwBPU=\"^^xsd:string ; knora-admin:preferredLanguage \"de\"^^xsd:string ; knora-admin:status \"true\"^^xsd:boolean ; knora-admin:isInProject <http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA> ; knora-admin:isInSystemAdminGroup \"false\"^^xsd:boolean ; knora-admin:isInProjectAdminGroup <http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA> .","title":"Example Data"},{"location":"03-endpoints/api-util/health/","text":"Health The health endpoint provides information about the health state of the dsp-stack. Example request GET /health Example response { \"name\":\"AppState\", \"message\" : \"Application is healthy\", \"severity\":\"non fatal\", \"status\":\"healthy\" }","title":"Health"},{"location":"03-endpoints/api-util/health/#health","text":"The health endpoint provides information about the health state of the dsp-stack.","title":"Health"},{"location":"03-endpoints/api-util/health/#example-request","text":"GET /health","title":"Example request"},{"location":"03-endpoints/api-util/health/#example-response","text":"{ \"name\":\"AppState\", \"message\" : \"Application is healthy\", \"severity\":\"non fatal\", \"status\":\"healthy\" }","title":"Example response"},{"location":"03-endpoints/api-util/version/","text":"Version The version endpoint provides the versions of the used components in the Knora-stack. The response has the type application/json and contains the following information: name: has the value \"version\" version numbers for the following components: akkaHttp gdbFree gdbSE sbt scala sipi webapi Example request GET /version Example response { \"akkaHttp\": \"10.1.7\", \"gdbFree\": \"8.10.0-free\", \"gdbSE\": \"8.5.0-se\", \"name\": \"version\", \"sbt\": \"1.2.8\", \"scala\": \"2.12.8\", \"sipi\": \"v2.0.1\", \"webapi\": \"10.0.0-7-gc5a72b3-SNAPSHOT\" }","title":"Version"},{"location":"03-endpoints/api-util/version/#version","text":"The version endpoint provides the versions of the used components in the Knora-stack. The response has the type application/json and contains the following information: name: has the value \"version\" version numbers for the following components: akkaHttp gdbFree gdbSE sbt scala sipi webapi","title":"Version"},{"location":"03-endpoints/api-util/version/#example-request","text":"GET /version","title":"Example request"},{"location":"03-endpoints/api-util/version/#example-response","text":"{ \"akkaHttp\": \"10.1.7\", \"gdbFree\": \"8.10.0-free\", \"gdbSE\": \"8.5.0-se\", \"name\": \"version\", \"sbt\": \"1.2.8\", \"scala\": \"2.12.8\", \"sipi\": \"v2.0.1\", \"webapi\": \"10.0.0-7-gc5a72b3-SNAPSHOT\" }","title":"Example response"},{"location":"03-endpoints/api-v1/adding-resources/","text":"Adding Resources To create a resource, the HTTP method POST has to be used. The request has to be sent to the Knora server using the resources path segment: HTTP POST to http://host/v1/resources Unlike in the case of GET requests, the request body consists of JSON describing the resource to be created. Creating resources requires authentication since only known users may add resources. Adding Resources Without Image Files The format of the JSON used to create a resource without an image file is described in the TypeScript interface createResourceWithoutRepresentationRequest in module createResourceFormats . It requires the IRI of the resource class the new resource belongs to, a label describing the new resource, the IRI of the project the new resource belongs to, and the properties to be assigned to the new resource. The request header's content type has to be set to application/json . Adding Resources with Image Files The first step is to upload an image file to Sipi, using a multipart/form-data request, where sipihost represents the host and port on which Sipi is running: HTTP POST to http://sipihost/upload?token=TOKEN The TOKEN is the sid returned by Knora in response to the client's login request (see Authentication ). The request must contain a body part providing the file as well as a parameter filename , providing the file's original filename, which both Knora and Sipi will store; these filenames can be descriptive and need not be unique. Sipi will then convert the uploaded image file to JPEG 2000 format and store it in a temporary location. If this is successful, it will return a JSON response that looks something like this: { \"uploadedFiles\": [{ \"originalFilename\": \"manuscript-1234-page-1.tiff\", \"internalFilename\": \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\", \"temporaryBaseIIIFUrl\": \"http://sipihost/tmp\" }] } This provides: the originalFilename , which we submitted when uploading the file the unique internalFilename that Sipi has randomly generated for the file the temporaryBaseIIIFUrl , which we can use to construct a IIIF URL for previewing the file The client may now wish to get a thumbnail of the uploaded image, to allow the user to confirm that the correct files have been uploaded. This can be done by adding the filename and IIIF parameters to temporaryBaseIIIFUrl . For example, to get a JPG thumbnail image whose width and height are at most 128 pixels wide, you would request http://sipihost/tmp/3UIsXH9bP0j-BV0D4sN51Xz.jp2/full/!128,128/0/default.jpg . The request to Knora works similarly to Adding Resources Without Image Files , with the addition of file , whose value is the internalFilename that Sipi returned. See the TypeScript interface createResourceWithRepresentationRequest in module createResourceFormats for details. The request header's content type must be set to application/json . Response to a Resource Creation When a resource has been successfully created, Knora sends back a JSON containing the new resource's IRI ( res_id ) and its properties. The resource IRI identifies the resource and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface createResourceResponse in module createResourceFormats . Changing a Resource's Label A resource's label can be changed by making a PUT request to the path segments resources/label . The resource's IRI has to be provided in the URL (as its last segment). The new label has to submitted as JSON in the HTTP request's body. HTTP PUT to http://host/v1/resources/label/resourceIRI The JSON format of the request is described in the TypeScript interface changeResourceLabelRequest in module createResourceFormats . The response is described in the TypeScript interface changeResourceLabelResponse in module createResourceFormats . Bulk Import If you have a large amount of data to import into Knora, it can be more convenient to use the bulk import feature than to create resources one by one. In a bulk import operation, you submit an XML document to Knora, describing multiple resources to be created. This is especially useful if the resources to be created have links to one another. Knora checks the entire request for consistency as as a whole, and performs the update in a single database transaction. Only system or project administrators may use the bulk import. The procedure for using this feature is as follows (see the example below ). Make an HTTP GET request to Knora to get XML schemas describing the XML to be provided for the import. If you are importing image files, upload files to Sipi . Generate an XML import document representing the data to be imported, following the Knora import schemas that were generated in step 1. You will probably want to write a script to do this. Knora is not involved in this step. If you are also importing image files, this XML document needs to contain the filenames that Sipi returned for the files you uploaded in step 2. Validate your XML import document , using an XML schema validator such as Apache Xerces or Saxon , or an XML development environment such as Oxygen . This will help ensure that the data you submit to Knora is correct. Knora is not involved in this step. Submit the XML import document to Knora . In this procedure, the person responsible for generating the XML import data need not be familiar with RDF or with the ontologies involved. When Knora receives an XML import, it validates it first using the relevant XML schemas, and then using the same internal checks that it performs when creating any resource. The details of the XML import format are illustrated in the following examples. Bulk Import Example Suppose we have a project with existing data (but no image files), which we want to import into Knora. We have created an ontology called http://www.knora.org/ontology/0801/biblio for the project, and this ontology also uses definitions from another ontology, called http://www.knora.org/ontology/0801/beol . 1. Get XML Schemas To get XML schemas for an import, we use the following route, specifying the (URL-encoded) IRI of our project's main ontology (in this case http://www.knora.org/ontology/0801/biblio ): HTTP GET to http://host/v1/resources/xmlimportschemas/ontologyIRI In our example, the URL could be: http://localhost:3333/v1/resources/xmlimportschemas/http%3A%2F%2Fwww.knora.org%2Fontology%2F0801%2Fbiblio This returns a Zip archive called p0801-biblio-xml-schemas.zip , containing three files: p0801-biblio.xsd : The schema for our main ontology. p0801-beol.xsd : A schema for another ontology that our main ontology depends on. knoraXmlImport.xsd : The standard Knora XML import schema, used by all XML imports. 2. Upload Files to Sipi See Upload Files to Sipi in the DSP-API v2 documentation. 3. Generate XML Import Document We now convert our existing data to XML, probably by writing a custom script. The resulting XML import document could look like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1# p0801-biblio.xsd\" xmlns:p0801-biblio=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:p0801-beol=\"http://api.knora.org/ontology/0801/beol/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\"> <p0801-beol:person id=\"abel\"> <knoraXmlImport:label>Niels Henrik Abel</knoraXmlImport:label> <p0801-beol:hasFamilyName knoraType=\"richtext_value\">Abel</p0801-beol:hasFamilyName> <p0801-beol:hasGivenName knoraType=\"richtext_value\">Niels Henrik</p0801-beol:hasGivenName> <p0801-beol:personHasTitle knoraType=\"richtext_value\" lang=\"en\">Sir</p0801-beol:personHasTitle> </p0801-beol:person> <p0801-beol:person id=\"holmes\"> <knoraXmlImport:label>Sherlock Holmes</knoraXmlImport:label> <p0801-beol:hasFamilyName knoraType=\"richtext_value\">Holmes</p0801-beol:hasFamilyName> <p0801-beol:hasGivenName knoraType=\"richtext_value\">Sherlock</p0801-beol:hasGivenName> </p0801-beol:person> <p0801-biblio:Journal id=\"math_intelligencer\"> <knoraXmlImport:label>Math Intelligencer</knoraXmlImport:label> <p0801-biblio:hasName knoraType=\"richtext_value\">Math Intelligencer</p0801-biblio:hasName> </p0801-biblio:Journal> <p0801-biblio:JournalArticle id=\"strings_in_the_16th_and_17th_centuries\" creationDate=\"2019-01-09T15:45:54Z\"> <knoraXmlImport:label>Strings in the 16th and 17th Centuries</knoraXmlImport:label> <p0801-biblio:p0801-beol__comment knoraType=\"richtext_value\" mapping_id=\"http://rdfh.ch/standoff/mappings/StandardMapping\"> <text xmlns=\"\">The most <strong>interesting</strong> article in <a class=\"salsah-link\" href=\"ref:math_intelligencer\">Math Intelligencer</a>.</text> </p0801-biblio:p0801-beol__comment> <p0801-biblio:endPage knoraType=\"richtext_value\">73</p0801-biblio:endPage> <p0801-biblio:isPartOfJournal> <p0801-biblio:Journal knoraType=\"link_value\" target=\"math_intelligencer\" linkType=\"ref\"/> </p0801-biblio:isPartOfJournal> <p0801-biblio:journalVolume knoraType=\"richtext_value\">27</p0801-biblio:journalVolume> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType=\"link_value\" linkType=\"ref\" target=\"abel\"/> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType=\"link_value\" linkType=\"ref\" target=\"holmes\"/> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasDate knoraType=\"date_value\">GREGORIAN:1976</p0801-biblio:publicationHasDate> <p0801-biblio:publicationHasTitle knoraType=\"richtext_value\" lang=\"en\">Strings in the 16th and 17th Centuries</p0801-biblio:publicationHasTitle> <p0801-biblio:publicationHasTitle knoraType=\"richtext_value\">An alternate title</p0801-biblio:publicationHasTitle> <p0801-biblio:startPage knoraType=\"richtext_value\">48</p0801-biblio:startPage> </p0801-biblio:JournalArticle> </knoraXmlImport:resources> This illustrates several aspects of XML imports: The root XML element must be knoraXmlImport:resources . There is an XML namespace corresponding each ontology used in the import. These namespaces can be found in the XML schema files returned by Knora. We have copied and pasted xmlns=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" from the main XML schema, p0801-biblio.xsd . This enables the Knora API server to identify the main ontology we are using. We have used xsi:schemaLocation to indicate the main schema's namespace and filename. If we put our XML document in the same directory as the schemas, and we run an XML validator to check the XML, it should load the schemas. The child elements of knoraXmlImport:resources represent resources to be created. The order of these elements is unimportant. Each resource must have an ID, which must be an XML NCName , and must be unique within the file. These IDs are used only during the import, and will not be stored in the triplestore. Each resource can optionally have a creationDate attribute, which can be an xsd:dateTime or an xsd:dateTimeStamp . If creationDate is not supplied, the current time is used. The first child element of each resource must be a knoraXmlImport:label , which will be stored as the resource's rdfs:label . Optionally, the second child element of a resource can provide metadata about a file to be attached to the resource (see bulk-import-with-digital-representations). The remaining child elements of each resource represent its property values. These must be sorted in alphabetical order by property name. If a property has mutliple values, these are represented as multiple adjacent property elements. The type of each value must be specified using the attribute knoraType . A link to another resource described in the XML import is represented as a child element of a property element, with attributes knoraType=\"link_value\" and linkType=\"ref\" , and a target attribute containing the ID of the target resource. There is a specfic syntax for referring to properties from other ontologies. In the example, p0801-beol:comment is defined in the ontology http://www.knora.org/ontology/0001/beol . In the XML, we refer to it as p0801-biblio:p0801-beol__comment . A text value can contain XML markup. If it does: The text value element must have the attribute mapping_id , specifying a mapping from XML to standoff markup (see XML-to-standoff-mapping). It is necessary to specify the appropriate XML namespace (in this case the null namespace, xmlns=\"\" ) for the XML markup in the text value. The XML markup in the text value will not be validated by the schema. In an XML tag that is mapped to a standoff link tag, the link target can refer either to the IRI of a resoruce that already exists in the triplestore, or to the ID of a resource described in the import. If a link points to a resource described in the import, the ID of the target resource must be prefixed with ref: . In the example above, using the standard mapping, the standoff link to math_intelligencer has the target ref:math_intelligencer . A text value can have a lang attribute, whose value is an ISO 639-1 code specifying the language of the text. 4. Validate XML Import Document You can use an XML schema validator such as Apache Xerces or Saxon , or an XML development environment such as Oxygen , to check that your XML import document is valid according to the schemas you got from Knora. For example, using Saxon: java -cp ./saxon9ee.jar com.saxonica.Validate -xsd:p0801-biblio.xsd -s:data.xml 5. Submit XML Import Document to Knora To create these resources in Knora, make an HTTP post request with the XML import document as the request body. The URL must specify the (URL-encoded) IRI of the project in which the resources should be created: HTTP POST to http://host/v1/resources/xmlimport/projectIRI For example, using curl : curl -v -u root@example.com:test --data @data.xml --header \"Content-Type: application/xml\" http://localhost:3333/v1/resources/xmlimport/http%3A%2F%2Frdfh.ch%2Fprojects%2F0801 Bulk Import with Links to Existing Resources Having run the import in the previous example, we can import more data with links to the data that is now in the triplestore: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1# p0801-biblio.xsd\" xmlns:p0801-biblio=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:p0801-beol=\"http://api.knora.org/ontology/0801/beol/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\"> <p0801-biblio:JournalArticle id=\"strings_in_the_18th_century\"> <knoraXmlImport:label>Strings in the 18th Century</knoraXmlImport:label> <p0801-biblio:p0801-beol__comment knoraType=\"richtext_value\" mapping_id=\"http://rdfh.ch/standoff/mappings/StandardMapping\"> <text xmlns=\"\">The most <strong>boring</strong> article in <a class=\"salsah-link\" href=\"http://rdfh.ch/biblio/QMDEHvBNQeOdw85Z2NSi9A\">Math Intelligencer</a>.</text> </p0801-biblio:p0801-beol__comment> <p0801-biblio:endPage knoraType=\"richtext_value\">76</p0801-biblio:endPage> <p0801-biblio:isPartOfJournal> <p0801-biblio:Journal knoraType=\"link_value\" linkType=\"iri\" target=\"http://rdfh.ch/biblio/QMDEHvBNQeOdw85Z2NSi9A\"/> </p0801-biblio:isPartOfJournal> <p0801-biblio:journalVolume knoraType=\"richtext_value\">27</p0801-biblio:journalVolume> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType=\"link_value\" linkType=\"iri\" target=\"http://rdfh.ch/biblio/c-xMB3qkRs232pWyjdUUvA\"/> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasDate knoraType=\"date_value\">GREGORIAN:1977</p0801-biblio:publicationHasDate> <p0801-biblio:publicationHasTitle knoraType=\"richtext_value\">Strings in the 18th Century</p0801-biblio:publicationHasTitle> <p0801-biblio:startPage knoraType=\"richtext_value\">52</p0801-biblio:startPage> </p0801-biblio:JournalArticle> </knoraXmlImport:resources> Note that in the link elements referring to existing resources, the linkType attribute has the value iri , and the target attribute contains the IRI of the target resource. Bulk Import with Image Files To attach an image file to a resource, we must provide the element knoraXmlImport:file before the property elements. In this element, we must provide a filename attribute, containing the internalFilename that Sipi returned for the file in 2. Upload Files to Sipi . <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns=\"http://api.knora.org/ontology/incunabula/xml-import/v1#\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/incunabula/xml-import/v1# incunabula.xsd\" xmlns:incunabula=\"http://api.knora.org/ontology/incunabula/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\"> <incunabula:book id=\"test_book\"> <knoraXmlImport:label>a book with one page</knoraXmlImport:label> <incunabula:title knoraType=\"richtext_value\">the title of a book with one page</incunabula:title> </incunabula:book> <incunabula:page id=\"test_page\"> <knoraXmlImport:label>a page with an image</knoraXmlImport:label> <knoraXmlImport:file filename=\"67SEfNU1wK2-CSf5abe2eh3.jp2\"/> <incunabula:origname knoraType=\"richtext_value\">Chlaus</incunabula:origname> <incunabula:pagenum knoraType=\"richtext_value\">1a</incunabula:pagenum> <incunabula:partOf> <incunabula:book knoraType=\"link_value\" linkType=\"ref\" ref=\"test_book\"/> </incunabula:partOf> <incunabula:seqnum knoraType=\"int_value\">1</incunabula:seqnum> </incunabula:page> </knoraXmlImport:resources> During the processing of the bulk import, Knora will ask Sipi for the rest of the file's metadata, and store that metadata in a file value attached to the resource.","title":"Adding Resources"},{"location":"03-endpoints/api-v1/adding-resources/#adding-resources","text":"To create a resource, the HTTP method POST has to be used. The request has to be sent to the Knora server using the resources path segment: HTTP POST to http://host/v1/resources Unlike in the case of GET requests, the request body consists of JSON describing the resource to be created. Creating resources requires authentication since only known users may add resources.","title":"Adding Resources"},{"location":"03-endpoints/api-v1/adding-resources/#adding-resources-without-image-files","text":"The format of the JSON used to create a resource without an image file is described in the TypeScript interface createResourceWithoutRepresentationRequest in module createResourceFormats . It requires the IRI of the resource class the new resource belongs to, a label describing the new resource, the IRI of the project the new resource belongs to, and the properties to be assigned to the new resource. The request header's content type has to be set to application/json .","title":"Adding Resources Without Image Files"},{"location":"03-endpoints/api-v1/adding-resources/#adding-resources-with-image-files","text":"The first step is to upload an image file to Sipi, using a multipart/form-data request, where sipihost represents the host and port on which Sipi is running: HTTP POST to http://sipihost/upload?token=TOKEN The TOKEN is the sid returned by Knora in response to the client's login request (see Authentication ). The request must contain a body part providing the file as well as a parameter filename , providing the file's original filename, which both Knora and Sipi will store; these filenames can be descriptive and need not be unique. Sipi will then convert the uploaded image file to JPEG 2000 format and store it in a temporary location. If this is successful, it will return a JSON response that looks something like this: { \"uploadedFiles\": [{ \"originalFilename\": \"manuscript-1234-page-1.tiff\", \"internalFilename\": \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\", \"temporaryBaseIIIFUrl\": \"http://sipihost/tmp\" }] } This provides: the originalFilename , which we submitted when uploading the file the unique internalFilename that Sipi has randomly generated for the file the temporaryBaseIIIFUrl , which we can use to construct a IIIF URL for previewing the file The client may now wish to get a thumbnail of the uploaded image, to allow the user to confirm that the correct files have been uploaded. This can be done by adding the filename and IIIF parameters to temporaryBaseIIIFUrl . For example, to get a JPG thumbnail image whose width and height are at most 128 pixels wide, you would request http://sipihost/tmp/3UIsXH9bP0j-BV0D4sN51Xz.jp2/full/!128,128/0/default.jpg . The request to Knora works similarly to Adding Resources Without Image Files , with the addition of file , whose value is the internalFilename that Sipi returned. See the TypeScript interface createResourceWithRepresentationRequest in module createResourceFormats for details. The request header's content type must be set to application/json .","title":"Adding Resources with Image Files"},{"location":"03-endpoints/api-v1/adding-resources/#response-to-a-resource-creation","text":"When a resource has been successfully created, Knora sends back a JSON containing the new resource's IRI ( res_id ) and its properties. The resource IRI identifies the resource and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface createResourceResponse in module createResourceFormats .","title":"Response to a Resource Creation"},{"location":"03-endpoints/api-v1/adding-resources/#changing-a-resources-label","text":"A resource's label can be changed by making a PUT request to the path segments resources/label . The resource's IRI has to be provided in the URL (as its last segment). The new label has to submitted as JSON in the HTTP request's body. HTTP PUT to http://host/v1/resources/label/resourceIRI The JSON format of the request is described in the TypeScript interface changeResourceLabelRequest in module createResourceFormats . The response is described in the TypeScript interface changeResourceLabelResponse in module createResourceFormats .","title":"Changing a Resource's Label"},{"location":"03-endpoints/api-v1/adding-resources/#bulk-import","text":"If you have a large amount of data to import into Knora, it can be more convenient to use the bulk import feature than to create resources one by one. In a bulk import operation, you submit an XML document to Knora, describing multiple resources to be created. This is especially useful if the resources to be created have links to one another. Knora checks the entire request for consistency as as a whole, and performs the update in a single database transaction. Only system or project administrators may use the bulk import. The procedure for using this feature is as follows (see the example below ). Make an HTTP GET request to Knora to get XML schemas describing the XML to be provided for the import. If you are importing image files, upload files to Sipi . Generate an XML import document representing the data to be imported, following the Knora import schemas that were generated in step 1. You will probably want to write a script to do this. Knora is not involved in this step. If you are also importing image files, this XML document needs to contain the filenames that Sipi returned for the files you uploaded in step 2. Validate your XML import document , using an XML schema validator such as Apache Xerces or Saxon , or an XML development environment such as Oxygen . This will help ensure that the data you submit to Knora is correct. Knora is not involved in this step. Submit the XML import document to Knora . In this procedure, the person responsible for generating the XML import data need not be familiar with RDF or with the ontologies involved. When Knora receives an XML import, it validates it first using the relevant XML schemas, and then using the same internal checks that it performs when creating any resource. The details of the XML import format are illustrated in the following examples.","title":"Bulk Import"},{"location":"03-endpoints/api-v1/adding-resources/#bulk-import-example","text":"Suppose we have a project with existing data (but no image files), which we want to import into Knora. We have created an ontology called http://www.knora.org/ontology/0801/biblio for the project, and this ontology also uses definitions from another ontology, called http://www.knora.org/ontology/0801/beol .","title":"Bulk Import Example"},{"location":"03-endpoints/api-v1/adding-resources/#1-get-xml-schemas","text":"To get XML schemas for an import, we use the following route, specifying the (URL-encoded) IRI of our project's main ontology (in this case http://www.knora.org/ontology/0801/biblio ): HTTP GET to http://host/v1/resources/xmlimportschemas/ontologyIRI In our example, the URL could be: http://localhost:3333/v1/resources/xmlimportschemas/http%3A%2F%2Fwww.knora.org%2Fontology%2F0801%2Fbiblio This returns a Zip archive called p0801-biblio-xml-schemas.zip , containing three files: p0801-biblio.xsd : The schema for our main ontology. p0801-beol.xsd : A schema for another ontology that our main ontology depends on. knoraXmlImport.xsd : The standard Knora XML import schema, used by all XML imports.","title":"1. Get XML Schemas"},{"location":"03-endpoints/api-v1/adding-resources/#2-upload-files-to-sipi","text":"See Upload Files to Sipi in the DSP-API v2 documentation.","title":"2. Upload Files to Sipi"},{"location":"03-endpoints/api-v1/adding-resources/#3-generate-xml-import-document","text":"We now convert our existing data to XML, probably by writing a custom script. The resulting XML import document could look like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1# p0801-biblio.xsd\" xmlns:p0801-biblio=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:p0801-beol=\"http://api.knora.org/ontology/0801/beol/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\"> <p0801-beol:person id=\"abel\"> <knoraXmlImport:label>Niels Henrik Abel</knoraXmlImport:label> <p0801-beol:hasFamilyName knoraType=\"richtext_value\">Abel</p0801-beol:hasFamilyName> <p0801-beol:hasGivenName knoraType=\"richtext_value\">Niels Henrik</p0801-beol:hasGivenName> <p0801-beol:personHasTitle knoraType=\"richtext_value\" lang=\"en\">Sir</p0801-beol:personHasTitle> </p0801-beol:person> <p0801-beol:person id=\"holmes\"> <knoraXmlImport:label>Sherlock Holmes</knoraXmlImport:label> <p0801-beol:hasFamilyName knoraType=\"richtext_value\">Holmes</p0801-beol:hasFamilyName> <p0801-beol:hasGivenName knoraType=\"richtext_value\">Sherlock</p0801-beol:hasGivenName> </p0801-beol:person> <p0801-biblio:Journal id=\"math_intelligencer\"> <knoraXmlImport:label>Math Intelligencer</knoraXmlImport:label> <p0801-biblio:hasName knoraType=\"richtext_value\">Math Intelligencer</p0801-biblio:hasName> </p0801-biblio:Journal> <p0801-biblio:JournalArticle id=\"strings_in_the_16th_and_17th_centuries\" creationDate=\"2019-01-09T15:45:54Z\"> <knoraXmlImport:label>Strings in the 16th and 17th Centuries</knoraXmlImport:label> <p0801-biblio:p0801-beol__comment knoraType=\"richtext_value\" mapping_id=\"http://rdfh.ch/standoff/mappings/StandardMapping\"> <text xmlns=\"\">The most <strong>interesting</strong> article in <a class=\"salsah-link\" href=\"ref:math_intelligencer\">Math Intelligencer</a>.</text> </p0801-biblio:p0801-beol__comment> <p0801-biblio:endPage knoraType=\"richtext_value\">73</p0801-biblio:endPage> <p0801-biblio:isPartOfJournal> <p0801-biblio:Journal knoraType=\"link_value\" target=\"math_intelligencer\" linkType=\"ref\"/> </p0801-biblio:isPartOfJournal> <p0801-biblio:journalVolume knoraType=\"richtext_value\">27</p0801-biblio:journalVolume> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType=\"link_value\" linkType=\"ref\" target=\"abel\"/> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType=\"link_value\" linkType=\"ref\" target=\"holmes\"/> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasDate knoraType=\"date_value\">GREGORIAN:1976</p0801-biblio:publicationHasDate> <p0801-biblio:publicationHasTitle knoraType=\"richtext_value\" lang=\"en\">Strings in the 16th and 17th Centuries</p0801-biblio:publicationHasTitle> <p0801-biblio:publicationHasTitle knoraType=\"richtext_value\">An alternate title</p0801-biblio:publicationHasTitle> <p0801-biblio:startPage knoraType=\"richtext_value\">48</p0801-biblio:startPage> </p0801-biblio:JournalArticle> </knoraXmlImport:resources> This illustrates several aspects of XML imports: The root XML element must be knoraXmlImport:resources . There is an XML namespace corresponding each ontology used in the import. These namespaces can be found in the XML schema files returned by Knora. We have copied and pasted xmlns=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" from the main XML schema, p0801-biblio.xsd . This enables the Knora API server to identify the main ontology we are using. We have used xsi:schemaLocation to indicate the main schema's namespace and filename. If we put our XML document in the same directory as the schemas, and we run an XML validator to check the XML, it should load the schemas. The child elements of knoraXmlImport:resources represent resources to be created. The order of these elements is unimportant. Each resource must have an ID, which must be an XML NCName , and must be unique within the file. These IDs are used only during the import, and will not be stored in the triplestore. Each resource can optionally have a creationDate attribute, which can be an xsd:dateTime or an xsd:dateTimeStamp . If creationDate is not supplied, the current time is used. The first child element of each resource must be a knoraXmlImport:label , which will be stored as the resource's rdfs:label . Optionally, the second child element of a resource can provide metadata about a file to be attached to the resource (see bulk-import-with-digital-representations). The remaining child elements of each resource represent its property values. These must be sorted in alphabetical order by property name. If a property has mutliple values, these are represented as multiple adjacent property elements. The type of each value must be specified using the attribute knoraType . A link to another resource described in the XML import is represented as a child element of a property element, with attributes knoraType=\"link_value\" and linkType=\"ref\" , and a target attribute containing the ID of the target resource. There is a specfic syntax for referring to properties from other ontologies. In the example, p0801-beol:comment is defined in the ontology http://www.knora.org/ontology/0001/beol . In the XML, we refer to it as p0801-biblio:p0801-beol__comment . A text value can contain XML markup. If it does: The text value element must have the attribute mapping_id , specifying a mapping from XML to standoff markup (see XML-to-standoff-mapping). It is necessary to specify the appropriate XML namespace (in this case the null namespace, xmlns=\"\" ) for the XML markup in the text value. The XML markup in the text value will not be validated by the schema. In an XML tag that is mapped to a standoff link tag, the link target can refer either to the IRI of a resoruce that already exists in the triplestore, or to the ID of a resource described in the import. If a link points to a resource described in the import, the ID of the target resource must be prefixed with ref: . In the example above, using the standard mapping, the standoff link to math_intelligencer has the target ref:math_intelligencer . A text value can have a lang attribute, whose value is an ISO 639-1 code specifying the language of the text.","title":"3. Generate XML Import Document"},{"location":"03-endpoints/api-v1/adding-resources/#4-validate-xml-import-document","text":"You can use an XML schema validator such as Apache Xerces or Saxon , or an XML development environment such as Oxygen , to check that your XML import document is valid according to the schemas you got from Knora. For example, using Saxon: java -cp ./saxon9ee.jar com.saxonica.Validate -xsd:p0801-biblio.xsd -s:data.xml","title":"4. Validate XML Import Document"},{"location":"03-endpoints/api-v1/adding-resources/#5-submit-xml-import-document-to-knora","text":"To create these resources in Knora, make an HTTP post request with the XML import document as the request body. The URL must specify the (URL-encoded) IRI of the project in which the resources should be created: HTTP POST to http://host/v1/resources/xmlimport/projectIRI For example, using curl : curl -v -u root@example.com:test --data @data.xml --header \"Content-Type: application/xml\" http://localhost:3333/v1/resources/xmlimport/http%3A%2F%2Frdfh.ch%2Fprojects%2F0801","title":"5. Submit XML Import Document to Knora"},{"location":"03-endpoints/api-v1/adding-resources/#bulk-import-with-links-to-existing-resources","text":"Having run the import in the previous example, we can import more data with links to the data that is now in the triplestore: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1# p0801-biblio.xsd\" xmlns:p0801-biblio=\"http://api.knora.org/ontology/0801/biblio/xml-import/v1#\" xmlns:p0801-beol=\"http://api.knora.org/ontology/0801/beol/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\"> <p0801-biblio:JournalArticle id=\"strings_in_the_18th_century\"> <knoraXmlImport:label>Strings in the 18th Century</knoraXmlImport:label> <p0801-biblio:p0801-beol__comment knoraType=\"richtext_value\" mapping_id=\"http://rdfh.ch/standoff/mappings/StandardMapping\"> <text xmlns=\"\">The most <strong>boring</strong> article in <a class=\"salsah-link\" href=\"http://rdfh.ch/biblio/QMDEHvBNQeOdw85Z2NSi9A\">Math Intelligencer</a>.</text> </p0801-biblio:p0801-beol__comment> <p0801-biblio:endPage knoraType=\"richtext_value\">76</p0801-biblio:endPage> <p0801-biblio:isPartOfJournal> <p0801-biblio:Journal knoraType=\"link_value\" linkType=\"iri\" target=\"http://rdfh.ch/biblio/QMDEHvBNQeOdw85Z2NSi9A\"/> </p0801-biblio:isPartOfJournal> <p0801-biblio:journalVolume knoraType=\"richtext_value\">27</p0801-biblio:journalVolume> <p0801-biblio:publicationHasAuthor> <p0801-beol:person knoraType=\"link_value\" linkType=\"iri\" target=\"http://rdfh.ch/biblio/c-xMB3qkRs232pWyjdUUvA\"/> </p0801-biblio:publicationHasAuthor> <p0801-biblio:publicationHasDate knoraType=\"date_value\">GREGORIAN:1977</p0801-biblio:publicationHasDate> <p0801-biblio:publicationHasTitle knoraType=\"richtext_value\">Strings in the 18th Century</p0801-biblio:publicationHasTitle> <p0801-biblio:startPage knoraType=\"richtext_value\">52</p0801-biblio:startPage> </p0801-biblio:JournalArticle> </knoraXmlImport:resources> Note that in the link elements referring to existing resources, the linkType attribute has the value iri , and the target attribute contains the IRI of the target resource.","title":"Bulk Import with Links to Existing Resources"},{"location":"03-endpoints/api-v1/adding-resources/#bulk-import-with-image-files","text":"To attach an image file to a resource, we must provide the element knoraXmlImport:file before the property elements. In this element, we must provide a filename attribute, containing the internalFilename that Sipi returned for the file in 2. Upload Files to Sipi . <?xml version=\"1.0\" encoding=\"UTF-8\"?> <knoraXmlImport:resources xmlns=\"http://api.knora.org/ontology/incunabula/xml-import/v1#\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://api.knora.org/ontology/incunabula/xml-import/v1# incunabula.xsd\" xmlns:incunabula=\"http://api.knora.org/ontology/incunabula/xml-import/v1#\" xmlns:knoraXmlImport=\"http://api.knora.org/ontology/knoraXmlImport/v1#\"> <incunabula:book id=\"test_book\"> <knoraXmlImport:label>a book with one page</knoraXmlImport:label> <incunabula:title knoraType=\"richtext_value\">the title of a book with one page</incunabula:title> </incunabula:book> <incunabula:page id=\"test_page\"> <knoraXmlImport:label>a page with an image</knoraXmlImport:label> <knoraXmlImport:file filename=\"67SEfNU1wK2-CSf5abe2eh3.jp2\"/> <incunabula:origname knoraType=\"richtext_value\">Chlaus</incunabula:origname> <incunabula:pagenum knoraType=\"richtext_value\">1a</incunabula:pagenum> <incunabula:partOf> <incunabula:book knoraType=\"link_value\" linkType=\"ref\" ref=\"test_book\"/> </incunabula:partOf> <incunabula:seqnum knoraType=\"int_value\">1</incunabula:seqnum> </incunabula:page> </knoraXmlImport:resources> During the processing of the bulk import, Knora will ask Sipi for the rest of the file's metadata, and store that metadata in a file value attached to the resource.","title":"Bulk Import with Image Files"},{"location":"03-endpoints/api-v1/adding-values/","text":"Adding a Value In order to add values to an existing resource, the HTTP method POST has to be used. The request has to be sent to the Knora server using the values path segment. Creating values requires authentication since only known users may add values. Adding a Property Value In order to add a value to a resource, its property type, value, and project has to be indicated in the JSON. Also the IRI of the resource the new value belongs has to be provided in the JSON. HTTP POST to http://host/v1/values Depending on the type of the new value, one of the following formats (all TypeScript interfaces defined in module addValueFormats ) has to be used in order to create a new value: addRichtextValueRequest addLinkValueRequest addIntegerValueRequest addDecimalValueRequest addBooleanValueRequest addUriValueRequest addDateValueRequest (see dateString in basicMessageComponents for the date format) addColorValueRequest addGeometryValueRequest addHierarchicalListValueRequest addintervalValueRequest addGeonameValueRequest Response on Value Creation When a value has been successfully created, Knora sends back a JSON with the new value's IRI. The value IRI identifies the value and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface addValueResponse in module addValueFormats .","title":"Adding Values"},{"location":"03-endpoints/api-v1/adding-values/#adding-a-value","text":"In order to add values to an existing resource, the HTTP method POST has to be used. The request has to be sent to the Knora server using the values path segment. Creating values requires authentication since only known users may add values.","title":"Adding a Value"},{"location":"03-endpoints/api-v1/adding-values/#adding-a-property-value","text":"In order to add a value to a resource, its property type, value, and project has to be indicated in the JSON. Also the IRI of the resource the new value belongs has to be provided in the JSON. HTTP POST to http://host/v1/values Depending on the type of the new value, one of the following formats (all TypeScript interfaces defined in module addValueFormats ) has to be used in order to create a new value: addRichtextValueRequest addLinkValueRequest addIntegerValueRequest addDecimalValueRequest addBooleanValueRequest addUriValueRequest addDateValueRequest (see dateString in basicMessageComponents for the date format) addColorValueRequest addGeometryValueRequest addHierarchicalListValueRequest addintervalValueRequest addGeonameValueRequest","title":"Adding a Property Value"},{"location":"03-endpoints/api-v1/adding-values/#response-on-value-creation","text":"When a value has been successfully created, Knora sends back a JSON with the new value's IRI. The value IRI identifies the value and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface addValueResponse in module addValueFormats .","title":"Response on Value Creation"},{"location":"03-endpoints/api-v1/authentication/","text":"Authentication Login and Logout When a client accesses the /v1/session?login route successfully, it gets back headers requesting that a cookie is created, which will store the session token. On all subsequent calls to any route, this session token needs to be sent with each request. Normally, a web browser does this automatically, i.e. sends the cookie on every request. The session token is used by the server to retrieve the user profile. If successful, the user is deemed authenticated. To logout the client can call the same route and provide the logout parameter /v1/session?logout . This will invalidate the session token and return headers for removing the cookie on the client. Submitting Credentials For login , credentials in form of email and password need to be sent with the request. There are two possibilities to do so: in the URL submitting the parameters email and password (e.g., http://knora-host/v1/resources/resIri?email=userUrlEncodedEmail&password=pw ) in the HTTP authorization header ( HTTP basic authentication ) when doing a HTTP request to the API When using Python's module requests , the credentials (email / password) can simply be submitted as a tuple with each request using the param auth ( python requests ). An alternative way for accessing all routes is to simply supply the email and password credentials on each request either as URL parameters or in the HTTP authorization header. Checking Credentials To check the credentials, there is a special route called /v1/authenticate , which can be used to check if the credentials are valid. Usage Scenarios Create session by logging-in, send session token on each subsequent request, and logout when finished. Send email/password credentials on every request.","title":"Authentication"},{"location":"03-endpoints/api-v1/authentication/#authentication","text":"","title":"Authentication"},{"location":"03-endpoints/api-v1/authentication/#login-and-logout","text":"When a client accesses the /v1/session?login route successfully, it gets back headers requesting that a cookie is created, which will store the session token. On all subsequent calls to any route, this session token needs to be sent with each request. Normally, a web browser does this automatically, i.e. sends the cookie on every request. The session token is used by the server to retrieve the user profile. If successful, the user is deemed authenticated. To logout the client can call the same route and provide the logout parameter /v1/session?logout . This will invalidate the session token and return headers for removing the cookie on the client.","title":"Login and Logout"},{"location":"03-endpoints/api-v1/authentication/#submitting-credentials","text":"For login , credentials in form of email and password need to be sent with the request. There are two possibilities to do so: in the URL submitting the parameters email and password (e.g., http://knora-host/v1/resources/resIri?email=userUrlEncodedEmail&password=pw ) in the HTTP authorization header ( HTTP basic authentication ) when doing a HTTP request to the API When using Python's module requests , the credentials (email / password) can simply be submitted as a tuple with each request using the param auth ( python requests ). An alternative way for accessing all routes is to simply supply the email and password credentials on each request either as URL parameters or in the HTTP authorization header.","title":"Submitting Credentials"},{"location":"03-endpoints/api-v1/authentication/#checking-credentials","text":"To check the credentials, there is a special route called /v1/authenticate , which can be used to check if the credentials are valid.","title":"Checking Credentials"},{"location":"03-endpoints/api-v1/authentication/#usage-scenarios","text":"Create session by logging-in, send session token on each subsequent request, and logout when finished. Send email/password credentials on every request.","title":"Usage Scenarios"},{"location":"03-endpoints/api-v1/changing-values/","text":"Changing a Value To add values to an existing resource, the HTTP method PUT has to be used. Changing values requires authentication since only known users may change values. Modifying a Property Value The request has to be sent to the Knora server using the values path segment followed by the value's IRI: HTTP PUT to http://host/values/valueIRI The value IRI has to be URL-encoded. To change an existing value (creating a new version of it), the value's current IRI and its new value have to be submitted as JSON in the HTTP body. Depending on the type of the new value, one of the following formats has to be used in order to create a new value (all these TypeScript interfaces are defined in module changeValueFormats ): changeRichtextValueRequest changeLinkValueRequest changeIntegerValueRequest changeDecimalValueRequest changeBooleanValueRequest changeUriValueRequest changeDateValueRequest changeColorValueRequest changeGeometryValueRequest changeHierarchicalListValueRequest changeIntervalValueRequest changeGeonameValueRequest Modifying a File Value To change a file value, the client first uploads the new file to Sipi, following the procedure described in Adding Resources with Image Files . Then the client sends a request to Knora, using this following route: HTTP PUT to http://host/filevalue/resourceIRI Here, resourceIRI is the URL-encoded IRI of the resource whose file value is to be changed. The body of the request is a JSON object described in the TypeScript interface changeFileValueRequest in module changeValueFormats , and contains file , whose value is the internalFilename that Sipi returned. The request header's content type must be set to application/json . Response on Value Change When a value has been successfully changed, Knora sends back a JSON with the new value's IRI. The value IRI identifies the value and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface changeValueResponse in module changeValueFormats .","title":"Changing Values"},{"location":"03-endpoints/api-v1/changing-values/#changing-a-value","text":"To add values to an existing resource, the HTTP method PUT has to be used. Changing values requires authentication since only known users may change values.","title":"Changing a Value"},{"location":"03-endpoints/api-v1/changing-values/#modifying-a-property-value","text":"The request has to be sent to the Knora server using the values path segment followed by the value's IRI: HTTP PUT to http://host/values/valueIRI The value IRI has to be URL-encoded. To change an existing value (creating a new version of it), the value's current IRI and its new value have to be submitted as JSON in the HTTP body. Depending on the type of the new value, one of the following formats has to be used in order to create a new value (all these TypeScript interfaces are defined in module changeValueFormats ): changeRichtextValueRequest changeLinkValueRequest changeIntegerValueRequest changeDecimalValueRequest changeBooleanValueRequest changeUriValueRequest changeDateValueRequest changeColorValueRequest changeGeometryValueRequest changeHierarchicalListValueRequest changeIntervalValueRequest changeGeonameValueRequest","title":"Modifying a Property Value"},{"location":"03-endpoints/api-v1/changing-values/#modifying-a-file-value","text":"To change a file value, the client first uploads the new file to Sipi, following the procedure described in Adding Resources with Image Files . Then the client sends a request to Knora, using this following route: HTTP PUT to http://host/filevalue/resourceIRI Here, resourceIRI is the URL-encoded IRI of the resource whose file value is to be changed. The body of the request is a JSON object described in the TypeScript interface changeFileValueRequest in module changeValueFormats , and contains file , whose value is the internalFilename that Sipi returned. The request header's content type must be set to application/json .","title":"Modifying a File Value"},{"location":"03-endpoints/api-v1/changing-values/#response-on-value-change","text":"When a value has been successfully changed, Knora sends back a JSON with the new value's IRI. The value IRI identifies the value and can be used to perform future DSP-API V1 operations. The JSON format of the response is described in the TypeScript interface changeValueResponse in module changeValueFormats .","title":"Response on Value Change"},{"location":"03-endpoints/api-v1/delete-resources-and-values/","text":"Deleting Resources and Values Knora does not actually delete resources or values; it just marks them as deleted. To mark a resource or value as deleted, you must use the HTTP method DELETE has to be used. This requires authentication. Mark a Resource as Deleted The delete request has to be sent to the Knora server using the resources path segment. HTTP DELETE to http://host/resources/resourceIRI?deleteComment=String The resource IRI must be URL-encoded. The deleteComment is an optional comment explaining why the resource is being marked as deleted. Mark a Value as Deleted The delete request has to be sent to the Knora server using the values path segment, providing the valueIRI: HTTP DELETE to http://host/values/valueIRI?deleteComment=String The value IRI must be URL-encoded. The deleteComment is an optional comment explaining why the value is being marked as deleted. Once a value has been marked as deleted, no new versions of it can be made.","title":"Deleting Resources and Values"},{"location":"03-endpoints/api-v1/delete-resources-and-values/#deleting-resources-and-values","text":"Knora does not actually delete resources or values; it just marks them as deleted. To mark a resource or value as deleted, you must use the HTTP method DELETE has to be used. This requires authentication.","title":"Deleting Resources and Values"},{"location":"03-endpoints/api-v1/delete-resources-and-values/#mark-a-resource-as-deleted","text":"The delete request has to be sent to the Knora server using the resources path segment. HTTP DELETE to http://host/resources/resourceIRI?deleteComment=String The resource IRI must be URL-encoded. The deleteComment is an optional comment explaining why the resource is being marked as deleted.","title":"Mark a Resource as Deleted"},{"location":"03-endpoints/api-v1/delete-resources-and-values/#mark-a-value-as-deleted","text":"The delete request has to be sent to the Knora server using the values path segment, providing the valueIRI: HTTP DELETE to http://host/values/valueIRI?deleteComment=String The value IRI must be URL-encoded. The deleteComment is an optional comment explaining why the value is being marked as deleted. Once a value has been marked as deleted, no new versions of it can be made.","title":"Mark a Value as Deleted"},{"location":"03-endpoints/api-v1/introduction/","text":"Introduction: Using API V1 RESTful API DSP-API V1 is a RESTful API that allows for reading and adding of resources from and to Knora and changing their values using HTTP requests. The actual data is submitted as JSON (request and response format). The diverse HTTP methods are applied according to the widespread practice of RESTful APIs: GET for reading, POST for adding, PUT for changing resources and values, and DELETE to delete resources or values (see Using HTTP Methods for RESTful Services ). Knora IRIs Every resource that is created or hosted by Knora is identified by a unique id, a so called Internationalized Resource Identifier (IRI). The IRI is required for every API operation to identify the resource in question. A Knora IRI has itself the format of a URL. For some API operations, the IRI has to be URL-encoded (HTTP GET requests). Unlike DSP-API v2, DSP-API v1 uses internal IRIs, i.e. the actual IRIs that are stored in the triplestore (see Knora IRIs ). V1 Path Segment Every request to API V1 includes v1 as a path segment, e.g. http://host/v1/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a . Accordingly, requests to another version of the API will require another path segment. DSP-API Response Format In case an API request could be handled successfully, Knora responds with a 200 HTTP status code. The actual answer from Knora (the representation of the requested resource or information about the executed API operation) is sent in the HTTP body, encoded as JSON (using UTF-8). In this JSON, an API specific status code is sent (member status ). The JSON formats are formally defined as TypeScript interfaces (located in salsah/src/typescript_interfaces ). Build the HTML documentation of these interfaces by executing make jsonformat (see docs/Readme.md for further instructions). Placeholder host in sample URLs Please note that all the sample URLs used in this documentation contain host as a placeholder. The placeholder host has to be replaced by the actual hostname (and port) of the server the Knora instance is running on. Authentication For all API operations that target at changing resources or values, the client has to provide credentials (username and password) so that the API server can authenticate the user making the request. When using the SALSAH web interface, after logging in a session is established (cookie based). When using the API with another client application, credentials can be sent as a part of the HTTP header or as parts of the URL (see Authentication in Knora ). Also when reading resources authentication my be needed as resources and their values may have restricted view permissions.","title":"Introduction"},{"location":"03-endpoints/api-v1/introduction/#introduction-using-api-v1","text":"","title":"Introduction: Using API V1"},{"location":"03-endpoints/api-v1/introduction/#restful-api","text":"DSP-API V1 is a RESTful API that allows for reading and adding of resources from and to Knora and changing their values using HTTP requests. The actual data is submitted as JSON (request and response format). The diverse HTTP methods are applied according to the widespread practice of RESTful APIs: GET for reading, POST for adding, PUT for changing resources and values, and DELETE to delete resources or values (see Using HTTP Methods for RESTful Services ).","title":"RESTful API"},{"location":"03-endpoints/api-v1/introduction/#knora-iris","text":"Every resource that is created or hosted by Knora is identified by a unique id, a so called Internationalized Resource Identifier (IRI). The IRI is required for every API operation to identify the resource in question. A Knora IRI has itself the format of a URL. For some API operations, the IRI has to be URL-encoded (HTTP GET requests). Unlike DSP-API v2, DSP-API v1 uses internal IRIs, i.e. the actual IRIs that are stored in the triplestore (see Knora IRIs ).","title":"Knora IRIs"},{"location":"03-endpoints/api-v1/introduction/#v1-path-segment","text":"Every request to API V1 includes v1 as a path segment, e.g. http://host/v1/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a . Accordingly, requests to another version of the API will require another path segment.","title":"V1 Path Segment"},{"location":"03-endpoints/api-v1/introduction/#dsp-api-response-format","text":"In case an API request could be handled successfully, Knora responds with a 200 HTTP status code. The actual answer from Knora (the representation of the requested resource or information about the executed API operation) is sent in the HTTP body, encoded as JSON (using UTF-8). In this JSON, an API specific status code is sent (member status ). The JSON formats are formally defined as TypeScript interfaces (located in salsah/src/typescript_interfaces ). Build the HTML documentation of these interfaces by executing make jsonformat (see docs/Readme.md for further instructions).","title":"DSP-API Response Format"},{"location":"03-endpoints/api-v1/introduction/#placeholder-host-in-sample-urls","text":"Please note that all the sample URLs used in this documentation contain host as a placeholder. The placeholder host has to be replaced by the actual hostname (and port) of the server the Knora instance is running on.","title":"Placeholder host in sample URLs"},{"location":"03-endpoints/api-v1/introduction/#authentication","text":"For all API operations that target at changing resources or values, the client has to provide credentials (username and password) so that the API server can authenticate the user making the request. When using the SALSAH web interface, after logging in a session is established (cookie based). When using the API with another client application, credentials can be sent as a part of the HTTP header or as parts of the URL (see Authentication in Knora ). Also when reading resources authentication my be needed as resources and their values may have restricted view permissions.","title":"Authentication"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/","text":"Reading and Searching Resources In order to get an existing resource, the HTTP method GET has to be used. The request has to be sent to the Knora server using the resources path segment (depending on the type of request, this segment has to be exchanged, see below). Reading resources may require authentication since some resources may have restricted viewing permissions. Get the Representation of a Resource by its IRI Simple Request of a Resource (full Resource Request) A resource can be obtained by making a GET request to the API providing its IRI. Because a Knora IRI has the format of a URL, its IRI has to be URL encoded. In order to get the resource with the IRI http://rdfh.ch/c5058f3a (an incunabula book contained in the test data), make a HTTP GET request to the resources route (path segment resources in the API call) and append the URL encoded IRI: HTTP GET to http://host/v1/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a More formalized, the URL looks like this: HTTP GET to http://host/v1/resources/resourceIRI As an answer, the client receives a JSON that represents the requested resource. It has the following members: status : The Knora status code, 0 if everything went well userdata : Data about the user that made the request resinfo : Data describing the requested resource and its class resdata : Short information about the resource and its class (including information about the given user's permissions on the resource) incoming : Resources pointing to the requested resource props : Properties of the requested resource. For a complete and more formalized description of a full resource request, look at the TypeScript interface resourceFullResponse in the module resourceResponseFormats . Provide Request Parameters To make a request more specific, the following parameters can be appended to the URL ( http://www.knora.org/resources/resourceIRI?param1=value1&param2=value2 ): reqtype=info|context|rights : Specifies the type of request. Setting the parameter's to value info returns short information about the requested resource (contains only resinfo and no properties, see TypeScript interface resourceInfoResponse in module resourceResponseFormats ). Setting the parameter's value to context returns context information ( resource_context ) about the requested resource: Either the dependent parts of a compound resource (e.g. pages of a book) or the parent resource of a dependent resource (e.g. the book a pages belongs to). By default, a context query does not return information about the requested resource itself, but only about its context (see TypeScript interface resourceContextResponse in module resourceResponseFormats ). See below how to get additional information about the resource. The parameter rights returns only the given user's permissions on the requested resource (see TypeScript interface resourceRightsResponse in module resourceResponseFormats ). resinfo=true : Can be used in combination with reqtype=context : If set, resinfo is added to the response representing information about the requested resource (complementary to its context), see TypeScript interface resourceContextResponse in module resourceResponseFormats . Obtain an HTML Representation of a Resource In order to get an HTML representation of a resource (not a JSON), the path segment resources.html can be used: HTTP GET to http://host/v1/resources.html/resourceIRI?reqtype=properties The request returns the properties of the requested resource as an HTML document. Get only the Properties belonging to a Resource In order to get only the properties of a resource without any other information, the path segment properties can be used: HTTP GET to http://host/v1/properties/resourceIRI The JSON contains just the member properties representing the requested resource's properties (see TypeScript interface resourcePropertiesResponse in module resourceResponseFormats ). Get Information about a Resource Class Get a Resource Class by its IRI In order to get information about a resource class, the path segment resourcetypes can be used. Append the IRI of the resource class to the URL (e.g. http://www.knora.org/ontology/0803/incunabula#book ). HTTP GET to http://host/v1/resourcetypes/resourceClassIRI In the JSON, the information about the resource class and all the property types that it may have are returned. None of these are actual instances of a property, but only types (see TypeScript interface resourceTypeResponse in module resourceResponseFormats ). Get all the Property Types of a Resource Class or a Vocabulary To get a list of all the available property types, the path segment propertylists can be used. It can be restricted to a certain vocbulary using the parameter vocabulary or to a certain resource class using the parameter restype . # returns all the property types for incunabula:page HTTP GET to http://host/v1/propertylists?restype=resourceClassIRI # returns all the property types for the incunabula vocabulary HTTP GET to http://host/v1/propertylists?vocabulary=vocabularyIRI Both of these queries return a list of property types. The default value for the parameter vocabulary is 0 and means that the resource classes from all the available vocabularies are returned. See TypeScript interface propertyTypesInResourceClassResponse in module resourceResponseFormats . Get the Resource Classes of a Vocabulary Resource classes and property types are organized in (project specific) name spaces, so called vocabularies. In order to get all the resource classes defined for a specific vocabulary (e.g. incunabula ), the parameter vocabulary has to be used and assigned the vocabulary's IRI: HTTP GET to http://host/v1/resourcetypes?vocabulary=vocabularyIRI This returns all the resource classes defined for the specified vocabulary and their property types. The default value for the parameter vocabulary is 0 and means that the resource classes from all the available vocabularies are returned. See TypeScript interface resourceTypesInVocabularyResponse in module resourceResponseFormats . Get all the Vocabularies To get a list of all available vocabularies, the path segment vocabularies can be used: HTTP GET to http://host/v1/vocabularies The response will list all the available vocabularies. See TypeScript interface vocabularyResponse in module resourceResponseFormats . Search for Resources Search for Resources by their Label This is a simplified way for searching for resources just by their label. Search by label automatically adds Lucene operators, search strings are expected not to contain any characters with a special meaning in Lucene Query Parser syntax . It is a simple string-based method: HTTP GET to http://host/v1/resources?searchstr=searchValue Additionally, the following parameters can be appended to the URL (search value is Zeitgl\u00f6cklein ): restype_id=resourceClassIRI : This restricts the search to resources of the specified class (subclasses of that class will also match). -1 is the default value and means no restriction to a specific class. If a resource class IRI is specified, it has to be URL encoded (e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&restype_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book ). numprops=Integer : Specifies the number of properties returned for each resource that was found (sorted by GUI order), e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&numprops=4 . limit=Integer : Limits the amount of results returned (e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&limit=1 ). The response lists the resources that matched the search criteria (see TypeScript interface resourceLabelSearchResponse in module resourceResponseFormats ). Fulltext Search DSP-API offers a fulltext search that searches through all textual representations of values. The search terms have to be URL encoded. Fulltext search supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. HTTP GET to http://host/v1/search/searchValue?searchtype=fulltext[&filter_by_restype=resourceClassIRI] [&filter_by_project=projectIRI][&show_nrows=Integer]{[&start_at=Integer] The parameter searchtype is required and has to be set to fulltext . Additionally, these parameters can be set: filter_by_restype=resourceClassIRI : restricts the search to resources of the specified resource class (subclasses of that class will also match). filter_by_project=projectIRI : restricts the search to resources of the specified project. show_nrows=Integer : Indicates how many reults should be presented on one page. If omitted, the default value 25 is used. start_at=Integer : Used to enable paging and go through all the results request by request. The response presents the retrieved resources (according to show_nrows and start_at ) and information about paging. If not all resources could be presented on one page ( nhits is greater than shown_nrows ), the next page can be requested (by increasing start_at by the number of show_nrows ). You can simply go through the elements of paging to request the single pages one by one. See TypeScript interface searchResponse in module searchResponseFormats . Extended Search for Resources HTTP GET to http://host/v1/search/?searchtype=extended [&filter_by_restype=resourceClassIRI][&filter_by_project=projectIRI][&filter_by_owner=userIRI] (&property_id=propertyTypeIRI&compop=comparisonOperator&searchval=searchValue)+ [&show_nrows=Integer][&start_at=Integer] The parameter searchtype is required and has to be set to extended . An extended search requires at least one set of parameters consisting of: property_id=propertyTypeIRI : the property the resource has to have (subproperties of that property will also match). compop=comparisonOperator : the comparison operator to be used to match between the resource's property value and the search term. searchval=searchTerm : the search value to look for. You can also provide several of these sets to make your query more specific. The following table indicates the possible combinations of value types and comparison operators: Value Type Comparison Operator Date Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Integer Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Float Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Text Value MATCH_BOOLEAN, MATCH, EQ, !EQ, LIKE, !LIKE, EXISTS Geometry Value EXISTS Geoname Value EQ, EXISTS URI Value EQ, EXISTS Resource Pointer EQ, EXISTS Color Value EQ, EXISTS List Value EQ, EXISTS Boolean Value EQ, !EQ, EXISTS Explanation of the comparison operators: EQ (equal): checks if a resource's value equals the search value. In case of a text value type, it checks for identity of the strings compared. In case of a date value type, equality is given if the dates overlap in any way. Since dates are internally always treated as periods, equality is given if a date value's period ends after or equals the start of the defined period and a date value's period starts before or equals the end of the defined period. !EQ (not equal): checks if a resource's value does not equal the search value. In case of a text value type, it checks if the compared strings are different. In case of a date value type, inequality is given if the dates do not overlap in any way, meaning that a date starts after the end of the defined period or ends before the beginning of the defined period (dates are internally always treated as periods, see above). GT (greater than): checks if a resource's value is greater than the search value. In case of a date value type, it assures that a period begins after the indicated period's end. GT_EQ (greater than or equal): checks if a resource's value equals or is greater than the search value. In case of a date value type, it assures that the periods overlap in any way (see EQ ) or that the period starts after the indicated period's end (see GT ). LT (less than): checks if a resource's value is lower than the search value. In case of a date value type, it assures that a period ends before the indicated period's start. LT_EQ (less than or equal): checks if a resource's value equals or is lower than the search value. In case of a date value type, it assures that the periods overlap in any way (see EQ ) or that the period ends before the indicated period's start (see LT ). EXISTS : checks if an instance of the indicated property type exists for a resource. Please always provide an empty search value when using EXISTS: \"searchval=\" . Otherwise, the query syntax rules would be violated. MATCH : checks if a resource's text value matches the search value, see Lucene Query Parser Syntax . LIKE : checks if the search value is contained in a resource's text value using the SPARQL REGEX function, thus supporting regular expressions. !LIKE (not like): checks if the search value is not contained in a resource's text value using the SPARQL REGEX function, thus supporting regular expressions. MATCH_BOOLEAN : checks if a resource's text value matches the provided list of positive (exist) and negative (do not exist) terms. The list takes this form: ([+-]term\\s)+ . Additionally, these parameters can be set: filter_by_restype=resourceClassIRI : restricts the search to resources of the specified resource class (subclasses of that class will also match). filter_by_project=projectIRI : restricts the search to resources of the specified project. filter_by_owner : restricts the search to resources owned by the specified user. show_nrows=Integer : Indicates how many reults should be presented on one page. If omitted, the default value 25 is used. start_at=Integer : Used to enable paging and go through all the results request by request. Some sample searches: http://localhost:3333/v1/search/?searchtype=extended&filter_by_restype=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23title&compop=!EQ&searchval=Zeitgl%C3%B6cklein%20des%20Lebens%20und%20Leidens%20Christi : searches for books that have a title that does not equal \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\". http://www.knora.org/v1/search/?searchtype=extended&filter_by_restype=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23title&compop=MATCH&searchval=Zeitgl%C3%B6cklein&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23pubdate&compop=EQ&searchval=JULIAN:1490 : searches for resources of type incunabula:book whose titles match \"Zeitgl\u00f6cklein\" and were published in the year 1490 (according to the Julian calendar). The response presents the retrieved resources (according to show_nrows and start_at ) and information about paging. If not all resources could be presented on one page ( nhits is greater than shown_nrows ), the next page can be requested (by increasing start_at by the number of show_nrows ). You can simply go through the elements of paging to request the single pages one by one. See the TypeScript interface searchResponse in module searchResponseFormats . Get a Graph of Resources The path segment graphdata returns a graph of resources that are reachable via links to or from an initial resource. HTTP GET to http://host/v1/graphdata/resourceIRI?depth=Integer The parameter depth specifies the maximum depth of the graph, and defaults to 4. If depth is 1, the operation will return only the initial resource and any resources that are directly linked to or from it. The graph includes any link that is a subproperty of knora-base:hasLinkTo , except for links that are subproperties of knora-base:isPartOf . Specifically, if resource R1 has a link that is a subproperty of knora-base:isPartOf pointing to resource R2 , no link from R1 to R2 is included in the graph. The response represents the graph as a list of nodes (resources) and a list of edges (links). For details, see the TypeScript interface graphDataResponse in module graphDataResponseFormats . Get Hierarchical Lists The knora-base ontology allows for the definition of hierarchical lists. These can be queried by providing the IRI of the root node. Selections are hierarchical list that are just one level deep. Internally, they are represented as hierarchical lists. You can get a hierarchical by using the path segment hlists and appending the hierarchical list's IRI (URL encoded): HTTP GET to http://host/v1/hlists/rootNodeIRI The response shows all of the list nodes that are element of the requested hierarchical list as a tree structure. See TypeScript interface hierarchicalListResponse in module hierarchicalListResponseFormats . For each node, the full path leading to it from the top level can be requested by making a query providing the node's IRI and setting the param reqtype=node : HTTP GET to http://host/v1/hlists/nodeIri?reqtype=node The response presents the full path to the current node. See the TypeScript interface nodePathResponse in module hierarchicalListResponseFormats .","title":"Reading and Searching Resources"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/#reading-and-searching-resources","text":"In order to get an existing resource, the HTTP method GET has to be used. The request has to be sent to the Knora server using the resources path segment (depending on the type of request, this segment has to be exchanged, see below). Reading resources may require authentication since some resources may have restricted viewing permissions.","title":"Reading and Searching Resources"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/#get-the-representation-of-a-resource-by-its-iri","text":"","title":"Get the Representation of a Resource by its IRI"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/#simple-request-of-a-resource-full-resource-request","text":"A resource can be obtained by making a GET request to the API providing its IRI. Because a Knora IRI has the format of a URL, its IRI has to be URL encoded. In order to get the resource with the IRI http://rdfh.ch/c5058f3a (an incunabula book contained in the test data), make a HTTP GET request to the resources route (path segment resources in the API call) and append the URL encoded IRI: HTTP GET to http://host/v1/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a More formalized, the URL looks like this: HTTP GET to http://host/v1/resources/resourceIRI As an answer, the client receives a JSON that represents the requested resource. It has the following members: status : The Knora status code, 0 if everything went well userdata : Data about the user that made the request resinfo : Data describing the requested resource and its class resdata : Short information about the resource and its class (including information about the given user's permissions on the resource) incoming : Resources pointing to the requested resource props : Properties of the requested resource. For a complete and more formalized description of a full resource request, look at the TypeScript interface resourceFullResponse in the module resourceResponseFormats .","title":"Simple Request of a Resource (full Resource Request)"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/#provide-request-parameters","text":"To make a request more specific, the following parameters can be appended to the URL ( http://www.knora.org/resources/resourceIRI?param1=value1&param2=value2 ): reqtype=info|context|rights : Specifies the type of request. Setting the parameter's to value info returns short information about the requested resource (contains only resinfo and no properties, see TypeScript interface resourceInfoResponse in module resourceResponseFormats ). Setting the parameter's value to context returns context information ( resource_context ) about the requested resource: Either the dependent parts of a compound resource (e.g. pages of a book) or the parent resource of a dependent resource (e.g. the book a pages belongs to). By default, a context query does not return information about the requested resource itself, but only about its context (see TypeScript interface resourceContextResponse in module resourceResponseFormats ). See below how to get additional information about the resource. The parameter rights returns only the given user's permissions on the requested resource (see TypeScript interface resourceRightsResponse in module resourceResponseFormats ). resinfo=true : Can be used in combination with reqtype=context : If set, resinfo is added to the response representing information about the requested resource (complementary to its context), see TypeScript interface resourceContextResponse in module resourceResponseFormats .","title":"Provide Request Parameters"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/#obtain-an-html-representation-of-a-resource","text":"In order to get an HTML representation of a resource (not a JSON), the path segment resources.html can be used: HTTP GET to http://host/v1/resources.html/resourceIRI?reqtype=properties The request returns the properties of the requested resource as an HTML document.","title":"Obtain an HTML Representation of a Resource"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/#get-only-the-properties-belonging-to-a-resource","text":"In order to get only the properties of a resource without any other information, the path segment properties can be used: HTTP GET to http://host/v1/properties/resourceIRI The JSON contains just the member properties representing the requested resource's properties (see TypeScript interface resourcePropertiesResponse in module resourceResponseFormats ).","title":"Get only the Properties belonging to a Resource"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/#get-information-about-a-resource-class","text":"","title":"Get Information about a Resource Class"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/#get-a-resource-class-by-its-iri","text":"In order to get information about a resource class, the path segment resourcetypes can be used. Append the IRI of the resource class to the URL (e.g. http://www.knora.org/ontology/0803/incunabula#book ). HTTP GET to http://host/v1/resourcetypes/resourceClassIRI In the JSON, the information about the resource class and all the property types that it may have are returned. None of these are actual instances of a property, but only types (see TypeScript interface resourceTypeResponse in module resourceResponseFormats ).","title":"Get a Resource Class by its IRI"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/#get-all-the-property-types-of-a-resource-class-or-a-vocabulary","text":"To get a list of all the available property types, the path segment propertylists can be used. It can be restricted to a certain vocbulary using the parameter vocabulary or to a certain resource class using the parameter restype . # returns all the property types for incunabula:page HTTP GET to http://host/v1/propertylists?restype=resourceClassIRI # returns all the property types for the incunabula vocabulary HTTP GET to http://host/v1/propertylists?vocabulary=vocabularyIRI Both of these queries return a list of property types. The default value for the parameter vocabulary is 0 and means that the resource classes from all the available vocabularies are returned. See TypeScript interface propertyTypesInResourceClassResponse in module resourceResponseFormats .","title":"Get all the Property Types of a Resource Class or a Vocabulary"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/#get-the-resource-classes-of-a-vocabulary","text":"Resource classes and property types are organized in (project specific) name spaces, so called vocabularies. In order to get all the resource classes defined for a specific vocabulary (e.g. incunabula ), the parameter vocabulary has to be used and assigned the vocabulary's IRI: HTTP GET to http://host/v1/resourcetypes?vocabulary=vocabularyIRI This returns all the resource classes defined for the specified vocabulary and their property types. The default value for the parameter vocabulary is 0 and means that the resource classes from all the available vocabularies are returned. See TypeScript interface resourceTypesInVocabularyResponse in module resourceResponseFormats .","title":"Get the Resource Classes of a Vocabulary"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/#get-all-the-vocabularies","text":"To get a list of all available vocabularies, the path segment vocabularies can be used: HTTP GET to http://host/v1/vocabularies The response will list all the available vocabularies. See TypeScript interface vocabularyResponse in module resourceResponseFormats .","title":"Get all the Vocabularies"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/#search-for-resources","text":"","title":"Search for Resources"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/#search-for-resources-by-their-label","text":"This is a simplified way for searching for resources just by their label. Search by label automatically adds Lucene operators, search strings are expected not to contain any characters with a special meaning in Lucene Query Parser syntax . It is a simple string-based method: HTTP GET to http://host/v1/resources?searchstr=searchValue Additionally, the following parameters can be appended to the URL (search value is Zeitgl\u00f6cklein ): restype_id=resourceClassIRI : This restricts the search to resources of the specified class (subclasses of that class will also match). -1 is the default value and means no restriction to a specific class. If a resource class IRI is specified, it has to be URL encoded (e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&restype_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book ). numprops=Integer : Specifies the number of properties returned for each resource that was found (sorted by GUI order), e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&numprops=4 . limit=Integer : Limits the amount of results returned (e.g. http://www.knora.org/v1/resources?searchstr=Zeitgl%C3%B6cklein&limit=1 ). The response lists the resources that matched the search criteria (see TypeScript interface resourceLabelSearchResponse in module resourceResponseFormats ).","title":"Search for Resources by their Label"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/#fulltext-search","text":"DSP-API offers a fulltext search that searches through all textual representations of values. The search terms have to be URL encoded. Fulltext search supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. HTTP GET to http://host/v1/search/searchValue?searchtype=fulltext[&filter_by_restype=resourceClassIRI] [&filter_by_project=projectIRI][&show_nrows=Integer]{[&start_at=Integer] The parameter searchtype is required and has to be set to fulltext . Additionally, these parameters can be set: filter_by_restype=resourceClassIRI : restricts the search to resources of the specified resource class (subclasses of that class will also match). filter_by_project=projectIRI : restricts the search to resources of the specified project. show_nrows=Integer : Indicates how many reults should be presented on one page. If omitted, the default value 25 is used. start_at=Integer : Used to enable paging and go through all the results request by request. The response presents the retrieved resources (according to show_nrows and start_at ) and information about paging. If not all resources could be presented on one page ( nhits is greater than shown_nrows ), the next page can be requested (by increasing start_at by the number of show_nrows ). You can simply go through the elements of paging to request the single pages one by one. See TypeScript interface searchResponse in module searchResponseFormats .","title":"Fulltext Search"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/#extended-search-for-resources","text":"HTTP GET to http://host/v1/search/?searchtype=extended [&filter_by_restype=resourceClassIRI][&filter_by_project=projectIRI][&filter_by_owner=userIRI] (&property_id=propertyTypeIRI&compop=comparisonOperator&searchval=searchValue)+ [&show_nrows=Integer][&start_at=Integer] The parameter searchtype is required and has to be set to extended . An extended search requires at least one set of parameters consisting of: property_id=propertyTypeIRI : the property the resource has to have (subproperties of that property will also match). compop=comparisonOperator : the comparison operator to be used to match between the resource's property value and the search term. searchval=searchTerm : the search value to look for. You can also provide several of these sets to make your query more specific. The following table indicates the possible combinations of value types and comparison operators: Value Type Comparison Operator Date Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Integer Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Float Value EQ, !EQ, GT, GT_EQ, LT, LT_EQ, EXISTS Text Value MATCH_BOOLEAN, MATCH, EQ, !EQ, LIKE, !LIKE, EXISTS Geometry Value EXISTS Geoname Value EQ, EXISTS URI Value EQ, EXISTS Resource Pointer EQ, EXISTS Color Value EQ, EXISTS List Value EQ, EXISTS Boolean Value EQ, !EQ, EXISTS Explanation of the comparison operators: EQ (equal): checks if a resource's value equals the search value. In case of a text value type, it checks for identity of the strings compared. In case of a date value type, equality is given if the dates overlap in any way. Since dates are internally always treated as periods, equality is given if a date value's period ends after or equals the start of the defined period and a date value's period starts before or equals the end of the defined period. !EQ (not equal): checks if a resource's value does not equal the search value. In case of a text value type, it checks if the compared strings are different. In case of a date value type, inequality is given if the dates do not overlap in any way, meaning that a date starts after the end of the defined period or ends before the beginning of the defined period (dates are internally always treated as periods, see above). GT (greater than): checks if a resource's value is greater than the search value. In case of a date value type, it assures that a period begins after the indicated period's end. GT_EQ (greater than or equal): checks if a resource's value equals or is greater than the search value. In case of a date value type, it assures that the periods overlap in any way (see EQ ) or that the period starts after the indicated period's end (see GT ). LT (less than): checks if a resource's value is lower than the search value. In case of a date value type, it assures that a period ends before the indicated period's start. LT_EQ (less than or equal): checks if a resource's value equals or is lower than the search value. In case of a date value type, it assures that the periods overlap in any way (see EQ ) or that the period ends before the indicated period's start (see LT ). EXISTS : checks if an instance of the indicated property type exists for a resource. Please always provide an empty search value when using EXISTS: \"searchval=\" . Otherwise, the query syntax rules would be violated. MATCH : checks if a resource's text value matches the search value, see Lucene Query Parser Syntax . LIKE : checks if the search value is contained in a resource's text value using the SPARQL REGEX function, thus supporting regular expressions. !LIKE (not like): checks if the search value is not contained in a resource's text value using the SPARQL REGEX function, thus supporting regular expressions. MATCH_BOOLEAN : checks if a resource's text value matches the provided list of positive (exist) and negative (do not exist) terms. The list takes this form: ([+-]term\\s)+ . Additionally, these parameters can be set: filter_by_restype=resourceClassIRI : restricts the search to resources of the specified resource class (subclasses of that class will also match). filter_by_project=projectIRI : restricts the search to resources of the specified project. filter_by_owner : restricts the search to resources owned by the specified user. show_nrows=Integer : Indicates how many reults should be presented on one page. If omitted, the default value 25 is used. start_at=Integer : Used to enable paging and go through all the results request by request. Some sample searches: http://localhost:3333/v1/search/?searchtype=extended&filter_by_restype=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23title&compop=!EQ&searchval=Zeitgl%C3%B6cklein%20des%20Lebens%20und%20Leidens%20Christi : searches for books that have a title that does not equal \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\". http://www.knora.org/v1/search/?searchtype=extended&filter_by_restype=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23book&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23title&compop=MATCH&searchval=Zeitgl%C3%B6cklein&property_id=http%3A%2F%2Fwww.knora.org%2Fontology%2Fincunabula%23pubdate&compop=EQ&searchval=JULIAN:1490 : searches for resources of type incunabula:book whose titles match \"Zeitgl\u00f6cklein\" and were published in the year 1490 (according to the Julian calendar). The response presents the retrieved resources (according to show_nrows and start_at ) and information about paging. If not all resources could be presented on one page ( nhits is greater than shown_nrows ), the next page can be requested (by increasing start_at by the number of show_nrows ). You can simply go through the elements of paging to request the single pages one by one. See the TypeScript interface searchResponse in module searchResponseFormats .","title":"Extended Search for Resources"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/#get-a-graph-of-resources","text":"The path segment graphdata returns a graph of resources that are reachable via links to or from an initial resource. HTTP GET to http://host/v1/graphdata/resourceIRI?depth=Integer The parameter depth specifies the maximum depth of the graph, and defaults to 4. If depth is 1, the operation will return only the initial resource and any resources that are directly linked to or from it. The graph includes any link that is a subproperty of knora-base:hasLinkTo , except for links that are subproperties of knora-base:isPartOf . Specifically, if resource R1 has a link that is a subproperty of knora-base:isPartOf pointing to resource R2 , no link from R1 to R2 is included in the graph. The response represents the graph as a list of nodes (resources) and a list of edges (links). For details, see the TypeScript interface graphDataResponse in module graphDataResponseFormats .","title":"Get a Graph of Resources"},{"location":"03-endpoints/api-v1/reading-and-searching-resources/#get-hierarchical-lists","text":"The knora-base ontology allows for the definition of hierarchical lists. These can be queried by providing the IRI of the root node. Selections are hierarchical list that are just one level deep. Internally, they are represented as hierarchical lists. You can get a hierarchical by using the path segment hlists and appending the hierarchical list's IRI (URL encoded): HTTP GET to http://host/v1/hlists/rootNodeIRI The response shows all of the list nodes that are element of the requested hierarchical list as a tree structure. See TypeScript interface hierarchicalListResponse in module hierarchicalListResponseFormats . For each node, the full path leading to it from the top level can be requested by making a query providing the node's IRI and setting the param reqtype=node : HTTP GET to http://host/v1/hlists/nodeIri?reqtype=node The response presents the full path to the current node. See the TypeScript interface nodePathResponse in module hierarchicalListResponseFormats .","title":"Get Hierarchical Lists"},{"location":"03-endpoints/api-v1/reading-values/","text":"Reading Values In order to get an existing value, the HTTP method GET has to be used. The request has to be sent to the Knora server using the values path segment. Reading values may require authentication since some resources may have restricted viewing permissions. Reading a Value The representation of a value can be obtained by making a GET request providing the value's IRI: HTTP GET to http://host/v1/values/valueIRI In the response, the value's type and value are returned (see TypeScript interface valueResponse in module valueResponseFormats ). Getting a Value's Version History In order to get the history of a value (its current and previous versions), the IRI of the resource it belongs to, the IRI of the property type that connects the resource to the value, and its current value IRI have to be submitted. Each of these elements is appended to the URL and separated by a slash. Please note that all of these have to be URL encoded. Additionally to values , the path segment history has to be used: HTTP GET to http://host/v1/values/history/resourceIRI/propertyTypeIRI/valueIRI In the response, the value's versions returned (see TypeScript interface valueVersionsResponse in module valueResponseFormats ). Getting a Linking Value In order to get information about a link between two resources, the path segment links has to be used. The IRI of the source object, the IRI of the property type linking the the two objects, and the IRI of the target object have to be provided in the URL separated by slashes. Each of these has to be URL encoded. HTTP GET to http://host/links/sourceObjectIRI/linkingPropertyIRI/targetObjectIRI In the response, information about the link is returned such as a reference count indicating how many links of the specified direction (source to target) and type (property) between the two objects exist (see TypeScript interface linkResponse in module valueResponseFormats ).","title":"Reading Values"},{"location":"03-endpoints/api-v1/reading-values/#reading-values","text":"In order to get an existing value, the HTTP method GET has to be used. The request has to be sent to the Knora server using the values path segment. Reading values may require authentication since some resources may have restricted viewing permissions.","title":"Reading Values"},{"location":"03-endpoints/api-v1/reading-values/#reading-a-value","text":"The representation of a value can be obtained by making a GET request providing the value's IRI: HTTP GET to http://host/v1/values/valueIRI In the response, the value's type and value are returned (see TypeScript interface valueResponse in module valueResponseFormats ).","title":"Reading a Value"},{"location":"03-endpoints/api-v1/reading-values/#getting-a-values-version-history","text":"In order to get the history of a value (its current and previous versions), the IRI of the resource it belongs to, the IRI of the property type that connects the resource to the value, and its current value IRI have to be submitted. Each of these elements is appended to the URL and separated by a slash. Please note that all of these have to be URL encoded. Additionally to values , the path segment history has to be used: HTTP GET to http://host/v1/values/history/resourceIRI/propertyTypeIRI/valueIRI In the response, the value's versions returned (see TypeScript interface valueVersionsResponse in module valueResponseFormats ).","title":"Getting a Value's Version History"},{"location":"03-endpoints/api-v1/reading-values/#getting-a-linking-value","text":"In order to get information about a link between two resources, the path segment links has to be used. The IRI of the source object, the IRI of the property type linking the the two objects, and the IRI of the target object have to be provided in the URL separated by slashes. Each of these has to be URL encoded. HTTP GET to http://host/links/sourceObjectIRI/linkingPropertyIRI/targetObjectIRI In the response, information about the link is returned such as a reference count indicating how many links of the specified direction (source to target) and type (property) between the two objects exist (see TypeScript interface linkResponse in module valueResponseFormats ).","title":"Getting a Linking Value"},{"location":"03-endpoints/api-v1/xml-to-standoff-mapping/","text":"XML to Standoff Mapping in API v1 The Knora Standard Mapping Description A mapping allows for the conversion of XML to standoff representation in RDF and back. In order to create a TextValue with markup, the text has to be provided in XML format, along with the IRI of the mapping that will be used to convert the markup to standoff. However, a mapping is only needed if a TextValue with markup should be created. If a text has no markup, it is submitted as a mere sequence of characters. The two cases are described in the TypeScript interfaces simpletext and richtext in module basicMessageComponents . Knora offers a standard mapping with the IRI http://rdfh.ch/standoff/mappings/StandardMapping . The standard mapping covers the HTML elements and attributes supported by the GUI's text editor, CKEditor . (Please note that the HTML has to be encoded in strict XML syntax. CKeditor offers the possibility to define filter rules. They should reflect the elements supported by the mapping; see jquery.htmleditor.js .) The standard mapping contains the following elements and attributes that are mapped to standoff classes and properties defined in the ontology: <text> \u2192 standoff:StandoffRootTag <p> \u2192 standoff:StandoffParagraphTag <em> \u2192 standoff:StandoffItalicTag <strong> \u2192 standoff:StandoffBoldTag <u> \u2192 standoff:StandoffUnderlineTag <sub> \u2192 standoff:StandoffSubscriptTag <sup> \u2192 standoff:StandoffSuperscriptTag <strike> \u2192 standoff:StandoffStrikeTag <a href=\"URL\"> \u2192 knora-base:StandoffUriTag <a class=\"salsah-link\" href=\"Knora IRI\"> \u2192 knora-base:StandoffLinkTag <a class=\"internal-link\" href=\"#fragment\"> \u2192 knora-base:StandoffInternalReferenceTag <h1> to <h6> \u2192 standoff:StandoffHeader1Tag to standoff:StandoffHeader6Tag <ol> \u2192 standoff:StandoffOrderedListTag <ul> \u2192 standoff:StandoffUnrderedListTag <li> \u2192 standoff:StandoffListElementTag <tbody> \u2192 standoff:StandoffTableBodyTag <table> \u2192 standoff:StandoffTableTag <tr> \u2192 standoff:StandoffTableRowTag <td> \u2192 standoff:StandoffTableCellTag <br> \u2192 standoff:StandoffBrTag <hr> \u2192 standoff:StandoffLineTag <pre> \u2192 standoff:StandoffPreTag <cite> \u2192 standoff:StandoffCiteTag <blockquote> \u2192 standoff:StandoffBlockquoteTag <code> \u2192 standoff:StandoffCodeTag The HTML produced by CKEditor is wrapped in an XML doctype and a pair of root tags <text>...</text> and then sent to Knora. The XML sent to the GUI by Knora is unwrapped accordingly (see jquery.htmleditor.js ). Although the GUI supports HTML5, it is treated as if it was XHTML in strict XML notation. Maintenance The standard mapping definition can be found at test_data/test_route/texts/mappingForStandardHTML.xml . It was used to generate the default mapping, distributed as knora-ontologies/standoff-data.ttl and that is loaded at a Knora installation. It should be used to re-generate it, whenever we want to amend or extend it. Note: once the mapping has been generated, one has to rework the resources' UUID in order to maintain backward compatibility. Creating a custom Mapping The Knora standard mapping only supports a few HTML tags. In order to submit more complex XML markup to Knora, a custom mapping has to be created first. Basically, a mapping expresses the relations between XML elements and attributes and their corresponding standoff classes and properties. The relations expressed in a mapping are one-to-one relations, so the XML can be recreated from the data in RDF. However, since HTML offers a very limited set of elements, Knora mappings support the combination of element names and classes. In this way, the same element can be used several times in combination with another classname (please note that <a> without a class is a mere hyperlink whereas <a class=\"salsah-link\"> is an internal link/standoff link). With a mapping, a default XSL transformation may be provided to transform the XML to HTML before sending it back to the client. This is useful when the client is a web-browser expecting HTML (instead of XML). Basic Structure of a Mapping The mapping is written in XML itself (for a formal description, see webapi/src/resources/mappingXMLToStandoff.xsd ). It has the following structure (the indentation corresponds to the nesting in XML): <mapping> : the root element <defaultXSLTransformation> (optional) : the Iri of the default XSL transformation to be applied to the XML when reading it back from Knora. The XSL transformation is expected to produce HTML. If given, the Iri has to refer to a resource of type knora-base:XSLTransformation . <mappingElement> : an element of the mapping (at least one) <tag> : information about the XML element that is mapped to a standoff class <name> : name of the XML element <class> : value of the class attribute of the XML element, if any. If the element has no class attribute, the keyword noClass has to be used. <namespace> : the namespace the XML element belongs to, if any. If the element does not belong to a namespace, the keyword noNamespace has to be used. <separatesWords> : a Boolean value indicating whether this tag separates words in the text. Once an XML document is converted to RDF-standoff the markup is stripped from the text, possibly leading to continuous text that has been separated by tags before. For structural tags like paragraphs etc., <separatesWords> can be set to true in which case a special separator is inserted in the the text in the RDF representation. In this way, words stay separated and are represented in the fulltext index as such. <standoffClass> : information about the standoff class the XML element is mapped to <classIri> : Iri of the standoff class the XML element is mapped to <attributes> : XML attributes to be mapped to standoff properties (other than id or class ), if any <attribute> : an XML attribute to be mapped to a standoff property, may be repeated <attributeName> : the name of the XML attribute <namespace> : the namespace the attribute belongs to, if any. If the attribute does not belong to a namespace, the keyword noNamespace has to be used. <propertyIri> : the Iri of the standoff property the XML attribute is mapped to. <datatype> : the data type of the standoff class, if any. <type> : the Iri of the data type standoff class <attributeName> : the name of the attribute holding the typed value in the expected Knora standard format XML structure of a mapping: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <defaultXSLTransformation>Iri of a knora-base:XSLTransformation</defaultXSLTransformation> <mappingElement> <tag> <name>XML element name</name> <class>XML class name or \"noClass\"</class> <namespace>XML namespace or \"noNamespace\"</namespace> <separatesWords>true or false</separatesWords> </tag> <standoffClass> <classIri>standoff class Iri</classIri> <attributes> <attribute> <attributeName>XML attribute name</attributeName> <namespace>XML namespace or \"noNamespace\"</namespace> <propertyIri>standoff property Iri</propertyIri> </attribute> </attributes> <datatype> <type>standoff data type class</type> <attributeName>XML attribute with the typed value</attributeName> </datatype> </standoffClass> </mappingElement> <mappingElement> ... </mappingElement> </mapping> Please note that the absence of an XML namespace and/or a class have to be explicitly stated using the keywords noNamespace and noClass . (This is because we use XML Schema validation to ensure the one-to-one relations between XML elements and standoff classes. XML Schema validation's unique checks do not support optional values.) id and class Attributes The id and class attributes are supported by default and do not have to be included in the mapping like other attributes. The id attribute identifies an element and must be unique in the document. id is an optional attribute. The class attribute allows for the reuse of an element in the mapping, i.e. the same element can be combined with different class names and mapped to different standoff classes (mapping element <class> in <tag> ). Respecting Cardinalities A mapping from XML elements and attributes to standoff classes and standoff properties must respect the cardinalities defined in the ontology for those very standoff classes. If an XML element is mapped to a certain standoff class and this class requires a standoff property, an attribute must be defined for the XML element mapping to that very standoff property. Equally, all mappings for attributes of an XML element must have corresponding cardinalities for standoff properties defined for the standoff class the XML element maps to. However, since an XML attribute may occur once at maximum, it makes sense to make the corresponding standoff property required ( owl:cardinality of one) in the ontology or optional ( owl:maxCardinality of one), but not allowing it more than once. Standoff Data Types Knora allows the use of all its value types as standoff data types (defined in knora-base.ttl ): knora-base:StandoffLinkTag : Represents a reference to a Knora resource (the IRI of the target resource must be submitted in the data type attribute). knora-base:StandoffInternalReferenceTag : Represents an internal reference inside a document (the id of the target element inside the same document must be indicated in the data type attribute); see Internal References in an XML Document . knora-base:StandoffUriTag : Represents a reference to a URI (the URI of the target resource must be submitted in the data type attribute). knora-base:StandoffDateTag : Represents a date (a Knora date string must be submitted in the data type attribute, e.g. GREGORIAN:2017-01-27 ). knora-base:StandoffColorTag : Represents a color (a hexadecimal RGB color string must be submitted in the data type attribute, e.g. #0000FF ). knora-base:StandoffIntegerTag : Represents an integer (the integer must be submitted in the data type attribute). knora-base:StandoffDecimalTag : Represents a number with fractions (the decimal number must be submitted in the data type attribute, e.g. 1.1 ). knora-base:StandoffIntervalTag : Represents an interval (two decimal numbers separated with a comma must be submitted in the data type attribute, e.g. 1.1,2.2 ). knora-base:StandoffBooleanTag : Represents a Boolean value ( true or false must be submitted in the data type attribute). knora-base:StandoffTimeTag : Represents a timestamp value (an xsd:dateTimeStamp must be submitted in the data type attribute). The basic idea is that parts of a text can be marked up in a way that allows using Knora's built-in data types. In order to do so, the typed values have to be provided in a standardized way in an attribute that has to be defined in the mapping. Data type standoff classes are standoff classes with predefined properties (e.g., a knora-base:StandoffLinkTag has a knora-base:standoffTagHasLink and a knora-base:StandoffIntegerTag has a knora-base:valueHasInteger ). Please note the data type standoff classes can not be combined, i.e. a standoff class can only be the subclass of one data type standoff class. However, standoff data type classes can be subclassed and extended further by assigning properties to them (see below). The following simple mapping illustrates this principle: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <mappingElement> <tag> <name>text</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffRootTag</classIri> </standoffClass> </mappingElement> <mappingElement> <tag> <name>mydate</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/0001/anything#StandoffEventTag</classIri> <attributes> <attribute> <attributeName>description</attributeName> <namespace>noNamespace</namespace> <propertyIri>http://www.knora.org/ontology/0001/anything#standoffEventTagHasDescription</propertyIri> </attribute> </attributes> <datatype> <type>http://www.knora.org/ontology/knora-base#StandoffDateTag</type> <attributeName>knoraDate</attributeName> </datatype> </standoffClass> </mappingElement> </mapping> <datatype> must hold the Iri of a standoff data type class (see list above). The <classIri> must be a subclass of this type or this type itself (the latter is probably not recommendable since semantics are missing: what is the meaning of the date?). In the example above, the standoff class is anything:StandoffEventTag which has the following definition in the ontology anything-onto.ttl : anything:StandoffEventTag rdf:type owl:Class ; rdfs:subClassOf knora-base:StandoffDateTag, [ rdf:type owl:Restriction ; owl:onProperty :standoffEventTagHasDescription ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:label \"Represents an event in a TextValue\"@en ; rdfs:comment \"\"\"Represents an event in a TextValue\"\"\"@en . anything:StandoffEventTag is a subclass of knora-base:StandoffDateTag and therefore has the data type date. It also requires the standoff property anything:standoffEventTagHasDescription which is defined as an attribute in the mapping. Once the mapping has been created, an XML like the following could be sent to Knora and converted to standoff: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> We had a party on <mydate description=\"new year\" knoraDate=\"GREGORIAN:2016-12-31\">New Year's Eve</mydate>. It was a lot of fun. </text> The attribute holds the date in the format of a Knora date string (the format is also documented in the typescript type alias dateString in module basicMessageComponents . There you will also find documentation about the other types like color etc.). Knora date strings have this format: GREGORIAN|JULIAN):YYYY[-MM[-DD]][:YYYY[-MM[-DD]]] . This allows for different formats as well as for imprecision and periods. Intervals are submitted as one attribute in the following format: interval-attribute=\"1.0,2.0\" (two decimal numbers separated with a comma). You will find a sample mapping with all the data types and a sample XML file in the the test data: test_data/test_route/texts/mappingForHTML.xml and test_data/test_route/texts/HTML.xml . Internal References in an XML Document Internal references inside an XML document can be represented using the data type standoff class knora-base:StandoffInternalReferenceTag or a subclass of it. This class has a standoff property that points to a standoff node representing the target XML element when converted to RDF. The following example shows the definition of a mapping element for an internal reference (for reasons of simplicity, only the mapping element for the element is question is depicted): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mappingElement> <tag> <name>ref</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/knora-base#StandoffInternalReferenceTag</classIri> <datatype> <type>http://www.knora.org/ontology/knora-base#StandoffInternalReferenceTag</type> <attributeName>internalRef</attributeName> </datatype> </standoffClass> </mappingElement> Now, an internal reference to an element in the same document can be made that will be converted to a pointer in RDF: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> This is an <sample id=\"1\">element</sample> and here is a reference to <ref internalRef=\"#1\">it</ref>. </text> An internal reference in XML has to start with a # followed by the value of the id attribute of the element referred to. Predefined Standoff Classes and Properties The standoff ontology standoff-onto.ttl offers a set of predefined standoff classes that can be used in a custom mapping like the following: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <mappingElement> <tag> <name>myDoc</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffRootTag</classIri> <attributes> <attribute> <attributeName>documentType</attributeName> <namespace>noNamespace</namespace> <propertyIri>http://www.knora.org/ontology/standoff#standoffRootTagHasDocumentType</propertyIri> </attribute> </attributes> </standoffClass> </mappingElement> <mappingElement> <tag> <name>p</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>true</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffParagraphTag</classIri> </standoffClass> </mappingElement> <mappingElement> <tag> <name>i</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffItalicTag</classIri> </standoffClass> </mappingElement> </mapping> Predefined standoff classes may be used by various projects, each providing a custom mapping to be able to recreate the original XML from RDF. Predefined standoff classes may also be inherited and extended in project specific ontologies. The mapping above allows for an XML like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <myDoc documentType=\"letter\"> <p> This my text that is <i>very</i> interesting. </p> <p> And here it goes on. </p> </myDoc> Respecting Property Types When mapping XML attributes to standoff properties, attention has to be paid to the properties' object constraints. In the ontology, standoff property literals may have one of the following knora-base:objectDatatypeConstraint : xsd:string xsd:integer xsd:boolean xsd:decimal xsd:anyURI In XML, all attribute values are submitted as strings. However, these string representations need to be convertible to the types defined in the ontology. If they are not, the request will be rejected. It is recommended to enforce types on attributes by applying XML Schema validations (restrictions). Links (object property) to a knora-base:Resource can be represented using the data type standoff class knora-base:StandoffLinkTag , internal links using the data type standoff class knora-base:StandoffInternalReferenceTag . Validating a Mapping and sending it to Knora A mapping can be validated before sending it to Knora with the following XML Schema file: webapi/src/resources/mappingXMLToStandoff.xsd . Any mapping that does not conform to this XML Schema file will be rejected by Knora. The mapping has to be sent as a multipart request to the standoff route using the path segment mapping : HTTP POST http://host/v1/mapping The multipart request consists of two named parts: \"json\": { \"project_id\": \"projectIRI\", \"label\": \"my mapping\", \"mappingName\": \"MappingNameSegment\" } \"xml\": <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> ... </mapping> A successful response returns the Iri of the mapping. However, the Iri of a mapping is predictable: it consists of the project Iri followed by /mappings/ and the mappingName submitted in the JSON (if the name already exists, the request will be rejected). Once created, a mapping can be used to create TextValues in Knora. The formats are documented in the typescript interfaces addMappingRequest and addMappingResponse in module mappingFormats","title":"XML to Standoff Mapping"},{"location":"03-endpoints/api-v1/xml-to-standoff-mapping/#xml-to-standoff-mapping-in-api-v1","text":"","title":"XML to Standoff Mapping in API v1"},{"location":"03-endpoints/api-v1/xml-to-standoff-mapping/#the-knora-standard-mapping","text":"","title":"The Knora Standard Mapping"},{"location":"03-endpoints/api-v1/xml-to-standoff-mapping/#description","text":"A mapping allows for the conversion of XML to standoff representation in RDF and back. In order to create a TextValue with markup, the text has to be provided in XML format, along with the IRI of the mapping that will be used to convert the markup to standoff. However, a mapping is only needed if a TextValue with markup should be created. If a text has no markup, it is submitted as a mere sequence of characters. The two cases are described in the TypeScript interfaces simpletext and richtext in module basicMessageComponents . Knora offers a standard mapping with the IRI http://rdfh.ch/standoff/mappings/StandardMapping . The standard mapping covers the HTML elements and attributes supported by the GUI's text editor, CKEditor . (Please note that the HTML has to be encoded in strict XML syntax. CKeditor offers the possibility to define filter rules. They should reflect the elements supported by the mapping; see jquery.htmleditor.js .) The standard mapping contains the following elements and attributes that are mapped to standoff classes and properties defined in the ontology: <text> \u2192 standoff:StandoffRootTag <p> \u2192 standoff:StandoffParagraphTag <em> \u2192 standoff:StandoffItalicTag <strong> \u2192 standoff:StandoffBoldTag <u> \u2192 standoff:StandoffUnderlineTag <sub> \u2192 standoff:StandoffSubscriptTag <sup> \u2192 standoff:StandoffSuperscriptTag <strike> \u2192 standoff:StandoffStrikeTag <a href=\"URL\"> \u2192 knora-base:StandoffUriTag <a class=\"salsah-link\" href=\"Knora IRI\"> \u2192 knora-base:StandoffLinkTag <a class=\"internal-link\" href=\"#fragment\"> \u2192 knora-base:StandoffInternalReferenceTag <h1> to <h6> \u2192 standoff:StandoffHeader1Tag to standoff:StandoffHeader6Tag <ol> \u2192 standoff:StandoffOrderedListTag <ul> \u2192 standoff:StandoffUnrderedListTag <li> \u2192 standoff:StandoffListElementTag <tbody> \u2192 standoff:StandoffTableBodyTag <table> \u2192 standoff:StandoffTableTag <tr> \u2192 standoff:StandoffTableRowTag <td> \u2192 standoff:StandoffTableCellTag <br> \u2192 standoff:StandoffBrTag <hr> \u2192 standoff:StandoffLineTag <pre> \u2192 standoff:StandoffPreTag <cite> \u2192 standoff:StandoffCiteTag <blockquote> \u2192 standoff:StandoffBlockquoteTag <code> \u2192 standoff:StandoffCodeTag The HTML produced by CKEditor is wrapped in an XML doctype and a pair of root tags <text>...</text> and then sent to Knora. The XML sent to the GUI by Knora is unwrapped accordingly (see jquery.htmleditor.js ). Although the GUI supports HTML5, it is treated as if it was XHTML in strict XML notation.","title":"Description"},{"location":"03-endpoints/api-v1/xml-to-standoff-mapping/#maintenance","text":"The standard mapping definition can be found at test_data/test_route/texts/mappingForStandardHTML.xml . It was used to generate the default mapping, distributed as knora-ontologies/standoff-data.ttl and that is loaded at a Knora installation. It should be used to re-generate it, whenever we want to amend or extend it. Note: once the mapping has been generated, one has to rework the resources' UUID in order to maintain backward compatibility.","title":"Maintenance"},{"location":"03-endpoints/api-v1/xml-to-standoff-mapping/#creating-a-custom-mapping","text":"The Knora standard mapping only supports a few HTML tags. In order to submit more complex XML markup to Knora, a custom mapping has to be created first. Basically, a mapping expresses the relations between XML elements and attributes and their corresponding standoff classes and properties. The relations expressed in a mapping are one-to-one relations, so the XML can be recreated from the data in RDF. However, since HTML offers a very limited set of elements, Knora mappings support the combination of element names and classes. In this way, the same element can be used several times in combination with another classname (please note that <a> without a class is a mere hyperlink whereas <a class=\"salsah-link\"> is an internal link/standoff link). With a mapping, a default XSL transformation may be provided to transform the XML to HTML before sending it back to the client. This is useful when the client is a web-browser expecting HTML (instead of XML).","title":"Creating a custom Mapping"},{"location":"03-endpoints/api-v1/xml-to-standoff-mapping/#basic-structure-of-a-mapping","text":"The mapping is written in XML itself (for a formal description, see webapi/src/resources/mappingXMLToStandoff.xsd ). It has the following structure (the indentation corresponds to the nesting in XML): <mapping> : the root element <defaultXSLTransformation> (optional) : the Iri of the default XSL transformation to be applied to the XML when reading it back from Knora. The XSL transformation is expected to produce HTML. If given, the Iri has to refer to a resource of type knora-base:XSLTransformation . <mappingElement> : an element of the mapping (at least one) <tag> : information about the XML element that is mapped to a standoff class <name> : name of the XML element <class> : value of the class attribute of the XML element, if any. If the element has no class attribute, the keyword noClass has to be used. <namespace> : the namespace the XML element belongs to, if any. If the element does not belong to a namespace, the keyword noNamespace has to be used. <separatesWords> : a Boolean value indicating whether this tag separates words in the text. Once an XML document is converted to RDF-standoff the markup is stripped from the text, possibly leading to continuous text that has been separated by tags before. For structural tags like paragraphs etc., <separatesWords> can be set to true in which case a special separator is inserted in the the text in the RDF representation. In this way, words stay separated and are represented in the fulltext index as such. <standoffClass> : information about the standoff class the XML element is mapped to <classIri> : Iri of the standoff class the XML element is mapped to <attributes> : XML attributes to be mapped to standoff properties (other than id or class ), if any <attribute> : an XML attribute to be mapped to a standoff property, may be repeated <attributeName> : the name of the XML attribute <namespace> : the namespace the attribute belongs to, if any. If the attribute does not belong to a namespace, the keyword noNamespace has to be used. <propertyIri> : the Iri of the standoff property the XML attribute is mapped to. <datatype> : the data type of the standoff class, if any. <type> : the Iri of the data type standoff class <attributeName> : the name of the attribute holding the typed value in the expected Knora standard format XML structure of a mapping: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <defaultXSLTransformation>Iri of a knora-base:XSLTransformation</defaultXSLTransformation> <mappingElement> <tag> <name>XML element name</name> <class>XML class name or \"noClass\"</class> <namespace>XML namespace or \"noNamespace\"</namespace> <separatesWords>true or false</separatesWords> </tag> <standoffClass> <classIri>standoff class Iri</classIri> <attributes> <attribute> <attributeName>XML attribute name</attributeName> <namespace>XML namespace or \"noNamespace\"</namespace> <propertyIri>standoff property Iri</propertyIri> </attribute> </attributes> <datatype> <type>standoff data type class</type> <attributeName>XML attribute with the typed value</attributeName> </datatype> </standoffClass> </mappingElement> <mappingElement> ... </mappingElement> </mapping> Please note that the absence of an XML namespace and/or a class have to be explicitly stated using the keywords noNamespace and noClass . (This is because we use XML Schema validation to ensure the one-to-one relations between XML elements and standoff classes. XML Schema validation's unique checks do not support optional values.)","title":"Basic Structure of a Mapping"},{"location":"03-endpoints/api-v1/xml-to-standoff-mapping/#id-and-class-attributes","text":"The id and class attributes are supported by default and do not have to be included in the mapping like other attributes. The id attribute identifies an element and must be unique in the document. id is an optional attribute. The class attribute allows for the reuse of an element in the mapping, i.e. the same element can be combined with different class names and mapped to different standoff classes (mapping element <class> in <tag> ).","title":"id and class Attributes"},{"location":"03-endpoints/api-v1/xml-to-standoff-mapping/#respecting-cardinalities","text":"A mapping from XML elements and attributes to standoff classes and standoff properties must respect the cardinalities defined in the ontology for those very standoff classes. If an XML element is mapped to a certain standoff class and this class requires a standoff property, an attribute must be defined for the XML element mapping to that very standoff property. Equally, all mappings for attributes of an XML element must have corresponding cardinalities for standoff properties defined for the standoff class the XML element maps to. However, since an XML attribute may occur once at maximum, it makes sense to make the corresponding standoff property required ( owl:cardinality of one) in the ontology or optional ( owl:maxCardinality of one), but not allowing it more than once.","title":"Respecting Cardinalities"},{"location":"03-endpoints/api-v1/xml-to-standoff-mapping/#standoff-data-types","text":"Knora allows the use of all its value types as standoff data types (defined in knora-base.ttl ): knora-base:StandoffLinkTag : Represents a reference to a Knora resource (the IRI of the target resource must be submitted in the data type attribute). knora-base:StandoffInternalReferenceTag : Represents an internal reference inside a document (the id of the target element inside the same document must be indicated in the data type attribute); see Internal References in an XML Document . knora-base:StandoffUriTag : Represents a reference to a URI (the URI of the target resource must be submitted in the data type attribute). knora-base:StandoffDateTag : Represents a date (a Knora date string must be submitted in the data type attribute, e.g. GREGORIAN:2017-01-27 ). knora-base:StandoffColorTag : Represents a color (a hexadecimal RGB color string must be submitted in the data type attribute, e.g. #0000FF ). knora-base:StandoffIntegerTag : Represents an integer (the integer must be submitted in the data type attribute). knora-base:StandoffDecimalTag : Represents a number with fractions (the decimal number must be submitted in the data type attribute, e.g. 1.1 ). knora-base:StandoffIntervalTag : Represents an interval (two decimal numbers separated with a comma must be submitted in the data type attribute, e.g. 1.1,2.2 ). knora-base:StandoffBooleanTag : Represents a Boolean value ( true or false must be submitted in the data type attribute). knora-base:StandoffTimeTag : Represents a timestamp value (an xsd:dateTimeStamp must be submitted in the data type attribute). The basic idea is that parts of a text can be marked up in a way that allows using Knora's built-in data types. In order to do so, the typed values have to be provided in a standardized way in an attribute that has to be defined in the mapping. Data type standoff classes are standoff classes with predefined properties (e.g., a knora-base:StandoffLinkTag has a knora-base:standoffTagHasLink and a knora-base:StandoffIntegerTag has a knora-base:valueHasInteger ). Please note the data type standoff classes can not be combined, i.e. a standoff class can only be the subclass of one data type standoff class. However, standoff data type classes can be subclassed and extended further by assigning properties to them (see below). The following simple mapping illustrates this principle: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <mappingElement> <tag> <name>text</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffRootTag</classIri> </standoffClass> </mappingElement> <mappingElement> <tag> <name>mydate</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/0001/anything#StandoffEventTag</classIri> <attributes> <attribute> <attributeName>description</attributeName> <namespace>noNamespace</namespace> <propertyIri>http://www.knora.org/ontology/0001/anything#standoffEventTagHasDescription</propertyIri> </attribute> </attributes> <datatype> <type>http://www.knora.org/ontology/knora-base#StandoffDateTag</type> <attributeName>knoraDate</attributeName> </datatype> </standoffClass> </mappingElement> </mapping> <datatype> must hold the Iri of a standoff data type class (see list above). The <classIri> must be a subclass of this type or this type itself (the latter is probably not recommendable since semantics are missing: what is the meaning of the date?). In the example above, the standoff class is anything:StandoffEventTag which has the following definition in the ontology anything-onto.ttl : anything:StandoffEventTag rdf:type owl:Class ; rdfs:subClassOf knora-base:StandoffDateTag, [ rdf:type owl:Restriction ; owl:onProperty :standoffEventTagHasDescription ; owl:cardinality \"1\"^^xsd:nonNegativeInteger ] ; rdfs:label \"Represents an event in a TextValue\"@en ; rdfs:comment \"\"\"Represents an event in a TextValue\"\"\"@en . anything:StandoffEventTag is a subclass of knora-base:StandoffDateTag and therefore has the data type date. It also requires the standoff property anything:standoffEventTagHasDescription which is defined as an attribute in the mapping. Once the mapping has been created, an XML like the following could be sent to Knora and converted to standoff: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> We had a party on <mydate description=\"new year\" knoraDate=\"GREGORIAN:2016-12-31\">New Year's Eve</mydate>. It was a lot of fun. </text> The attribute holds the date in the format of a Knora date string (the format is also documented in the typescript type alias dateString in module basicMessageComponents . There you will also find documentation about the other types like color etc.). Knora date strings have this format: GREGORIAN|JULIAN):YYYY[-MM[-DD]][:YYYY[-MM[-DD]]] . This allows for different formats as well as for imprecision and periods. Intervals are submitted as one attribute in the following format: interval-attribute=\"1.0,2.0\" (two decimal numbers separated with a comma). You will find a sample mapping with all the data types and a sample XML file in the the test data: test_data/test_route/texts/mappingForHTML.xml and test_data/test_route/texts/HTML.xml .","title":"Standoff Data Types"},{"location":"03-endpoints/api-v1/xml-to-standoff-mapping/#internal-references-in-an-xml-document","text":"Internal references inside an XML document can be represented using the data type standoff class knora-base:StandoffInternalReferenceTag or a subclass of it. This class has a standoff property that points to a standoff node representing the target XML element when converted to RDF. The following example shows the definition of a mapping element for an internal reference (for reasons of simplicity, only the mapping element for the element is question is depicted): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mappingElement> <tag> <name>ref</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/knora-base#StandoffInternalReferenceTag</classIri> <datatype> <type>http://www.knora.org/ontology/knora-base#StandoffInternalReferenceTag</type> <attributeName>internalRef</attributeName> </datatype> </standoffClass> </mappingElement> Now, an internal reference to an element in the same document can be made that will be converted to a pointer in RDF: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> This is an <sample id=\"1\">element</sample> and here is a reference to <ref internalRef=\"#1\">it</ref>. </text> An internal reference in XML has to start with a # followed by the value of the id attribute of the element referred to.","title":"Internal References in an XML Document"},{"location":"03-endpoints/api-v1/xml-to-standoff-mapping/#predefined-standoff-classes-and-properties","text":"The standoff ontology standoff-onto.ttl offers a set of predefined standoff classes that can be used in a custom mapping like the following: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> <mappingElement> <tag> <name>myDoc</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffRootTag</classIri> <attributes> <attribute> <attributeName>documentType</attributeName> <namespace>noNamespace</namespace> <propertyIri>http://www.knora.org/ontology/standoff#standoffRootTagHasDocumentType</propertyIri> </attribute> </attributes> </standoffClass> </mappingElement> <mappingElement> <tag> <name>p</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>true</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffParagraphTag</classIri> </standoffClass> </mappingElement> <mappingElement> <tag> <name>i</name> <class>noClass</class> <namespace>noNamespace</namespace> <separatesWords>false</separatesWords> </tag> <standoffClass> <classIri>http://www.knora.org/ontology/standoff#StandoffItalicTag</classIri> </standoffClass> </mappingElement> </mapping> Predefined standoff classes may be used by various projects, each providing a custom mapping to be able to recreate the original XML from RDF. Predefined standoff classes may also be inherited and extended in project specific ontologies. The mapping above allows for an XML like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <myDoc documentType=\"letter\"> <p> This my text that is <i>very</i> interesting. </p> <p> And here it goes on. </p> </myDoc>","title":"Predefined Standoff Classes and Properties"},{"location":"03-endpoints/api-v1/xml-to-standoff-mapping/#respecting-property-types","text":"When mapping XML attributes to standoff properties, attention has to be paid to the properties' object constraints. In the ontology, standoff property literals may have one of the following knora-base:objectDatatypeConstraint : xsd:string xsd:integer xsd:boolean xsd:decimal xsd:anyURI In XML, all attribute values are submitted as strings. However, these string representations need to be convertible to the types defined in the ontology. If they are not, the request will be rejected. It is recommended to enforce types on attributes by applying XML Schema validations (restrictions). Links (object property) to a knora-base:Resource can be represented using the data type standoff class knora-base:StandoffLinkTag , internal links using the data type standoff class knora-base:StandoffInternalReferenceTag .","title":"Respecting Property Types"},{"location":"03-endpoints/api-v1/xml-to-standoff-mapping/#validating-a-mapping-and-sending-it-to-knora","text":"A mapping can be validated before sending it to Knora with the following XML Schema file: webapi/src/resources/mappingXMLToStandoff.xsd . Any mapping that does not conform to this XML Schema file will be rejected by Knora. The mapping has to be sent as a multipart request to the standoff route using the path segment mapping : HTTP POST http://host/v1/mapping The multipart request consists of two named parts: \"json\": { \"project_id\": \"projectIRI\", \"label\": \"my mapping\", \"mappingName\": \"MappingNameSegment\" } \"xml\": <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> ... </mapping> A successful response returns the Iri of the mapping. However, the Iri of a mapping is predictable: it consists of the project Iri followed by /mappings/ and the mappingName submitted in the JSON (if the name already exists, the request will be rejected). Once created, a mapping can be used to create TextValues in Knora. The formats are documented in the typescript interfaces addMappingRequest and addMappingResponse in module mappingFormats","title":"Validating a Mapping and sending it to Knora"},{"location":"03-endpoints/api-v2/authentication/","text":"Authentication Access to the DSP-API can for certain operations require a user to authenticate. Authentication can be performed in two ways: By providing password credentials , which are a combination of a identifier and password . The user identifier can be one of the following: the user's IRI, the user's Email, or the user's Username. By providing an access token Submitting Password Credentials When accessing any route and password credentials would need to be sent, we support two options to do so: in the URL submitting the parameters iri / email / username and password (e.g., http://knora-host/v1/resources/resIri?email=userUrlEncodedIdentifier&password=pw ), and in the HTTP header ( HTTP basic authentication ), where the identifier can be the user's email (IRI and username not supported). When using Python's module requests , the credentials can simply be submitted as a tuple with each request using the param auth ( python requests ). Access Token / Session / Login and Logout A client can generate an access token by sending a POST request (e.g., {\"identifier_type\":\"identifier_value\", \"password\":\"password_value\"} ) to the /v2/authentication route with identifier and password in the body. The identifier_type can be iri , email , or username . If the credentials are valid, a JSON WEB Token (JWT) will be sent back in the response (e.g., {\"token\": \"eyJ0eXAiOiJ...\"} ). Additionally, for web browser clients a session cookie containing the JWT token is also created, containing KnoraAuthentication=eyJ0eXAiOiJ... . When accessing any route, the access token would need to be supplied, we support three options to do so: the session cookie, in the URL submitting the parameter token (e.g., http://knora-host/v1/resources/resIri?token=1234567890 ), and in the HTTP authorization header with the HTTP bearer scheme . If the token is successfully validated, then the user is deemed authenticated. To logout , the client sends a DELETE request to the same route /v2/authentication and the access token in one of the three described ways. This will invalidate the access token, thus not allowing further request that would supply the invalidated token. Checking Credentials To check the credentials, send a GET request to /v2/authentication with the credentials supplied as URL parameters or HTTP authentication headers as described before. Usage Scenarios Create token by logging-in, send token on each subsequent request, and logout when finished. Send email/password credentials on every request.","title":"Authentication"},{"location":"03-endpoints/api-v2/authentication/#authentication","text":"Access to the DSP-API can for certain operations require a user to authenticate. Authentication can be performed in two ways: By providing password credentials , which are a combination of a identifier and password . The user identifier can be one of the following: the user's IRI, the user's Email, or the user's Username. By providing an access token","title":"Authentication"},{"location":"03-endpoints/api-v2/authentication/#submitting-password-credentials","text":"When accessing any route and password credentials would need to be sent, we support two options to do so: in the URL submitting the parameters iri / email / username and password (e.g., http://knora-host/v1/resources/resIri?email=userUrlEncodedIdentifier&password=pw ), and in the HTTP header ( HTTP basic authentication ), where the identifier can be the user's email (IRI and username not supported). When using Python's module requests , the credentials can simply be submitted as a tuple with each request using the param auth ( python requests ).","title":"Submitting Password Credentials"},{"location":"03-endpoints/api-v2/authentication/#access-token-session-login-and-logout","text":"A client can generate an access token by sending a POST request (e.g., {\"identifier_type\":\"identifier_value\", \"password\":\"password_value\"} ) to the /v2/authentication route with identifier and password in the body. The identifier_type can be iri , email , or username . If the credentials are valid, a JSON WEB Token (JWT) will be sent back in the response (e.g., {\"token\": \"eyJ0eXAiOiJ...\"} ). Additionally, for web browser clients a session cookie containing the JWT token is also created, containing KnoraAuthentication=eyJ0eXAiOiJ... . When accessing any route, the access token would need to be supplied, we support three options to do so: the session cookie, in the URL submitting the parameter token (e.g., http://knora-host/v1/resources/resIri?token=1234567890 ), and in the HTTP authorization header with the HTTP bearer scheme . If the token is successfully validated, then the user is deemed authenticated. To logout , the client sends a DELETE request to the same route /v2/authentication and the access token in one of the three described ways. This will invalidate the access token, thus not allowing further request that would supply the invalidated token.","title":"Access Token / Session / Login and Logout"},{"location":"03-endpoints/api-v2/authentication/#checking-credentials","text":"To check the credentials, send a GET request to /v2/authentication with the credentials supplied as URL parameters or HTTP authentication headers as described before.","title":"Checking Credentials"},{"location":"03-endpoints/api-v2/authentication/#usage-scenarios","text":"Create token by logging-in, send token on each subsequent request, and logout when finished. Send email/password credentials on every request.","title":"Usage Scenarios"},{"location":"03-endpoints/api-v2/editing-resources/","text":"Creating and Editing Resources Creating a Resource To create a new resources, use this route: HTTP POST to http://host/v2/resources The body of the request is a JSON-LD document in the complex API schema , specifying the type, rdfs:label , and its Knora resource properties and their values. The representation of the resource is the same as when it is returned in a GET request, except that its knora-api:attachedToUser is not given, and the resource IRI and those of its values can be optionally specified. The format of the values submitted is described in Creating and Editing Values . If there are multiple values for a property, these must be given in an array. For example, here is a request to create a resource with various value types: { \"@type\" : \"anything:Thing\", \"anything:hasBoolean\" : { \"@type\" : \"knora-api:BooleanValue\", \"knora-api:booleanValueAsBoolean\" : true }, \"anything:hasColor\" : { \"@type\" : \"knora-api:ColorValue\", \"knora-api:colorValueAsColor\" : \"#ff3333\" }, \"anything:hasDate\" : { \"@type\" : \"knora-api:DateValue\", \"knora-api:dateValueHasCalendar\" : \"GREGORIAN\", \"knora-api:dateValueHasEndEra\" : \"CE\", \"knora-api:dateValueHasEndYear\" : 1489, \"knora-api:dateValueHasStartEra\" : \"CE\", \"knora-api:dateValueHasStartYear\" : 1489 }, \"anything:hasDecimal\" : { \"@type\" : \"knora-api:DecimalValue\", \"knora-api:decimalValueAsDecimal\" : { \"@type\" : \"xsd:decimal\", \"@value\" : \"100000000000000.000000000000001\" } }, \"anything:hasGeometry\" : { \"@type\" : \"knora-api:GeomValue\", \"knora-api:geometryValueAsGeometry\" : \"{\\\"status\\\":\\\"active\\\",\\\"lineColor\\\":\\\"#ff3333\\\",\\\"lineWidth\\\":2,\\\"points\\\":[{\\\"x\\\":0.08098591549295775,\\\"y\\\":0.16741071428571427},{\\\"x\\\":0.7394366197183099,\\\"y\\\":0.7299107142857143}],\\\"type\\\":\\\"rectangle\\\",\\\"original_index\\\":0}\" }, \"anything:hasGeoname\" : { \"@type\" : \"knora-api:GeonameValue\", \"knora-api:geonameValueAsGeonameCode\" : \"2661604\" }, \"anything:hasInteger\" : [ { \"@type\" : \"knora-api:IntValue\", \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\", \"knora-api:intValueAsInt\" : 5, \"knora-api:valueHasComment\" : \"this is the number five\" }, { \"@type\" : \"knora-api:IntValue\", \"knora-api:intValueAsInt\" : 6 } ], \"anything:hasInterval\" : { \"@type\" : \"knora-api:IntervalValue\", \"knora-api:intervalValueHasEnd\" : { \"@type\" : \"xsd:decimal\", \"@value\" : \"3.4\" }, \"knora-api:intervalValueHasStart\" : { \"@type\" : \"xsd:decimal\", \"@value\" : \"1.2\" } }, \"anything:hasListItem\" : { \"@type\" : \"knora-api:ListValue\", \"knora-api:listValueAsListNode\" : { \"@id\" : \"http://rdfh.ch/lists/0001/treeList03\" } }, \"anything:hasOtherThingValue\" : { \"@type\" : \"knora-api:LinkValue\", \"knora-api:linkValueHasTargetIri\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing\" } }, \"anything:hasRichtext\" : { \"@type\" : \"knora-api:TextValue\", \"knora-api:textValueAsXml\" : \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<text><p><strong>this is</strong> text</p> with standoff</text>\", \"knora-api:textValueHasMapping\" : { \"@id\" : \"http://rdfh.ch/standoff/mappings/StandardMapping\" } }, \"anything:hasText\" : { \"@type\" : \"knora-api:TextValue\", \"knora-api:valueAsString\" : \"this is text without standoff\" }, \"anything:hasUri\" : { \"@type\" : \"knora-api:UriValue\", \"knora-api:uriValueAsUri\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"https://www.knora.org\" } }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" }, \"rdfs:label\" : \"test thing\", \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Permissions for the new resource can be given by adding knora-api:hasPermissions , a custom creation date can be specified by adding knora-api:creationDate (an xsd:dateTimeStamp ), and the resource's creator can be specfied by adding knora-api:attachedToUser . For example: { \"@type\" : \"anything:Thing\", \"anything:hasBoolean\" : { \"@type\" : \"knora-api:BooleanValue\", \"knora-api:booleanValueAsBoolean\" : true }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"rdfs:label\" : \"test thing\", \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\", \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-01-09T15:45:54.502951Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The format of the object of knora-api:hasPermissions is described in Permissions . If permissions are not given, configurable default permissions are used (see Default Object Access Permissions ). To create a resource, the user must have permission to create resources of that class in that project. The predicate knora-api:attachedToUser can be used to specify a creator other than the requesting user only if the requesting user is an administrator of the project or a system administrator. The specified creator must also have permission to create resources of that class in that project. In addition to the creation date, in the body of the request, it is possible to specify a custom IRI ( of Knora IRI form) for a resource through the @id attribute which will then be assigned to the resource; otherwise the resource will get a unique random IRI. A custom resource IRI must be http://rdfh.ch/PROJECT_SHORTCODE/ (where PROJECT_SHORTCODE is the shortcode of the project that the resource belongs to) plus a custom ID string. Similarly, it is possible to assign a custom IRI to the values using their @id attributes; if not given, random IRIs will be assigned to the values. A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. An optional custom UUID of a value can also be given by adding knora-api:valueHasUUID . Each custom UUID must be base64url-encoded without padding. Each value of the new resource can also have a custom creation date specified by adding knora-api:creationDate (an xsd:dateTimeStamp ). For example: { \"@id\" : \"http://rdfh.ch/0001/oveR1dQltEUwNrls9Lu5Rw\", \"@type\" : \"anything:Thing\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" }, \"anything:hasInteger\" : { \"@id\" : \"http://rdfh.ch/0001/oveR1dQltEUwNrls9Lu5Rw/values/IN4R19yYR0ygi3K2VEHpUQ\", \"@type\" : \"knora-api:IntValue\", \"knora-api:intValueAsInt\" : 10, \"knora-api:valueHasUUID\" : \"IN4R19yYR0ygi3K2VEHpUQ\", \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2020-06-04T12:58:54.502951Z\" } }, \"rdfs:label\" : \"test thing with custom IRI\", \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-01-09T15:45:54.502951Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The response is a JSON-LD document containing a preview of the resource. Modifying a Resource's Values See Creating and Editing Values . Modifying a Resource's Metadata You can modify the following metadata attached to a resource: label permissions last modification date To do this, use this route: HTTP PUT to http://host/v2/resources The request body is a JSON-LD object containing the following information about the resource: @id : the resource's IRI @type : the resource's class IRI knora-api:lastModificationDate : an xsd:dateTimeStamp representing the last modification date that is currently attached to the resource, if any. This is used to make sure that the resource has not been modified by someone else since you last read it. The submitted JSON-LD object must also contain one or more of the following predicates, representing the metadata you want to change: rdfs:label : a string knora-api:hasPermissions , in the format described in Permissions knora-api:newModificationDate : an xsd:dateTimeStamp . Here is an example: { \"@id\" : \"http://rdfh.ch/0001/a-thing\", \"@type\" : \"anything:Thing\", \"rdfs:label\" : \"this is the new label\", \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:ProjectMember\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2017-11-20T15:55:17Z\" }, \"knora-api:newModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2018-12-21T16:56:18Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } If you submit a knora-api:lastModificationDate that is different from the resource's actual last modification date, you will get an HTTP 409 (Conflict) error. If you submit a knora-api:newModificationDate that is earlier than the resource's knora-api:lastModificationDate , you will get an HTTP 400 (Bad Request) error. A successful response is an HTTP 200 (OK) status containing the resource's metadata. Deleting a Resource Knora does not normally delete resources; instead, it marks them as deleted, which means that they do not appear in normal query results. To mark a resource as deleted, use this route: HTTP POST to http://host/v2/resources/delete The request body is a JSON-LD object containing the following information about the resource: @id : the resource's IRI @type : the resource's class IRI knora-api:lastModificationDate : an xsd:dateTimeStamp representing the last modification date that is currently attached to the resource, if any. This is used to make sure that the resource has not been modified by someone else since you last read it. { \"@id\" : \"http://rdfh.ch/0001/a-thing\", \"@type\" : \"anything:Thing\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-02-05T17:05:35.776747Z\" }, \"knora-api:deleteComment\" : \"This resource was created by mistake.\", \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The optional property knora-api:deleteComment specifies a comment to be attached to the resource, explaining why it has been marked as deleted. The optional property knora-api:deleteDate (an xsd:dateTimeStamp ) indicates when the resource was marked as deleted; if not given, the current time is used. The response is a JSON-LD document containing the predicate knora-api:result with a confirmation message. Requesting Deleted Resources Resources marked as deleted are not found in search queries. It is however possible to request them directly or from an ARK URL. In these instances, the API will not return the deleted resource, but instead a generic resource of type knora-base:DeletedResource . This resource will be similar to the requested resource, having e.g. the same IRI. The resource will contain the deletion date and optionally the deletion comment. The response to requesting a deleted resource will look as the following example: { \"rdfs:label\": \"Deleted Resource\", \"knora-api:versionArkUrl\": { \"@value\": \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO.20211214T084407677335Z\", \"@type\": \"xsd:anyURI\" }, \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" }, \"knora-api:userHasPermission\": \"CR\", \"knora-api:attachedToUser\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:hasPermissions\": \"CR knora-admin:ProjectMember|V knora-admin:ProjectMember\", \"knora-api:isDeleted\": true, \"@type\": \"knora-api:DeletedResource\", \"@id\": \"http://rdfh.ch/0001/a-thing\", \"knora-api:deleteComment\": \"This resource is too boring.\", \"knora-api:arkUrl\": { \"@value\": \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO\", \"@type\": \"xsd:anyURI\" }, \"knora-api:creationDate\": { \"@value\": \"2021-12-14T08:44:07.677335Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-api:deleteDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"2021-12-14T08:44:07.372543Z\" }, \"@context\": { \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } } Links to Deleted Resources If resource A has a link to resource B , and resource B is later marked as deleted, A 's link will still exist. DSP-API v2 will still return the link when A is queried, but without any information about B (except for B 's IRI). If A 's link is necessary to meet the requirements of a cardinality, marking B as deleted will not violate the cardinality. The reason for this design is that A and B might be in different projects, and each project must retain control of its resources and be able to mark them as deleted, even if they are used by another project. Erasing a Resource from the Triplestore Normally, resources are not actually removed from the triplestore; they are only marked as deleted (see Deleting a Resource ). However, sometimes it is necessary to erase a resource from the triplestore. To do so, use this route: HTTP POST to http://host/v2/resources/erase The request body is the same as for Deleting a Resource , except that knora-api:deleteComment is not relevant and will be ignored. To do this, a user must be a system administrator or an administrator of the project containing the resource. The user's permissions on the resource are not otherwise checked. A resource cannot be erased if any other resource has a link to it. Any such links must first be changed or marked as deleted (see Updating a Value and Deleting a Value ). Then, when the resource is erased, the deleted link values that referred to it will also be erased. This operation cannot be undone (except by restoring the repository from a backup), so use it with care.","title":"Creating and Editing Resources"},{"location":"03-endpoints/api-v2/editing-resources/#creating-and-editing-resources","text":"","title":"Creating and Editing Resources"},{"location":"03-endpoints/api-v2/editing-resources/#creating-a-resource","text":"To create a new resources, use this route: HTTP POST to http://host/v2/resources The body of the request is a JSON-LD document in the complex API schema , specifying the type, rdfs:label , and its Knora resource properties and their values. The representation of the resource is the same as when it is returned in a GET request, except that its knora-api:attachedToUser is not given, and the resource IRI and those of its values can be optionally specified. The format of the values submitted is described in Creating and Editing Values . If there are multiple values for a property, these must be given in an array. For example, here is a request to create a resource with various value types: { \"@type\" : \"anything:Thing\", \"anything:hasBoolean\" : { \"@type\" : \"knora-api:BooleanValue\", \"knora-api:booleanValueAsBoolean\" : true }, \"anything:hasColor\" : { \"@type\" : \"knora-api:ColorValue\", \"knora-api:colorValueAsColor\" : \"#ff3333\" }, \"anything:hasDate\" : { \"@type\" : \"knora-api:DateValue\", \"knora-api:dateValueHasCalendar\" : \"GREGORIAN\", \"knora-api:dateValueHasEndEra\" : \"CE\", \"knora-api:dateValueHasEndYear\" : 1489, \"knora-api:dateValueHasStartEra\" : \"CE\", \"knora-api:dateValueHasStartYear\" : 1489 }, \"anything:hasDecimal\" : { \"@type\" : \"knora-api:DecimalValue\", \"knora-api:decimalValueAsDecimal\" : { \"@type\" : \"xsd:decimal\", \"@value\" : \"100000000000000.000000000000001\" } }, \"anything:hasGeometry\" : { \"@type\" : \"knora-api:GeomValue\", \"knora-api:geometryValueAsGeometry\" : \"{\\\"status\\\":\\\"active\\\",\\\"lineColor\\\":\\\"#ff3333\\\",\\\"lineWidth\\\":2,\\\"points\\\":[{\\\"x\\\":0.08098591549295775,\\\"y\\\":0.16741071428571427},{\\\"x\\\":0.7394366197183099,\\\"y\\\":0.7299107142857143}],\\\"type\\\":\\\"rectangle\\\",\\\"original_index\\\":0}\" }, \"anything:hasGeoname\" : { \"@type\" : \"knora-api:GeonameValue\", \"knora-api:geonameValueAsGeonameCode\" : \"2661604\" }, \"anything:hasInteger\" : [ { \"@type\" : \"knora-api:IntValue\", \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\", \"knora-api:intValueAsInt\" : 5, \"knora-api:valueHasComment\" : \"this is the number five\" }, { \"@type\" : \"knora-api:IntValue\", \"knora-api:intValueAsInt\" : 6 } ], \"anything:hasInterval\" : { \"@type\" : \"knora-api:IntervalValue\", \"knora-api:intervalValueHasEnd\" : { \"@type\" : \"xsd:decimal\", \"@value\" : \"3.4\" }, \"knora-api:intervalValueHasStart\" : { \"@type\" : \"xsd:decimal\", \"@value\" : \"1.2\" } }, \"anything:hasListItem\" : { \"@type\" : \"knora-api:ListValue\", \"knora-api:listValueAsListNode\" : { \"@id\" : \"http://rdfh.ch/lists/0001/treeList03\" } }, \"anything:hasOtherThingValue\" : { \"@type\" : \"knora-api:LinkValue\", \"knora-api:linkValueHasTargetIri\" : { \"@id\" : \"http://rdfh.ch/0001/a-thing\" } }, \"anything:hasRichtext\" : { \"@type\" : \"knora-api:TextValue\", \"knora-api:textValueAsXml\" : \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<text><p><strong>this is</strong> text</p> with standoff</text>\", \"knora-api:textValueHasMapping\" : { \"@id\" : \"http://rdfh.ch/standoff/mappings/StandardMapping\" } }, \"anything:hasText\" : { \"@type\" : \"knora-api:TextValue\", \"knora-api:valueAsString\" : \"this is text without standoff\" }, \"anything:hasUri\" : { \"@type\" : \"knora-api:UriValue\", \"knora-api:uriValueAsUri\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"https://www.knora.org\" } }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" }, \"rdfs:label\" : \"test thing\", \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Permissions for the new resource can be given by adding knora-api:hasPermissions , a custom creation date can be specified by adding knora-api:creationDate (an xsd:dateTimeStamp ), and the resource's creator can be specfied by adding knora-api:attachedToUser . For example: { \"@type\" : \"anything:Thing\", \"anything:hasBoolean\" : { \"@type\" : \"knora-api:BooleanValue\", \"knora-api:booleanValueAsBoolean\" : true }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"rdfs:label\" : \"test thing\", \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\", \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-01-09T15:45:54.502951Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The format of the object of knora-api:hasPermissions is described in Permissions . If permissions are not given, configurable default permissions are used (see Default Object Access Permissions ). To create a resource, the user must have permission to create resources of that class in that project. The predicate knora-api:attachedToUser can be used to specify a creator other than the requesting user only if the requesting user is an administrator of the project or a system administrator. The specified creator must also have permission to create resources of that class in that project. In addition to the creation date, in the body of the request, it is possible to specify a custom IRI ( of Knora IRI form) for a resource through the @id attribute which will then be assigned to the resource; otherwise the resource will get a unique random IRI. A custom resource IRI must be http://rdfh.ch/PROJECT_SHORTCODE/ (where PROJECT_SHORTCODE is the shortcode of the project that the resource belongs to) plus a custom ID string. Similarly, it is possible to assign a custom IRI to the values using their @id attributes; if not given, random IRIs will be assigned to the values. A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. An optional custom UUID of a value can also be given by adding knora-api:valueHasUUID . Each custom UUID must be base64url-encoded without padding. Each value of the new resource can also have a custom creation date specified by adding knora-api:creationDate (an xsd:dateTimeStamp ). For example: { \"@id\" : \"http://rdfh.ch/0001/oveR1dQltEUwNrls9Lu5Rw\", \"@type\" : \"anything:Thing\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" }, \"anything:hasInteger\" : { \"@id\" : \"http://rdfh.ch/0001/oveR1dQltEUwNrls9Lu5Rw/values/IN4R19yYR0ygi3K2VEHpUQ\", \"@type\" : \"knora-api:IntValue\", \"knora-api:intValueAsInt\" : 10, \"knora-api:valueHasUUID\" : \"IN4R19yYR0ygi3K2VEHpUQ\", \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2020-06-04T12:58:54.502951Z\" } }, \"rdfs:label\" : \"test thing with custom IRI\", \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-01-09T15:45:54.502951Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The response is a JSON-LD document containing a preview of the resource.","title":"Creating a Resource"},{"location":"03-endpoints/api-v2/editing-resources/#modifying-a-resources-values","text":"See Creating and Editing Values .","title":"Modifying a Resource's Values"},{"location":"03-endpoints/api-v2/editing-resources/#modifying-a-resources-metadata","text":"You can modify the following metadata attached to a resource: label permissions last modification date To do this, use this route: HTTP PUT to http://host/v2/resources The request body is a JSON-LD object containing the following information about the resource: @id : the resource's IRI @type : the resource's class IRI knora-api:lastModificationDate : an xsd:dateTimeStamp representing the last modification date that is currently attached to the resource, if any. This is used to make sure that the resource has not been modified by someone else since you last read it. The submitted JSON-LD object must also contain one or more of the following predicates, representing the metadata you want to change: rdfs:label : a string knora-api:hasPermissions , in the format described in Permissions knora-api:newModificationDate : an xsd:dateTimeStamp . Here is an example: { \"@id\" : \"http://rdfh.ch/0001/a-thing\", \"@type\" : \"anything:Thing\", \"rdfs:label\" : \"this is the new label\", \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:ProjectMember\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2017-11-20T15:55:17Z\" }, \"knora-api:newModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2018-12-21T16:56:18Z\" }, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } If you submit a knora-api:lastModificationDate that is different from the resource's actual last modification date, you will get an HTTP 409 (Conflict) error. If you submit a knora-api:newModificationDate that is earlier than the resource's knora-api:lastModificationDate , you will get an HTTP 400 (Bad Request) error. A successful response is an HTTP 200 (OK) status containing the resource's metadata.","title":"Modifying a Resource's Metadata"},{"location":"03-endpoints/api-v2/editing-resources/#deleting-a-resource","text":"Knora does not normally delete resources; instead, it marks them as deleted, which means that they do not appear in normal query results. To mark a resource as deleted, use this route: HTTP POST to http://host/v2/resources/delete The request body is a JSON-LD object containing the following information about the resource: @id : the resource's IRI @type : the resource's class IRI knora-api:lastModificationDate : an xsd:dateTimeStamp representing the last modification date that is currently attached to the resource, if any. This is used to make sure that the resource has not been modified by someone else since you last read it. { \"@id\" : \"http://rdfh.ch/0001/a-thing\", \"@type\" : \"anything:Thing\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-02-05T17:05:35.776747Z\" }, \"knora-api:deleteComment\" : \"This resource was created by mistake.\", \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The optional property knora-api:deleteComment specifies a comment to be attached to the resource, explaining why it has been marked as deleted. The optional property knora-api:deleteDate (an xsd:dateTimeStamp ) indicates when the resource was marked as deleted; if not given, the current time is used. The response is a JSON-LD document containing the predicate knora-api:result with a confirmation message.","title":"Deleting a Resource"},{"location":"03-endpoints/api-v2/editing-resources/#requesting-deleted-resources","text":"Resources marked as deleted are not found in search queries. It is however possible to request them directly or from an ARK URL. In these instances, the API will not return the deleted resource, but instead a generic resource of type knora-base:DeletedResource . This resource will be similar to the requested resource, having e.g. the same IRI. The resource will contain the deletion date and optionally the deletion comment. The response to requesting a deleted resource will look as the following example: { \"rdfs:label\": \"Deleted Resource\", \"knora-api:versionArkUrl\": { \"@value\": \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO.20211214T084407677335Z\", \"@type\": \"xsd:anyURI\" }, \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" }, \"knora-api:userHasPermission\": \"CR\", \"knora-api:attachedToUser\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:hasPermissions\": \"CR knora-admin:ProjectMember|V knora-admin:ProjectMember\", \"knora-api:isDeleted\": true, \"@type\": \"knora-api:DeletedResource\", \"@id\": \"http://rdfh.ch/0001/a-thing\", \"knora-api:deleteComment\": \"This resource is too boring.\", \"knora-api:arkUrl\": { \"@value\": \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO\", \"@type\": \"xsd:anyURI\" }, \"knora-api:creationDate\": { \"@value\": \"2021-12-14T08:44:07.677335Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-api:deleteDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"2021-12-14T08:44:07.372543Z\" }, \"@context\": { \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Requesting Deleted Resources"},{"location":"03-endpoints/api-v2/editing-resources/#links-to-deleted-resources","text":"If resource A has a link to resource B , and resource B is later marked as deleted, A 's link will still exist. DSP-API v2 will still return the link when A is queried, but without any information about B (except for B 's IRI). If A 's link is necessary to meet the requirements of a cardinality, marking B as deleted will not violate the cardinality. The reason for this design is that A and B might be in different projects, and each project must retain control of its resources and be able to mark them as deleted, even if they are used by another project.","title":"Links to Deleted Resources"},{"location":"03-endpoints/api-v2/editing-resources/#erasing-a-resource-from-the-triplestore","text":"Normally, resources are not actually removed from the triplestore; they are only marked as deleted (see Deleting a Resource ). However, sometimes it is necessary to erase a resource from the triplestore. To do so, use this route: HTTP POST to http://host/v2/resources/erase The request body is the same as for Deleting a Resource , except that knora-api:deleteComment is not relevant and will be ignored. To do this, a user must be a system administrator or an administrator of the project containing the resource. The user's permissions on the resource are not otherwise checked. A resource cannot be erased if any other resource has a link to it. Any such links must first be changed or marked as deleted (see Updating a Value and Deleting a Value ). Then, when the resource is erased, the deleted link values that referred to it will also be erased. This operation cannot be undone (except by restoring the repository from a backup), so use it with care.","title":"Erasing a Resource from the Triplestore"},{"location":"03-endpoints/api-v2/editing-values/","text":"Creating and Editing Values Creating a Value To create a value in an existing resource, use this route: HTTP POST to http://host/v2/values The body of the request is a JSON-LD document in the complex API schema , specifying the resource's IRI and type, the resource property, and the content of the value. The representation of the value is the same as when it is returned in a GET request, except that its IRI and knora-api:attachedToUser are not given. For example, to create an integer value: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 4 }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Each value can have a comment, given in knora-api:valueHasComment . For example: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 4, \"knora-api:valueHasComment\": \"This is a comment.\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Permissions for the new value can be given by adding knora-api:hasPermissions . For example: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 4, \"knora-api:hasPermissions\": \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Each value can have an optional custom IRI (of Knora IRI form) specified by the @id attribute, a custom creation date specified by adding knora-api:valueCreationDate (an xsd:dateTimeStamp ), or a custom UUID given by knora-api:valueHasUUID . Each custom UUID must be base64url-encoded , without padding. If a custom UUID is provided, it will be used in value IRI. If a custom IRI is given for the value, its UUID should match the given custom UUID. If a custom IRI is provided, but there is no custom UUID provided, then the UUID given in the IRI will be assigned to the knora-api:valueHasUUID . A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. For example: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/IN4R19yYR0ygi3K2VEHpUQ\", \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 21, \"knora-api:valueHasUUID\": \"IN4R19yYR0ygi3K2VEHpUQ\", \"knora-api:valueCreationDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"2020-06-04T12:58:54.502951Z\" } }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\" } } The format of the object of knora-api:hasPermissions is described in Permissions . If permissions are not given, configurable default permissions are used (see Default Object Access Permissions ). To create a value, the user must have modify permission on the containing resource. The response is a JSON-LD document containing: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions (except for link values, as explained below). Creating a Link Between Resources To create a link, you must create a knora-api:LinkValue , which represents metadata about the link. The property that connects the resource to the LinkValue is a link value property, whose name is constructed by adding Value to the name of the link property (see Links Between Resources ). The triple representing the direct link between the resources is created automatically. For example, if the link property that should connect the resources is anything:hasOtherThing , we can create a link like this: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasOtherThingValue\": { \"@type\": \"knora-api:LinkValue\", \"knora-api:linkValueHasTargetIri\": { \"@id\": \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\" } }, \"@context\": { \"xsd\": \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } As with ordinary values, permissions on links can be specified by adding knora-api:hasPermissions . The response is a JSON-LD document containing: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions, unless the link is changed to point to a different resource, in which case it is considered a new link and gets a new UUID. Changing a link's metadata, without changing its target, creates a new version of the link value with the same UUID. Creating a Text Value Without Standoff Markup Use the predicate knora-api:valueAsString of knora-api:TextValue : { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasText\": { \"@type\": \"knora-api:TextValue\", \"knora-api:valueAsString\": \"This is a text without markup.\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Creating a Text Value with Standoff Markup Currently, the only way to create a text value with standoff markup is to submit it in XML format using an XML-to-standoff mapping . Creating a Text Value with Standard Mapping To create a value with the standard mapping ( http://rdfh.ch/standoff/mappings/StandardMapping ), we can make an XML document like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> This text links to another <a class=\"salsah-link\" href=\"http://rdfh.ch/0001/another-thing\">resource</a>. </text> This document can then be embedded in a JSON-LD request, using the predicate knora-api:textValueAsXml : { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasText\": { \"@type\": \"knora-api:TextValue\", \"knora-api:textValueAsXml\": \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<text>\\n This text links to another <a class=\\\"salsah-link\\\" href=\\\"http://rdfh.ch/0001/another-thing\\\">resource</a>.\\n</text>\", \"knora-api:textValueHasMapping\": { \"@id\": \"http://rdfh.ch/standoff/mappings/StandardMapping\" } }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Note that quotation marks and line breaks in the XML must be escaped, and that the IRI of the mapping must be provided. Creating a Text Value with a Custom Mapping To create a text value with custom mapping, the following steps are required: Optionally, an XSL transformation resource ( kb:XSLTransformation ) can be created that may be defined as the default transformation of the mapping. The mapping resource ( kb:XMLToStandoffMapping ) must be created, if it does not already exist. The text value can be created as in the example above, using the mapping resource IRI in kb:textValueHasMapping . The kb:XSLTransformation resource is a subclass of kb:TextRepresentation , so it has a kb:hasTextFileValue pointing to a kb:TextFileValue which represents the XSLT file stored in SIPI. For more Details, see Creating File Values . The kb:XMLToStandoffMapping resource requires the mapping XML as specified here . If an XSL transformation has been defined, the IRI the transformation can be placed in the <defaultXSLTransformation> tag of the mapping XML. If a mapping has been defined, then requesting the text value will return both the kb:textValueAsXml and the kb:textValueAsHtml properties, where the XML can be used for editing the value, while the HTML can be used to display it. If no mapping has been defined, only kb:textValueAsXml can be returned. Creating File Values Knora supports the storage of certain types of data as files, using Sipi (see FileValue ). DSP-API v2 currently supports using Sipi to store the following types of files: Images: JPEG, JPEG2000, TIFF, or PNG which are stored internally as JPEG2000 Documents: PDF Audio: MPEG or Waveform audio file format (.wav, .x-wav, .vnd.wave) Text files: TXT, XML, or CSV Video files: MP4 Archive files: ZIP, TAR, GZIP Support for other types of files will be added in the future. The following sections describe the steps for creating a file value. Upload Files to Sipi The first step is to upload one or more files to Sipi, using a multipart/form-data request, where sipihost represents the host and port on which Sipi is running: HTTP POST to http://sipihost/upload?token=TOKEN The token parameter must provide the JSON Web Token that Knora returned when the client logged in. Each body part in the request must contain a parameter filename , providing the file's original filename, which both Knora and Sipi will store; these filenames can be descriptive and need not be unique. Sipi stores the file in a temporary location. If the file is an image, it is converted first to JPEG2000 format, and the converted file is stored. Sipi then returns a JSON response that looks something like this: { \"uploadedFiles\": [ { \"originalFilename\": \"manuscript-1234-page-1.tiff\", \"internalFilename\": \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\", \"temporaryBaseIIIFUrl\": \"http://sipihost/tmp\" }, { \"originalFilename\": \"manuscript-1234-page-2.tiff\", \"internalFilename\": \"2RvJgguglpe-B45EOk0Gx8H.jp2\", \"temporaryBaseIIIFUrl\": \"http://sipihost/tmp\" } ] } In this example, we uploaded two files to Sipi, so uploadedFiles is an array with two elements. For each file, we have: the originalFilename , which we submitted when uploading the file the unique internalFilename that Sipi has randomly generated for the file the temporaryBaseIIIFUrl , which we can use to construct a IIIF URL for previewing the file In the case of an image file, the client may now wish to get a thumbnail of each uploaded image, to allow the user to confirm that the correct files have been uploaded. This can be done by adding IIIF parameters to temporaryBaseIIIFUrl . For example, to get a JPG thumbnail image that is 150 pixels wide, you would add /full/150,/0/default.jpg . Submit A File Value to Knora A Knora Representation (i.e. a resource containing information about a file) must always have exactly one file value attached to it. (see Representations ). Therefore, a request to create a new file value must always be submitted as part of a request to create a new resource (see Creating a Resource ). You can also update a file value in an existing Representation ; see Updating a Value . Instead of providing the file's complete metadata to Knora, you just provide the unique internal filename generated by Sipi. Here is an example of a request to create a resource of class anything:ThingPicture , which is a subclass of knora-api:StillImageRepresentation and therefore has the property knora-api:hasStillImageFileValue : { \"@type\": \"anything:ThingPicture\", \"knora-api:hasStillImageFileValue\": { \"@type\": \"knora-api:StillImageFileValue\", \"knora-api:fileValueHasFilename\": \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\" }, \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" }, \"rdfs:label\": \"test thing\", \"@context\": { \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Knora then gets the rest of the file's metadata from Sipi. If the client's request to Knora is valid, Knora saves the file value in the triplestore and instructs Sipi to move the file to permanent storage. Otherwise, the temporary file that was stored by Sipi is deleted. If you're submitting a PDF document, use the resource class knora-api:DocumentRepresentation , which has the property knora-api:hasDocumentFileValue , pointing to a knora-api:DocumentFileValue . For a text file, use knora-api:TextRepresentation , which has the property knora-api:hasTextFileValue , pointing to a knora-api:TextFileValue . For an archive like zip, use knora-api:ArchiveRepresentation , which has the property knora-api:hasArchiveFileValue , pointing to a knora-api:ArchiveFileValue . Updating a Value To update a value, use this route: HTTP PUT to http://host/v2/values Updating a value means creating a new version of an existing value. The new version will have a different IRI. The request is the same as for creating a value, except that the @id of the current value version is given. For example, to update an integer value: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\", \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 5 }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The value can be given a comment by using knora-api:valueHasComment . To change only the comment of a value, you can resubmit the existing value with the updated comment. Permissions can be specified by adding knora-api:hasPermissions . Otherwise, the new version has the same permissions as the previous one. To change the permissions on a value, the user must have change rights permission on the value. To update only the permissions on a value, submit it with the new permissions and with its @id and @type but without any other content, like this: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\", \"@type\": \"knora-api:IntValue\", \"knora-api:hasPermissions\": \"CR knora-admin:Creator|V knora-admin:KnownUser\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } To update a link, the user must have modify permission on the containing resource as well as on the value. To update a value and give it a custom timestamp, add knora-api:valueCreationDate (an xsd:dateTimeStamp ). To update a value and give the new version a custom IRI, add knora-api:newValueVersionIri , like this: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\", \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 21, \"knora-api:newValueVersionIri\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/int-value-IRI\" } }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. The response is a JSON-LD document containing only @id and @type , returning the IRI and type of the new value version. If you submit an outdated value ID in a request to update a value, the response will be an HTTP 404 (Not Found) error. The response to a value update request contains: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions, unless the value is a link value and is changed to point to a different resource, in which case it is considered a new link and gets a new UUID. Deleting a Value Knora does not normally delete values; instead, it marks them as deleted, which means that they do not appear in normal query results. To mark a value as deleted, use this route: HTTP POST to http://host/v2/values/delete The request must include the resource's ID and type, the property that points from the resource to the value, and the value's ID and type. For example: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\", \"@type\": \"knora-api:IntValue\", \"knora-api:deleteComment\": \"This value was created by mistake.\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The optional property knora-api:deleteComment specifies a comment to be attached to the value, explaining why it has been marked as deleted The optional property knora-api:deleteDate (an xsd:dateTimeStamp ) specifies a custom timestamp indicating when the value was deleted. If not specified, the current time is used. The response is a JSON-LD document containing the predicate knora-api:result with a confirmation message. Requesting Deleted Values Values marked as deleted are not found in search queries. But when requesting a resource that has deleted values, these will show up as generic knora-api:DeletedValue values. This value will be similar to the deleted value, having e.g. the same IRI. The DeletedValue will contain the deletion date and optionally the deletion comment. The response to requesting a deleted resource will look as the following example: { \"knora-api:DeletedValue\": [ { \"knora-api:versionArkUrl\": { \"@value\": \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO/sWSymIzAS_qXqyHLhwbwwAU.20211216T18193124797Z\", \"@type\": \"xsd:anyURI\" }, \"knora-api:userHasPermission\": \"RV\", \"knora-api:valueCreationDate\": { \"@value\": \"2021-12-16T18:19:31.247970Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-api:deleteDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"2021-12-16T18:20:02.550828Z\" }, \"knora-api:attachedToUser\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:valueHasUUID\": \"sWSymIzAS_qXqyHLhwbwwA\", \"knora-api:hasPermissions\": \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:KnownUser|RV knora-admin:UnknownUser\", \"knora-api:isDeleted\": true, \"@type\": \"knora-api:DeletedValue\", \"http://www.knora.org/ontology/knora-base#DeletedValue\": \"DeletedValue\", \"@id\": \"http://rdfh.ch/0001/a-thing/values/DrXts3Up3DijGriI403nhg\", \"knora-api:deleteComment\": \"This value is obsolete\", \"knora-api:arkUrl\": { \"@value\": \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO/sWSymIzAS_qXqyHLhwbwwAU\", \"@type\": \"xsd:anyURI\" } }, {} ] }","title":"Creating and Editing Values"},{"location":"03-endpoints/api-v2/editing-values/#creating-and-editing-values","text":"","title":"Creating and Editing Values"},{"location":"03-endpoints/api-v2/editing-values/#creating-a-value","text":"To create a value in an existing resource, use this route: HTTP POST to http://host/v2/values The body of the request is a JSON-LD document in the complex API schema , specifying the resource's IRI and type, the resource property, and the content of the value. The representation of the value is the same as when it is returned in a GET request, except that its IRI and knora-api:attachedToUser are not given. For example, to create an integer value: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 4 }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Each value can have a comment, given in knora-api:valueHasComment . For example: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 4, \"knora-api:valueHasComment\": \"This is a comment.\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Permissions for the new value can be given by adding knora-api:hasPermissions . For example: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 4, \"knora-api:hasPermissions\": \"CR knora-admin:Creator|V http://rdfh.ch/groups/0001/thing-searcher\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Each value can have an optional custom IRI (of Knora IRI form) specified by the @id attribute, a custom creation date specified by adding knora-api:valueCreationDate (an xsd:dateTimeStamp ), or a custom UUID given by knora-api:valueHasUUID . Each custom UUID must be base64url-encoded , without padding. If a custom UUID is provided, it will be used in value IRI. If a custom IRI is given for the value, its UUID should match the given custom UUID. If a custom IRI is provided, but there is no custom UUID provided, then the UUID given in the IRI will be assigned to the knora-api:valueHasUUID . A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. For example: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/IN4R19yYR0ygi3K2VEHpUQ\", \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 21, \"knora-api:valueHasUUID\": \"IN4R19yYR0ygi3K2VEHpUQ\", \"knora-api:valueCreationDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"2020-06-04T12:58:54.502951Z\" } }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\" } } The format of the object of knora-api:hasPermissions is described in Permissions . If permissions are not given, configurable default permissions are used (see Default Object Access Permissions ). To create a value, the user must have modify permission on the containing resource. The response is a JSON-LD document containing: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions (except for link values, as explained below).","title":"Creating a Value"},{"location":"03-endpoints/api-v2/editing-values/#creating-a-link-between-resources","text":"To create a link, you must create a knora-api:LinkValue , which represents metadata about the link. The property that connects the resource to the LinkValue is a link value property, whose name is constructed by adding Value to the name of the link property (see Links Between Resources ). The triple representing the direct link between the resources is created automatically. For example, if the link property that should connect the resources is anything:hasOtherThing , we can create a link like this: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasOtherThingValue\": { \"@type\": \"knora-api:LinkValue\", \"knora-api:linkValueHasTargetIri\": { \"@id\": \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\" } }, \"@context\": { \"xsd\": \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } As with ordinary values, permissions on links can be specified by adding knora-api:hasPermissions . The response is a JSON-LD document containing: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions, unless the link is changed to point to a different resource, in which case it is considered a new link and gets a new UUID. Changing a link's metadata, without changing its target, creates a new version of the link value with the same UUID.","title":"Creating a Link Between Resources"},{"location":"03-endpoints/api-v2/editing-values/#creating-a-text-value-without-standoff-markup","text":"Use the predicate knora-api:valueAsString of knora-api:TextValue : { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasText\": { \"@type\": \"knora-api:TextValue\", \"knora-api:valueAsString\": \"This is a text without markup.\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } }","title":"Creating a Text Value Without Standoff Markup"},{"location":"03-endpoints/api-v2/editing-values/#creating-a-text-value-with-standoff-markup","text":"Currently, the only way to create a text value with standoff markup is to submit it in XML format using an XML-to-standoff mapping .","title":"Creating a Text Value with Standoff Markup"},{"location":"03-endpoints/api-v2/editing-values/#creating-a-text-value-with-standard-mapping","text":"To create a value with the standard mapping ( http://rdfh.ch/standoff/mappings/StandardMapping ), we can make an XML document like this: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text> This text links to another <a class=\"salsah-link\" href=\"http://rdfh.ch/0001/another-thing\">resource</a>. </text> This document can then be embedded in a JSON-LD request, using the predicate knora-api:textValueAsXml : { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasText\": { \"@type\": \"knora-api:TextValue\", \"knora-api:textValueAsXml\": \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n<text>\\n This text links to another <a class=\\\"salsah-link\\\" href=\\\"http://rdfh.ch/0001/another-thing\\\">resource</a>.\\n</text>\", \"knora-api:textValueHasMapping\": { \"@id\": \"http://rdfh.ch/standoff/mappings/StandardMapping\" } }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Note that quotation marks and line breaks in the XML must be escaped, and that the IRI of the mapping must be provided.","title":"Creating a Text Value with Standard Mapping"},{"location":"03-endpoints/api-v2/editing-values/#creating-a-text-value-with-a-custom-mapping","text":"To create a text value with custom mapping, the following steps are required: Optionally, an XSL transformation resource ( kb:XSLTransformation ) can be created that may be defined as the default transformation of the mapping. The mapping resource ( kb:XMLToStandoffMapping ) must be created, if it does not already exist. The text value can be created as in the example above, using the mapping resource IRI in kb:textValueHasMapping . The kb:XSLTransformation resource is a subclass of kb:TextRepresentation , so it has a kb:hasTextFileValue pointing to a kb:TextFileValue which represents the XSLT file stored in SIPI. For more Details, see Creating File Values . The kb:XMLToStandoffMapping resource requires the mapping XML as specified here . If an XSL transformation has been defined, the IRI the transformation can be placed in the <defaultXSLTransformation> tag of the mapping XML. If a mapping has been defined, then requesting the text value will return both the kb:textValueAsXml and the kb:textValueAsHtml properties, where the XML can be used for editing the value, while the HTML can be used to display it. If no mapping has been defined, only kb:textValueAsXml can be returned.","title":"Creating a Text Value with a Custom Mapping"},{"location":"03-endpoints/api-v2/editing-values/#creating-file-values","text":"Knora supports the storage of certain types of data as files, using Sipi (see FileValue ). DSP-API v2 currently supports using Sipi to store the following types of files: Images: JPEG, JPEG2000, TIFF, or PNG which are stored internally as JPEG2000 Documents: PDF Audio: MPEG or Waveform audio file format (.wav, .x-wav, .vnd.wave) Text files: TXT, XML, or CSV Video files: MP4 Archive files: ZIP, TAR, GZIP Support for other types of files will be added in the future. The following sections describe the steps for creating a file value.","title":"Creating File Values"},{"location":"03-endpoints/api-v2/editing-values/#upload-files-to-sipi","text":"The first step is to upload one or more files to Sipi, using a multipart/form-data request, where sipihost represents the host and port on which Sipi is running: HTTP POST to http://sipihost/upload?token=TOKEN The token parameter must provide the JSON Web Token that Knora returned when the client logged in. Each body part in the request must contain a parameter filename , providing the file's original filename, which both Knora and Sipi will store; these filenames can be descriptive and need not be unique. Sipi stores the file in a temporary location. If the file is an image, it is converted first to JPEG2000 format, and the converted file is stored. Sipi then returns a JSON response that looks something like this: { \"uploadedFiles\": [ { \"originalFilename\": \"manuscript-1234-page-1.tiff\", \"internalFilename\": \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\", \"temporaryBaseIIIFUrl\": \"http://sipihost/tmp\" }, { \"originalFilename\": \"manuscript-1234-page-2.tiff\", \"internalFilename\": \"2RvJgguglpe-B45EOk0Gx8H.jp2\", \"temporaryBaseIIIFUrl\": \"http://sipihost/tmp\" } ] } In this example, we uploaded two files to Sipi, so uploadedFiles is an array with two elements. For each file, we have: the originalFilename , which we submitted when uploading the file the unique internalFilename that Sipi has randomly generated for the file the temporaryBaseIIIFUrl , which we can use to construct a IIIF URL for previewing the file In the case of an image file, the client may now wish to get a thumbnail of each uploaded image, to allow the user to confirm that the correct files have been uploaded. This can be done by adding IIIF parameters to temporaryBaseIIIFUrl . For example, to get a JPG thumbnail image that is 150 pixels wide, you would add /full/150,/0/default.jpg .","title":"Upload Files to Sipi"},{"location":"03-endpoints/api-v2/editing-values/#submit-a-file-value-to-knora","text":"A Knora Representation (i.e. a resource containing information about a file) must always have exactly one file value attached to it. (see Representations ). Therefore, a request to create a new file value must always be submitted as part of a request to create a new resource (see Creating a Resource ). You can also update a file value in an existing Representation ; see Updating a Value . Instead of providing the file's complete metadata to Knora, you just provide the unique internal filename generated by Sipi. Here is an example of a request to create a resource of class anything:ThingPicture , which is a subclass of knora-api:StillImageRepresentation and therefore has the property knora-api:hasStillImageFileValue : { \"@type\": \"anything:ThingPicture\", \"knora-api:hasStillImageFileValue\": { \"@type\": \"knora-api:StillImageFileValue\", \"knora-api:fileValueHasFilename\": \"3UIsXH9bP0j-BV0D4sN51Xz.jp2\" }, \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" }, \"rdfs:label\": \"test thing\", \"@context\": { \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Knora then gets the rest of the file's metadata from Sipi. If the client's request to Knora is valid, Knora saves the file value in the triplestore and instructs Sipi to move the file to permanent storage. Otherwise, the temporary file that was stored by Sipi is deleted. If you're submitting a PDF document, use the resource class knora-api:DocumentRepresentation , which has the property knora-api:hasDocumentFileValue , pointing to a knora-api:DocumentFileValue . For a text file, use knora-api:TextRepresentation , which has the property knora-api:hasTextFileValue , pointing to a knora-api:TextFileValue . For an archive like zip, use knora-api:ArchiveRepresentation , which has the property knora-api:hasArchiveFileValue , pointing to a knora-api:ArchiveFileValue .","title":"Submit A File Value to Knora"},{"location":"03-endpoints/api-v2/editing-values/#updating-a-value","text":"To update a value, use this route: HTTP PUT to http://host/v2/values Updating a value means creating a new version of an existing value. The new version will have a different IRI. The request is the same as for creating a value, except that the @id of the current value version is given. For example, to update an integer value: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\", \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 5 }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The value can be given a comment by using knora-api:valueHasComment . To change only the comment of a value, you can resubmit the existing value with the updated comment. Permissions can be specified by adding knora-api:hasPermissions . Otherwise, the new version has the same permissions as the previous one. To change the permissions on a value, the user must have change rights permission on the value. To update only the permissions on a value, submit it with the new permissions and with its @id and @type but without any other content, like this: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\", \"@type\": \"knora-api:IntValue\", \"knora-api:hasPermissions\": \"CR knora-admin:Creator|V knora-admin:KnownUser\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } To update a link, the user must have modify permission on the containing resource as well as on the value. To update a value and give it a custom timestamp, add knora-api:valueCreationDate (an xsd:dateTimeStamp ). To update a value and give the new version a custom IRI, add knora-api:newValueVersionIri , like this: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\", \"@type\": \"knora-api:IntValue\", \"knora-api:intValueAsInt\": 21, \"knora-api:newValueVersionIri\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/int-value-IRI\" } }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } A custom value IRI must be the IRI of the containing resource, followed by a /values/ and a custom ID string. The response is a JSON-LD document containing only @id and @type , returning the IRI and type of the new value version. If you submit an outdated value ID in a request to update a value, the response will be an HTTP 404 (Not Found) error. The response to a value update request contains: @id : the IRI of the value that was created. @type : the value's type. knora-api:valueHasUUID , the value's UUID, which remains stable across value versions, unless the value is a link value and is changed to point to a different resource, in which case it is considered a new link and gets a new UUID.","title":"Updating a Value"},{"location":"03-endpoints/api-v2/editing-values/#deleting-a-value","text":"Knora does not normally delete values; instead, it marks them as deleted, which means that they do not appear in normal query results. To mark a value as deleted, use this route: HTTP POST to http://host/v2/values/delete The request must include the resource's ID and type, the property that points from the resource to the value, and the value's ID and type. For example: { \"@id\": \"http://rdfh.ch/0001/a-thing\", \"@type\": \"anything:Thing\", \"anything:hasInteger\": { \"@id\": \"http://rdfh.ch/0001/a-thing/values/vp96riPIRnmQcbMhgpv_Rg\", \"@type\": \"knora-api:IntValue\", \"knora-api:deleteComment\": \"This value was created by mistake.\" }, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"anything\": \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } The optional property knora-api:deleteComment specifies a comment to be attached to the value, explaining why it has been marked as deleted The optional property knora-api:deleteDate (an xsd:dateTimeStamp ) specifies a custom timestamp indicating when the value was deleted. If not specified, the current time is used. The response is a JSON-LD document containing the predicate knora-api:result with a confirmation message.","title":"Deleting a Value"},{"location":"03-endpoints/api-v2/editing-values/#requesting-deleted-values","text":"Values marked as deleted are not found in search queries. But when requesting a resource that has deleted values, these will show up as generic knora-api:DeletedValue values. This value will be similar to the deleted value, having e.g. the same IRI. The DeletedValue will contain the deletion date and optionally the deletion comment. The response to requesting a deleted resource will look as the following example: { \"knora-api:DeletedValue\": [ { \"knora-api:versionArkUrl\": { \"@value\": \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO/sWSymIzAS_qXqyHLhwbwwAU.20211216T18193124797Z\", \"@type\": \"xsd:anyURI\" }, \"knora-api:userHasPermission\": \"RV\", \"knora-api:valueCreationDate\": { \"@value\": \"2021-12-16T18:19:31.247970Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-api:deleteDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"2021-12-16T18:20:02.550828Z\" }, \"knora-api:attachedToUser\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:valueHasUUID\": \"sWSymIzAS_qXqyHLhwbwwA\", \"knora-api:hasPermissions\": \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:KnownUser|RV knora-admin:UnknownUser\", \"knora-api:isDeleted\": true, \"@type\": \"knora-api:DeletedValue\", \"http://www.knora.org/ontology/knora-base#DeletedValue\": \"DeletedValue\", \"@id\": \"http://rdfh.ch/0001/a-thing/values/DrXts3Up3DijGriI403nhg\", \"knora-api:deleteComment\": \"This value is obsolete\", \"knora-api:arkUrl\": { \"@value\": \"http://0.0.0.0:3336/ark:/72163/1/0001/a=thingO/sWSymIzAS_qXqyHLhwbwwAU\", \"@type\": \"xsd:anyURI\" } }, {} ] }","title":"Requesting Deleted Values"},{"location":"03-endpoints/api-v2/getting-lists/","text":"Getting Lists Getting a complete List In order to request a complete list, make a HTTP GET request to the lists route appending the Iri of the list's root node (URL-encoded): HTTP GET to http://host/v2/lists/listRootNodeIri Lists are only returned in the complex schema. The response to a list request is a List (see interface List in module ListResponse ). Getting a single Node In order to request a single node of a list, make a HTTP GET request to the node route appending the node's Iri (URL-encoded): HTTP GET to http://host/v2/node/nodeIri Nodes are only returned in the complex schema. The response to a node request is a ListNode (see interface List in module ListResponse ).","title":"Getting Lists"},{"location":"03-endpoints/api-v2/getting-lists/#getting-lists","text":"","title":"Getting Lists"},{"location":"03-endpoints/api-v2/getting-lists/#getting-a-complete-list","text":"In order to request a complete list, make a HTTP GET request to the lists route appending the Iri of the list's root node (URL-encoded): HTTP GET to http://host/v2/lists/listRootNodeIri Lists are only returned in the complex schema. The response to a list request is a List (see interface List in module ListResponse ).","title":"Getting a complete List"},{"location":"03-endpoints/api-v2/getting-lists/#getting-a-single-node","text":"In order to request a single node of a list, make a HTTP GET request to the node route appending the node's Iri (URL-encoded): HTTP GET to http://host/v2/node/nodeIri Nodes are only returned in the complex schema. The response to a node request is a ListNode (see interface List in module ListResponse ).","title":"Getting a single Node"},{"location":"03-endpoints/api-v2/introduction/","text":"Introduction: Using API v2 Version 2 of the DSP-API aims to make both the response and request formats more generic and consistent. Version 1 was basically the result of the reimplementation of the existing API of the SALSAH prototype. Since the development of this prototype has a long history and the specification of API V1 was an evolving process, V1 has various inconsistencies and peculiarities. With V2, we would like to offer a format that is consistent and hence easier to use for a client. API v2 Path Segment Every request to API v2 includes v2 as a path segment, e.g. http://host/v2/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a . Accordingly, requests using any other version of the API will require another path segment. Response Formats All API v2 responses can be returned in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation . The client can request these formats using the following MIME types: Format MIME Type JSON-LD application/ld+json Turtle text/turtle RDF/XML application/rdf+xml JSON-LD Our preferred format for data exchange is JSON-LD . JSON-LD allows the DSP-API server to provide responses that are relatively easy for automated processes to interpret, since their structure and semantics is explicitly defined. For example, each user-created Knora resource property is identified by an IRI, which can be dereferenced to get more information about it (e.g. its label in different languages). Moreover, each value has a type represented by an IRI. These are either standard RDF types (e.g. XSD datatypes) or more complex types whose IRIs can be dereferenced to get more information about their structure. At the same time, JSON-LD responses are relatively easy for software developers to work with, and are more concise and easier to read than the equivalent XML. Items in a response can have human-readable names, which can nevertheless be expanded to full IRIs. Also, while a format such as Turtle just provides a set of RDF triples, an equivalent JSON-LD response can explicitly provide data in a hierarchical structure, with objects nested inside other objects. Hierarchical vs. Flat JSON-LD The client can choose between hierarchical and flat JSON-LD. In hierarchical JSON-LD, entities with IRIs are inlined (nested) where they are used. If the same entity is used in more than one place, it is inlined only once, and other uses just refer to its IRI. In Knora's flat JSON-LD, all entities with IRIs are located at the top level of the document (in a @graph if there is more than one of them). This setting does not affect blank nodes, which are always inlined (unlike in standard flat JSON-LD). DSP ontologies are always returned in the flat rendering; other kinds of responses default to hierarchical . To use this setting, submit the HTTP header X-Knora-JSON-LD-Rendering with the value hierarchical or flat . Knora IRIs Resources and entities are identified by IRIs. The format of these IRIs is explained in Knora IRIs . API Schema DSP-API v2 uses RDF data structures that are simpler than the ones actually stored in the triplestore, and more suitable for the development of client software. Thus we refer to the internal schema of data as it is stored in the triplestore, and to external schemas which are used to represent that data in API v2. DSP-API v2 offers a complex schema and a simple one. The main difference is that the complex schema exposes the complexity of value objects, while the simple version does not. A client that needs to edit values must use the complex schema in order to obtain the IRI of each value. A client that reads but does not update data can use the simplified schema. The simple schema is mainly intended to facilitate interoperability with other RDF-based systems in the context of Linked Open Data. It is therefore designed to use the simplest possible datatypes and to require minimal knowledge of Knora. In either case, the client deals only with data whose structure and semantics are defined by external DSP-API ontologies, which are distinct from the internal ontologies that are used to store date in the triplestore. The Knora API server automatically converts back and forth between these internal and external representations. This approach encapsulates the internals and adds a layer of abstraction to them. IRIs representing ontologies and ontology entities are different in different schemas; see Knora IRIs . Some API operations inherently require the client to accept responses in the complex schema. For example, if an ontology is requested using an IRI indicating the simple schema, the ontology will be returned in the simple schema (see Querying, Creating, and Updating Ontologies ). Other API operations can return data in either schema. In this case, the complex schema is used by default in the response, unless the request specifically asks for the simple schema. The client can specify the desired schema by using an HTTP header or a URL parameter: the HTTP header X-Knora-Accept-Schema the URL parameter schema Both the HTTP header and the URL parameter accept the values simple or complex .","title":"Introduction"},{"location":"03-endpoints/api-v2/introduction/#introduction-using-api-v2","text":"Version 2 of the DSP-API aims to make both the response and request formats more generic and consistent. Version 1 was basically the result of the reimplementation of the existing API of the SALSAH prototype. Since the development of this prototype has a long history and the specification of API V1 was an evolving process, V1 has various inconsistencies and peculiarities. With V2, we would like to offer a format that is consistent and hence easier to use for a client.","title":"Introduction: Using API v2"},{"location":"03-endpoints/api-v2/introduction/#api-v2-path-segment","text":"Every request to API v2 includes v2 as a path segment, e.g. http://host/v2/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a . Accordingly, requests using any other version of the API will require another path segment.","title":"API v2 Path Segment"},{"location":"03-endpoints/api-v2/introduction/#response-formats","text":"All API v2 responses can be returned in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation . The client can request these formats using the following MIME types: Format MIME Type JSON-LD application/ld+json Turtle text/turtle RDF/XML application/rdf+xml","title":"Response Formats"},{"location":"03-endpoints/api-v2/introduction/#json-ld","text":"Our preferred format for data exchange is JSON-LD . JSON-LD allows the DSP-API server to provide responses that are relatively easy for automated processes to interpret, since their structure and semantics is explicitly defined. For example, each user-created Knora resource property is identified by an IRI, which can be dereferenced to get more information about it (e.g. its label in different languages). Moreover, each value has a type represented by an IRI. These are either standard RDF types (e.g. XSD datatypes) or more complex types whose IRIs can be dereferenced to get more information about their structure. At the same time, JSON-LD responses are relatively easy for software developers to work with, and are more concise and easier to read than the equivalent XML. Items in a response can have human-readable names, which can nevertheless be expanded to full IRIs. Also, while a format such as Turtle just provides a set of RDF triples, an equivalent JSON-LD response can explicitly provide data in a hierarchical structure, with objects nested inside other objects.","title":"JSON-LD"},{"location":"03-endpoints/api-v2/introduction/#hierarchical-vs-flat-json-ld","text":"The client can choose between hierarchical and flat JSON-LD. In hierarchical JSON-LD, entities with IRIs are inlined (nested) where they are used. If the same entity is used in more than one place, it is inlined only once, and other uses just refer to its IRI. In Knora's flat JSON-LD, all entities with IRIs are located at the top level of the document (in a @graph if there is more than one of them). This setting does not affect blank nodes, which are always inlined (unlike in standard flat JSON-LD). DSP ontologies are always returned in the flat rendering; other kinds of responses default to hierarchical . To use this setting, submit the HTTP header X-Knora-JSON-LD-Rendering with the value hierarchical or flat .","title":"Hierarchical vs. Flat JSON-LD"},{"location":"03-endpoints/api-v2/introduction/#knora-iris","text":"Resources and entities are identified by IRIs. The format of these IRIs is explained in Knora IRIs .","title":"Knora IRIs"},{"location":"03-endpoints/api-v2/introduction/#api-schema","text":"DSP-API v2 uses RDF data structures that are simpler than the ones actually stored in the triplestore, and more suitable for the development of client software. Thus we refer to the internal schema of data as it is stored in the triplestore, and to external schemas which are used to represent that data in API v2. DSP-API v2 offers a complex schema and a simple one. The main difference is that the complex schema exposes the complexity of value objects, while the simple version does not. A client that needs to edit values must use the complex schema in order to obtain the IRI of each value. A client that reads but does not update data can use the simplified schema. The simple schema is mainly intended to facilitate interoperability with other RDF-based systems in the context of Linked Open Data. It is therefore designed to use the simplest possible datatypes and to require minimal knowledge of Knora. In either case, the client deals only with data whose structure and semantics are defined by external DSP-API ontologies, which are distinct from the internal ontologies that are used to store date in the triplestore. The Knora API server automatically converts back and forth between these internal and external representations. This approach encapsulates the internals and adds a layer of abstraction to them. IRIs representing ontologies and ontology entities are different in different schemas; see Knora IRIs . Some API operations inherently require the client to accept responses in the complex schema. For example, if an ontology is requested using an IRI indicating the simple schema, the ontology will be returned in the simple schema (see Querying, Creating, and Updating Ontologies ). Other API operations can return data in either schema. In this case, the complex schema is used by default in the response, unless the request specifically asks for the simple schema. The client can specify the desired schema by using an HTTP header or a URL parameter: the HTTP header X-Knora-Accept-Schema the URL parameter schema Both the HTTP header and the URL parameter accept the values simple or complex .","title":"API Schema"},{"location":"03-endpoints/api-v2/knora-iris/","text":"Knora IRIs The IRIs used in Knora repositories and in the DSP-API v2 follow certain conventions. Project Short-Codes A project short-code is a hexadecimal number of at least four digits, assigned by the DaSCH to uniquely identify a Knora project regardless of where it is hosted. The IRIs of ontologies that are built into Knora do not contain shortcodes; these ontologies implicitly belong to the Knora system project. Project ID 0000 is reserved for shared ontologies (see Shared Ontologies ). The range of project IDs from 0001 to 00FF inclusive is reserved for local testing. Thus, the first useful project will be 0100 . In the beginning, Unil will use the IDs 0100 to 07FF , and Unibas 0800 to 08FF . IRIs for Ontologies and Ontology Entities Internal Ontology IRIs Knora makes a distinction between internal and external ontologies. Internal ontologies are used in the triplestore, while external ontologies are used in API v2. For each internal ontology, there is a corresponding external ontology. Some internal ontologies are built into Knora, while others are user-created. Knora automatically generates external ontologies based on user-created internal ontologies. Each internal ontology has an IRI, which is also the IRI of the named graph that contains the ontology in the triplestore. An internal ontology IRI has the form: http://www.knora.org/ontology/PROJECT_SHORTCODE/ONTOLOGY_NAME For example, the internal ontology IRI based on project code 0001 and ontology name example would be: http://www.knora.org/ontology/0001/example An ontology name must be a valid XML NCName and must be URL safe. The following names are reserved for built-in internal DSP ontologies: knora-base standoff salsah-gui Names starting with knora are reserved for future built-in Knora ontologies. A user-created ontology name may not start with the letter v followed by a digit, and may not contain these reserved words: knora ontology simple shared External Ontology IRIs Unlike internal ontology IRIs, external ontology IRIs are meant to be dereferenced as URLs. When an ontology IRI is dereferenced, the ontology itself can be served either in a machine-readable format or as human-readable documentation. The IRI of an external Knora ontology has the form: http://HOST[:PORT]/ontology/PROJECT_SHORTCODE/ONTOLOGY_NAME/API_VERSION For built-in and shared ontologies, the host is always api.knora.org . Otherwise, the hostname and port configured in application.conf under app.http.knora-api.host and app.http.knora-api.http-port are used (the port is omitted if it is 80). This means that when a built-in or shared external ontology IRI is dereferenced, the ontology can be served by a DSP-API server running at api.knora.org . When the external IRI of a non-shared, project-specific ontology is dereferenced, the ontology can be served by Knora that hosts the project. During development and testing, this could be localhost . The name of an external ontology is the same as the name of the corresponding internal ontology, with one exception: the external form of knora-base is called knora-api . The API version identifier indicates not only the version of the API, but also an API 'schema'. The DSP-API v2 is available in two schemas: A complex schema, which is suitable both for reading and for editing data. The complex schema represents values primarily as complex objects. Its version identifier is v2 . A simple schema, which is suitable for reading data but not for editing it. The simple schema facilitates interoperability between DSP ontologies and non-DSP ontologies, since it represents values primarily as literals. Its version identifier is simple/v2 . Other schemas could be added in the future for more specific use cases. When requesting an ontology, the client requests a particular schema. (This will also be true of most DSP-API v2 requests: the client will be able to specify which schema the response should be provided in.) For example, suppose a DSP-API server is running at knora.example.org and hosts an ontology whose internal IRI is http://www.knora.org/ontology/0001/example . That ontology can then be requested using either of these IRIs: http://knora.example.org/ontology/0001/example/v2 (in the complex schema) http://knora.example.org/ontology/0001/example/simple/v2 (in the simple schema) While the internal example ontology refers to definitions in knora-base , the external example ontology that is served by the API refers instead to a knora-api ontology, whose IRI depends on the schema being used: http://api.knora.org/ontology/knora-api/v2 (in the complex schema) http://api.knora.org/ontology/knora-api/simple/v2 (in the simple schema) Ontology Entity IRIs DSP ontologies use 'hash namespaces' (see URI Namespaces ). This means that the IRI of an ontology entity (a class or property definition) is constructed by adding a hash character ( # ) to the ontology IRI, followed by the name of the entity. In Knora, an entity name must be a valid XML NCName . Thus, if there is a class called ExampleThing in an ontology whose internal IRI is http://www.knora.org/ontology/0001/example , that class has the following IRIs: http://www.knora.org/ontology/0001/example#ExampleThing (in the internal ontology) http://HOST[:PORT]/ontology/0001/example/v2#ExampleThing (in the API v2 complex schema) http://HOST[:PORT]/ontology/0001/example/simple/v2#ExampleThing (in the API v2 simple schema) Shared Ontology IRIs As explained in Shared Ontologies , a user-created ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators will not change it in ways that could affect other ontologies or data that are based on it. There is currently one project for shared ontologies: http://www.knora.org/ontology/knora-base#DefaultSharedOntologiesProject Its project code is 0000 . Additional projects for shared ontologies may be supported in future. The internal and external IRIs of shared ontologies always use the hostname api.knora.org , and have an additional segment, shared , after ontology . The project code can be omitted, in which case the default shared ontology project, 0000 , is assumed. The sample shared ontology, example-box , has these IRIs: http://www.knora.org/ontology/shared/example-box (internal) http://api.knora.org/ontology/shared/example-box/v2 (external, complex schema) http://api.knora.org/ontology/shared/example-box/simple/v2 (external, simple schema) IRIs for Data Knora generates IRIs for data that it creates in the triplestore. Each generated data IRI contains one or more UUID identifiers to make it unique. To keep data IRIs relatively short, each UUID is base64url-encoded , without padding; thus each UUID is a 22-character string. DSP-API supports UUID version 4 or 5. Data IRIs are not currently intended to be dereferenced as URLs. Instead, each Knora resource has a separate permalink . A Knora value does not have a stable IRI throughout its version history. Each time a new version of a value is made, the new version gets a new IRI. Therefore, it would not make sense to publish Knora value IRIs. When designing ontologies for Knora projects, keep in mind that if you want something be directly citable, it needs to be a resource, not a value. The formats of generated data IRIs for different types of objects are as follows: Resource: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID . Value: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID/values/VALUE_UUID Standoff tag: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID/values/VALUE_UUID/STANDOFF_UUID XML-to-standoff mapping: http://rdfh.ch/projects/PROJECT_SHORTCODE/mappings/MAPPING_NAME XML-to-standoff mapping element: http://rdfh.ch/projects/PROJECT_SHORTCODE/mappings/MAPPING_NAME/elements/MAPPING_ELEMENT_UUID Project: http://rdfh.ch/projects/PROJECT_UUID Group: http://rdfh.ch/groups/PROJECT_SHORTCODE/GROUP_UUID Permission: http://rdfh.ch/permissions/PROJECT_SHORTCODE/PERMISSION_UUID Lists: http://rdfh.ch/lists/PROJECT_SHORTCODE/LIST_UUID User: http://rdfh.ch/users/USER_UUID","title":"Knora IRIs"},{"location":"03-endpoints/api-v2/knora-iris/#knora-iris","text":"The IRIs used in Knora repositories and in the DSP-API v2 follow certain conventions.","title":"Knora IRIs"},{"location":"03-endpoints/api-v2/knora-iris/#project-short-codes","text":"A project short-code is a hexadecimal number of at least four digits, assigned by the DaSCH to uniquely identify a Knora project regardless of where it is hosted. The IRIs of ontologies that are built into Knora do not contain shortcodes; these ontologies implicitly belong to the Knora system project. Project ID 0000 is reserved for shared ontologies (see Shared Ontologies ). The range of project IDs from 0001 to 00FF inclusive is reserved for local testing. Thus, the first useful project will be 0100 . In the beginning, Unil will use the IDs 0100 to 07FF , and Unibas 0800 to 08FF .","title":"Project Short-Codes"},{"location":"03-endpoints/api-v2/knora-iris/#iris-for-ontologies-and-ontology-entities","text":"","title":"IRIs for Ontologies and Ontology Entities"},{"location":"03-endpoints/api-v2/knora-iris/#internal-ontology-iris","text":"Knora makes a distinction between internal and external ontologies. Internal ontologies are used in the triplestore, while external ontologies are used in API v2. For each internal ontology, there is a corresponding external ontology. Some internal ontologies are built into Knora, while others are user-created. Knora automatically generates external ontologies based on user-created internal ontologies. Each internal ontology has an IRI, which is also the IRI of the named graph that contains the ontology in the triplestore. An internal ontology IRI has the form: http://www.knora.org/ontology/PROJECT_SHORTCODE/ONTOLOGY_NAME For example, the internal ontology IRI based on project code 0001 and ontology name example would be: http://www.knora.org/ontology/0001/example An ontology name must be a valid XML NCName and must be URL safe. The following names are reserved for built-in internal DSP ontologies: knora-base standoff salsah-gui Names starting with knora are reserved for future built-in Knora ontologies. A user-created ontology name may not start with the letter v followed by a digit, and may not contain these reserved words: knora ontology simple shared","title":"Internal Ontology IRIs"},{"location":"03-endpoints/api-v2/knora-iris/#external-ontology-iris","text":"Unlike internal ontology IRIs, external ontology IRIs are meant to be dereferenced as URLs. When an ontology IRI is dereferenced, the ontology itself can be served either in a machine-readable format or as human-readable documentation. The IRI of an external Knora ontology has the form: http://HOST[:PORT]/ontology/PROJECT_SHORTCODE/ONTOLOGY_NAME/API_VERSION For built-in and shared ontologies, the host is always api.knora.org . Otherwise, the hostname and port configured in application.conf under app.http.knora-api.host and app.http.knora-api.http-port are used (the port is omitted if it is 80). This means that when a built-in or shared external ontology IRI is dereferenced, the ontology can be served by a DSP-API server running at api.knora.org . When the external IRI of a non-shared, project-specific ontology is dereferenced, the ontology can be served by Knora that hosts the project. During development and testing, this could be localhost . The name of an external ontology is the same as the name of the corresponding internal ontology, with one exception: the external form of knora-base is called knora-api . The API version identifier indicates not only the version of the API, but also an API 'schema'. The DSP-API v2 is available in two schemas: A complex schema, which is suitable both for reading and for editing data. The complex schema represents values primarily as complex objects. Its version identifier is v2 . A simple schema, which is suitable for reading data but not for editing it. The simple schema facilitates interoperability between DSP ontologies and non-DSP ontologies, since it represents values primarily as literals. Its version identifier is simple/v2 . Other schemas could be added in the future for more specific use cases. When requesting an ontology, the client requests a particular schema. (This will also be true of most DSP-API v2 requests: the client will be able to specify which schema the response should be provided in.) For example, suppose a DSP-API server is running at knora.example.org and hosts an ontology whose internal IRI is http://www.knora.org/ontology/0001/example . That ontology can then be requested using either of these IRIs: http://knora.example.org/ontology/0001/example/v2 (in the complex schema) http://knora.example.org/ontology/0001/example/simple/v2 (in the simple schema) While the internal example ontology refers to definitions in knora-base , the external example ontology that is served by the API refers instead to a knora-api ontology, whose IRI depends on the schema being used: http://api.knora.org/ontology/knora-api/v2 (in the complex schema) http://api.knora.org/ontology/knora-api/simple/v2 (in the simple schema)","title":"External Ontology IRIs"},{"location":"03-endpoints/api-v2/knora-iris/#ontology-entity-iris","text":"DSP ontologies use 'hash namespaces' (see URI Namespaces ). This means that the IRI of an ontology entity (a class or property definition) is constructed by adding a hash character ( # ) to the ontology IRI, followed by the name of the entity. In Knora, an entity name must be a valid XML NCName . Thus, if there is a class called ExampleThing in an ontology whose internal IRI is http://www.knora.org/ontology/0001/example , that class has the following IRIs: http://www.knora.org/ontology/0001/example#ExampleThing (in the internal ontology) http://HOST[:PORT]/ontology/0001/example/v2#ExampleThing (in the API v2 complex schema) http://HOST[:PORT]/ontology/0001/example/simple/v2#ExampleThing (in the API v2 simple schema)","title":"Ontology Entity IRIs"},{"location":"03-endpoints/api-v2/knora-iris/#shared-ontology-iris","text":"As explained in Shared Ontologies , a user-created ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators will not change it in ways that could affect other ontologies or data that are based on it. There is currently one project for shared ontologies: http://www.knora.org/ontology/knora-base#DefaultSharedOntologiesProject Its project code is 0000 . Additional projects for shared ontologies may be supported in future. The internal and external IRIs of shared ontologies always use the hostname api.knora.org , and have an additional segment, shared , after ontology . The project code can be omitted, in which case the default shared ontology project, 0000 , is assumed. The sample shared ontology, example-box , has these IRIs: http://www.knora.org/ontology/shared/example-box (internal) http://api.knora.org/ontology/shared/example-box/v2 (external, complex schema) http://api.knora.org/ontology/shared/example-box/simple/v2 (external, simple schema)","title":"Shared Ontology IRIs"},{"location":"03-endpoints/api-v2/knora-iris/#iris-for-data","text":"Knora generates IRIs for data that it creates in the triplestore. Each generated data IRI contains one or more UUID identifiers to make it unique. To keep data IRIs relatively short, each UUID is base64url-encoded , without padding; thus each UUID is a 22-character string. DSP-API supports UUID version 4 or 5. Data IRIs are not currently intended to be dereferenced as URLs. Instead, each Knora resource has a separate permalink . A Knora value does not have a stable IRI throughout its version history. Each time a new version of a value is made, the new version gets a new IRI. Therefore, it would not make sense to publish Knora value IRIs. When designing ontologies for Knora projects, keep in mind that if you want something be directly citable, it needs to be a resource, not a value. The formats of generated data IRIs for different types of objects are as follows: Resource: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID . Value: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID/values/VALUE_UUID Standoff tag: http://rdfh.ch/PROJECT_SHORTCODE/RESOURCE_UUID/values/VALUE_UUID/STANDOFF_UUID XML-to-standoff mapping: http://rdfh.ch/projects/PROJECT_SHORTCODE/mappings/MAPPING_NAME XML-to-standoff mapping element: http://rdfh.ch/projects/PROJECT_SHORTCODE/mappings/MAPPING_NAME/elements/MAPPING_ELEMENT_UUID Project: http://rdfh.ch/projects/PROJECT_UUID Group: http://rdfh.ch/groups/PROJECT_SHORTCODE/GROUP_UUID Permission: http://rdfh.ch/permissions/PROJECT_SHORTCODE/PERMISSION_UUID Lists: http://rdfh.ch/lists/PROJECT_SHORTCODE/LIST_UUID User: http://rdfh.ch/users/USER_UUID","title":"IRIs for Data"},{"location":"03-endpoints/api-v2/ontology-information/","text":"Querying, Creating, and Updating Ontologies Querying Ontology Information Before reading this document, you should have a basic understanding of DSP-API v2 external ontology schemas (see API Schema ). Each request returns a single RDF graph, which can be represented in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation (see Response Formats ). The response format uses prefixes to shorten IRIs, making them more human-readable. A client may wish to convert these to full IRIs for processing. This can be done with responses in JSON-LD by using a library that implements the JSON-LD API to compact the document with an empty JSON-LD @context . Querying Ontology Metadata Requests for ontology metadata can return information about more than one ontology, unlike other requests for ontology information. To get metadata about all ontologies: HTTP GET to http://host/v2/ontologies/metadata If you submit a project IRI in the X-Knora-Accept-Project header, only the ontologies for that project will be returned. The response is in the complex API v2 schema. Sample response: { \"@graph\": [ { \"knora-api:lastModificationDate\": { \"@value\": \"2017-12-19T15:23:42.166Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The anything ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/0001/anything/v2\" }, { \"knora-api:lastModificationDate\": { \"@value\": \"2022-03-23T07:14:17.445208Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The something ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/0001/something/v2\" }, { \"knora-api:lastModificationDate\": { \"@value\": \"2022-03-23T07:14:17.445208Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The images demo ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/00FF/images/v2\" }, { \"knora-api:lastModificationDate\": { \"@value\": \"2022-03-23T07:14:17.445208Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The BEOL ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/bL0y8GRuTUiFmvF1oXbeFQ\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/0801/beol/v2\" }, { \"knora-api:lastModificationDate\": { \"@value\": \"2022-03-23T07:14:17.445208Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The Biblio ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/bL0y8GRuTUiFmvF1oXbeFQ\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/0801/biblio/v2\" }, { \"knora-api:lastModificationDate\": { \"@value\": \"2022-03-23T07:14:17.445208Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The Newton-Project ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/bL0y8GRuTUiFmvF1oXbeFQ\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/0801/newton/v2\" }, { \"knora-api:lastModificationDate\": { \"@value\": \"2022-03-23T07:14:17.445208Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The incunabula ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/yISnUYe6SYmoyuqeMdW39w\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/0803/incunabula/v2\" }, { \"knora-api:lastModificationDate\": { \"@value\": \"2022-03-23T07:14:17.445208Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The dokubib ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/oIjhUsZmQLuJ0VMGvJ2pfg\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/0804/dokubib/v2\" }, { \"knora-api:lastModificationDate\": { \"@value\": \"2022-03-23T07:14:17.445208Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The Anton Webern project ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/NeWmPqGNQ5KVMAG6L8AjNA\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/08AE/webern/v2\" }, { \"rdfs:label\": \"The Knora admin ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://www.knora.org/ontology/knora-admin#SystemProject\" }, \"knora-api:isBuiltIn\": true, \"@type\": \"owl:Ontology\", \"@id\": \"http://api.knora.org/ontology/knora-admin/v2\" }, { \"rdfs:label\": \"The knora-api ontology in the complex schema\", \"knora-api:attachedToProject\": { \"@id\": \"http://www.knora.org/ontology/knora-admin#SystemProject\" }, \"knora-api:isBuiltIn\": true, \"@type\": \"owl:Ontology\", \"@id\": \"http://api.knora.org/ontology/knora-api/v2\" }, { \"rdfs:label\": \"The salsah-gui ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://www.knora.org/ontology/knora-admin#SystemProject\" }, \"knora-api:isBuiltIn\": true, \"@type\": \"owl:Ontology\", \"@id\": \"http://api.knora.org/ontology/salsah-gui/v2\" }, { \"rdfs:label\": \"The standoff ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://www.knora.org/ontology/knora-admin#SystemProject\" }, \"knora-api:isBuiltIn\": true, \"@type\": \"owl:Ontology\", \"@id\": \"http://api.knora.org/ontology/standoff/v2\" } ], \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\", \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"owl\": \"http://www.w3.org/2002/07/owl#\" } } To get metadata about the ontologies that belong to one or more particular projects: HTTP GET to http://host/v2/ontologies/metadata/PROJECT_IRI[/PROJECT_IRI...] The project IRIs must be URL-encoded. Example response for the anything test project (project IRI http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ ): { \"@id\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" }, \"knora-api:lastModificationDate\": \"2017-12-19T15:23:42.166Z\", \"rdfs:label\" : \"The anything ontology\", \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\" } } Querying an Ontology An ontology can be queried either by using an API route directly or by simply dereferencing the ontology IRI. The API route is as follows: HTTP GET to http://host/v2/ontologies/allentities/ONTOLOGY_IRI The ontology IRI must be URL-encoded, and may be in either the complex or the simple schema. The response will be in the same schema. For example, if the server is running on 0.0.0.0:3333 , you can request the knora-api ontology in the complex schema as follows: HTTP GET to http://0.0.0.0:3333/v2/ontologies/allentities/http%3A%2F%2Fapi.knora.org%2Fontology%2Fknora-api%2Fv2 By default, this returns the ontology in JSON-LD; to request Turtle or RDF/XML, add an HTTP Accept header (see Response Formats ). If the client dereferences a project-specific ontology IRI as a URL, the DSP-API server running on the hostname in the IRI will serve the ontology. For example, if the server is running on 0.0.0.0:3333 , the IRI http://0.0.0.0:3333/ontology/00FF/images/simple/v2 can be dereferenced to request the images sample ontology in the simple schema. If the client dereferences a built-in Knora ontology, such as http://api.knora.org/ontology/knora-api/simple/v2 , there must be a DSP-API server running at api.knora.org that can serve the ontology. The DaSCH intends to run such as server. For testing, you can configure your local /etc/hosts file to resolve api.knora.org as localhost . Differences Between Internal and External Ontologies The external ontologies used by DSP-API v2 are different to the internal ontologies that are actually stored in the triplestore (see API Schema ). In general, the external ontologies use simpler data structures, but they also provide additional information to make it easier for clients to use them. This is illustrated in the examples in the next sections. The internal predicates knora-base:subjectClassConstraint and knora-base:objectClassConstraint (see Constraints on the Types of Property Subjects and Objects ) are represented as knora-api:subjectType and knora-api:objectType in external ontologies. JSON-LD Representation of an Ontology in the Simple Schema The simple schema is suitable for client applications that need to read but not update data in Knora. For example, here is the response for the images sample ontology in the simple schema, http://0.0.0.0:3333/ontology/00FF/images/simple/v2 (simplified for clarity): { \"@id\" : \"http://0.0.0.0:3333/ontology/00FF/images/simple/v2\", \"@type\" : \"owl:Ontology\", \"rdfs:label\" : \"The images demo ontology\", \"@graph\" : [ { \"@id\" : \"images:bild\", \"@type\" : \"owl:Class\", \"knora-api:resourceIcon\" : \"bild.png\", \"rdfs:comment\" : \"An image of the demo image collection\", \"rdfs:label\" : \"Image\", \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:StillImageRepresentation\" }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStillImageFile\" } }, { \"@type\" : \"owl:Restriction\", \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:description\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:erfassungsdatum\" } }, { \"@type\" : \"owl:Restriction\", \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:urheber\" } } ] }, { \"@id\" : \"images:description\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : \"Description\", \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] }, { \"@id\" : \"images:erfassungsdatum\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"knora-api:Date\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : \"Date of acquisition\", \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/date\" } ] }, { \"@id\" : \"images:firstname\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"rdfs:comment\" : \"First name of a person\", \"rdfs:label\" : \"First name\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:lastname\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"rdfs:comment\" : \"Last name of a person\", \"rdfs:label\" : \"Name\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:person\", \"@type\" : \"owl:Class\", \"knora-api:resourceIcon\" : \"person.png\", \"rdfs:comment\" : \"Person\", \"rdfs:label\" : \"Person\", \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:Resource\" }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\", \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:lastname\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:firstname\" } } ] }, { \"@id\" : \"images:urheber\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:objectType\" : { \"@id\" : \"images:person\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\", \"rdfs:label\" : \"Creator\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkTo\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"images\" : \"http://0.0.0.0:3333/ontology/00FF/images/simple/v2#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/simple/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } The response format is an RDF graph. The top level object describes the ontology itself, providing its IRI (in the @id member) and its rdfs:label . The @graph member (see Named Graphs in the JSON-LD specification) contains an array of entities that belong to the ontology. In a class definition, cardinalities for properties of the class are represented as in OWL, using objects of type owl:Restriction . The supported cardinalities are the ones indicated in OWL Cardinalities . The class definitions include cardinalities that are directly defined on each class, as well as cardinalities inherited from base classes. For example, we can see cardinalities inherited from knora-api:Resource , such as knora-api:hasStandoffLinkTo and http://schema.org/name (which represents rdfs:label ). In the simple schema, Knora value properties can be datatype properties. The knora-base:objectType of a Knora value property such as images:description is a literal datatype, in this case xsd:string . Moreover, images:description is a subproperty of the standard property dcterms:description , whose object can be a literal value. A client that understands rdfs:subPropertyOf , and is familiar with dcterms:description , can then work with images:description on the basis of its knowledge about dcterms:description . By default, values for rdfs:label and rdfs:comment are returned only in the user's preferred language, or in the system default language. To obtain these values in all available languages, add the URL parameter ?allLanguages=true . For example, with this parameter, the definition of images:description becomes: { \"@id\" : \"images:description\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : [ { \"@language\" : \"en\", \"@value\" : \"Description\" }, { \"@language\" : \"de\", \"@value\" : \"Beschreibung\" }, { \"@language\" : \"fr\", \"@value\" : \"Description\" }, { \"@language\" : \"it\", \"@value\" : \"Descrizione\" } ], \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] } To find out more about the knora-api entities used in the response, the client can request the knora-api ontology in the simple schema: http://api.knora.org/ontology/knora-api/simple/v2 . For example, images:erfassungsdatum has a knora-api:objectType of knora-api:Date , which is a subtype of xsd:string with a Knora-specific, human-readable format. In the knora-api simple ontology, there is a definition of this type: { \"@id\" : \"http://api.knora.org/ontology/knora-api/simple/v2\", \"@type\" : \"owl:Ontology\", \"rdfs:label\" : \"The knora-api ontology in the simple schema\", \"@graph\" : [ { \"@id\" : \"knora-api:Date\", \"@type\" : \"rdfs:Datatype\", \"rdfs:comment\" : \"Represents a date as a period with different possible precisions.\", \"rdfs:label\" : \"Date literal\", \"rdfs:subClassOf\" : { \"@type\" : \"rdfs:Datatype\", \"owl:onDatatype\" : { \"@id\" : \"xsd:string\" }, \"owl:withRestrictions\" : { \"xsd:pattern\" : \"(GREGORIAN|JULIAN|ISLAMIC):\\\\d{1,4}(-\\\\d{1,2}(-\\\\d{1,2})?)?( BC| AD| BCE| CE)?(:\\\\d{1,4}(-\\\\d{1,2}(-\\\\d{1,2})?)?( BC| AD| BCE| CE)?)?\" } } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/simple/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } JSON-LD Representation of an Ontology in the Complex Schema The complex schema is suitable for client applications that need to update data in Knora. For example, here is the response for the images sample ontology in the complex schema, http://0.0.0.0:3333/ontology/00FF/images/v2 (simplified for clarity): { \"@id\" : \"http://0.0.0.0:3333/ontology/00FF/images/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA\" }, \"rdfs:label\" : \"The images demo ontology\", \"@graph\" : [ { \"@id\" : \"images:bild\", \"@type\" : \"owl:Class\", \"knora-api:canBeInstantiated\" : true, \"knora-api:isResourceClass\" : true, \"knora-api:resourceIcon\" : \"bild.png\", \"rdfs:comment\" : \"An image of the demo image collection\", \"rdfs:label\" : \"Image\", \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:StillImageRepresentation\" }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToProject\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToUser\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasPermissions\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkToValue\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStillImageFileValue\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 3, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:description\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 8, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:erfassungsdatum\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 12, \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:urheber\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 12, \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:urheberValue\" } } ] }, { \"@id\" : \"images:description\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : [ \"rows=10\", \"width=95%\", \"wrap=soft\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Textarea\" }, \"rdfs:label\" : \"Description\", \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] }, { \"@id\" : \"images:erfassungsdatum\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:DateValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Date\" }, \"rdfs:label\" : \"Date of acquisition\", \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/date\" } ] }, { \"@id\" : \"images:firstname\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"salsah-gui:guiAttribute\" : [ \"maxlength=32\", \"size=32\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:SimpleText\" }, \"rdfs:comment\" : \"First name of a person\", \"rdfs:label\" : \"First name\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:lastname\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"salsah-gui:guiAttribute\" : [ \"maxlength=32\", \"size=32\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:SimpleText\" }, \"rdfs:comment\" : \"Last name of a person\", \"rdfs:label\" : \"Name\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:person\", \"@type\" : \"owl:Class\", \"knora-api:canBeInstantiated\" : true, \"knora-api:isResourceClass\" : true, \"knora-api:resourceIcon\" : \"person.png\", \"rdfs:comment\" : \"Person\", \"rdfs:label\" : \"Person\", \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:Resource\" }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToProject\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToUser\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasPermissions\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkToValue\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 0, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:lastname\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 1, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:firstname\" } } ] }, { \"@id\" : \"images:urheber\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isLinkProperty\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"images:person\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : \"numprops=2\", \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Searchbox\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\", \"rdfs:label\" : \"Creator\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkTo\" } }, { \"@id\" : \"images:urheberValue\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isLinkValueProperty\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:LinkValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : \"numprops=2\", \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Searchbox\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\", \"rdfs:label\" : \"Creator\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkToValue\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"images\" : \"http://0.0.0.0:3333/ontology/00FF/images/v2#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } In the complex schema, all Knora value properties are object properties, whose objects are IRIs, each of which uniquely identifies a value that contains metadata and can potentially be edited. The knora-base:objectType of a Knora value property such as images:description is a Knora value class, in this case knora-api:TextValue . Similarly, images:erfassungsdatum has a knora-api:objectType of knora-api:DateValue , which has a more complex structure than the knora-api:Date datatype shown in the previous section. A client can find out more about these value classes by requesting the knora-api ontology in the complex schema, http://api.knora.org/ontology/knora-api/v2 . Moreover, additional information is provided in the complex schema, to help clients that wish to create or update resources and values. A Knora resource class that can be instantiated is identified with the boolean properties knora-api:isResourceClass and knora-api:canBeInstantiated , to distinguish it from built-in abstract classes. Knora resource properties whose values can be edited by clients are identified with knora-api:isResourceProperty and knora-api:isEditable , to distinguish them from properties whose values are maintained automatically by Knora. Link value properties are shown along with link properties, because a client that updates links will need the IRIs of their link values. The predicate salsah-gui:guiOrder tells a GUI client in what order to display the properties of a class, and the predicates salsah-gui:guiElement and salsah-gui:guiAttribute specify how to configure a GUI element for editing the value of a property. For more information on the salsah-gui ontology, see The SALSAH GUI Ontology . Ontology Updates The ontology update API must ensure that the ontologies it creates are valid and consistent, and that existing data is not invalidated by a change to an ontology. To make this easier to enforce, the ontology update API allows only one entity to be created or modified at a time. It is not possible to submit an entire ontology all at once. Each update request is a JSON-LD document providing only the information that is relevant to the update. Moreover, the API enforces the following rules: An entity (i.e. a class or property) cannot be referred to until it has been created. An entity cannot be modified or deleted if it is used in data, except for changes to its rdfs:label or rdfs:comment . An entity cannot be modified if another entity refers to it, with one exception: a knora-api:subjectType or knora-api:objectType that refers to a class will not prevent the class's cardinalities from being modified. Because of these rules, some operations have to be done in a specific order: Properties have to be defined before they can be used in the cardinalities of a class, but a property's knora-api:subjectType cannot refer to a class that does not yet exist. The recommended approach is to first create a class with no cardinalities, then create the properties that it needs, then add cardinalities for those properties to the class. To delete a class along with its properties, the client must first remove the cardinalities from the class, then delete the property definitions, then delete the class definition. When changing an existing ontology, the client must always supply the ontology's knora-api:lastModificationDate , which is returned in the response to each update or when querying the ontology . If user A attempts to update an ontology, but user B has already updated it since the last time user A received the ontology's knora-api:lastModificationDate , user A's update will be rejected with an HTTP 409 Conflict error. This means that it is possible for two different users to work concurrently on the same ontology, but this is discouraged since it is likely to lead to confusion. An ontology can be created or updated only by a system administrator, or by a project administrator in the ontology's project. Ontology updates always use the complex schema. Creating a New Ontology An ontology is always created within a particular project. HTTP POST to http://host/v2/ontologies { \"knora-api:ontologyName\" : \"ONTOLOGY_NAME\", \"knora-api:attachedToProject\" : { \"@id\" : \"PROJECT_IRI\" }, \"rdfs:label\" : \"ONTOLOGY_NAME\", \"@context\" : { \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The ontology name must follow the rules given in Knora IRIs . The ontology metadata can have an optional comment given in the request body as: \"rdfs:comment\": \"some comment\", If the ontology is to be shared by multiple projects, it must be created in the default shared ontologies project, http://www.knora.org/ontology/knora-base#DefaultSharedOntologiesProject , and the request must have this additional boolean property: \"knora-api:isShared\" : true See Shared Ontologies for details about shared ontologies. A successful response will be a JSON-LD document providing only the ontology's metadata, which includes the ontology's IRI. When the client makes further requests to create entities (classes and properties) in the ontology, it must construct entity IRIs by concatenating the ontology IRI, a # character, and the entity name. An entity name must be a valid XML NCName . Changing an Ontology's Metadata One can modify an ontology's metadata by updating its rdfs:label or rdfs:comment or both. The example below shows the request for changing the label of an ontology. HTTP PUT to http://host/v2/ontologies/metadata { \"@id\" : \"ONTOLOGY_IRI\", \"rdfs:label\" : \"NEW_ONTOLOGY_LABEL\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@context\" : { \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Similarly, a user can change an ontology's existing comment or add one by specifying the new comment in the request body: { \"@id\" : \"ONTOLOGY_IRI\", \"rdfs:comment\" : \"NEW_ONTOLOGY_COMMENT\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@context\" : { \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The request body can also contain a new label and a new comment for the ontology's metadata. A successful response will be a JSON-LD document providing only the ontology's metadata. Deleting an Ontology's comment HTTP DELETE to http://host/v2/ontologies/comment/ONTOLOGY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The ontology IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document containing the ontology's updated metadata. Deleting an Ontology An ontology can be deleted only if it is not used in data. HTTP DELETE to http://host/v2/ontologies/ONTOLOGY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The ontology IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document containing a confirmation message. To check whether an ontology can be deleted: HTTP GET to http://host/v2/ontologies/candeleteontology/ONTOLOGY_IRI The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } } Creating a Class Without Cardinalities HTTP POST to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" }, \"rdfs:subClassOf\" : { \"@id\" : \"BASE_CLASS_IRI\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. At least one base class must be provided, which can be knora-api:Resource or any of its subclasses. A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). Creating a Class With Cardinalities This can work if the new class will have cardinalities for properties that have no knora-api:subjectType , or if the new class will be a subclass of their knora-api:subjectType . HTTP POST to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" }, \"rdfs:subClassOf\" : [ { \"@id\" : \"BASE_CLASS_IRI\" }, { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" } } ] } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. At least one base class must be provided. When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). Changing the Labels of a Class This operation is permitted even if the class is used in data. HTTP PUT to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. The submitted labels will replace the existing ones. Changing the Comments of a Class This operation is permitted even if the class is used in data. HTTP PUT to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:comment must be submitted in at least one language, either as an object or as an array of objects. The submitted comments will replace the existing ones. Deleting the Comments of a Class This operation is permitted even if the class is used in data. HTTP DELETE to http://host/v2/ontologies/classes/comment/CLASS_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The class IRI and the ontology's last modification date must be URL-encoded. All values i.e. all languages for rdfs:comment are deleted. A successful response will be a JSON-LD document providing the class definition. Creating a Property HTTP POST to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:subjectType\" : { \"@id\" : \"SUBJECT_TYPE\" }, \"knora-api:objectType\" : { \"@id\" : \"OBJECT_TYPE\" }, \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" }, \"rdfs:subPropertyOf\" : { \"@id\" : \"BASE_PROPERTY_IRI\" }, \"salsah-gui:guiElement\" : { \"@id\" : \"GUI_ELEMENT_IRI\" }, \"salsah-gui:guiAttribute\" : [ \"GUI_ATTRIBUTE\" ] } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. At least one base property must be provided, which can be knora-api:hasValue , knora-api:hasLinkTo , or any of their subproperties, with the exception of file properties (subproperties of knora-api:hasFileValue ) and link value properties (subproperties of knora-api:hasLinkToValue ). If the property is a link property, the corresponding link value property (see Links Between Resources ) will automatically be created. The property definition must specify its knora-api:objectType . If the new property is a subproperty of knora-api:hasValue , its knora-api:objectType must be one of the built-in subclasses of knora-api:Value , which are defined in the knora-api ontology in the complex schema. If the new property is a subproperty of knora-base:hasLinkTo , its knora-api:objectType must be a subclass of knora-api:Resource . To improve consistency checking, it is recommended, but not required, to provide knora-api:subjectType , which must be a subclass of knora-api:Resource . The predicates salsah-gui:guiElement and salsah-gui:guiAttribute are optional. If provided, the object of guiElement must be one of the OWL named individuals defined in The SALSAH GUI Ontology . Some GUI elements take required or optional attributes, which are provided as objects of salsah-gui:guiAttribute ; see The SALSAH GUI Ontology for details. A successful response will be a JSON-LD document providing the new property definition (but not any of the other entities in the ontology). Changing the Labels of a Property This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\", \"@type\" : \"owl:ObjectProperty\", \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. Changing the Comments of a Property This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\", \"@type\" : \"owl:ObjectProperty\", \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:comment must be submitted in at least one language, either as an object or as an array of objects. Deleting the Comments of a Property This operation is permitted even if the property is used in data. HTTP DELETE to http://host/v2/ontologies/properties/comment/PROPERTY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The property IRI and the ontology's last modification date must be URL-encoded. All values i.e. all languages for rdfs:comment are deleted. If the property is a link property, the rdfs:comment of its corresponding link value property will automatically be deleted. A successful response will be a JSON-LD document providing the property definition. Changing the GUI Element and GUI Attributes of a Property This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties/guielement { \"@id\": \"ONTOLOGY_IRI\", \"@type\": \"owl:Ontology\", \"knora-api:lastModificationDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\": [ { \"@id\": \"PROPERTY_IRI\", \"@type\": \"owl:ObjectProperty\", \"salsah-gui:guiElement\": { \"@id\": \"salsah-gui:Textarea\" }, \"salsah-gui:guiAttribute\": [ \"cols=80\", \"rows=24\" ] } ], \"@context\": { \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"salsah-gui\": \"http://api.knora.org/ontology/salsah-gui/v2#\", \"owl\": \"http://www.w3.org/2002/07/owl#\", \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\" } } To remove the values of salsah-gui:guiElement and salsah-gui:guiAttribute from the property definition, submit the request without those predicates. Adding Cardinalities to a Class If the class (or any of its sub-classes) is used in data, it is not allowed to add cardinalities owl:minCardinality greater than 0 or owl:cardinality 1 to the class. HTTP POST to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:subClassOf\" : { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } At least one cardinality must be submitted. OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). Replacing the Cardinalities of a Class This removes all the cardinalities from the class and replaces them with the submitted cardinalities. If no cardinalities are submitted (i.e. the request contains no rdfs:subClassOf ), the class is left with no cardinalities. This operation is not permitted if the class is used in data, or if it has a subclass. HTTP PUT to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:subClassOf\" : { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). To check whether a class's cardinalities can be replaced: HTTP GET to http://host/v2/ontologies/canreplacecardinalities/CLASS_IRI The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } } Delete a single cardinality from a class If a class is used in data, it is only allowed to delete a cardinality, if the property a cardinality refers to, is not used inside the data. Also, the property isn't allowed to be used inside the data in any subclasses of this class. HTTP PATCH to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:subClassOf\" : { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). To check whether a class's cardinality can be deleted: HTTP POST to http://host/v2/ontologies/candeletecardinalities The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } } Changing the GUI Order of Cardinalities To change the GUI order of one or more cardinalities in a class: HTTP PUT to http://host/v2/ontologies/guiorder This can be done even if the class is used in data. The request body includes the cardinalities whose GUI order should be changed, using the predicate salsah-gui:guiOrder , whose object is an integer: { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:subClassOf\" : { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" }, \"salsah-gui:guiOrder\": \"GUI_ORDER_VALUE\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Only the cardinalities whose GUI order is to be changed need to be included in the request. The OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE are ignored; only the GUI_ORDER_VALUE is changed. Deleting a Property A property can be deleted only if no other ontology entity refers to it, and if it is not used in data. HTTP DELETE to http://host/v2/ontologies/properties/PROPERTY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The property IRI and the ontology's last modification date must be URL-encoded. If the property is a link property, the corresponding link value property (see Links Between Resources ) will automatically be deleted. A successful response will be a JSON-LD document providing only the ontology's metadata. To check whether a property can be deleted: HTTP GET to http://host/v2/ontologies/candeleteproperty/PROPERTY_IRI The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } } Deleting a Class A class can be deleted only if no other ontology entity refers to it, and if it is not used in data. HTTP DELETE to http://host/v2/ontologies/classes/CLASS_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The class IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document providing only the ontology's metadata. To check whether a class can be deleted: HTTP GET to http://host/v2/ontologies/candeleteclass/CLASS_IRI The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Querying, Creating, and Updating Ontologies"},{"location":"03-endpoints/api-v2/ontology-information/#querying-creating-and-updating-ontologies","text":"","title":"Querying, Creating, and Updating Ontologies"},{"location":"03-endpoints/api-v2/ontology-information/#querying-ontology-information","text":"Before reading this document, you should have a basic understanding of DSP-API v2 external ontology schemas (see API Schema ). Each request returns a single RDF graph, which can be represented in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation (see Response Formats ). The response format uses prefixes to shorten IRIs, making them more human-readable. A client may wish to convert these to full IRIs for processing. This can be done with responses in JSON-LD by using a library that implements the JSON-LD API to compact the document with an empty JSON-LD @context .","title":"Querying Ontology Information"},{"location":"03-endpoints/api-v2/ontology-information/#querying-ontology-metadata","text":"Requests for ontology metadata can return information about more than one ontology, unlike other requests for ontology information. To get metadata about all ontologies: HTTP GET to http://host/v2/ontologies/metadata If you submit a project IRI in the X-Knora-Accept-Project header, only the ontologies for that project will be returned. The response is in the complex API v2 schema. Sample response: { \"@graph\": [ { \"knora-api:lastModificationDate\": { \"@value\": \"2017-12-19T15:23:42.166Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The anything ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/0001/anything/v2\" }, { \"knora-api:lastModificationDate\": { \"@value\": \"2022-03-23T07:14:17.445208Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The something ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/0001/something/v2\" }, { \"knora-api:lastModificationDate\": { \"@value\": \"2022-03-23T07:14:17.445208Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The images demo ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/00FF/images/v2\" }, { \"knora-api:lastModificationDate\": { \"@value\": \"2022-03-23T07:14:17.445208Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The BEOL ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/bL0y8GRuTUiFmvF1oXbeFQ\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/0801/beol/v2\" }, { \"knora-api:lastModificationDate\": { \"@value\": \"2022-03-23T07:14:17.445208Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The Biblio ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/bL0y8GRuTUiFmvF1oXbeFQ\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/0801/biblio/v2\" }, { \"knora-api:lastModificationDate\": { \"@value\": \"2022-03-23T07:14:17.445208Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The Newton-Project ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/bL0y8GRuTUiFmvF1oXbeFQ\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/0801/newton/v2\" }, { \"knora-api:lastModificationDate\": { \"@value\": \"2022-03-23T07:14:17.445208Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The incunabula ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/yISnUYe6SYmoyuqeMdW39w\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/0803/incunabula/v2\" }, { \"knora-api:lastModificationDate\": { \"@value\": \"2022-03-23T07:14:17.445208Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The dokubib ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/oIjhUsZmQLuJ0VMGvJ2pfg\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/0804/dokubib/v2\" }, { \"knora-api:lastModificationDate\": { \"@value\": \"2022-03-23T07:14:17.445208Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"rdfs:label\": \"The Anton Webern project ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/NeWmPqGNQ5KVMAG6L8AjNA\" }, \"@type\": \"owl:Ontology\", \"@id\": \"http://0.0.0.0:3333/ontology/08AE/webern/v2\" }, { \"rdfs:label\": \"The Knora admin ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://www.knora.org/ontology/knora-admin#SystemProject\" }, \"knora-api:isBuiltIn\": true, \"@type\": \"owl:Ontology\", \"@id\": \"http://api.knora.org/ontology/knora-admin/v2\" }, { \"rdfs:label\": \"The knora-api ontology in the complex schema\", \"knora-api:attachedToProject\": { \"@id\": \"http://www.knora.org/ontology/knora-admin#SystemProject\" }, \"knora-api:isBuiltIn\": true, \"@type\": \"owl:Ontology\", \"@id\": \"http://api.knora.org/ontology/knora-api/v2\" }, { \"rdfs:label\": \"The salsah-gui ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://www.knora.org/ontology/knora-admin#SystemProject\" }, \"knora-api:isBuiltIn\": true, \"@type\": \"owl:Ontology\", \"@id\": \"http://api.knora.org/ontology/salsah-gui/v2\" }, { \"rdfs:label\": \"The standoff ontology\", \"knora-api:attachedToProject\": { \"@id\": \"http://www.knora.org/ontology/knora-admin#SystemProject\" }, \"knora-api:isBuiltIn\": true, \"@type\": \"owl:Ontology\", \"@id\": \"http://api.knora.org/ontology/standoff/v2\" } ], \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\", \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"owl\": \"http://www.w3.org/2002/07/owl#\" } } To get metadata about the ontologies that belong to one or more particular projects: HTTP GET to http://host/v2/ontologies/metadata/PROJECT_IRI[/PROJECT_IRI...] The project IRIs must be URL-encoded. Example response for the anything test project (project IRI http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ ): { \"@id\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" }, \"knora-api:lastModificationDate\": \"2017-12-19T15:23:42.166Z\", \"rdfs:label\" : \"The anything ontology\", \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\" } }","title":"Querying Ontology Metadata"},{"location":"03-endpoints/api-v2/ontology-information/#querying-an-ontology","text":"An ontology can be queried either by using an API route directly or by simply dereferencing the ontology IRI. The API route is as follows: HTTP GET to http://host/v2/ontologies/allentities/ONTOLOGY_IRI The ontology IRI must be URL-encoded, and may be in either the complex or the simple schema. The response will be in the same schema. For example, if the server is running on 0.0.0.0:3333 , you can request the knora-api ontology in the complex schema as follows: HTTP GET to http://0.0.0.0:3333/v2/ontologies/allentities/http%3A%2F%2Fapi.knora.org%2Fontology%2Fknora-api%2Fv2 By default, this returns the ontology in JSON-LD; to request Turtle or RDF/XML, add an HTTP Accept header (see Response Formats ). If the client dereferences a project-specific ontology IRI as a URL, the DSP-API server running on the hostname in the IRI will serve the ontology. For example, if the server is running on 0.0.0.0:3333 , the IRI http://0.0.0.0:3333/ontology/00FF/images/simple/v2 can be dereferenced to request the images sample ontology in the simple schema. If the client dereferences a built-in Knora ontology, such as http://api.knora.org/ontology/knora-api/simple/v2 , there must be a DSP-API server running at api.knora.org that can serve the ontology. The DaSCH intends to run such as server. For testing, you can configure your local /etc/hosts file to resolve api.knora.org as localhost .","title":"Querying an Ontology"},{"location":"03-endpoints/api-v2/ontology-information/#differences-between-internal-and-external-ontologies","text":"The external ontologies used by DSP-API v2 are different to the internal ontologies that are actually stored in the triplestore (see API Schema ). In general, the external ontologies use simpler data structures, but they also provide additional information to make it easier for clients to use them. This is illustrated in the examples in the next sections. The internal predicates knora-base:subjectClassConstraint and knora-base:objectClassConstraint (see Constraints on the Types of Property Subjects and Objects ) are represented as knora-api:subjectType and knora-api:objectType in external ontologies.","title":"Differences Between Internal and External Ontologies"},{"location":"03-endpoints/api-v2/ontology-information/#json-ld-representation-of-an-ontology-in-the-simple-schema","text":"The simple schema is suitable for client applications that need to read but not update data in Knora. For example, here is the response for the images sample ontology in the simple schema, http://0.0.0.0:3333/ontology/00FF/images/simple/v2 (simplified for clarity): { \"@id\" : \"http://0.0.0.0:3333/ontology/00FF/images/simple/v2\", \"@type\" : \"owl:Ontology\", \"rdfs:label\" : \"The images demo ontology\", \"@graph\" : [ { \"@id\" : \"images:bild\", \"@type\" : \"owl:Class\", \"knora-api:resourceIcon\" : \"bild.png\", \"rdfs:comment\" : \"An image of the demo image collection\", \"rdfs:label\" : \"Image\", \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:StillImageRepresentation\" }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStillImageFile\" } }, { \"@type\" : \"owl:Restriction\", \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:description\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:erfassungsdatum\" } }, { \"@type\" : \"owl:Restriction\", \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:urheber\" } } ] }, { \"@id\" : \"images:description\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : \"Description\", \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] }, { \"@id\" : \"images:erfassungsdatum\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"knora-api:Date\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : \"Date of acquisition\", \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/date\" } ] }, { \"@id\" : \"images:firstname\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"rdfs:comment\" : \"First name of a person\", \"rdfs:label\" : \"First name\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:lastname\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"rdfs:comment\" : \"Last name of a person\", \"rdfs:label\" : \"Name\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:person\", \"@type\" : \"owl:Class\", \"knora-api:resourceIcon\" : \"person.png\", \"rdfs:comment\" : \"Person\", \"rdfs:label\" : \"Person\", \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:Resource\" }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\", \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\", \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:lastname\" } }, { \"@type\" : \"owl:Restriction\", \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:firstname\" } } ] }, { \"@id\" : \"images:urheber\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:objectType\" : { \"@id\" : \"images:person\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\", \"rdfs:label\" : \"Creator\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkTo\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"images\" : \"http://0.0.0.0:3333/ontology/00FF/images/simple/v2#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/simple/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } The response format is an RDF graph. The top level object describes the ontology itself, providing its IRI (in the @id member) and its rdfs:label . The @graph member (see Named Graphs in the JSON-LD specification) contains an array of entities that belong to the ontology. In a class definition, cardinalities for properties of the class are represented as in OWL, using objects of type owl:Restriction . The supported cardinalities are the ones indicated in OWL Cardinalities . The class definitions include cardinalities that are directly defined on each class, as well as cardinalities inherited from base classes. For example, we can see cardinalities inherited from knora-api:Resource , such as knora-api:hasStandoffLinkTo and http://schema.org/name (which represents rdfs:label ). In the simple schema, Knora value properties can be datatype properties. The knora-base:objectType of a Knora value property such as images:description is a literal datatype, in this case xsd:string . Moreover, images:description is a subproperty of the standard property dcterms:description , whose object can be a literal value. A client that understands rdfs:subPropertyOf , and is familiar with dcterms:description , can then work with images:description on the basis of its knowledge about dcterms:description . By default, values for rdfs:label and rdfs:comment are returned only in the user's preferred language, or in the system default language. To obtain these values in all available languages, add the URL parameter ?allLanguages=true . For example, with this parameter, the definition of images:description becomes: { \"@id\" : \"images:description\", \"@type\" : \"owl:DatatypeProperty\", \"knora-api:objectType\" : { \"@id\" : \"xsd:string\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"rdfs:label\" : [ { \"@language\" : \"en\", \"@value\" : \"Description\" }, { \"@language\" : \"de\", \"@value\" : \"Beschreibung\" }, { \"@language\" : \"fr\", \"@value\" : \"Description\" }, { \"@language\" : \"it\", \"@value\" : \"Descrizione\" } ], \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] } To find out more about the knora-api entities used in the response, the client can request the knora-api ontology in the simple schema: http://api.knora.org/ontology/knora-api/simple/v2 . For example, images:erfassungsdatum has a knora-api:objectType of knora-api:Date , which is a subtype of xsd:string with a Knora-specific, human-readable format. In the knora-api simple ontology, there is a definition of this type: { \"@id\" : \"http://api.knora.org/ontology/knora-api/simple/v2\", \"@type\" : \"owl:Ontology\", \"rdfs:label\" : \"The knora-api ontology in the simple schema\", \"@graph\" : [ { \"@id\" : \"knora-api:Date\", \"@type\" : \"rdfs:Datatype\", \"rdfs:comment\" : \"Represents a date as a period with different possible precisions.\", \"rdfs:label\" : \"Date literal\", \"rdfs:subClassOf\" : { \"@type\" : \"rdfs:Datatype\", \"owl:onDatatype\" : { \"@id\" : \"xsd:string\" }, \"owl:withRestrictions\" : { \"xsd:pattern\" : \"(GREGORIAN|JULIAN|ISLAMIC):\\\\d{1,4}(-\\\\d{1,2}(-\\\\d{1,2})?)?( BC| AD| BCE| CE)?(:\\\\d{1,4}(-\\\\d{1,2}(-\\\\d{1,2})?)?( BC| AD| BCE| CE)?)?\" } } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/simple/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } }","title":"JSON-LD Representation of an Ontology in the Simple Schema"},{"location":"03-endpoints/api-v2/ontology-information/#json-ld-representation-of-an-ontology-in-the-complex-schema","text":"The complex schema is suitable for client applications that need to update data in Knora. For example, here is the response for the images sample ontology in the complex schema, http://0.0.0.0:3333/ontology/00FF/images/v2 (simplified for clarity): { \"@id\" : \"http://0.0.0.0:3333/ontology/00FF/images/v2\", \"@type\" : \"owl:Ontology\", \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA\" }, \"rdfs:label\" : \"The images demo ontology\", \"@graph\" : [ { \"@id\" : \"images:bild\", \"@type\" : \"owl:Class\", \"knora-api:canBeInstantiated\" : true, \"knora-api:isResourceClass\" : true, \"knora-api:resourceIcon\" : \"bild.png\", \"rdfs:comment\" : \"An image of the demo image collection\", \"rdfs:label\" : \"Image\", \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:StillImageRepresentation\" }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToProject\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToUser\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasPermissions\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkToValue\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStillImageFileValue\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 3, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:description\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 8, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:erfassungsdatum\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 12, \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:urheber\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 12, \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:urheberValue\" } } ] }, { \"@id\" : \"images:description\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : [ \"rows=10\", \"width=95%\", \"wrap=soft\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Textarea\" }, \"rdfs:label\" : \"Description\", \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/description\" } ] }, { \"@id\" : \"images:erfassungsdatum\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:DateValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Date\" }, \"rdfs:label\" : \"Date of acquisition\", \"rdfs:subPropertyOf\" : [ { \"@id\" : \"knora-api:hasValue\" }, { \"@id\" : \"http://purl.org/dc/terms/date\" } ] }, { \"@id\" : \"images:firstname\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"salsah-gui:guiAttribute\" : [ \"maxlength=32\", \"size=32\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:SimpleText\" }, \"rdfs:comment\" : \"First name of a person\", \"rdfs:label\" : \"First name\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:lastname\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:TextValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:person\" }, \"salsah-gui:guiAttribute\" : [ \"maxlength=32\", \"size=32\" ], \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:SimpleText\" }, \"rdfs:comment\" : \"Last name of a person\", \"rdfs:label\" : \"Name\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasValue\" } }, { \"@id\" : \"images:person\", \"@type\" : \"owl:Class\", \"knora-api:canBeInstantiated\" : true, \"knora-api:isResourceClass\" : true, \"knora-api:resourceIcon\" : \"person.png\", \"rdfs:comment\" : \"Person\", \"rdfs:label\" : \"Person\", \"rdfs:subClassOf\" : [ { \"@id\" : \"knora-api:Resource\" }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToProject\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:attachedToUser\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:creationDate\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasIncomingLink\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasPermissions\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkTo\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:minCardinality\" : 0, \"owl:onProperty\" : { \"@id\" : \"knora-api:hasStandoffLinkToValue\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:maxCardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"knora-api:lastModificationDate\" } }, { \"@type\" : \"owl:Restriction\", \"knora-api:isInherited\" : true, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"rdfs:label\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 0, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:lastname\" } }, { \"@type\" : \"owl:Restriction\", \"salsah-gui:guiOrder\" : 1, \"owl:cardinality\" : 1, \"owl:onProperty\" : { \"@id\" : \"images:firstname\" } } ] }, { \"@id\" : \"images:urheber\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isLinkProperty\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"images:person\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : \"numprops=2\", \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Searchbox\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\", \"rdfs:label\" : \"Creator\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkTo\" } }, { \"@id\" : \"images:urheberValue\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:isEditable\" : true, \"knora-api:isLinkValueProperty\" : true, \"knora-api:isResourceProperty\" : true, \"knora-api:objectType\" : { \"@id\" : \"knora-api:LinkValue\" }, \"knora-api:subjectType\" : { \"@id\" : \"images:bild\" }, \"salsah-gui:guiAttribute\" : \"numprops=2\", \"salsah-gui:guiElement\" : { \"@id\" : \"salsah-gui:Searchbox\" }, \"rdfs:comment\" : \"An entity primarily responsible for making the resource. Examples of a Creator include a person, an organization, or a service. Typically, the name of a Creator should be used to indicate the entity.\", \"rdfs:label\" : \"Creator\", \"rdfs:subPropertyOf\" : { \"@id\" : \"knora-api:hasLinkToValue\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"images\" : \"http://0.0.0.0:3333/ontology/00FF/images/v2#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } In the complex schema, all Knora value properties are object properties, whose objects are IRIs, each of which uniquely identifies a value that contains metadata and can potentially be edited. The knora-base:objectType of a Knora value property such as images:description is a Knora value class, in this case knora-api:TextValue . Similarly, images:erfassungsdatum has a knora-api:objectType of knora-api:DateValue , which has a more complex structure than the knora-api:Date datatype shown in the previous section. A client can find out more about these value classes by requesting the knora-api ontology in the complex schema, http://api.knora.org/ontology/knora-api/v2 . Moreover, additional information is provided in the complex schema, to help clients that wish to create or update resources and values. A Knora resource class that can be instantiated is identified with the boolean properties knora-api:isResourceClass and knora-api:canBeInstantiated , to distinguish it from built-in abstract classes. Knora resource properties whose values can be edited by clients are identified with knora-api:isResourceProperty and knora-api:isEditable , to distinguish them from properties whose values are maintained automatically by Knora. Link value properties are shown along with link properties, because a client that updates links will need the IRIs of their link values. The predicate salsah-gui:guiOrder tells a GUI client in what order to display the properties of a class, and the predicates salsah-gui:guiElement and salsah-gui:guiAttribute specify how to configure a GUI element for editing the value of a property. For more information on the salsah-gui ontology, see The SALSAH GUI Ontology .","title":"JSON-LD Representation of an Ontology in the Complex Schema"},{"location":"03-endpoints/api-v2/ontology-information/#ontology-updates","text":"The ontology update API must ensure that the ontologies it creates are valid and consistent, and that existing data is not invalidated by a change to an ontology. To make this easier to enforce, the ontology update API allows only one entity to be created or modified at a time. It is not possible to submit an entire ontology all at once. Each update request is a JSON-LD document providing only the information that is relevant to the update. Moreover, the API enforces the following rules: An entity (i.e. a class or property) cannot be referred to until it has been created. An entity cannot be modified or deleted if it is used in data, except for changes to its rdfs:label or rdfs:comment . An entity cannot be modified if another entity refers to it, with one exception: a knora-api:subjectType or knora-api:objectType that refers to a class will not prevent the class's cardinalities from being modified. Because of these rules, some operations have to be done in a specific order: Properties have to be defined before they can be used in the cardinalities of a class, but a property's knora-api:subjectType cannot refer to a class that does not yet exist. The recommended approach is to first create a class with no cardinalities, then create the properties that it needs, then add cardinalities for those properties to the class. To delete a class along with its properties, the client must first remove the cardinalities from the class, then delete the property definitions, then delete the class definition. When changing an existing ontology, the client must always supply the ontology's knora-api:lastModificationDate , which is returned in the response to each update or when querying the ontology . If user A attempts to update an ontology, but user B has already updated it since the last time user A received the ontology's knora-api:lastModificationDate , user A's update will be rejected with an HTTP 409 Conflict error. This means that it is possible for two different users to work concurrently on the same ontology, but this is discouraged since it is likely to lead to confusion. An ontology can be created or updated only by a system administrator, or by a project administrator in the ontology's project. Ontology updates always use the complex schema.","title":"Ontology Updates"},{"location":"03-endpoints/api-v2/ontology-information/#creating-a-new-ontology","text":"An ontology is always created within a particular project. HTTP POST to http://host/v2/ontologies { \"knora-api:ontologyName\" : \"ONTOLOGY_NAME\", \"knora-api:attachedToProject\" : { \"@id\" : \"PROJECT_IRI\" }, \"rdfs:label\" : \"ONTOLOGY_NAME\", \"@context\" : { \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The ontology name must follow the rules given in Knora IRIs . The ontology metadata can have an optional comment given in the request body as: \"rdfs:comment\": \"some comment\", If the ontology is to be shared by multiple projects, it must be created in the default shared ontologies project, http://www.knora.org/ontology/knora-base#DefaultSharedOntologiesProject , and the request must have this additional boolean property: \"knora-api:isShared\" : true See Shared Ontologies for details about shared ontologies. A successful response will be a JSON-LD document providing only the ontology's metadata, which includes the ontology's IRI. When the client makes further requests to create entities (classes and properties) in the ontology, it must construct entity IRIs by concatenating the ontology IRI, a # character, and the entity name. An entity name must be a valid XML NCName .","title":"Creating a New Ontology"},{"location":"03-endpoints/api-v2/ontology-information/#changing-an-ontologys-metadata","text":"One can modify an ontology's metadata by updating its rdfs:label or rdfs:comment or both. The example below shows the request for changing the label of an ontology. HTTP PUT to http://host/v2/ontologies/metadata { \"@id\" : \"ONTOLOGY_IRI\", \"rdfs:label\" : \"NEW_ONTOLOGY_LABEL\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@context\" : { \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Similarly, a user can change an ontology's existing comment or add one by specifying the new comment in the request body: { \"@id\" : \"ONTOLOGY_IRI\", \"rdfs:comment\" : \"NEW_ONTOLOGY_COMMENT\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@context\" : { \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The request body can also contain a new label and a new comment for the ontology's metadata. A successful response will be a JSON-LD document providing only the ontology's metadata.","title":"Changing an Ontology's Metadata"},{"location":"03-endpoints/api-v2/ontology-information/#deleting-an-ontologys-comment","text":"HTTP DELETE to http://host/v2/ontologies/comment/ONTOLOGY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The ontology IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document containing the ontology's updated metadata.","title":"Deleting an Ontology's comment"},{"location":"03-endpoints/api-v2/ontology-information/#deleting-an-ontology","text":"An ontology can be deleted only if it is not used in data. HTTP DELETE to http://host/v2/ontologies/ONTOLOGY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The ontology IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document containing a confirmation message. To check whether an ontology can be deleted: HTTP GET to http://host/v2/ontologies/candeleteontology/ONTOLOGY_IRI The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Deleting an Ontology"},{"location":"03-endpoints/api-v2/ontology-information/#creating-a-class-without-cardinalities","text":"HTTP POST to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" }, \"rdfs:subClassOf\" : { \"@id\" : \"BASE_CLASS_IRI\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. At least one base class must be provided, which can be knora-api:Resource or any of its subclasses. A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology).","title":"Creating a Class Without Cardinalities"},{"location":"03-endpoints/api-v2/ontology-information/#creating-a-class-with-cardinalities","text":"This can work if the new class will have cardinalities for properties that have no knora-api:subjectType , or if the new class will be a subclass of their knora-api:subjectType . HTTP POST to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" }, \"rdfs:subClassOf\" : [ { \"@id\" : \"BASE_CLASS_IRI\" }, { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" } } ] } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. At least one base class must be provided. When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology).","title":"Creating a Class With Cardinalities"},{"location":"03-endpoints/api-v2/ontology-information/#changing-the-labels-of-a-class","text":"This operation is permitted even if the class is used in data. HTTP PUT to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. The submitted labels will replace the existing ones.","title":"Changing the Labels of a Class"},{"location":"03-endpoints/api-v2/ontology-information/#changing-the-comments-of-a-class","text":"This operation is permitted even if the class is used in data. HTTP PUT to http://host/v2/ontologies/classes { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:comment must be submitted in at least one language, either as an object or as an array of objects. The submitted comments will replace the existing ones.","title":"Changing the Comments of a Class"},{"location":"03-endpoints/api-v2/ontology-information/#deleting-the-comments-of-a-class","text":"This operation is permitted even if the class is used in data. HTTP DELETE to http://host/v2/ontologies/classes/comment/CLASS_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The class IRI and the ontology's last modification date must be URL-encoded. All values i.e. all languages for rdfs:comment are deleted. A successful response will be a JSON-LD document providing the class definition.","title":"Deleting the Comments of a Class"},{"location":"03-endpoints/api-v2/ontology-information/#creating-a-property","text":"HTTP POST to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\", \"@type\" : \"owl:ObjectProperty\", \"knora-api:subjectType\" : { \"@id\" : \"SUBJECT_TYPE\" }, \"knora-api:objectType\" : { \"@id\" : \"OBJECT_TYPE\" }, \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" }, \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" }, \"rdfs:subPropertyOf\" : { \"@id\" : \"BASE_PROPERTY_IRI\" }, \"salsah-gui:guiElement\" : { \"@id\" : \"GUI_ELEMENT_IRI\" }, \"salsah-gui:guiAttribute\" : [ \"GUI_ATTRIBUTE\" ] } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects. At least one base property must be provided, which can be knora-api:hasValue , knora-api:hasLinkTo , or any of their subproperties, with the exception of file properties (subproperties of knora-api:hasFileValue ) and link value properties (subproperties of knora-api:hasLinkToValue ). If the property is a link property, the corresponding link value property (see Links Between Resources ) will automatically be created. The property definition must specify its knora-api:objectType . If the new property is a subproperty of knora-api:hasValue , its knora-api:objectType must be one of the built-in subclasses of knora-api:Value , which are defined in the knora-api ontology in the complex schema. If the new property is a subproperty of knora-base:hasLinkTo , its knora-api:objectType must be a subclass of knora-api:Resource . To improve consistency checking, it is recommended, but not required, to provide knora-api:subjectType , which must be a subclass of knora-api:Resource . The predicates salsah-gui:guiElement and salsah-gui:guiAttribute are optional. If provided, the object of guiElement must be one of the OWL named individuals defined in The SALSAH GUI Ontology . Some GUI elements take required or optional attributes, which are provided as objects of salsah-gui:guiAttribute ; see The SALSAH GUI Ontology for details. A successful response will be a JSON-LD document providing the new property definition (but not any of the other entities in the ontology).","title":"Creating a Property"},{"location":"03-endpoints/api-v2/ontology-information/#changing-the-labels-of-a-property","text":"This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\", \"@type\" : \"owl:ObjectProperty\", \"rdfs:label\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"LABEL\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:label must be submitted in at least one language, either as an object or as an array of objects.","title":"Changing the Labels of a Property"},{"location":"03-endpoints/api-v2/ontology-information/#changing-the-comments-of-a-property","text":"This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"PROPERTY_IRI\", \"@type\" : \"owl:ObjectProperty\", \"rdfs:comment\" : { \"@language\" : \"LANGUAGE_CODE\", \"@value\" : \"COMMENT\" } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Values for rdfs:comment must be submitted in at least one language, either as an object or as an array of objects.","title":"Changing the Comments of a Property"},{"location":"03-endpoints/api-v2/ontology-information/#deleting-the-comments-of-a-property","text":"This operation is permitted even if the property is used in data. HTTP DELETE to http://host/v2/ontologies/properties/comment/PROPERTY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The property IRI and the ontology's last modification date must be URL-encoded. All values i.e. all languages for rdfs:comment are deleted. If the property is a link property, the rdfs:comment of its corresponding link value property will automatically be deleted. A successful response will be a JSON-LD document providing the property definition.","title":"Deleting the Comments of a Property"},{"location":"03-endpoints/api-v2/ontology-information/#changing-the-gui-element-and-gui-attributes-of-a-property","text":"This operation is permitted even if the property is used in data. HTTP PUT to http://host/v2/ontologies/properties/guielement { \"@id\": \"ONTOLOGY_IRI\", \"@type\": \"owl:Ontology\", \"knora-api:lastModificationDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\": [ { \"@id\": \"PROPERTY_IRI\", \"@type\": \"owl:ObjectProperty\", \"salsah-gui:guiElement\": { \"@id\": \"salsah-gui:Textarea\" }, \"salsah-gui:guiAttribute\": [ \"cols=80\", \"rows=24\" ] } ], \"@context\": { \"rdf\": \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\", \"salsah-gui\": \"http://api.knora.org/ontology/salsah-gui/v2#\", \"owl\": \"http://www.w3.org/2002/07/owl#\", \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\": \"http://www.w3.org/2001/XMLSchema#\" } } To remove the values of salsah-gui:guiElement and salsah-gui:guiAttribute from the property definition, submit the request without those predicates.","title":"Changing the GUI Element and GUI Attributes of a Property"},{"location":"03-endpoints/api-v2/ontology-information/#adding-cardinalities-to-a-class","text":"If the class (or any of its sub-classes) is used in data, it is not allowed to add cardinalities owl:minCardinality greater than 0 or owl:cardinality 1 to the class. HTTP POST to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:subClassOf\" : { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } At least one cardinality must be submitted. OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology).","title":"Adding Cardinalities to a Class"},{"location":"03-endpoints/api-v2/ontology-information/#replacing-the-cardinalities-of-a-class","text":"This removes all the cardinalities from the class and replaces them with the submitted cardinalities. If no cardinalities are submitted (i.e. the request contains no rdfs:subClassOf ), the class is left with no cardinalities. This operation is not permitted if the class is used in data, or if it has a subclass. HTTP PUT to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:subClassOf\" : { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). To check whether a class's cardinalities can be replaced: HTTP GET to http://host/v2/ontologies/canreplacecardinalities/CLASS_IRI The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Replacing the Cardinalities of a Class"},{"location":"03-endpoints/api-v2/ontology-information/#delete-a-single-cardinality-from-a-class","text":"If a class is used in data, it is only allowed to delete a cardinality, if the property a cardinality refers to, is not used inside the data. Also, the property isn't allowed to be used inside the data in any subclasses of this class. HTTP PATCH to http://host/v2/ontologies/cardinalities { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:subClassOf\" : { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" } } } ], \"@context\" : { \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE must correspond to the supported combinations given in OWL Cardinalities . (The placeholder OWL_CARDINALITY_VALUE is shown here in quotes, but it should be an unquoted integer.) When a cardinality on a link property is submitted, an identical cardinality on the corresponding link value property is automatically added (see Links Between Resources ). A successful response will be a JSON-LD document providing the new class definition (but not any of the other entities in the ontology). To check whether a class's cardinality can be deleted: HTTP POST to http://host/v2/ontologies/candeletecardinalities The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Delete a single cardinality from a class"},{"location":"03-endpoints/api-v2/ontology-information/#changing-the-gui-order-of-cardinalities","text":"To change the GUI order of one or more cardinalities in a class: HTTP PUT to http://host/v2/ontologies/guiorder This can be done even if the class is used in data. The request body includes the cardinalities whose GUI order should be changed, using the predicate salsah-gui:guiOrder , whose object is an integer: { \"@id\" : \"ONTOLOGY_IRI\", \"@type\" : \"owl:Ontology\", \"knora-api:lastModificationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"ONTOLOGY_LAST_MODIFICATION_DATE\" }, \"@graph\" : [ { \"@id\" : \"CLASS_IRI\", \"@type\" : \"owl:Class\", \"rdfs:subClassOf\" : { \"@type\": \"owl:Restriction\", \"OWL_CARDINALITY_PREDICATE\": \"OWL_CARDINALITY_VALUE\", \"owl:onProperty\": { \"@id\" : \"PROPERTY_IRI\" }, \"salsah-gui:guiOrder\": \"GUI_ORDER_VALUE\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"salsah-gui\" : \"http://api.knora.org/ontology/salsah-gui/v2#\", \"owl\" : \"http://www.w3.org/2002/07/owl#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } Only the cardinalities whose GUI order is to be changed need to be included in the request. The OWL_CARDINALITY_PREDICATE and OWL_CARDINALITY_VALUE are ignored; only the GUI_ORDER_VALUE is changed.","title":"Changing the GUI Order of Cardinalities"},{"location":"03-endpoints/api-v2/ontology-information/#deleting-a-property","text":"A property can be deleted only if no other ontology entity refers to it, and if it is not used in data. HTTP DELETE to http://host/v2/ontologies/properties/PROPERTY_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The property IRI and the ontology's last modification date must be URL-encoded. If the property is a link property, the corresponding link value property (see Links Between Resources ) will automatically be deleted. A successful response will be a JSON-LD document providing only the ontology's metadata. To check whether a property can be deleted: HTTP GET to http://host/v2/ontologies/candeleteproperty/PROPERTY_IRI The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Deleting a Property"},{"location":"03-endpoints/api-v2/ontology-information/#deleting-a-class","text":"A class can be deleted only if no other ontology entity refers to it, and if it is not used in data. HTTP DELETE to http://host/v2/ontologies/classes/CLASS_IRI?lastModificationDate=ONTOLOGY_LAST_MODIFICATION_DATE The class IRI and the ontology's last modification date must be URL-encoded. A successful response will be a JSON-LD document providing only the ontology's metadata. To check whether a class can be deleted: HTTP GET to http://host/v2/ontologies/candeleteclass/CLASS_IRI The response will look like this: { \"knora-api:canDo\": false, \"@context\": { \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } }","title":"Deleting a Class"},{"location":"03-endpoints/api-v2/permalinks/","text":"Permalinks Knora provides a permanent, citable URL for each resource and value. These URLs use Archival Resource Key (ARK) Identifiers , and are designed to remain valid even if the resource itself is moved from one Knora repository to another. Obtaining ARK URLs In the complex schema , a resource or value is always returned with two ARK URLs: one that will always refer to the latest version of the resource or value ( knora-api:arkUrl ), and one that refers specifically to the version being returned ( knora-api:versionArkUrl ). For example: { \"@id\" : \"http://rdfh.ch/0803/2a6221216701\", \"@type\" : \"incunabula:book\", \"incunabula:book_comment\" : { \"@id\" : \"http://rdfh.ch/0803/2a6221216701/values/56c287fc9505\", \"@type\" : \"knora-api:TextValue\", \"knora-api:arkUrl\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W/dhaRsvZATjmOxhCOOzHqewB\" }, \"knora-api:versionArkUrl\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W/dhaRsvZATjmOxhCOOzHqewB.20160302T150521Z\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/91e19f1e01\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\", \"knora-api:userHasPermission\" : \"V\", \"knora-api:valueAsString\" : \"Katalogaufnahme anhand ISTC und v.d.Haegen\", \"knora-api:valueCreationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2016-03-02T15:05:21Z\" }, \"knora-api:valueHasUUID\" : \"dhaRsvZATjmOxhCOOzHqew\" }, \"knora-api:arkUrl\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W\" }, \"knora-api:versionArkUrl\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W.20160302T150521Z\" }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/yISnUYe6SYmoyuqeMdW39w\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/91e19f1e01\" }, \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2016-03-02T15:05:21Z\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\", \"knora-api:userHasPermission\" : \"V\", \"rdfs:label\" : \"Reise ins Heilige Land\", \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"incunabula\" : \"http://0.0.0.0:3333/ontology/0803/incunabula/v2#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } In the simple schema , resources are returned with ARK URLs, but values are returned as literals, so ARK URLs are not provided for values. For more information on getting past versions of resources and values, see: Get a Full Representation of a Version of a Resource by IRI Get a Version of a Value in a Resource Get the Version History of a Resource Resolving Knora ARK URLs A Knora ARK URL is intended to be resolved by the Knora ARK resolver . Knora ARK URL Format For details, see Archival Resource Key (ARK) Identifiers . ARK URLs for Projects The format of a Knora project ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), and PROJECT is the project's short-code . For example, given a project with ID 0001 , and using the DaSCH's ARK resolver hostname and NAAN, the ARK URL for the project itself is: http://ark.dasch.swiss/ark:/72163/1/0001 This could redirect to a page describing the project. ARK URLs for Resources The format of a Knora resource ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID[.TIMESTAMP] NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), PROJECT is the project's short-code , and RESOURCE_UUID is the resource's UUID . For example, given the Knora resource IRI http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY.20180604T085622513Z Without a timestamp, a Knora resource ARK URL refers to the latest version of the resource at the time when the URL is resolved. ARK URLs for Values The format of a Knora value ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID/VALUE_UUID[.TIMESTAMP] NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), PROJECT is the project's short-code , RESOURCE_UUID is the resource's UUID , and VALUE_UUID is the value's knora-api:valueHasUUID . For example, given a value with knora-api:valueHasUUID \"4OOf3qJUTnCDXlPNnygSzQ\" in the resource http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX.20180604T085622513Z Without a timestamp, a Knora value ARK URL refers to the latest version of the value at the time when the URL is resolved.","title":"Permalinks"},{"location":"03-endpoints/api-v2/permalinks/#permalinks","text":"Knora provides a permanent, citable URL for each resource and value. These URLs use Archival Resource Key (ARK) Identifiers , and are designed to remain valid even if the resource itself is moved from one Knora repository to another.","title":"Permalinks"},{"location":"03-endpoints/api-v2/permalinks/#obtaining-ark-urls","text":"In the complex schema , a resource or value is always returned with two ARK URLs: one that will always refer to the latest version of the resource or value ( knora-api:arkUrl ), and one that refers specifically to the version being returned ( knora-api:versionArkUrl ). For example: { \"@id\" : \"http://rdfh.ch/0803/2a6221216701\", \"@type\" : \"incunabula:book\", \"incunabula:book_comment\" : { \"@id\" : \"http://rdfh.ch/0803/2a6221216701/values/56c287fc9505\", \"@type\" : \"knora-api:TextValue\", \"knora-api:arkUrl\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W/dhaRsvZATjmOxhCOOzHqewB\" }, \"knora-api:versionArkUrl\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W/dhaRsvZATjmOxhCOOzHqewB.20160302T150521Z\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/91e19f1e01\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\", \"knora-api:userHasPermission\" : \"V\", \"knora-api:valueAsString\" : \"Katalogaufnahme anhand ISTC und v.d.Haegen\", \"knora-api:valueCreationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2016-03-02T15:05:21Z\" }, \"knora-api:valueHasUUID\" : \"dhaRsvZATjmOxhCOOzHqew\" }, \"knora-api:arkUrl\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W\" }, \"knora-api:versionArkUrl\" : { \"@type\" : \"xsd:anyURI\", \"@value\" : \"http://ark.dasch.swiss/ark:/72163/1/0803/2a6221216701W.20160302T150521Z\" }, \"knora-api:attachedToProject\" : { \"@id\" : \"http://rdfh.ch/projects/yISnUYe6SYmoyuqeMdW39w\" }, \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/91e19f1e01\" }, \"knora-api:creationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2016-03-02T15:05:21Z\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\", \"knora-api:userHasPermission\" : \"V\", \"rdfs:label\" : \"Reise ins Heilige Land\", \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"incunabula\" : \"http://0.0.0.0:3333/ontology/0803/incunabula/v2#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\" } } In the simple schema , resources are returned with ARK URLs, but values are returned as literals, so ARK URLs are not provided for values. For more information on getting past versions of resources and values, see: Get a Full Representation of a Version of a Resource by IRI Get a Version of a Value in a Resource Get the Version History of a Resource","title":"Obtaining ARK URLs"},{"location":"03-endpoints/api-v2/permalinks/#resolving-knora-ark-urls","text":"A Knora ARK URL is intended to be resolved by the Knora ARK resolver .","title":"Resolving Knora ARK URLs"},{"location":"03-endpoints/api-v2/permalinks/#knora-ark-url-format","text":"For details, see Archival Resource Key (ARK) Identifiers .","title":"Knora ARK URL Format"},{"location":"03-endpoints/api-v2/permalinks/#ark-urls-for-projects","text":"The format of a Knora project ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), and PROJECT is the project's short-code . For example, given a project with ID 0001 , and using the DaSCH's ARK resolver hostname and NAAN, the ARK URL for the project itself is: http://ark.dasch.swiss/ark:/72163/1/0001 This could redirect to a page describing the project.","title":"ARK URLs for Projects"},{"location":"03-endpoints/api-v2/permalinks/#ark-urls-for-resources","text":"The format of a Knora resource ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID[.TIMESTAMP] NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), PROJECT is the project's short-code , and RESOURCE_UUID is the resource's UUID . For example, given the Knora resource IRI http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY.20180604T085622513Z Without a timestamp, a Knora resource ARK URL refers to the latest version of the resource at the time when the URL is resolved.","title":"ARK URLs for Resources"},{"location":"03-endpoints/api-v2/permalinks/#ark-urls-for-values","text":"The format of a Knora value ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID/VALUE_UUID[.TIMESTAMP] NAAN is a Name Assigning Authority Number , VERSION is the version number of the Knora ARK URL format (currently always 1), PROJECT is the project's short-code , RESOURCE_UUID is the resource's UUID , and VALUE_UUID is the value's knora-api:valueHasUUID . For example, given a value with knora-api:valueHasUUID \"4OOf3qJUTnCDXlPNnygSzQ\" in the resource http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX.20180604T085622513Z Without a timestamp, a Knora value ARK URL refers to the latest version of the value at the time when the URL is resolved.","title":"ARK URLs for Values"},{"location":"03-endpoints/api-v2/query-language/","text":"Gravsearch: Virtual Graph Search Basic Concept Gravsearch is intended to offer the advantages of SPARQL endpoints (particularly the ability to perform queries using complex search criteria) while avoiding their drawbacks in terms of performance and security (see The Enduring Myth of the SPARQL Endpoint ). It also has the benefit of enabling clients to work with a simpler RDF data model than the one the API actually uses to store data in the triplestore, and makes it possible to provide better error-checking. Rather than being processed directly by the triplestore, a Gravsearch query is interpreted by the API, which enforces certain restrictions on the query, and implements paging and permission checking. The API server generates SPARQL based on the Gravsearch query submitted, queries the triplestore, filters the results according to the user's permissions, and returns each page of query results as an API response. Thus, Gravsearch is a hybrid between a RESTful API and a SPARQL endpoint. A Gravsearch query conforms to a subset of the syntax of a SPARQL CONSTRUCT query, with some additional restrictions and functionality. In particular, the variable representing the top-level (or 'main') resource that will appear in each search result must be identified, statements must be included to specify the types of the entities being queried, OFFSET is used to control paging, and ORDER BY is used to sort the results. It is certainly possible to write Gravsearch queries by hand, but we expect that in general, they will be automatically generated by client software, e.g. by a client user interface. For a more detailed overview of Gravsearch, see Gravsearch: Transforming SPARQL to query humanities data . Submitting Gravsearch Queries The recommended way to submit a Gravsearch query is via HTTP POST: HTTP POST to http://host/v2/searchextended This works like query via POST directly in the SPARQL 1.1 Protocol : the query is sent unencoded as the HTTP request message body, in the UTF-8 charset. It is also possible to submit a Gravsearch query using HTTP GET. The entire query must be URL-encoded and included as the last element of the URL path: HTTP GET to http://host/v2/searchextended/QUERY The response to a Gravsearch query is an RDF graph, which can be requested in various formats (see Responses Describing Resources ). To request the number of results rather than the results themselves, you can do a count query: HTTP POST to http://host/v2/searchextended/count The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value. If a gravsearch query times out, a 504 Gateway Timeout will be returned. Gravsearch and API Schemas A Gravsearch query can be written in either of the two DSP-API v2 schemas . The simple schema is easier to work with, and is sufficient if you don't need to query anything below the level of a DSP-API value. If your query needs to refer to standoff markup, you must use the complex schema. Each query must use a single schema, with one exception (see Date Comparisons ). Gravsearch query results can be requested in the simple or complex schema; see API Schema . All examples hereafter run with the DSP stack started locally as documented in the section Getting Started with DSP-API . If you access another stack, you can check the IRI of the ontology you are targeting by requesting the ontologies metadata . Using the Simple Schema To write a query in the simple schema, use the knora-api ontology in the simple schema, and use the simple schema for any other DSP ontologies the query refers to, e.g.: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> In the simple schema, DSP-API values are represented as literals, which can be used FILTER expressions (see Filtering on Values in the Simple Schema ). Using the Complex Schema To write a query in the complex schema, use the knora-api ontology in the complex schema, and use the complex schema for any other DSP ontologies the query refers to, e.g.: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> In the complex schema, DSP-API values are represented as objects belonging to subclasses of knora-api:Value , e.g. knora-api:TextValue , and have predicates of their own, which can be used in FILTER expressions (see Filtering on Values in the Complex Schema ). Main and Dependent Resources The main resource is the top-level resource in a search result. Other resources that are in some way connected to the main resource are referred to as dependent resources. If the client asks for a resource A relating to a resource B, then all matches for A will be presented as main resources and those for B as dependent resources. The main resource must be represented by a variable, marked with knora-api:isMainResource , as explained under CONSTRUCT Clause . Virtual incoming Links Depending on the ontology design, a resource A points to B or vice versa. For example, a page A is part of a book B using the property incunabula:partOf . If A is marked as the main resource, then B is nested as a dependent resource in its link value incunabula:partOfValue . But in case B is marked as the main resource, B does not have a link value pointing to A because in fact B is pointed to by A. Instead, B has a virtual property knora-api:hasIncomingLink containing A's link value: \"knora-api:hasIncomingLinkValue\" : { \"@id\" : \"http://rdfh.ch/A/values/xy\", \"@type\" : \"knora-api:LinkValue\", \"knora-api:linkValueHasSource\" : { \"@id\" : \"http://rdfh.ch/A\", \"@type\" : \"incunabula:page\", \"incunabula:partOfValue\" : { \"@id\" : \"http://rdfh.ch/A/values/xy\", \"@type\" : \"knora-api:LinkValue\", \"knora-api:linkValueHasTargetIri\" : { \"@id\" : \"http://rdfh.ch/B\" } } } }, Note that the virtually inserted link value inverts the relation by using knora-api:linkValueHasSource . The source of the link is A and its target B is only represented by an Iri ( knora-api:linkValueHasTargetIri ) since B is the main resource. Graph Patterns and Result Graphs The WHERE clause of a Gravsearch query specifies a graph pattern. Each query result will match this graph pattern, and will have the form of a graph whose starting point is a main resource. The query's graph pattern, and hence each query result graph, can span zero more levels of relations between resources. For example, a query could request regions in images on pages of books written by a certain author, articles by authors who were students of a particular professor, or authors of texts that refer to events that took place within a certain date range. Permission Checking Each matching resource is returned with the values that the user has permission to see. If the user does not have permission to see a matching main resource, it is hidden in the results. If a user does not have permission to see a matching dependent resource, the link value is hidden. Paging Gravsearch results are returned in pages. The maximum number of main resources per page is determined by the API (and can be configured in application.conf via the setting app/v2/resources-sequence/results-per-page ). If some resources have been filtered out because the user does not have permission to see them, a page could contain fewer results, or no results. If it is possible that more results are available in subsequent pages, the Gravsearch response will contain the predicate knora-api:mayHaveMoreResults with the boolean value true , otherwise it will not contain this predicate. Therefore, to retrieve all available results, the client must request each page one at a time, until the response does not contain knora-api:mayHaveMoreResults . Inference Gravsearch queries are understood to imply a subset of RDFS reasoning . This is done by the API by expanding the incoming query. Specifically, if a statement pattern specifies a property, the pattern will also match subproperties of that property, and if a statement specifies that a subject has a particular rdf:type , the statement will also match subjects belonging to subclasses of that type. If you know that reasoning will not return any additional results for your query, you can disable it by adding this line to the WHERE clause, which may improve query performance: knora-api:GravsearchOptions knora-api:useInference false . Gravsearch Syntax Every Gravsearch query is a valid SPARQL 1.1 CONSTRUCT query. However, Gravsearch only supports a subset of the elements that can be used in a SPARQL Construct query, and a Gravsearch CONSTRUCT Clause has to indicate which variable is to be used for the main resource in each search result. Supported SPARQL Syntax The current version of Gravsearch accepts CONSTRUCT queries whose WHERE clauses use the following patterns, with the specified restrictions: OPTIONAL : cannot be nested in a UNION . UNION : cannot be nested in a UNION . FILTER : may contain a complex expression using the Boolean operators AND and OR, as well as comparison operators. The left argument of a comparison operator must be a query variable. A Knora ontology entity IRI used in a FILTER must be a property IRI. FILTER NOT EXISTS MINUS OFFSET : the OFFSET is needed for paging. It does not actually refer to the number of triples to be returned, but to the requested page of results. The default value is 0, which refers to the first page of results. ORDER BY : In SPARQL, the result of a CONSTRUCT query is an unordered set of triples. However, a Gravsearch query returns an ordered list of resources, which can be ordered by the values of specified properties. If the query is written in the complex schema, items below the level of DSP-API values may not be used in ORDER BY . BIND : The value assigned must be a DSP resource IRI. Resources, Properties, and Values Resources can be represented either by an IRI or by a variable, except for the main resource, which must be represented by a variable. It is possible to do a Gravsearch query in which the IRI of the main resource is already known, e.g. to request specific information about that resource and perhaps about linked resources. In this case, the IRI of the main resource must be assigned to a variable using BIND . Note that BIND statements slow the query down, therefore we recommend that you do not use them unless you have to. Properties can be represented by an IRI or a query variable. If a property is represented by a query variable, it can be restricted to certain property IRIs using a FILTER . A Knora value (i.e. a value attached to a knora-api:Resource ) must be represented as a query variable. Filtering on Values Filtering on Values in the Simple Schema In the simple schema, a variable representing a DSP-API value can be used directly in a FILTER expression. For example: ?book incunabula:title ?title . FILTER(?title = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") Here the type of ?title is xsd:string . The following value types can be compared with literals in FILTER expressions in the simple schema: Text values ( xsd:string ) Uri values ( xsd:anyURI ) Integer values ( xsd:integer ) Decimal values ( xsd:decimal ) Boolean values ( xsd:boolean ) Date values ( knora-api:Date ) List values ( knora-api:ListNode ) List values can only be searched for using the equal operator ( = ), performing an exact match on a list node's label. Labels can be given in different languages for a specific list node. If one of the given list node labels matches, it is considered a match. Note that in the simple schema, uniqueness is not guaranteed (as opposed to the complex schema). A DSP-API value may not be represented as the literal object of a predicate; for example, this is not allowed: ?book incunabula:title \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . Filtering on Values in the Complex Schema In the complex schema, variables representing DSP-API values are not literals. You must add something to the query (generally a statement) to get a literal from a DSP-API value. For example: ?book incunabula:title ?title . ?title knora-api:valueAsString \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . Here the type of ?title is knora-api:TextValue . Note that no FILTER is needed in this example. But if you want to use a different comparison operator, you need a FILTER : ?page incunabula:seqnum ?seqnum . ?seqnum knora-api:intValueAsInt ?seqnumInt . FILTER(?seqnumInt <= 10) To match a date value in the complex schema, you must use the knora-api:toSimpleDate function in a FILTER (see Date Comparisons ). The predicates of knora-api:DateValue ( knora-api:dateValueHasStartYear , etc.) are not available in Gravsearch. Date Comparisons In the simple schema, you can compare a date value directly with a knora-api:Date in a FILTER : ?book incunabula:pubdate ?pubdate . FILTER(?pubdate < \"JULIAN:1497\"^^knora-api:Date) In the complex schema, you must use the function knora-api:toSimpleDate , passing it the variable representing the date value. The date literal used in the comparison must still be a knora-api:Date in the simple schema. This is the only case in which you can use both schemas in a single query: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true . ?book incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book . ?book incunabula:pubdate ?pubdate . FILTER(knora-api:toSimpleDate(?pubdate) < \"JULIAN:1497\"^^knora-api-simple:Date) } ORDER BY ?pubdate You can also use knora-api:toSimpleDate with to search for date tags in standoff text markup (see Matching Standoff Dates ). Note that the given date value for comparison must have the following format: ``` (GREGORIAN|JULIAN|ISLAMIC):\\d{1,4}(-\\d{1,2}(-\\d{1,2})?)?( BC| AD| BCE| CE)?(:\\d{1,4}(-\\d{1,2}(-\\d{1,2})?)?( BC| AD| BCE| CE)?)? ``` E.g. an exact date like GREGORIAN:2015-12-03 or a period like GREGORIAN:2015-12-03:2015-12-04 . Dates may also have month or year precision, e.g. ISLAMIC:1407-02 (the whole month of december) or JULIAN:1330 (the whole year 1330). An optional ERA indicator term ( BCE , CE , or BC , AD ) can be added to the date, when no era is provided the default era AD will be considered. Era can be given as GREGORIAN:1220 BC or in range as GREGORIAN:600 BC:480 BC . Searching for Matching Words The function knora-api:matchText searches for matching words anywhere in a text value, and is implemented using a full-text search index if available. The first argument must represent a text value (a knore-api:TextValue in the complex schema, or an xsd:string in the simple schema). The second argument is a string literal containing the words to be matched, separated by spaces. The function supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. This function can only be used as the top-level expression in a FILTER . For example, to search for titles that contain the words 'Zeitgl\u00f6cklein' and 'Lebens': ?book incunabule:title ?title . FILTER knora-api:matchText(?title, \"Zeitgl\u00f6cklein Lebens\") Filtering Text by Language To filter a text value by language in the simple schema, use the SPARQL lang function on the text value, e.g.: FILTER(lang(?text) = \"fr\") In the complex schema, the lang function is not supported. Use the text value's knora-api:textValueHasLanguage predicate instead: ?text knora-api:textValueHasLanguage \"fr\" . Regular Expressions The SPARQL regex function is supported. In the simple schema, you can use it directly on the text value, e.g. ?book incunabula:title ?title . FILTER regex(?title, \"Zeit\", \"i\") In the complex schema, use it on the object of the text value's knora-api:valueAsString predicate: ?book incunabula:title ?title . ?title knora-api:valueAsString ?titleStr . FILTER regex(?titleStr, \"Zeit\", \"i\") Searching for Text Markup To refer to standoff markup in text values, you must write your query in the complex schema. A knora-api:TextValue can have the property knora-api:textValueHasStandoff , whose objects are the standoff markup tags in the text. You can match the tags you're interested in using rdf:type or other properties of each tag. Matching Text in a Standoff Tag The function knora-api:matchTextInStandoff searches for standoff tags containing certain terms. The implementation is optimised using the full-text search index if available. The function takes three arguments: A variable representing a text value. A variable representing a standoff tag. A string literal containing space-separated search terms. This function can only be used as the top-level expression in a FILTER . For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffParagraphTag . ?standoffParagraphTag a standoff:StandoffParagraphTag . FILTER knora-api:matchTextInStandoff(?text, ?standoffParagraphTag, \"Grund Richtigkeit\") } Here we are looking for letters containing the words \"Grund\" and \"Richtigkeit\" within a single paragraph. Matching Standoff Links If you are only interested in specifying that a resource has some text value containing a standoff link to another resource, the most efficient way is to use the property knora-api:hasStandoffLinkTo , whose subjects and objects are resources. This property is automatically maintained by the API. For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?letter knora-api:hasStandoffLinkTo ?person . ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . } Here we are looking for letters containing a link to the historian Claude Jordan, who is identified by his Integrated Authority File identifier, (VIAF)271899510 . However, if you need to specify the context in which the link tag occurs, you must use the function knora-api:standoffLink . It takes three arguments: A variable or IRI representing the resource that is the source of the link. A variable representing the standoff link tag. A variable or IRI representing the resource that is the target of the link. This function can only be used as the top-level expression in a FILTER . For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffLinkTag . ?standoffLinkTag a knora-api:StandoffLinkTag . FILTER knora-api:standoffLink(?letter, ?standoffLinkTag, ?person) ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . ?standoffLinkTag knora-api:standoffTagHasStartParent ?standoffItalicTag . ?standoffItalicTag a standoff:StandoffItalicTag . } This has the same effect as the previous example, except that because we are matching the link tag itself, we can specify that its immediate parent is a StandoffItalicTag . If you actually want to get the target of the link (in this example, ?person ) in the search results, you need to add a statement like ?letter knora-api:hasStandoffLinkTo ?person . to the WHERE clause and to the CONSTRUCT clause: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . ?letter knora-api:hasStandoffLinkTo ?person . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffLinkTag . ?standoffLinkTag a knora-api:StandoffLinkTag . FILTER knora-api:standoffLink(?letter, ?standoffLinkTag, ?person) ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . ?standoffLinkTag knora-api:standoffTagHasStartParent ?standoffItalicTag . ?standoffItalicTag a standoff:StandoffItalicTag . ?letter knora-api:hasStandoffLinkTo ?person . } Matching Standoff Dates You can use the knora-api:toSimpleDate function (see @ref Date Comparisons ) to match dates in standoff date tags, i.e. instances of knora-api:StandoffDateTag or of one of its subclasses. For example, here we are looking for a text containing an anything:StandoffEventTag (which is a project-specific subclass of knora-api:StandoffDateTag ) representing an event that occurred sometime during the month of December 2016: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasText ?text . } WHERE { ?thing a anything:Thing . ?thing anything:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffEventTag . ?standoffEventTag a anything:StandoffEventTag . FILTER(knora-api:toSimpleDate(?standoffEventTag) = \"GREGORIAN:2016-12 CE\"^^knora-api-simple:Date) } Matching Ancestor Tags Suppose we want to search for a standoff date in a paragraph, but we know that the paragraph tag might not be the immediate parent of the date tag. For example, the date tag might be in an italics tag, which is in a paragraph tag. In that case, we can use the inferred property knora-api:standoffTagHasStartAncestor . We can modify the previous example to do this: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasText ?text . } WHERE { ?thing a anything:Thing . ?thing anything:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffDateTag . ?standoffDateTag a knora-api:StandoffDateTag . FILTER(knora-api:toSimpleDate(?standoffDateTag) = \"GREGORIAN:2016-12-24 CE\"^^knora-api-simple:Date) ?standoffDateTag knora-api:standoffTagHasStartAncestor ?standoffParagraphTag . ?standoffParagraphTag a standoff:StandoffParagraphTag . } Filtering on rdfs:label The rdfs:label of a resource is not a DSP-API value, but you can still search for it. This can be done in the same ways in the simple or complex schema: Using a string literal object: ?book rdfs:label \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . Using a variable and a FILTER: ?book rdfs:label ?label . FILTER(?label = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") Using the regex function: ?book rdfs:label ?bookLabel . FILTER regex(?bookLabel, \"Zeit\", \"i\") To match words in an rdfs:label using the full-text search index, use the knora-api:matchLabel function, which works like knora-api:matchText , except that the first argument is a variable representing a resource: FILTER knora-api:matchLabel(?book, \"Zeitgl\u00f6cklein\") Filtering on Resource IRIs A FILTER can compare a variable with another variable or IRI representing a resource. For example, to find a letter whose author and recipient are different persons: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . } WHERE { ?letter a beol:letter . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . FILTER(?person1 != ?person2) . } OFFSET 0 To find a letter whose author is not a person with a specified IRI: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . } WHERE { ?letter a beol:letter . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . FILTER(?person1 != <http://rdfh.ch/0801/F4n1xKa3TCiR4llJeElAGA>) . } OFFSET 0 CONSTRUCT Clause In the CONSTRUCT clause of a Gravsearch query, the variable representing the main resource must be indicated with knora-api:isMainResource true . Exactly one variable representing a resource must be marked in this way. Any other statements in the CONSTRUCT clause must also be present in the WHERE clause. If a variable representing a resource or value is used in the WHERE clause but not in the CONSTRUCT clause, the matching resources or values will not be included in the results. If the query is written in the complex schema, all variables in the CONSTRUCT clause must refer to DSP-API resources, DSP-API values, or properties. Data below the level of values may not be mentioned in the CONSTRUCT clause. Predicates from the rdf , rdfs , and owl ontologies may not be used in the CONSTRUCT clause. The rdfs:label of each matching resource is always returned, so there is no need to mention it in the query. Gravsearch by Example In this section, we provide some sample queries of different complexity to illustrate the usage of Gravsearch. Getting All the Components of a Compound Resource In order to get all the components of a compound resource, the following Gravsearch query can be sent to the API. In this case, the compound resource is an incunabula:book identified by the IRI http://rdfh.ch/0803/c5058f3a and the components are of type incunabula:page (test data for the Incunabula project). Since inference is assumed, we can use knora-api:StillImageRepresentation ( incunabula:page is one of its subclasses). This makes the query more generic and allows for reuse (for instance, a client would like to query different types of compound resources defined in different ontologies). ORDER BY is used to sort the components by their sequence number. OFFSET is set to 0 to get the first page of results. PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?component knora-api:isMainResource true . # marking of the component searched for as the main resource, required ?component knora-api:seqnum ?seqnum . # return the sequence number in the response ?component knora-api:hasStillImageFileValue ?file . # return the StillImageFile in the response } WHERE { ?component a knora-api:StillImageRepresentation . # restriction of the type of component ?component knora-api:isPartOf <http://rdfh.ch/0803/c5058f3a> . # component relates to a compound resource via this property ?component knora-api:seqnum ?seqnum . # component must have a sequence number ?component knora-api:hasStillImageFileValue ?file . # component must have a StillImageFile } ORDER BY ASC(?seqnum) # order by sequence number, ascending OFFSET 0 # get first page of results The incunabula:book with the IRI http://rdfh.ch/0803/c5058f3a has 402 pages. (This result can be obtained by doing a count query; see Submitting Gravsearch Queries .) However, with OFFSET 0 , only the first page of results is returned. The same query can be sent again with OFFSET 1 to get the next page of results, and so forth. When a page of results is not full (see settings in app/v2 in application.conf ) or is empty, no more results are available. By design, it is not possible for the client to get more than one page of results at a time; this is intended to prevent performance problems that would be caused by huge responses. A client that wants to download all the results of a query must request each page sequentially. Let's assume the client is not interested in all of the book's pages, but just in first ten of them. In that case, the sequence number can be restricted using a FILTER that is added to the query's WHERE clause: FILTER (?seqnum <= 10) The first page starts with sequence number 1, so with this FILTER only the first ten pages are returned. This query would be exactly the same in the complex schema, except for the expansion of the knora-api prefix: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> Traversing Multiple Links Here we are looking for regions of pages that are part of books that have a particular title. In the simple schema: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?region knora-api:isMainResource true ; knora-api:isRegionOf ?page . ?page incunabula:partOf ?book . ?book incunabula:title ?title . } WHERE { ?region a knora-api:Region ; knora-api:isRegionOf ?page . ?page a incunabula:page ; incunabula:partOf ?book . ?book incunabula:title ?title . FILTER(?title = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") } In the complex schema: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?region knora-api:isMainResource true ; knora-api:isRegionOf ?page . ?page incunabula:partOf ?book . ?book incunabula:title ?title . } WHERE { ?region a knora-api:Region ; knora-api:isRegionOf ?page . ?page a incunabula:page ; incunabula:partOf ?book . ?book incunabula:title ?title . ?title knora-api:valueAsString \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . } If we remove the line ?book incunabula:title ?title . from the CONSTRUCT clause, so that the CONSTRUCT clause no longer mentions ?title , the response will contain the same matching resources, but the titles of those resources will not be included in the response. Requesting a Graph Starting with a Known Resource Here the IRI of the main resource is already known, and we want specific information about it, as well as about related resources. In this case, the IRI of the main resource must be assigned to a variable using BIND : PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?letter knora-api:isMainResource true ; beol:creationDate ?date ; ?linkingProp1 ?person1 . ?person1 beol:hasFamilyName ?familyName . } WHERE { BIND(<http://rdfh.ch/0801/_B3lQa6tSymIq7_7SowBsA> AS ?letter) ?letter a beol:letter ; beol:creationDate ?date ; ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient) ?person1 beol:hasFamilyName ?familyName . } ORDER BY ?date This query would be the same in the complex schema, except for the prefix expansions: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> Searching for a List Value Referring to a Particular List Node Since list nodes are represented by their Iri in the complex schema, uniqueness is guranteed (as opposed to the simple schema). Also all the subnodes of the given list node are considered a match. PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasListItem ?listItem . } WHERE { ?thing anything:hasListItem ?listItem . ?listItem knora-api:listValueAsListNode <http://rdfh.ch/lists/0001/treeList02> . } Type Inference Gravsearch needs to be able to determine the types of the entities that query variables and IRIs refer to in the WHERE clause. In most cases, it can infer these from context and from the ontologies used. In particular, it needs to know: The type of the subject and object of each statement. The type that is expected as the object of each predicate. Type Annotations When one or more types cannot be inferred, Gravsearch will return an error message indicating the entities for which it could not determine types. The missing information must then be given by adding type annotations to the query. This can always done by adding statements with the predicate rdf:type . The subject must be a resource or value, and the object must either be knora-api:Resource (if the subject is a resource) or the subject's specific type (if it is a value). For example, consider this query that uses a non-DSP property: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book dcterms:title ?title . } This produces the error message: The types of one or more entities could not be determined: ?book, <http://purl.org/dc/terms/title>, ?title To solve this problem, it is enough to specify the types of ?book and ?title ; the type of the expected object of dcterms:title can then be inferred from the type of ?title . PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book rdf:type incunabula:book ; dcterms:title ?title . ?title rdf:type xsd:string . } It would also be possible to annotate the property itself, using the predicate knora-api:objectType ; then the type of ?title would be inferred: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book rdf:type incunabula:book ; dcterms:title ?title . dcterms:title knora-api:objectType xsd:string . } Note that it only makes sense to use dcterms:title in the simple schema, because its object is supposed to be a literal. Here is another example, using a non-DSP class: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT { ?person knora-api:isMainResource true . } WHERE { ?person a foaf:Person . ?person foaf:familyName ?familyName . FILTER(?familyName = \"Meier\") } This produces the error message: Types could not be determined for one or more entities: ?person The solution is to specify that ?person is a knora-api:Resource : PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT { ?person knora-api:isMainResource true . } WHERE { ?person a foaf:Person . ?person a knora-api:Resource . ?person foaf:familyName ?familyName . FILTER(?familyName = \"Meier\") } Inconsistent Types Gravsearch will also reject a query if an entity is used with inconsistent types. For example: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true ; incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book ; incunabula:pubdate ?pubdate . FILTER(?pubdate = \"JULIAN:1497-03-01\") . } This returns the error message: One or more entities have inconsistent types: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#pubdate> knora-api:objectType <http://api.knora.org/ontology/knora-api/simple/v2#Date> ; knora-api:objectType <http://www.w3.org/2001/XMLSchema#string> . ?pubdate rdf:type <http://api.knora.org/ontology/knora-api/simple/v2#Date> ; rdf:type <http://www.w3.org/2001/XMLSchema#string> . This is because the incunabula ontology says that the object of incunabula:pubdate must be a knora-api:Date , but the FILTER expression compares ?pubdate with an xsd:string . The solution is to specify the type of the literal in the FILTER : PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true ; incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book ; incunabula:pubdate ?pubdate . FILTER(?pubdate = \"JULIAN:1497-03-01\"^^knora-api:Date) . } Scoping Issues SPARQL is evaluated from the bottom up . A UNION block therefore opens a new scope, in which variables bound at higher levels are not necessarily in scope. This can cause unexpected results if queries are not carefully designed. Gravsearch tries to prevent this by rejecting queries in the following cases. FILTER in UNION A FILTER in a UNION block can only use variables that are bound in the same block, otherwise the query will be rejected. This query is invalid because ?text is not bound in the UNION block containing the FILTER where the variable is used: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX mls: <http://0.0.0.0:3333/ontology/0807/mls/simple/v2#> CONSTRUCT { ?lemma knora-api:isMainResource true . ?lemma mls:hasLemmaText ?text . } WHERE { ?lemma a mls:Lemma . ?lemma mls:hasLemmaText ?text . { ?lemma mls:hasPseudonym ?pseudo . FILTER regex(?pseudo, \"Abel\", \"i\") . } UNION { FILTER regex(?text, \"Abel\", \"i\") . } } ORDER BY ASC(?text) OFFSET 0 It can be corrected like this: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX mls: <http://0.0.0.0:3333/ontology/0807/mls/simple/v2#> CONSTRUCT { ?lemma knora-api:isMainResource true . ?lemma mls:hasLemmaText ?text . } WHERE { ?lemma a mls:Lemma . ?lemma mls:hasLemmaText ?text . { ?lemma mls:hasPseudonym ?pseudo . FILTER regex(?pseudo, \"Abel\", \"i\") . } UNION { ?lemma mls:hasLemmaText ?text . FILTER regex(?text, \"Abel\", \"i\") . } } ORDER BY ASC(?text) OFFSET 0 ORDER BY A variable used in ORDER BY must be bound at the top level of the WHERE clause. This query is invalid, because ?int is not bound at the top level of the WHERE clause: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasInteger ?int . ?thing anything:hasRichtext ?richtext . ?thing anything:hasText ?text . } WHERE { ?thing a knora-api:Resource . ?thing a anything:Thing . { ?thing anything:hasRichtext ?richtext . FILTER knora-api:matchText(?richtext, \"test\") ?thing anything:hasInteger ?int . } UNION { ?thing anything:hasText ?text . FILTER knora-api:matchText(?text, \"test\") ?thing anything:hasInteger ?int . } } ORDER BY (?int) It can be corrected like this: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasInteger ?int . ?thing anything:hasRichtext ?richtext . ?thing anything:hasText ?text . } WHERE { ?thing a knora-api:Resource . ?thing a anything:Thing . ?thing anything:hasInteger ?int . { ?thing anything:hasRichtext ?richtext . FILTER knora-api:matchText(?richtext, \"test\") } UNION { ?thing anything:hasText ?text . FILTER knora-api:matchText(?text, \"test\") } } ORDER BY (?int) Query Optimization by Dependency The query performance of triplestores, such as Fuseki, is highly dependent on the order of query patterns. To improve performance, Gravsearch automatically reorders the statement patterns in the WHERE clause according to their dependencies on each other, to minimise the number of possible matches for each pattern. Consider the following Gravsearch query: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol:creationDate ?date . } WHERE { ?letter beol:creationDate ?date . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?person1 beol:hasIAFIdentifier ?gnd1 . ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?person2 beol:hasIAFIdentifier ?gnd2 . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . } ORDER BY ?date Gravsearch optimises the performance of this query by moving these statements to the top of the WHERE clause: ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . The rest of the WHERE clause then reads: ?person1 beol:hasIAFIdentifier ?gnd1 . ?person2 beol:hasIAFIdentifier ?gnd2 . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?letter beol:creationDate ?date .","title":"Gravsearch - Virtual Graph Search"},{"location":"03-endpoints/api-v2/query-language/#gravsearch-virtual-graph-search","text":"","title":"Gravsearch: Virtual Graph Search"},{"location":"03-endpoints/api-v2/query-language/#basic-concept","text":"Gravsearch is intended to offer the advantages of SPARQL endpoints (particularly the ability to perform queries using complex search criteria) while avoiding their drawbacks in terms of performance and security (see The Enduring Myth of the SPARQL Endpoint ). It also has the benefit of enabling clients to work with a simpler RDF data model than the one the API actually uses to store data in the triplestore, and makes it possible to provide better error-checking. Rather than being processed directly by the triplestore, a Gravsearch query is interpreted by the API, which enforces certain restrictions on the query, and implements paging and permission checking. The API server generates SPARQL based on the Gravsearch query submitted, queries the triplestore, filters the results according to the user's permissions, and returns each page of query results as an API response. Thus, Gravsearch is a hybrid between a RESTful API and a SPARQL endpoint. A Gravsearch query conforms to a subset of the syntax of a SPARQL CONSTRUCT query, with some additional restrictions and functionality. In particular, the variable representing the top-level (or 'main') resource that will appear in each search result must be identified, statements must be included to specify the types of the entities being queried, OFFSET is used to control paging, and ORDER BY is used to sort the results. It is certainly possible to write Gravsearch queries by hand, but we expect that in general, they will be automatically generated by client software, e.g. by a client user interface. For a more detailed overview of Gravsearch, see Gravsearch: Transforming SPARQL to query humanities data .","title":"Basic Concept"},{"location":"03-endpoints/api-v2/query-language/#submitting-gravsearch-queries","text":"The recommended way to submit a Gravsearch query is via HTTP POST: HTTP POST to http://host/v2/searchextended This works like query via POST directly in the SPARQL 1.1 Protocol : the query is sent unencoded as the HTTP request message body, in the UTF-8 charset. It is also possible to submit a Gravsearch query using HTTP GET. The entire query must be URL-encoded and included as the last element of the URL path: HTTP GET to http://host/v2/searchextended/QUERY The response to a Gravsearch query is an RDF graph, which can be requested in various formats (see Responses Describing Resources ). To request the number of results rather than the results themselves, you can do a count query: HTTP POST to http://host/v2/searchextended/count The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value. If a gravsearch query times out, a 504 Gateway Timeout will be returned.","title":"Submitting Gravsearch Queries"},{"location":"03-endpoints/api-v2/query-language/#gravsearch-and-api-schemas","text":"A Gravsearch query can be written in either of the two DSP-API v2 schemas . The simple schema is easier to work with, and is sufficient if you don't need to query anything below the level of a DSP-API value. If your query needs to refer to standoff markup, you must use the complex schema. Each query must use a single schema, with one exception (see Date Comparisons ). Gravsearch query results can be requested in the simple or complex schema; see API Schema . All examples hereafter run with the DSP stack started locally as documented in the section Getting Started with DSP-API . If you access another stack, you can check the IRI of the ontology you are targeting by requesting the ontologies metadata .","title":"Gravsearch and API Schemas"},{"location":"03-endpoints/api-v2/query-language/#using-the-simple-schema","text":"To write a query in the simple schema, use the knora-api ontology in the simple schema, and use the simple schema for any other DSP ontologies the query refers to, e.g.: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> In the simple schema, DSP-API values are represented as literals, which can be used FILTER expressions (see Filtering on Values in the Simple Schema ).","title":"Using the Simple Schema"},{"location":"03-endpoints/api-v2/query-language/#using-the-complex-schema","text":"To write a query in the complex schema, use the knora-api ontology in the complex schema, and use the complex schema for any other DSP ontologies the query refers to, e.g.: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> In the complex schema, DSP-API values are represented as objects belonging to subclasses of knora-api:Value , e.g. knora-api:TextValue , and have predicates of their own, which can be used in FILTER expressions (see Filtering on Values in the Complex Schema ).","title":"Using the Complex Schema"},{"location":"03-endpoints/api-v2/query-language/#main-and-dependent-resources","text":"The main resource is the top-level resource in a search result. Other resources that are in some way connected to the main resource are referred to as dependent resources. If the client asks for a resource A relating to a resource B, then all matches for A will be presented as main resources and those for B as dependent resources. The main resource must be represented by a variable, marked with knora-api:isMainResource , as explained under CONSTRUCT Clause .","title":"Main and Dependent Resources"},{"location":"03-endpoints/api-v2/query-language/#virtual-incoming-links","text":"Depending on the ontology design, a resource A points to B or vice versa. For example, a page A is part of a book B using the property incunabula:partOf . If A is marked as the main resource, then B is nested as a dependent resource in its link value incunabula:partOfValue . But in case B is marked as the main resource, B does not have a link value pointing to A because in fact B is pointed to by A. Instead, B has a virtual property knora-api:hasIncomingLink containing A's link value: \"knora-api:hasIncomingLinkValue\" : { \"@id\" : \"http://rdfh.ch/A/values/xy\", \"@type\" : \"knora-api:LinkValue\", \"knora-api:linkValueHasSource\" : { \"@id\" : \"http://rdfh.ch/A\", \"@type\" : \"incunabula:page\", \"incunabula:partOfValue\" : { \"@id\" : \"http://rdfh.ch/A/values/xy\", \"@type\" : \"knora-api:LinkValue\", \"knora-api:linkValueHasTargetIri\" : { \"@id\" : \"http://rdfh.ch/B\" } } } }, Note that the virtually inserted link value inverts the relation by using knora-api:linkValueHasSource . The source of the link is A and its target B is only represented by an Iri ( knora-api:linkValueHasTargetIri ) since B is the main resource.","title":"Virtual incoming Links"},{"location":"03-endpoints/api-v2/query-language/#graph-patterns-and-result-graphs","text":"The WHERE clause of a Gravsearch query specifies a graph pattern. Each query result will match this graph pattern, and will have the form of a graph whose starting point is a main resource. The query's graph pattern, and hence each query result graph, can span zero more levels of relations between resources. For example, a query could request regions in images on pages of books written by a certain author, articles by authors who were students of a particular professor, or authors of texts that refer to events that took place within a certain date range.","title":"Graph Patterns and Result Graphs"},{"location":"03-endpoints/api-v2/query-language/#permission-checking","text":"Each matching resource is returned with the values that the user has permission to see. If the user does not have permission to see a matching main resource, it is hidden in the results. If a user does not have permission to see a matching dependent resource, the link value is hidden.","title":"Permission Checking"},{"location":"03-endpoints/api-v2/query-language/#paging","text":"Gravsearch results are returned in pages. The maximum number of main resources per page is determined by the API (and can be configured in application.conf via the setting app/v2/resources-sequence/results-per-page ). If some resources have been filtered out because the user does not have permission to see them, a page could contain fewer results, or no results. If it is possible that more results are available in subsequent pages, the Gravsearch response will contain the predicate knora-api:mayHaveMoreResults with the boolean value true , otherwise it will not contain this predicate. Therefore, to retrieve all available results, the client must request each page one at a time, until the response does not contain knora-api:mayHaveMoreResults .","title":"Paging"},{"location":"03-endpoints/api-v2/query-language/#inference","text":"Gravsearch queries are understood to imply a subset of RDFS reasoning . This is done by the API by expanding the incoming query. Specifically, if a statement pattern specifies a property, the pattern will also match subproperties of that property, and if a statement specifies that a subject has a particular rdf:type , the statement will also match subjects belonging to subclasses of that type. If you know that reasoning will not return any additional results for your query, you can disable it by adding this line to the WHERE clause, which may improve query performance: knora-api:GravsearchOptions knora-api:useInference false .","title":"Inference"},{"location":"03-endpoints/api-v2/query-language/#gravsearch-syntax","text":"Every Gravsearch query is a valid SPARQL 1.1 CONSTRUCT query. However, Gravsearch only supports a subset of the elements that can be used in a SPARQL Construct query, and a Gravsearch CONSTRUCT Clause has to indicate which variable is to be used for the main resource in each search result.","title":"Gravsearch Syntax"},{"location":"03-endpoints/api-v2/query-language/#supported-sparql-syntax","text":"The current version of Gravsearch accepts CONSTRUCT queries whose WHERE clauses use the following patterns, with the specified restrictions: OPTIONAL : cannot be nested in a UNION . UNION : cannot be nested in a UNION . FILTER : may contain a complex expression using the Boolean operators AND and OR, as well as comparison operators. The left argument of a comparison operator must be a query variable. A Knora ontology entity IRI used in a FILTER must be a property IRI. FILTER NOT EXISTS MINUS OFFSET : the OFFSET is needed for paging. It does not actually refer to the number of triples to be returned, but to the requested page of results. The default value is 0, which refers to the first page of results. ORDER BY : In SPARQL, the result of a CONSTRUCT query is an unordered set of triples. However, a Gravsearch query returns an ordered list of resources, which can be ordered by the values of specified properties. If the query is written in the complex schema, items below the level of DSP-API values may not be used in ORDER BY . BIND : The value assigned must be a DSP resource IRI.","title":"Supported SPARQL Syntax"},{"location":"03-endpoints/api-v2/query-language/#resources-properties-and-values","text":"Resources can be represented either by an IRI or by a variable, except for the main resource, which must be represented by a variable. It is possible to do a Gravsearch query in which the IRI of the main resource is already known, e.g. to request specific information about that resource and perhaps about linked resources. In this case, the IRI of the main resource must be assigned to a variable using BIND . Note that BIND statements slow the query down, therefore we recommend that you do not use them unless you have to. Properties can be represented by an IRI or a query variable. If a property is represented by a query variable, it can be restricted to certain property IRIs using a FILTER . A Knora value (i.e. a value attached to a knora-api:Resource ) must be represented as a query variable.","title":"Resources, Properties, and Values"},{"location":"03-endpoints/api-v2/query-language/#filtering-on-values","text":"","title":"Filtering on Values"},{"location":"03-endpoints/api-v2/query-language/#filtering-on-values-in-the-simple-schema","text":"In the simple schema, a variable representing a DSP-API value can be used directly in a FILTER expression. For example: ?book incunabula:title ?title . FILTER(?title = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") Here the type of ?title is xsd:string . The following value types can be compared with literals in FILTER expressions in the simple schema: Text values ( xsd:string ) Uri values ( xsd:anyURI ) Integer values ( xsd:integer ) Decimal values ( xsd:decimal ) Boolean values ( xsd:boolean ) Date values ( knora-api:Date ) List values ( knora-api:ListNode ) List values can only be searched for using the equal operator ( = ), performing an exact match on a list node's label. Labels can be given in different languages for a specific list node. If one of the given list node labels matches, it is considered a match. Note that in the simple schema, uniqueness is not guaranteed (as opposed to the complex schema). A DSP-API value may not be represented as the literal object of a predicate; for example, this is not allowed: ?book incunabula:title \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" .","title":"Filtering on Values in the Simple Schema"},{"location":"03-endpoints/api-v2/query-language/#filtering-on-values-in-the-complex-schema","text":"In the complex schema, variables representing DSP-API values are not literals. You must add something to the query (generally a statement) to get a literal from a DSP-API value. For example: ?book incunabula:title ?title . ?title knora-api:valueAsString \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . Here the type of ?title is knora-api:TextValue . Note that no FILTER is needed in this example. But if you want to use a different comparison operator, you need a FILTER : ?page incunabula:seqnum ?seqnum . ?seqnum knora-api:intValueAsInt ?seqnumInt . FILTER(?seqnumInt <= 10) To match a date value in the complex schema, you must use the knora-api:toSimpleDate function in a FILTER (see Date Comparisons ). The predicates of knora-api:DateValue ( knora-api:dateValueHasStartYear , etc.) are not available in Gravsearch.","title":"Filtering on Values in the Complex Schema"},{"location":"03-endpoints/api-v2/query-language/#date-comparisons","text":"In the simple schema, you can compare a date value directly with a knora-api:Date in a FILTER : ?book incunabula:pubdate ?pubdate . FILTER(?pubdate < \"JULIAN:1497\"^^knora-api:Date) In the complex schema, you must use the function knora-api:toSimpleDate , passing it the variable representing the date value. The date literal used in the comparison must still be a knora-api:Date in the simple schema. This is the only case in which you can use both schemas in a single query: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true . ?book incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book . ?book incunabula:pubdate ?pubdate . FILTER(knora-api:toSimpleDate(?pubdate) < \"JULIAN:1497\"^^knora-api-simple:Date) } ORDER BY ?pubdate You can also use knora-api:toSimpleDate with to search for date tags in standoff text markup (see Matching Standoff Dates ). Note that the given date value for comparison must have the following format: ``` (GREGORIAN|JULIAN|ISLAMIC):\\d{1,4}(-\\d{1,2}(-\\d{1,2})?)?( BC| AD| BCE| CE)?(:\\d{1,4}(-\\d{1,2}(-\\d{1,2})?)?( BC| AD| BCE| CE)?)? ``` E.g. an exact date like GREGORIAN:2015-12-03 or a period like GREGORIAN:2015-12-03:2015-12-04 . Dates may also have month or year precision, e.g. ISLAMIC:1407-02 (the whole month of december) or JULIAN:1330 (the whole year 1330). An optional ERA indicator term ( BCE , CE , or BC , AD ) can be added to the date, when no era is provided the default era AD will be considered. Era can be given as GREGORIAN:1220 BC or in range as GREGORIAN:600 BC:480 BC .","title":"Date Comparisons"},{"location":"03-endpoints/api-v2/query-language/#searching-for-matching-words","text":"The function knora-api:matchText searches for matching words anywhere in a text value, and is implemented using a full-text search index if available. The first argument must represent a text value (a knore-api:TextValue in the complex schema, or an xsd:string in the simple schema). The second argument is a string literal containing the words to be matched, separated by spaces. The function supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. This function can only be used as the top-level expression in a FILTER . For example, to search for titles that contain the words 'Zeitgl\u00f6cklein' and 'Lebens': ?book incunabule:title ?title . FILTER knora-api:matchText(?title, \"Zeitgl\u00f6cklein Lebens\")","title":"Searching for Matching Words"},{"location":"03-endpoints/api-v2/query-language/#filtering-text-by-language","text":"To filter a text value by language in the simple schema, use the SPARQL lang function on the text value, e.g.: FILTER(lang(?text) = \"fr\") In the complex schema, the lang function is not supported. Use the text value's knora-api:textValueHasLanguage predicate instead: ?text knora-api:textValueHasLanguage \"fr\" .","title":"Filtering Text by Language"},{"location":"03-endpoints/api-v2/query-language/#regular-expressions","text":"The SPARQL regex function is supported. In the simple schema, you can use it directly on the text value, e.g. ?book incunabula:title ?title . FILTER regex(?title, \"Zeit\", \"i\") In the complex schema, use it on the object of the text value's knora-api:valueAsString predicate: ?book incunabula:title ?title . ?title knora-api:valueAsString ?titleStr . FILTER regex(?titleStr, \"Zeit\", \"i\")","title":"Regular Expressions"},{"location":"03-endpoints/api-v2/query-language/#searching-for-text-markup","text":"To refer to standoff markup in text values, you must write your query in the complex schema. A knora-api:TextValue can have the property knora-api:textValueHasStandoff , whose objects are the standoff markup tags in the text. You can match the tags you're interested in using rdf:type or other properties of each tag.","title":"Searching for Text Markup"},{"location":"03-endpoints/api-v2/query-language/#matching-text-in-a-standoff-tag","text":"The function knora-api:matchTextInStandoff searches for standoff tags containing certain terms. The implementation is optimised using the full-text search index if available. The function takes three arguments: A variable representing a text value. A variable representing a standoff tag. A string literal containing space-separated search terms. This function can only be used as the top-level expression in a FILTER . For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffParagraphTag . ?standoffParagraphTag a standoff:StandoffParagraphTag . FILTER knora-api:matchTextInStandoff(?text, ?standoffParagraphTag, \"Grund Richtigkeit\") } Here we are looking for letters containing the words \"Grund\" and \"Richtigkeit\" within a single paragraph.","title":"Matching Text in a Standoff Tag"},{"location":"03-endpoints/api-v2/query-language/#matching-standoff-links","text":"If you are only interested in specifying that a resource has some text value containing a standoff link to another resource, the most efficient way is to use the property knora-api:hasStandoffLinkTo , whose subjects and objects are resources. This property is automatically maintained by the API. For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?letter knora-api:hasStandoffLinkTo ?person . ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . } Here we are looking for letters containing a link to the historian Claude Jordan, who is identified by his Integrated Authority File identifier, (VIAF)271899510 . However, if you need to specify the context in which the link tag occurs, you must use the function knora-api:standoffLink . It takes three arguments: A variable or IRI representing the resource that is the source of the link. A variable representing the standoff link tag. A variable or IRI representing the resource that is the target of the link. This function can only be used as the top-level expression in a FILTER . For example: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffLinkTag . ?standoffLinkTag a knora-api:StandoffLinkTag . FILTER knora-api:standoffLink(?letter, ?standoffLinkTag, ?person) ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . ?standoffLinkTag knora-api:standoffTagHasStartParent ?standoffItalicTag . ?standoffItalicTag a standoff:StandoffItalicTag . } This has the same effect as the previous example, except that because we are matching the link tag itself, we can specify that its immediate parent is a StandoffItalicTag . If you actually want to get the target of the link (in this example, ?person ) in the search results, you need to add a statement like ?letter knora-api:hasStandoffLinkTo ?person . to the WHERE clause and to the CONSTRUCT clause: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasText ?text . ?letter knora-api:hasStandoffLinkTo ?person . } WHERE { ?letter a beol:letter . ?letter beol:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffLinkTag . ?standoffLinkTag a knora-api:StandoffLinkTag . FILTER knora-api:standoffLink(?letter, ?standoffLinkTag, ?person) ?person a beol:person . ?person beol:hasIAFIdentifier ?iafIdentifier . ?iafIdentifier knora-api:valueAsString \"(VIAF)271899510\" . ?standoffLinkTag knora-api:standoffTagHasStartParent ?standoffItalicTag . ?standoffItalicTag a standoff:StandoffItalicTag . ?letter knora-api:hasStandoffLinkTo ?person . }","title":"Matching Standoff Links"},{"location":"03-endpoints/api-v2/query-language/#matching-standoff-dates","text":"You can use the knora-api:toSimpleDate function (see @ref Date Comparisons ) to match dates in standoff date tags, i.e. instances of knora-api:StandoffDateTag or of one of its subclasses. For example, here we are looking for a text containing an anything:StandoffEventTag (which is a project-specific subclass of knora-api:StandoffDateTag ) representing an event that occurred sometime during the month of December 2016: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasText ?text . } WHERE { ?thing a anything:Thing . ?thing anything:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffEventTag . ?standoffEventTag a anything:StandoffEventTag . FILTER(knora-api:toSimpleDate(?standoffEventTag) = \"GREGORIAN:2016-12 CE\"^^knora-api-simple:Date) }","title":"Matching Standoff Dates"},{"location":"03-endpoints/api-v2/query-language/#matching-ancestor-tags","text":"Suppose we want to search for a standoff date in a paragraph, but we know that the paragraph tag might not be the immediate parent of the date tag. For example, the date tag might be in an italics tag, which is in a paragraph tag. In that case, we can use the inferred property knora-api:standoffTagHasStartAncestor . We can modify the previous example to do this: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX standoff: <http://api.knora.org/ontology/standoff/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> PREFIX knora-api-simple: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasText ?text . } WHERE { ?thing a anything:Thing . ?thing anything:hasText ?text . ?text knora-api:textValueHasStandoff ?standoffDateTag . ?standoffDateTag a knora-api:StandoffDateTag . FILTER(knora-api:toSimpleDate(?standoffDateTag) = \"GREGORIAN:2016-12-24 CE\"^^knora-api-simple:Date) ?standoffDateTag knora-api:standoffTagHasStartAncestor ?standoffParagraphTag . ?standoffParagraphTag a standoff:StandoffParagraphTag . }","title":"Matching Ancestor Tags"},{"location":"03-endpoints/api-v2/query-language/#filtering-on-rdfslabel","text":"The rdfs:label of a resource is not a DSP-API value, but you can still search for it. This can be done in the same ways in the simple or complex schema: Using a string literal object: ?book rdfs:label \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . Using a variable and a FILTER: ?book rdfs:label ?label . FILTER(?label = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") Using the regex function: ?book rdfs:label ?bookLabel . FILTER regex(?bookLabel, \"Zeit\", \"i\") To match words in an rdfs:label using the full-text search index, use the knora-api:matchLabel function, which works like knora-api:matchText , except that the first argument is a variable representing a resource: FILTER knora-api:matchLabel(?book, \"Zeitgl\u00f6cklein\")","title":"Filtering on rdfs:label"},{"location":"03-endpoints/api-v2/query-language/#filtering-on-resource-iris","text":"A FILTER can compare a variable with another variable or IRI representing a resource. For example, to find a letter whose author and recipient are different persons: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . } WHERE { ?letter a beol:letter . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . FILTER(?person1 != ?person2) . } OFFSET 0 To find a letter whose author is not a person with a specified IRI: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . } WHERE { ?letter a beol:letter . ?letter beol:hasAuthor ?person1 . ?letter beol:hasRecipient ?person2 . FILTER(?person1 != <http://rdfh.ch/0801/F4n1xKa3TCiR4llJeElAGA>) . } OFFSET 0","title":"Filtering on Resource IRIs"},{"location":"03-endpoints/api-v2/query-language/#construct-clause","text":"In the CONSTRUCT clause of a Gravsearch query, the variable representing the main resource must be indicated with knora-api:isMainResource true . Exactly one variable representing a resource must be marked in this way. Any other statements in the CONSTRUCT clause must also be present in the WHERE clause. If a variable representing a resource or value is used in the WHERE clause but not in the CONSTRUCT clause, the matching resources or values will not be included in the results. If the query is written in the complex schema, all variables in the CONSTRUCT clause must refer to DSP-API resources, DSP-API values, or properties. Data below the level of values may not be mentioned in the CONSTRUCT clause. Predicates from the rdf , rdfs , and owl ontologies may not be used in the CONSTRUCT clause. The rdfs:label of each matching resource is always returned, so there is no need to mention it in the query.","title":"CONSTRUCT Clause"},{"location":"03-endpoints/api-v2/query-language/#gravsearch-by-example","text":"In this section, we provide some sample queries of different complexity to illustrate the usage of Gravsearch.","title":"Gravsearch by Example"},{"location":"03-endpoints/api-v2/query-language/#getting-all-the-components-of-a-compound-resource","text":"In order to get all the components of a compound resource, the following Gravsearch query can be sent to the API. In this case, the compound resource is an incunabula:book identified by the IRI http://rdfh.ch/0803/c5058f3a and the components are of type incunabula:page (test data for the Incunabula project). Since inference is assumed, we can use knora-api:StillImageRepresentation ( incunabula:page is one of its subclasses). This makes the query more generic and allows for reuse (for instance, a client would like to query different types of compound resources defined in different ontologies). ORDER BY is used to sort the components by their sequence number. OFFSET is set to 0 to get the first page of results. PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?component knora-api:isMainResource true . # marking of the component searched for as the main resource, required ?component knora-api:seqnum ?seqnum . # return the sequence number in the response ?component knora-api:hasStillImageFileValue ?file . # return the StillImageFile in the response } WHERE { ?component a knora-api:StillImageRepresentation . # restriction of the type of component ?component knora-api:isPartOf <http://rdfh.ch/0803/c5058f3a> . # component relates to a compound resource via this property ?component knora-api:seqnum ?seqnum . # component must have a sequence number ?component knora-api:hasStillImageFileValue ?file . # component must have a StillImageFile } ORDER BY ASC(?seqnum) # order by sequence number, ascending OFFSET 0 # get first page of results The incunabula:book with the IRI http://rdfh.ch/0803/c5058f3a has 402 pages. (This result can be obtained by doing a count query; see Submitting Gravsearch Queries .) However, with OFFSET 0 , only the first page of results is returned. The same query can be sent again with OFFSET 1 to get the next page of results, and so forth. When a page of results is not full (see settings in app/v2 in application.conf ) or is empty, no more results are available. By design, it is not possible for the client to get more than one page of results at a time; this is intended to prevent performance problems that would be caused by huge responses. A client that wants to download all the results of a query must request each page sequentially. Let's assume the client is not interested in all of the book's pages, but just in first ten of them. In that case, the sequence number can be restricted using a FILTER that is added to the query's WHERE clause: FILTER (?seqnum <= 10) The first page starts with sequence number 1, so with this FILTER only the first ten pages are returned. This query would be exactly the same in the complex schema, except for the expansion of the knora-api prefix: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#>","title":"Getting All the Components of a Compound Resource"},{"location":"03-endpoints/api-v2/query-language/#traversing-multiple-links","text":"Here we are looking for regions of pages that are part of books that have a particular title. In the simple schema: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?region knora-api:isMainResource true ; knora-api:isRegionOf ?page . ?page incunabula:partOf ?book . ?book incunabula:title ?title . } WHERE { ?region a knora-api:Region ; knora-api:isRegionOf ?page . ?page a incunabula:page ; incunabula:partOf ?book . ?book incunabula:title ?title . FILTER(?title = \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\") } In the complex schema: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?region knora-api:isMainResource true ; knora-api:isRegionOf ?page . ?page incunabula:partOf ?book . ?book incunabula:title ?title . } WHERE { ?region a knora-api:Region ; knora-api:isRegionOf ?page . ?page a incunabula:page ; incunabula:partOf ?book . ?book incunabula:title ?title . ?title knora-api:valueAsString \"Zeitgl\u00f6cklein des Lebens und Leidens Christi\" . } If we remove the line ?book incunabula:title ?title . from the CONSTRUCT clause, so that the CONSTRUCT clause no longer mentions ?title , the response will contain the same matching resources, but the titles of those resources will not be included in the response.","title":"Traversing Multiple Links"},{"location":"03-endpoints/api-v2/query-language/#requesting-a-graph-starting-with-a-known-resource","text":"Here the IRI of the main resource is already known, and we want specific information about it, as well as about related resources. In this case, the IRI of the main resource must be assigned to a variable using BIND : PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?letter knora-api:isMainResource true ; beol:creationDate ?date ; ?linkingProp1 ?person1 . ?person1 beol:hasFamilyName ?familyName . } WHERE { BIND(<http://rdfh.ch/0801/_B3lQa6tSymIq7_7SowBsA> AS ?letter) ?letter a beol:letter ; beol:creationDate ?date ; ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient) ?person1 beol:hasFamilyName ?familyName . } ORDER BY ?date This query would be the same in the complex schema, except for the prefix expansions: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#>","title":"Requesting a Graph Starting with a Known Resource"},{"location":"03-endpoints/api-v2/query-language/#searching-for-a-list-value-referring-to-a-particular-list-node","text":"Since list nodes are represented by their Iri in the complex schema, uniqueness is guranteed (as opposed to the simple schema). Also all the subnodes of the given list node are considered a match. PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasListItem ?listItem . } WHERE { ?thing anything:hasListItem ?listItem . ?listItem knora-api:listValueAsListNode <http://rdfh.ch/lists/0001/treeList02> . }","title":"Searching for a List Value Referring to a Particular List Node"},{"location":"03-endpoints/api-v2/query-language/#type-inference","text":"Gravsearch needs to be able to determine the types of the entities that query variables and IRIs refer to in the WHERE clause. In most cases, it can infer these from context and from the ontologies used. In particular, it needs to know: The type of the subject and object of each statement. The type that is expected as the object of each predicate.","title":"Type Inference"},{"location":"03-endpoints/api-v2/query-language/#type-annotations","text":"When one or more types cannot be inferred, Gravsearch will return an error message indicating the entities for which it could not determine types. The missing information must then be given by adding type annotations to the query. This can always done by adding statements with the predicate rdf:type . The subject must be a resource or value, and the object must either be knora-api:Resource (if the subject is a resource) or the subject's specific type (if it is a value). For example, consider this query that uses a non-DSP property: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book dcterms:title ?title . } This produces the error message: The types of one or more entities could not be determined: ?book, <http://purl.org/dc/terms/title>, ?title To solve this problem, it is enough to specify the types of ?book and ?title ; the type of the expected object of dcterms:title can then be inferred from the type of ?title . PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book rdf:type incunabula:book ; dcterms:title ?title . ?title rdf:type xsd:string . } It would also be possible to annotate the property itself, using the predicate knora-api:objectType ; then the type of ?title would be inferred: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX dcterms: <http://purl.org/dc/terms/> CONSTRUCT { ?book knora-api:isMainResource true ; dcterms:title ?title . } WHERE { ?book rdf:type incunabula:book ; dcterms:title ?title . dcterms:title knora-api:objectType xsd:string . } Note that it only makes sense to use dcterms:title in the simple schema, because its object is supposed to be a literal. Here is another example, using a non-DSP class: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT { ?person knora-api:isMainResource true . } WHERE { ?person a foaf:Person . ?person foaf:familyName ?familyName . FILTER(?familyName = \"Meier\") } This produces the error message: Types could not be determined for one or more entities: ?person The solution is to specify that ?person is a knora-api:Resource : PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX foaf: <http://xmlns.com/foaf/0.1/> CONSTRUCT { ?person knora-api:isMainResource true . } WHERE { ?person a foaf:Person . ?person a knora-api:Resource . ?person foaf:familyName ?familyName . FILTER(?familyName = \"Meier\") }","title":"Type Annotations"},{"location":"03-endpoints/api-v2/query-language/#inconsistent-types","text":"Gravsearch will also reject a query if an entity is used with inconsistent types. For example: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true ; incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book ; incunabula:pubdate ?pubdate . FILTER(?pubdate = \"JULIAN:1497-03-01\") . } This returns the error message: One or more entities have inconsistent types: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#pubdate> knora-api:objectType <http://api.knora.org/ontology/knora-api/simple/v2#Date> ; knora-api:objectType <http://www.w3.org/2001/XMLSchema#string> . ?pubdate rdf:type <http://api.knora.org/ontology/knora-api/simple/v2#Date> ; rdf:type <http://www.w3.org/2001/XMLSchema#string> . This is because the incunabula ontology says that the object of incunabula:pubdate must be a knora-api:Date , but the FILTER expression compares ?pubdate with an xsd:string . The solution is to specify the type of the literal in the FILTER : PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?book knora-api:isMainResource true ; incunabula:pubdate ?pubdate . } WHERE { ?book a incunabula:book ; incunabula:pubdate ?pubdate . FILTER(?pubdate = \"JULIAN:1497-03-01\"^^knora-api:Date) . }","title":"Inconsistent Types"},{"location":"03-endpoints/api-v2/query-language/#scoping-issues","text":"SPARQL is evaluated from the bottom up . A UNION block therefore opens a new scope, in which variables bound at higher levels are not necessarily in scope. This can cause unexpected results if queries are not carefully designed. Gravsearch tries to prevent this by rejecting queries in the following cases.","title":"Scoping Issues"},{"location":"03-endpoints/api-v2/query-language/#filter-in-union","text":"A FILTER in a UNION block can only use variables that are bound in the same block, otherwise the query will be rejected. This query is invalid because ?text is not bound in the UNION block containing the FILTER where the variable is used: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX mls: <http://0.0.0.0:3333/ontology/0807/mls/simple/v2#> CONSTRUCT { ?lemma knora-api:isMainResource true . ?lemma mls:hasLemmaText ?text . } WHERE { ?lemma a mls:Lemma . ?lemma mls:hasLemmaText ?text . { ?lemma mls:hasPseudonym ?pseudo . FILTER regex(?pseudo, \"Abel\", \"i\") . } UNION { FILTER regex(?text, \"Abel\", \"i\") . } } ORDER BY ASC(?text) OFFSET 0 It can be corrected like this: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX mls: <http://0.0.0.0:3333/ontology/0807/mls/simple/v2#> CONSTRUCT { ?lemma knora-api:isMainResource true . ?lemma mls:hasLemmaText ?text . } WHERE { ?lemma a mls:Lemma . ?lemma mls:hasLemmaText ?text . { ?lemma mls:hasPseudonym ?pseudo . FILTER regex(?pseudo, \"Abel\", \"i\") . } UNION { ?lemma mls:hasLemmaText ?text . FILTER regex(?text, \"Abel\", \"i\") . } } ORDER BY ASC(?text) OFFSET 0","title":"FILTER in UNION"},{"location":"03-endpoints/api-v2/query-language/#order-by","text":"A variable used in ORDER BY must be bound at the top level of the WHERE clause. This query is invalid, because ?int is not bound at the top level of the WHERE clause: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasInteger ?int . ?thing anything:hasRichtext ?richtext . ?thing anything:hasText ?text . } WHERE { ?thing a knora-api:Resource . ?thing a anything:Thing . { ?thing anything:hasRichtext ?richtext . FILTER knora-api:matchText(?richtext, \"test\") ?thing anything:hasInteger ?int . } UNION { ?thing anything:hasText ?text . FILTER knora-api:matchText(?text, \"test\") ?thing anything:hasInteger ?int . } } ORDER BY (?int) It can be corrected like this: PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . ?thing anything:hasInteger ?int . ?thing anything:hasRichtext ?richtext . ?thing anything:hasText ?text . } WHERE { ?thing a knora-api:Resource . ?thing a anything:Thing . ?thing anything:hasInteger ?int . { ?thing anything:hasRichtext ?richtext . FILTER knora-api:matchText(?richtext, \"test\") } UNION { ?thing anything:hasText ?text . FILTER knora-api:matchText(?text, \"test\") } } ORDER BY (?int)","title":"ORDER BY"},{"location":"03-endpoints/api-v2/query-language/#query-optimization-by-dependency","text":"The query performance of triplestores, such as Fuseki, is highly dependent on the order of query patterns. To improve performance, Gravsearch automatically reorders the statement patterns in the WHERE clause according to their dependencies on each other, to minimise the number of possible matches for each pattern. Consider the following Gravsearch query: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol:creationDate ?date . } WHERE { ?letter beol:creationDate ?date . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?person1 beol:hasIAFIdentifier ?gnd1 . ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?person2 beol:hasIAFIdentifier ?gnd2 . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . } ORDER BY ?date Gravsearch optimises the performance of this query by moving these statements to the top of the WHERE clause: ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . The rest of the WHERE clause then reads: ?person1 beol:hasIAFIdentifier ?gnd1 . ?person2 beol:hasIAFIdentifier ?gnd2 . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?letter beol:creationDate ?date .","title":"Query Optimization by Dependency"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/","text":"Reading and Searching Resources To retrieve an existing resource, the HTTP method GET has to be used. Reading resources may require authentication, since some resources may have restricted viewing permissions. Responses Describing Resources Resources can be returned in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation (see Response Formats ). Operations for reading and searching resources can return responses in either the simple or the complex ontology schema. The complex schema is used by default. To receive a response in the simple schema, use the HTTP request header or URL parameter described in API Schema . Each DSP-API v2 response describing one or more resources returns a single RDF graph. For example, a request for a single resource returns that resource and all its values. In a full-text search, the resource is returned with the values that matched the search criteria. A response to an extended search may represent a whole graph of interconnected resources. In JSON-LD, if only one resource is returned, it is the top-level object; if more than one resource is returned, they are represented as an array of objects of the @graph member of the top-level object (see Named Graphs in the JSON-LD specification). In the complex schema, dependent resources, i.e. resources that are referred to by other resources on the top level, are nested in link value objects. If resources on the top level are referred to by other resources and these links are part of the response, virtual incoming links are generated; see Gravsearch: Virtual Graph Search ). See the interfaces Resource and ResourcesSequence in module ResourcesResponse (exists for both API schemas: ApiV2Simple and ApiV2WithValueObjects ). Text Markup Options Text markup can be returned in one of two ways: As XML embedded in the response, using an XML to Standoff Mapping . As standoff/RDF , which is DSP-API's internal markup representation. Embedded XML is the default. Requesting Text Markup as XML When requesting a text value with standoff mark up, there are three possibilities: The text value uses standard mapping. The text value uses a custom mapping which does not specify an XSL transformation. The text value uses a custom mapping which specifies an XSL transformation. In the first case, the mapping will be defined as: \"kb:textValueHasMapping\": { \"@id\": \"http://rdfh.ch/standoff/mappings/StandardMapping\" } the text value will only be available as kb:textValueAsXml , which will be of the following structure: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text documentType=\"html\"> ... </text> where the content of <text> is a limited set of HTML tags that can be handled by CKEditor in DSP-APP. This allows for both displaying and editing the text value. In the second and third case, kb:textValueHasMapping will point to the custom mapping that may or may not specify an XSL transformation. If no transformation is specified (second case), the text value will be returned only as kb:textValueAsXml . This property will be a string containing the contents of the initially uploaded XML. Note: The returned XML document is equivalent to the uploaded document but it is not necessarily identical - the order of the attributes in one element may vary from the original. In the third case, when a transformation is specified, both kb:textValueAsXml and kb:textValueAsHtml will be returned. kb:textValueAsHtml is the result of the XSL transformation applied to kb:textValueAsXml . The HTML representation is intended to display the text value in a human readable and properly styled way, while the XML representation can be used to update the text value. Requesting Text Markup as Standoff Implementation of support for standoff/RDF in API v2 is in its early stages; its use is currently discouraged. The basic procedure works like this: First, request a resource in the complex schema , using any relevant API v2 route, submitting the string standoff as the value of either: the HTTP header X-Knora-Accept-Markup the URL parameter markup If a text value in the resource contains markup, the text value will look something like this: { \"@id\" : \"http://rdfh.ch/0001/LK-wKXDNQJaRHOf0F0aJ2g/values/1Er1OpVwQR2u6peTwyNpJw\", \"@type\" : \"knora-api:TextValue\", \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V knora-admin:UnknownUser\", \"knora-api:textValueHasMarkup\" : true, \"knora-api:textValueHasMaxStandoffStartIndex\" : 6737, \"knora-api:userHasPermission\" : \"CR\", \"knora-api:valueAsString\" : \"\\nHamlet\\nACT I\\nSCENE I. Elsinore. A platform before the castle...\", \"knora-api:valueCreationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-05-08T17:08:32.158401Z\" } } The object knora-api:valueAsString contains the text without markup. The predicate knora-api:textValueHasMarkup indicates that the text value has markup, and the value of the predicate knora-api:textValueHasMaxStandoffStartIndex gives the start index of the last standoff tag; this gives the client some idea of how much markup there is. You can then request the text value's standoff/RDF, which is returned in pages of a limited size. To get each page: HTTP GET to http://host/v2/standoff/RESOURCE_IRI/TEXT_VALUE_IRI/OFFSET Both RESOURCE_IRI and TEXT_VALUE_IRI must be URL-encoded. The offset is an integer whose initial value is 0. The response will look like this: { \"@graph\" : [ { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffRootTag\", \"knora-api:standoffTagHasEnd\" : 184716, \"knora-api:standoffTagHasStart\" : 0, \"knora-api:standoffTagHasStartIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"sbBzeAaNTzaUXl90UtlYzw\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader1Tag\", \"knora-api:standoffTagHasEnd\" : 7, \"knora-api:standoffTagHasStart\" : 1, \"knora-api:standoffTagHasStartIndex\" : 1, \"knora-api:standoffTagHasStartParentIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"HhXjcdSTS_G6eSQ0apdjUw\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader3Tag\", \"knora-api:standoffTagHasEnd\" : 14, \"knora-api:standoffTagHasStart\" : 9, \"knora-api:standoffTagHasStartIndex\" : 2, \"knora-api:standoffTagHasStartParentIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"Ymr2aDUqTx6nMwGZGiqduA\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader3Tag\", \"knora-api:standoffTagHasEnd\" : 64, \"knora-api:standoffTagHasStart\" : 16, \"knora-api:standoffTagHasStartIndex\" : 3, \"knora-api:standoffTagHasStartParentIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"_Zk0B1edRK6mgdtokmosXg\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffBlockquoteTag\", \"knora-api:standoffTagHasEnd\" : 112, \"knora-api:standoffTagHasStart\" : 66, \"knora-api:standoffTagHasStartIndex\" : 4, \"knora-api:standoffTagHasStartParentIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"1DLdI0LJTCy07w6ZsOM_Sg\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffItalicTag\", \"knora-api:standoffTagHasEnd\" : 111, \"knora-api:standoffTagHasStart\" : 67, \"knora-api:standoffTagHasStartIndex\" : 5, \"knora-api:standoffTagHasStartParentIndex\" : 4, \"knora-api:standoffTagHasUUID\" : \"XJ6GVO1VQSqrTyLHGnHqcA\" } ], \"knora-api:nextStandoffStartIndex\" : 100, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } See Text with Standoff Markup for details of the predicates in each standoff tag. If there are more pages of standoff to be requested, the response will contain knora-api:nextStandoffStartIndex , whose object should be submitted as the next OFFSET to the same route. This continues until you receive a response without knora-api:nextStandoffStartIndex . Get the Representation of a Resource by IRI Get a Full Representation of a Resource by IRI A full representation of resource can be obtained by making a GET request to the API providing its IRI. Because a Knora IRI has the format of a URL, its IRI has to be URL-encoded. To get the resource with the IRI http://rdfh.ch/c5058f3a (a book from the sample Incunabula project, which is included in the Knora API server's test data), make a HTTP GET request to the resources route (path segment resources in the API call) and append the URL-encoded IRI: HTTP GET to http://host/v2/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a If necessary, several resources can be queried at the same time, their IRIs separated by slashes. Please note that the amount of resources that can be queried in one requested is limited. See the settings for app/v2 in application.conf . More formally, the URL looks like this: HTTP GET to http://host/v2/resources/resourceIRI(/anotherResourceIri)* Get a Full Representation of a Version of a Resource by IRI To get a specific past version of a resource, use the route described in Get a Full Representation of a Resource by IRI , and add the URL parameter ?version=TIMESTAMP , where TIMESTAMP is an xsd:dateTimeStamp in the UTC timezone. The timestamp can either be URL-encoded, or submitted with all punctuation ( - , : , and . ) removed (this is to accept timestamps from Knora's ARK URLs ). The resource will be returned with the values that it had at the specified time. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), the current metadata will be returned. Each value will be returned with the permissions that are attached to the current version of the value (see Permissions ). The returned resource will include the predicate knora-api:versionDate , containing the timestamp that was submitted, and its knora-api:versionArkUrl (see Resource Permalinks ) will contain the same timestamp. Get a Value in a Resource To get a specific value of a resource, use this route: HTTP GET to http://host/v2/values/resourceIRI/valueUUID The resource IRI must be URL-encoded. The path element valueUUID is the string object of the value's knora-api:valueHasUUID . The value will be returned within its containing resource, in the same format as for Responses Describing Resources , but without any of the resource's other values. Get a Version of a Value in a Resource To get a particular version of a specific value of a resource, use the route described in Get a Value in a Resource , and add the URL parameter ?version=TIMESTAMP , where TIMESTAMP is an xsd:dateTimeStamp in the UTC timezone. The timestamp can either be URL-encoded, or submitted with all punctuation ( - , : , and . ) removed (this is to accept timestamps from Knora's ARK URLs ). The value will be returned within its containing resource, in the same format as for Responses Describing Resources , but without any of the resource's other values. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), the current resource metadata will be returned. The value will be returned with the permissions that are attached to its current version (see Permissions ). Get the Version History of a Resource To get a list of the changes that have been made to a resource since its creation, use this route: HTTP GET to http://host/v2/resources/history/resourceIRI[?startDate=START_DATE&endDate=END_DATE] The resource IRI must be URL-encoded. The start and end dates are optional, and are URL-encoded timestamps in xsd:dateTimeStamp format. The start date is inclusive, and the end date is exclusive. If the start date is not provided, the resource's history since its creation is returned. If the end date is not provided, the resource's history up to the present is returned. The response is a list of changes made to the resource, in reverse chronological order. Each entry has the properties knora-api:author (the IRI of the user who made the change) and knora-api:versionDate (the date when the change was made). For example: { \"@graph\" : [ { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-02-11T09:05:10Z\" } }, { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-02-10T10:30:10Z\" } }, { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-02-10T10:05:10Z\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The entries include all the dates when the resource's values were created or modified (within the requested date range), as well as the date when the resource was created (if the requested date range allows it). Each date is included only once. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), changes to a resource's metadata are not included in its version history. To request the resource as it was at each of these dates, see Get a Full Representation of a Version of a Resource by IRI . For consistency in citation, we recommend using these dates when requesting resource versions. Get the preview of a resource by IRI In some cases, the client may only want to request the preview of a resource, which just provides its metadata (e.g. its IRI, rdfs:label , and type), without its values. This works exactly like making a conventional resource request, using the path segment resourcespreview : HTTP GET to http://host/v2/resourcespreview/resourceIRI(/anotherResourceIri)* Get a Graph of Resources Knora can return a graph of connections between resources, e.g. for generating a network diagram. HTTP GET to http://host/v2/graph/resourceIRI[depth=Integer] [direction=outbound|inbound|both][excludeProperty=propertyIri] The first parameter must be preceded by a question mark ? , any following parameter by an ampersand & . depth must be at least 1. The maximum depth is an Knora configuration setting. The default is 4. direction specifies the direction of the links to be queried, i.e. links to and/or from the given resource. The default is outbound . excludeProperty is an optional link property to be excluded from the results. To accommodate large graphs, the graph response format is very concise, and is therefore simpler than the usual resources response format. Each resource represented only by its IRI, class, and label. Direct links are shown instead of link values. For example: { \"@graph\" : [ { \"@id\" : \"http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ\", \"@type\" : \"anything:Thing\", \"rdfs:label\" : \"Sierra\" }, { \"@id\" : \"http://rdfh.ch/0001/A67ka6UQRHWf313tbhQBjw\", \"@type\" : \"anything:Thing\", \"rdfs:label\" : \"Victor\" }, { \"@id\" : \"http://rdfh.ch/0001/Lz7WEqJETJqqsUZQYexBQg\", \"@type\" : \"anything:Thing\", \"rdfs:label\" : \"Foxtrot\" }, { \"@id\" : \"http://rdfh.ch/0001/WLSHxQUgTOmG1T0lBU2r5w\", \"@type\" : \"anything:Thing\", \"anything:hasOtherThing\" : { \"@id\" : \"http://rdfh.ch/0001/A67ka6UQRHWf313tbhQBjw\" }, \"rdfs:label\" : \"Tango\" }, { \"@id\" : \"http://rdfh.ch/0001/start\", \"@type\" : \"anything:Thing\", \"anything:hasOtherThing\" : [ { \"@id\" : \"http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ\" }, { \"@id\" : \"http://rdfh.ch/0001/WLSHxQUgTOmG1T0lBU2r5w\" }, { \"@id\" : \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\" } ], \"rdfs:label\" : \"Romeo\" }, { \"@id\" : \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\", \"@type\" : \"anything:Thing\", \"anything:hasOtherThing\" : { \"@id\" : \"http://rdfh.ch/0001/Lz7WEqJETJqqsUZQYexBQg\" }, \"rdfs:label\" : \"Echo\" } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } } Search for Resources Search for a Resource by its rdfs:label Knora offers the possibility to search for resources by their rdfs:label . The use case for this search is to find a specific resource as you type. E.g., the user wants to get a list of resources whose rdfs:label contain some search terms separated by a whitespace character: Zeit Zeitg ... Zeitgl\u00f6cklein d ... Zeitgl\u00f6cklein des Lebens With each character added to the last term, the selection gets more specific. The first term should at least contain three characters. To make this kind of \"search as you type\" possible, a wildcard character is automatically added to the last search term. Characters provided by the user that have a special meaning in the Lucene Query Parser syntax are replaced by a whitespace character for this search. If a user types \"Zeit-Gl\u00f6cklein\" it is interpreted as \"Zeit Gl\u00f6cklein\". Whitespace is normalized afterwards. The special characters that are replaced are: + , - , & , | , ! , ( , ) , [ , ] , { , } , ^ , \" , ~ , * , ? , : , \\ If the rdfs:label of a resource contains a special character, it is found nonetheless. HTTP GET to http://host/v2/searchbylabel/searchValue[limitToResourceClass=resourceClassIRI] [limitToProject=projectIRI][offset=Integer] The first parameter must be preceded by a question mark ? , any following parameter by an ampersand & . The default value for the parameter offset is 0, which returns the first page of search results. Subsequent pages of results can be fetched by increasing offset by one. The amount of results per page is defined in app/v2 in application.conf . For performance reasons, standoff markup is not queried for this route. To request the number of results rather than the results themselves, you can do a count query: HTTP GET to http://host/v2/searchbylabel/count/searchValue[limitToResourceClass=resourceClassIRI][limitToProject=projectIRI][offset=Integer] The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value. Full-text Search Knora offers a full-text search that searches through all textual representations of values and rdfs:label of resources. Full-text search supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. Please note that the search terms have to be URL-encoded. HTTP GET to http://host/v2/search/searchValue[limitToResourceClass=resourceClassIRI] [limitToStandoffClass=standoffClassIri][limitToProject=projectIRI][offset=Integer] The first parameter has to be preceded by a question mark ? , any following parameter by an ampersand & . A search value must have a minimal length of three characters (default value) as defined in app/v2 in application.conf . A search term may contain wildcards. A ? represents a single character. It has to be URL-encoded as %3F since it has a special meaning in the URL syntax. For example, the term Uniform can be search for like this: HTTP GET to http://host/v2/search/Unif%3Frm A * represents zero, one or multiple characters. For example, the term Uniform can be searched for like this: HTTP GET to http://host/v2/search/Uni*m The default value for the parameter offset is 0 which returns the first page of search results. Subsequent pages of results can be fetched by increasing offset by one. The amount of results per page is defined in app/v2 in application.conf . If the parameter limitToStandoffClass is provided, Knora will look for search terms that are marked up with the indicated standoff class. If the parameter returnFiles=true is provided, Knora will return any file value attached to each matching resource. To request the number of results rather than the results themselves, you can do a count query: HTTP GET to http://host/v2/search/count/searchValue[limitToResourceClass=resourceClassIRI][limitToStandoffClass=standoffClassIri][limitToProject=projectIRI][offset=Integer] The first parameter has to be preceded by a question mark ? , any following parameter by an ampersand & . The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value. Gravsearch For more complex queries than a full-text search, Knora offers a query language called Gravsearch: Virtual Graph Search ). Support of TEI/XML To convert standoff markup to TEI/XML, see TEI/XML . IIIF Manifests This is an experimental feature and may change. To generate a IIIF manifest for a resource, containing the still image representations that have knora-api:isPartOf (or a subproperty) pointing to that resource: HTTP GET to http://host/v2/resources//iiifmanifest/RESOURCE_IRI Reading Resources by Class from a Project To facilitate the development of tabular user interfaces for data entry, it is possible to get a paged list of all the resources belonging to a particular class in a given project, sorted by the value of a property: HTTP GET to http://host/v2/resources?resourceClass=RESOURCE_CLASS_IRI&page=PAGE[&orderByProperty=PROPERTY_IRI] This is useful only if the project does not contain a large amount of data; otherwise, you should use Gravsearch to search using more specific criteria. The specified class and property are used without inference; they will not match subclasses or subproperties. The HTTP header X-Knora-Accept-Project must be submitted; its value is a Knora project IRI. In the request URL, the values of resourceClass and orderByProperty are URL-encoded IRIs in the complex schema . The orderByProperty parameter is optional; if it is not supplied, resources will be sorted alphabetically by resource IRI (an arbitrary but consistent order). The value of page is a 0-based integer page number. Paging works as it does in Gravsearch ). Get the Full History of a Resource and its Values as Events To get a list of the changes that have been made to a resource and its values since its creation as events ordered by date: HTTP GET to http://host/v2/resources/resourceHistoryEvents/<resourceIRI> The resource IRI must be URL-encoded. The response is a list of events describing changes made to the resource and its values, in chronological order. Each entry has the properties: knora-api:eventType (the type of the operation performed on a specific date. The operation can be either createdResource , updatedResourceMetadata , deletedResource , createdValue , updatedValueContent , updatedValuePermissions , or deletedValue .), knora-api:versionDate (the date when the change was made), knora-api:author (the IRI of the user who made the change), knora-api:eventBody (the information necessary to make the same request). For example, the following response contains the list of events describing the version history of the resource http://rdfh.ch/0001/thing-with-history ordered by date: { \"@graph\" : [ { \"knora-api:eventType\": \"createdResource\", \"knora-api:author\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\": { \"rdfs:label\": \"A thing with version history\", \"knora-api:resourceIri\": \"http://rdfh.ch/0001/thing-with-history\", \"knora-api:resourceClassIri\": \"http://www.knora.org/ontology/0001/anything#Thing\", \"knora-api:hasPermissions\": \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\", \"knora-api:creationDate\": { \"@value\": \"2019-02-08T15:05:10Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" } }, \"knora-api:versionDate\": { \"@value\": \"2019-02-08T15:05:10Z\", \"@type\": \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\": \"createdValue\", \"knora-api:author\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\": { \"knora-api:resourceIri\": \"http://rdfh.ch/0001/thing-with-history\", \"knora-api:resourceClassIri\": \"http://www.knora.org/ontology/0001/anything#Thing\", \"knora-api:valueCreationDate\": { \"@value\": \"2019-02-10T10:30:10Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-api:valueHasUUID\": \"IZGOjVqxTfSNO4ieKyp0SA\", \"knora-api:hasPermissions\": \"V knora-admin:UnknownUser|M knora-admin:ProjectMember\", \"@type\": \"knora-base:LinkValue\", \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\": { \"knora-api:linkValueHasTargetIri\": { \"@id\": \"http://rdfh.ch/0001/2qMtTWvVRXWMBcRNlduvCQ\" } }, \"rdf:Property\": \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\", \"@id\": \"http://rdfh.ch/0001/thing-with-history/values/3a\" }, \"knora-api:versionDate\": { \"@value\": \"2019-02-10T10:30:10Z\", \"@type\": \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\": \"updatedValueContent\", \"knora-api:author\": { \"@id\": \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:eventBody\": { \"knora-api:resourceIri\": \"http://rdfh.ch/0001/thing-with-history\", \"knora-api:resourceClassIri\": \"http://www.knora.org/ontology/0001/anything#Thing\" \"http://www.knora.org/ontology/0001/anything#hasText\": { \"knora-api:valueAsString\": \"two\" }, \"knora-api:valueCreationDate\": { \"@value\": \"2019-02-11T10:05:10Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-base:previousValue\": \"http://rdfh.ch/0001/thing-with-history/values/2a\", \"knora-api:valueHasUUID\": \"W5fm67e0QDWxRZumcXcs6g\", \"@type\": \"knora-base:TextValue\", \"rdf:Property\": \"http://www.knora.org/ontology/0001/anything#hasText\", \"@id\": \"http://rdfh.ch/0001/thing-with-history/values/2b\" }, \"knora-api:versionDate\": { \"@value\": \"2019-02-11T10:05:10Z\", \"@type\": \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\": \"deletedValue\", \"knora-api:author\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\": { \"knora-api:resourceIri\": \"http://rdfh.ch/0001/thing-with-history\", \"knora-api:resourceClassIri\": \"http://www.knora.org/ontology/0001/anything#Thing\", \"knora-base:previousValue\": \"http://rdfh.ch/0001/thing-with-history/values/3a\", \"knora-api:deleteDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"2019-02-13T09:00:10Z\" }, \"knora-api:isDeleted\": true, \"@type\": \"knora-base:LinkValue\", \"rdf:Property\": \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\", \"@id\": \"http://rdfh.ch/0001/thing-with-history/values/3b\" }, \"knora-api:versionDate\": { \"@value\": \"2019-02-13T09:00:10Z\", \"@type\": \"xsd:dateTimeStamp\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Since the history of changes made to the metadata of a resource is not part of resouce's version history, there are no events describing the changes on metadata elements like its rdfs:label or rdfs:comment . The only record depicting a change in a resource's metadata is the knora-api:lastModificationDate of the resource. Thus the event updatedResourceMetadata indicates a change in a resource's metadata, its knora-api:eventBody contains the payload needed to update the value of the resource's lastModificationDate , see modifying metadata of a resource . Get the Full History of all Resources of a Project as Events To get a list of the changes that have been made to the resources and their values of a project as events ordered by date: HTTP GET to http://host/v2/resources/projectHistoryEvents/<projectIRI> The project IRI must be URL-encoded. The response contains the resource history events of all resources that belong to the specified project.","title":"Reading and Searching Resources"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#reading-and-searching-resources","text":"To retrieve an existing resource, the HTTP method GET has to be used. Reading resources may require authentication, since some resources may have restricted viewing permissions.","title":"Reading and Searching Resources"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#responses-describing-resources","text":"Resources can be returned in JSON-LD , Turtle , or RDF/XML , using HTTP content negotiation (see Response Formats ). Operations for reading and searching resources can return responses in either the simple or the complex ontology schema. The complex schema is used by default. To receive a response in the simple schema, use the HTTP request header or URL parameter described in API Schema . Each DSP-API v2 response describing one or more resources returns a single RDF graph. For example, a request for a single resource returns that resource and all its values. In a full-text search, the resource is returned with the values that matched the search criteria. A response to an extended search may represent a whole graph of interconnected resources. In JSON-LD, if only one resource is returned, it is the top-level object; if more than one resource is returned, they are represented as an array of objects of the @graph member of the top-level object (see Named Graphs in the JSON-LD specification). In the complex schema, dependent resources, i.e. resources that are referred to by other resources on the top level, are nested in link value objects. If resources on the top level are referred to by other resources and these links are part of the response, virtual incoming links are generated; see Gravsearch: Virtual Graph Search ). See the interfaces Resource and ResourcesSequence in module ResourcesResponse (exists for both API schemas: ApiV2Simple and ApiV2WithValueObjects ).","title":"Responses Describing Resources"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#text-markup-options","text":"Text markup can be returned in one of two ways: As XML embedded in the response, using an XML to Standoff Mapping . As standoff/RDF , which is DSP-API's internal markup representation. Embedded XML is the default.","title":"Text Markup Options"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#requesting-text-markup-as-xml","text":"When requesting a text value with standoff mark up, there are three possibilities: The text value uses standard mapping. The text value uses a custom mapping which does not specify an XSL transformation. The text value uses a custom mapping which specifies an XSL transformation. In the first case, the mapping will be defined as: \"kb:textValueHasMapping\": { \"@id\": \"http://rdfh.ch/standoff/mappings/StandardMapping\" } the text value will only be available as kb:textValueAsXml , which will be of the following structure: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <text documentType=\"html\"> ... </text> where the content of <text> is a limited set of HTML tags that can be handled by CKEditor in DSP-APP. This allows for both displaying and editing the text value. In the second and third case, kb:textValueHasMapping will point to the custom mapping that may or may not specify an XSL transformation. If no transformation is specified (second case), the text value will be returned only as kb:textValueAsXml . This property will be a string containing the contents of the initially uploaded XML. Note: The returned XML document is equivalent to the uploaded document but it is not necessarily identical - the order of the attributes in one element may vary from the original. In the third case, when a transformation is specified, both kb:textValueAsXml and kb:textValueAsHtml will be returned. kb:textValueAsHtml is the result of the XSL transformation applied to kb:textValueAsXml . The HTML representation is intended to display the text value in a human readable and properly styled way, while the XML representation can be used to update the text value.","title":"Requesting Text Markup as XML"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#requesting-text-markup-as-standoff","text":"Implementation of support for standoff/RDF in API v2 is in its early stages; its use is currently discouraged. The basic procedure works like this: First, request a resource in the complex schema , using any relevant API v2 route, submitting the string standoff as the value of either: the HTTP header X-Knora-Accept-Markup the URL parameter markup If a text value in the resource contains markup, the text value will look something like this: { \"@id\" : \"http://rdfh.ch/0001/LK-wKXDNQJaRHOf0F0aJ2g/values/1Er1OpVwQR2u6peTwyNpJw\", \"@type\" : \"knora-api:TextValue\", \"knora-api:attachedToUser\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:hasPermissions\" : \"CR knora-admin:Creator|V knora-admin:UnknownUser\", \"knora-api:textValueHasMarkup\" : true, \"knora-api:textValueHasMaxStandoffStartIndex\" : 6737, \"knora-api:userHasPermission\" : \"CR\", \"knora-api:valueAsString\" : \"\\nHamlet\\nACT I\\nSCENE I. Elsinore. A platform before the castle...\", \"knora-api:valueCreationDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-05-08T17:08:32.158401Z\" } } The object knora-api:valueAsString contains the text without markup. The predicate knora-api:textValueHasMarkup indicates that the text value has markup, and the value of the predicate knora-api:textValueHasMaxStandoffStartIndex gives the start index of the last standoff tag; this gives the client some idea of how much markup there is. You can then request the text value's standoff/RDF, which is returned in pages of a limited size. To get each page: HTTP GET to http://host/v2/standoff/RESOURCE_IRI/TEXT_VALUE_IRI/OFFSET Both RESOURCE_IRI and TEXT_VALUE_IRI must be URL-encoded. The offset is an integer whose initial value is 0. The response will look like this: { \"@graph\" : [ { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffRootTag\", \"knora-api:standoffTagHasEnd\" : 184716, \"knora-api:standoffTagHasStart\" : 0, \"knora-api:standoffTagHasStartIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"sbBzeAaNTzaUXl90UtlYzw\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader1Tag\", \"knora-api:standoffTagHasEnd\" : 7, \"knora-api:standoffTagHasStart\" : 1, \"knora-api:standoffTagHasStartIndex\" : 1, \"knora-api:standoffTagHasStartParentIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"HhXjcdSTS_G6eSQ0apdjUw\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader3Tag\", \"knora-api:standoffTagHasEnd\" : 14, \"knora-api:standoffTagHasStart\" : 9, \"knora-api:standoffTagHasStartIndex\" : 2, \"knora-api:standoffTagHasStartParentIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"Ymr2aDUqTx6nMwGZGiqduA\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffHeader3Tag\", \"knora-api:standoffTagHasEnd\" : 64, \"knora-api:standoffTagHasStart\" : 16, \"knora-api:standoffTagHasStartIndex\" : 3, \"knora-api:standoffTagHasStartParentIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"_Zk0B1edRK6mgdtokmosXg\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffBlockquoteTag\", \"knora-api:standoffTagHasEnd\" : 112, \"knora-api:standoffTagHasStart\" : 66, \"knora-api:standoffTagHasStartIndex\" : 4, \"knora-api:standoffTagHasStartParentIndex\" : 0, \"knora-api:standoffTagHasUUID\" : \"1DLdI0LJTCy07w6ZsOM_Sg\" }, { \"@type\" : \"http://api.knora.org/ontology/standoff/v2#StandoffItalicTag\", \"knora-api:standoffTagHasEnd\" : 111, \"knora-api:standoffTagHasStart\" : 67, \"knora-api:standoffTagHasStartIndex\" : 5, \"knora-api:standoffTagHasStartParentIndex\" : 4, \"knora-api:standoffTagHasUUID\" : \"XJ6GVO1VQSqrTyLHGnHqcA\" } ], \"knora-api:nextStandoffStartIndex\" : 100, \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } See Text with Standoff Markup for details of the predicates in each standoff tag. If there are more pages of standoff to be requested, the response will contain knora-api:nextStandoffStartIndex , whose object should be submitted as the next OFFSET to the same route. This continues until you receive a response without knora-api:nextStandoffStartIndex .","title":"Requesting Text Markup as Standoff"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#get-the-representation-of-a-resource-by-iri","text":"","title":"Get the Representation of a Resource by IRI"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#get-a-full-representation-of-a-resource-by-iri","text":"A full representation of resource can be obtained by making a GET request to the API providing its IRI. Because a Knora IRI has the format of a URL, its IRI has to be URL-encoded. To get the resource with the IRI http://rdfh.ch/c5058f3a (a book from the sample Incunabula project, which is included in the Knora API server's test data), make a HTTP GET request to the resources route (path segment resources in the API call) and append the URL-encoded IRI: HTTP GET to http://host/v2/resources/http%3A%2F%2Frdfh.ch%2Fc5058f3a If necessary, several resources can be queried at the same time, their IRIs separated by slashes. Please note that the amount of resources that can be queried in one requested is limited. See the settings for app/v2 in application.conf . More formally, the URL looks like this: HTTP GET to http://host/v2/resources/resourceIRI(/anotherResourceIri)*","title":"Get a Full Representation of a Resource by IRI"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#get-a-full-representation-of-a-version-of-a-resource-by-iri","text":"To get a specific past version of a resource, use the route described in Get a Full Representation of a Resource by IRI , and add the URL parameter ?version=TIMESTAMP , where TIMESTAMP is an xsd:dateTimeStamp in the UTC timezone. The timestamp can either be URL-encoded, or submitted with all punctuation ( - , : , and . ) removed (this is to accept timestamps from Knora's ARK URLs ). The resource will be returned with the values that it had at the specified time. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), the current metadata will be returned. Each value will be returned with the permissions that are attached to the current version of the value (see Permissions ). The returned resource will include the predicate knora-api:versionDate , containing the timestamp that was submitted, and its knora-api:versionArkUrl (see Resource Permalinks ) will contain the same timestamp.","title":"Get a Full Representation of a Version of a Resource by IRI"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#get-a-value-in-a-resource","text":"To get a specific value of a resource, use this route: HTTP GET to http://host/v2/values/resourceIRI/valueUUID The resource IRI must be URL-encoded. The path element valueUUID is the string object of the value's knora-api:valueHasUUID . The value will be returned within its containing resource, in the same format as for Responses Describing Resources , but without any of the resource's other values.","title":"Get a Value in a Resource"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#get-a-version-of-a-value-in-a-resource","text":"To get a particular version of a specific value of a resource, use the route described in Get a Value in a Resource , and add the URL parameter ?version=TIMESTAMP , where TIMESTAMP is an xsd:dateTimeStamp in the UTC timezone. The timestamp can either be URL-encoded, or submitted with all punctuation ( - , : , and . ) removed (this is to accept timestamps from Knora's ARK URLs ). The value will be returned within its containing resource, in the same format as for Responses Describing Resources , but without any of the resource's other values. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), the current resource metadata will be returned. The value will be returned with the permissions that are attached to its current version (see Permissions ).","title":"Get a Version of a Value in a Resource"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#get-the-version-history-of-a-resource","text":"To get a list of the changes that have been made to a resource since its creation, use this route: HTTP GET to http://host/v2/resources/history/resourceIRI[?startDate=START_DATE&endDate=END_DATE] The resource IRI must be URL-encoded. The start and end dates are optional, and are URL-encoded timestamps in xsd:dateTimeStamp format. The start date is inclusive, and the end date is exclusive. If the start date is not provided, the resource's history since its creation is returned. If the end date is not provided, the resource's history up to the present is returned. The response is a list of changes made to the resource, in reverse chronological order. Each entry has the properties knora-api:author (the IRI of the user who made the change) and knora-api:versionDate (the date when the change was made). For example: { \"@graph\" : [ { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-02-11T09:05:10Z\" } }, { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-02-10T10:30:10Z\" } }, { \"knora-api:author\" : { \"@id\" : \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:versionDate\" : { \"@type\" : \"xsd:dateTimeStamp\", \"@value\" : \"2019-02-10T10:05:10Z\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } The entries include all the dates when the resource's values were created or modified (within the requested date range), as well as the date when the resource was created (if the requested date range allows it). Each date is included only once. Since Knora only versions values, not resource metadata (e.g. rdfs:label ), changes to a resource's metadata are not included in its version history. To request the resource as it was at each of these dates, see Get a Full Representation of a Version of a Resource by IRI . For consistency in citation, we recommend using these dates when requesting resource versions.","title":"Get the Version History of a Resource"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#get-the-preview-of-a-resource-by-iri","text":"In some cases, the client may only want to request the preview of a resource, which just provides its metadata (e.g. its IRI, rdfs:label , and type), without its values. This works exactly like making a conventional resource request, using the path segment resourcespreview : HTTP GET to http://host/v2/resourcespreview/resourceIRI(/anotherResourceIri)*","title":"Get the preview of a resource by IRI"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#get-a-graph-of-resources","text":"Knora can return a graph of connections between resources, e.g. for generating a network diagram. HTTP GET to http://host/v2/graph/resourceIRI[depth=Integer] [direction=outbound|inbound|both][excludeProperty=propertyIri] The first parameter must be preceded by a question mark ? , any following parameter by an ampersand & . depth must be at least 1. The maximum depth is an Knora configuration setting. The default is 4. direction specifies the direction of the links to be queried, i.e. links to and/or from the given resource. The default is outbound . excludeProperty is an optional link property to be excluded from the results. To accommodate large graphs, the graph response format is very concise, and is therefore simpler than the usual resources response format. Each resource represented only by its IRI, class, and label. Direct links are shown instead of link values. For example: { \"@graph\" : [ { \"@id\" : \"http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ\", \"@type\" : \"anything:Thing\", \"rdfs:label\" : \"Sierra\" }, { \"@id\" : \"http://rdfh.ch/0001/A67ka6UQRHWf313tbhQBjw\", \"@type\" : \"anything:Thing\", \"rdfs:label\" : \"Victor\" }, { \"@id\" : \"http://rdfh.ch/0001/Lz7WEqJETJqqsUZQYexBQg\", \"@type\" : \"anything:Thing\", \"rdfs:label\" : \"Foxtrot\" }, { \"@id\" : \"http://rdfh.ch/0001/WLSHxQUgTOmG1T0lBU2r5w\", \"@type\" : \"anything:Thing\", \"anything:hasOtherThing\" : { \"@id\" : \"http://rdfh.ch/0001/A67ka6UQRHWf313tbhQBjw\" }, \"rdfs:label\" : \"Tango\" }, { \"@id\" : \"http://rdfh.ch/0001/start\", \"@type\" : \"anything:Thing\", \"anything:hasOtherThing\" : [ { \"@id\" : \"http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ\" }, { \"@id\" : \"http://rdfh.ch/0001/WLSHxQUgTOmG1T0lBU2r5w\" }, { \"@id\" : \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\" } ], \"rdfs:label\" : \"Romeo\" }, { \"@id\" : \"http://rdfh.ch/0001/tPfZeNMvRVujCQqbIbvO0A\", \"@type\" : \"anything:Thing\", \"anything:hasOtherThing\" : { \"@id\" : \"http://rdfh.ch/0001/Lz7WEqJETJqqsUZQYexBQg\" }, \"rdfs:label\" : \"Echo\" } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"anything\" : \"http://0.0.0.0:3333/ontology/0001/anything/v2#\" } }","title":"Get a Graph of Resources"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#search-for-resources","text":"","title":"Search for Resources"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#search-for-a-resource-by-its-rdfslabel","text":"Knora offers the possibility to search for resources by their rdfs:label . The use case for this search is to find a specific resource as you type. E.g., the user wants to get a list of resources whose rdfs:label contain some search terms separated by a whitespace character: Zeit Zeitg ... Zeitgl\u00f6cklein d ... Zeitgl\u00f6cklein des Lebens With each character added to the last term, the selection gets more specific. The first term should at least contain three characters. To make this kind of \"search as you type\" possible, a wildcard character is automatically added to the last search term. Characters provided by the user that have a special meaning in the Lucene Query Parser syntax are replaced by a whitespace character for this search. If a user types \"Zeit-Gl\u00f6cklein\" it is interpreted as \"Zeit Gl\u00f6cklein\". Whitespace is normalized afterwards. The special characters that are replaced are: + , - , & , | , ! , ( , ) , [ , ] , { , } , ^ , \" , ~ , * , ? , : , \\ If the rdfs:label of a resource contains a special character, it is found nonetheless. HTTP GET to http://host/v2/searchbylabel/searchValue[limitToResourceClass=resourceClassIRI] [limitToProject=projectIRI][offset=Integer] The first parameter must be preceded by a question mark ? , any following parameter by an ampersand & . The default value for the parameter offset is 0, which returns the first page of search results. Subsequent pages of results can be fetched by increasing offset by one. The amount of results per page is defined in app/v2 in application.conf . For performance reasons, standoff markup is not queried for this route. To request the number of results rather than the results themselves, you can do a count query: HTTP GET to http://host/v2/searchbylabel/count/searchValue[limitToResourceClass=resourceClassIRI][limitToProject=projectIRI][offset=Integer] The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value.","title":"Search for a Resource by its rdfs:label"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#full-text-search","text":"Knora offers a full-text search that searches through all textual representations of values and rdfs:label of resources. Full-text search supports the Lucene Query Parser syntax . Note that Lucene's default operator is a logical OR when submitting several search terms. Please note that the search terms have to be URL-encoded. HTTP GET to http://host/v2/search/searchValue[limitToResourceClass=resourceClassIRI] [limitToStandoffClass=standoffClassIri][limitToProject=projectIRI][offset=Integer] The first parameter has to be preceded by a question mark ? , any following parameter by an ampersand & . A search value must have a minimal length of three characters (default value) as defined in app/v2 in application.conf . A search term may contain wildcards. A ? represents a single character. It has to be URL-encoded as %3F since it has a special meaning in the URL syntax. For example, the term Uniform can be search for like this: HTTP GET to http://host/v2/search/Unif%3Frm A * represents zero, one or multiple characters. For example, the term Uniform can be searched for like this: HTTP GET to http://host/v2/search/Uni*m The default value for the parameter offset is 0 which returns the first page of search results. Subsequent pages of results can be fetched by increasing offset by one. The amount of results per page is defined in app/v2 in application.conf . If the parameter limitToStandoffClass is provided, Knora will look for search terms that are marked up with the indicated standoff class. If the parameter returnFiles=true is provided, Knora will return any file value attached to each matching resource. To request the number of results rather than the results themselves, you can do a count query: HTTP GET to http://host/v2/search/count/searchValue[limitToResourceClass=resourceClassIRI][limitToStandoffClass=standoffClassIri][limitToProject=projectIRI][offset=Integer] The first parameter has to be preceded by a question mark ? , any following parameter by an ampersand & . The response to a count query request is an object with one predicate, http://schema.org/numberOfItems , with an integer value.","title":"Full-text Search"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#gravsearch","text":"For more complex queries than a full-text search, Knora offers a query language called Gravsearch: Virtual Graph Search ).","title":"Gravsearch"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#support-of-teixml","text":"To convert standoff markup to TEI/XML, see TEI/XML .","title":"Support of TEI/XML"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#iiif-manifests","text":"This is an experimental feature and may change. To generate a IIIF manifest for a resource, containing the still image representations that have knora-api:isPartOf (or a subproperty) pointing to that resource: HTTP GET to http://host/v2/resources//iiifmanifest/RESOURCE_IRI","title":"IIIF Manifests"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#reading-resources-by-class-from-a-project","text":"To facilitate the development of tabular user interfaces for data entry, it is possible to get a paged list of all the resources belonging to a particular class in a given project, sorted by the value of a property: HTTP GET to http://host/v2/resources?resourceClass=RESOURCE_CLASS_IRI&page=PAGE[&orderByProperty=PROPERTY_IRI] This is useful only if the project does not contain a large amount of data; otherwise, you should use Gravsearch to search using more specific criteria. The specified class and property are used without inference; they will not match subclasses or subproperties. The HTTP header X-Knora-Accept-Project must be submitted; its value is a Knora project IRI. In the request URL, the values of resourceClass and orderByProperty are URL-encoded IRIs in the complex schema . The orderByProperty parameter is optional; if it is not supplied, resources will be sorted alphabetically by resource IRI (an arbitrary but consistent order). The value of page is a 0-based integer page number. Paging works as it does in Gravsearch ).","title":"Reading Resources by Class from a Project"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#get-the-full-history-of-a-resource-and-its-values-as-events","text":"To get a list of the changes that have been made to a resource and its values since its creation as events ordered by date: HTTP GET to http://host/v2/resources/resourceHistoryEvents/<resourceIRI> The resource IRI must be URL-encoded. The response is a list of events describing changes made to the resource and its values, in chronological order. Each entry has the properties: knora-api:eventType (the type of the operation performed on a specific date. The operation can be either createdResource , updatedResourceMetadata , deletedResource , createdValue , updatedValueContent , updatedValuePermissions , or deletedValue .), knora-api:versionDate (the date when the change was made), knora-api:author (the IRI of the user who made the change), knora-api:eventBody (the information necessary to make the same request). For example, the following response contains the list of events describing the version history of the resource http://rdfh.ch/0001/thing-with-history ordered by date: { \"@graph\" : [ { \"knora-api:eventType\": \"createdResource\", \"knora-api:author\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\": { \"rdfs:label\": \"A thing with version history\", \"knora-api:resourceIri\": \"http://rdfh.ch/0001/thing-with-history\", \"knora-api:resourceClassIri\": \"http://www.knora.org/ontology/0001/anything#Thing\", \"knora-api:hasPermissions\": \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:UnknownUser\", \"knora-api:creationDate\": { \"@value\": \"2019-02-08T15:05:10Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-api:attachedToProject\": { \"@id\": \"http://rdfh.ch/projects/Lw3FC39BSzCwvmdOaTyLqQ\" } }, \"knora-api:versionDate\": { \"@value\": \"2019-02-08T15:05:10Z\", \"@type\": \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\": \"createdValue\", \"knora-api:author\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\": { \"knora-api:resourceIri\": \"http://rdfh.ch/0001/thing-with-history\", \"knora-api:resourceClassIri\": \"http://www.knora.org/ontology/0001/anything#Thing\", \"knora-api:valueCreationDate\": { \"@value\": \"2019-02-10T10:30:10Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-api:valueHasUUID\": \"IZGOjVqxTfSNO4ieKyp0SA\", \"knora-api:hasPermissions\": \"V knora-admin:UnknownUser|M knora-admin:ProjectMember\", \"@type\": \"knora-base:LinkValue\", \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\": { \"knora-api:linkValueHasTargetIri\": { \"@id\": \"http://rdfh.ch/0001/2qMtTWvVRXWMBcRNlduvCQ\" } }, \"rdf:Property\": \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\", \"@id\": \"http://rdfh.ch/0001/thing-with-history/values/3a\" }, \"knora-api:versionDate\": { \"@value\": \"2019-02-10T10:30:10Z\", \"@type\": \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\": \"updatedValueContent\", \"knora-api:author\": { \"@id\": \"http://rdfh.ch/users/BhkfBc3hTeS_IDo-JgXRbQ\" }, \"knora-api:eventBody\": { \"knora-api:resourceIri\": \"http://rdfh.ch/0001/thing-with-history\", \"knora-api:resourceClassIri\": \"http://www.knora.org/ontology/0001/anything#Thing\" \"http://www.knora.org/ontology/0001/anything#hasText\": { \"knora-api:valueAsString\": \"two\" }, \"knora-api:valueCreationDate\": { \"@value\": \"2019-02-11T10:05:10Z\", \"@type\": \"xsd:dateTimeStamp\" }, \"knora-base:previousValue\": \"http://rdfh.ch/0001/thing-with-history/values/2a\", \"knora-api:valueHasUUID\": \"W5fm67e0QDWxRZumcXcs6g\", \"@type\": \"knora-base:TextValue\", \"rdf:Property\": \"http://www.knora.org/ontology/0001/anything#hasText\", \"@id\": \"http://rdfh.ch/0001/thing-with-history/values/2b\" }, \"knora-api:versionDate\": { \"@value\": \"2019-02-11T10:05:10Z\", \"@type\": \"xsd:dateTimeStamp\" } }, { \"knora-api:eventType\": \"deletedValue\", \"knora-api:author\": { \"@id\": \"http://rdfh.ch/users/9XBCrDV3SRa7kS1WwynB4Q\" }, \"knora-api:eventBody\": { \"knora-api:resourceIri\": \"http://rdfh.ch/0001/thing-with-history\", \"knora-api:resourceClassIri\": \"http://www.knora.org/ontology/0001/anything#Thing\", \"knora-base:previousValue\": \"http://rdfh.ch/0001/thing-with-history/values/3a\", \"knora-api:deleteDate\": { \"@type\": \"xsd:dateTimeStamp\", \"@value\": \"2019-02-13T09:00:10Z\" }, \"knora-api:isDeleted\": true, \"@type\": \"knora-base:LinkValue\", \"rdf:Property\": \"http://www.knora.org/ontology/0001/anything#hasOtherThingValue\", \"@id\": \"http://rdfh.ch/0001/thing-with-history/values/3b\" }, \"knora-api:versionDate\": { \"@value\": \"2019-02-13T09:00:10Z\", \"@type\": \"xsd:dateTimeStamp\" } } ], \"@context\" : { \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\", \"rdfs\" : \"http://www.w3.org/2000/01/rdf-schema#\", \"xsd\" : \"http://www.w3.org/2001/XMLSchema#\", \"knora-api\" : \"http://api.knora.org/ontology/knora-api/v2#\" } } Since the history of changes made to the metadata of a resource is not part of resouce's version history, there are no events describing the changes on metadata elements like its rdfs:label or rdfs:comment . The only record depicting a change in a resource's metadata is the knora-api:lastModificationDate of the resource. Thus the event updatedResourceMetadata indicates a change in a resource's metadata, its knora-api:eventBody contains the payload needed to update the value of the resource's lastModificationDate , see modifying metadata of a resource .","title":"Get the Full History of a Resource and its Values as Events"},{"location":"03-endpoints/api-v2/reading-and-searching-resources/#get-the-full-history-of-all-resources-of-a-project-as-events","text":"To get a list of the changes that have been made to the resources and their values of a project as events ordered by date: HTTP GET to http://host/v2/resources/projectHistoryEvents/<projectIRI> The project IRI must be URL-encoded. The response contains the resource history events of all resources that belong to the specified project.","title":"Get the Full History of all Resources of a Project as Events"},{"location":"03-endpoints/api-v2/reading-user-permissions/","text":"Reading the User's Permissions on Resources and Values In the complex API schema , each resource and value is returned with the predicate knora-api:userHasPermission . The object of this predicate is a string containing a permission code, which indicates the requesting user's maximum permission on the resource or value. These are the possible permission codes, in ascending order: RV : restricted view permission (least privileged) V : view permission M modify permission D : delete permission CR : change rights permission (most privileged) Each permission implies all lesser permissions. For more details, see Permissions .","title":"Reading the User's Permissions on Resources and Values"},{"location":"03-endpoints/api-v2/reading-user-permissions/#reading-the-users-permissions-on-resources-and-values","text":"In the complex API schema , each resource and value is returned with the predicate knora-api:userHasPermission . The object of this predicate is a string containing a permission code, which indicates the requesting user's maximum permission on the resource or value. These are the possible permission codes, in ascending order: RV : restricted view permission (least privileged) V : view permission M modify permission D : delete permission CR : change rights permission (most privileged) Each permission implies all lesser permissions. For more details, see Permissions .","title":"Reading the User's Permissions on Resources and Values"},{"location":"03-endpoints/api-v2/tei-xml/","text":"TEI/XML: Converting Standoff to TEI/XML General Knora offers a way to convert standoff markup to TEI/XML. The conversion is based on the assumption that a whole resource is to be turned into a TEI document. There is a basic distinction between the body and the header of a TEI document. The resource's property that contains the text with standoff markup is mapped to the TEI document's body. Other of the resource's property may be mapped to the TEI header. Standard Standoff to TEI Conversion Knora offers a built-in conversion form standard standoff entities (defined in the standoff ontology) tags to TEI. In order to obtain a resource as a TEI document, the following request has to be performed. Please note that the URL parameters have to be URL-encoded. HTTP GET to http://host/v2/tei/resourceIri?textProperty=textPropertyIri In addition to the resource's Iri, the Iri of the property containing the text with standoff has to be submitted. This will be converted to the TEI body. Please note that the resource can only have one instance of this property and the text must have standoff markup. The Knora test data contain the resource http://rdfh.ch/0001/thing_with_richtext_with_markup with the text property http://0.0.0.0:3333/ontology/0001/anything/v2#hasRichtext that can be converted to TEI as follows: HTTP GET to http://host/v2/tei/http%3A%2F%2Frdfh.ch%2F0001%2Fthing_with_richtext_with_markup?textProperty=http%3A%2F%2F0.0.0.0%3A3333%2Fontology%2F0001%2Fanything%2Fv2%23hasRichtext The answer to this request is a TEI XML document: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" version=\"3.3.0\"> <teiHeader> <fileDesc> <titleStmt> <title>test thing with markup</title> </titleStmt> <publicationStmt> <p> This is the TEI/XML representation of a resource identified by the Iri http://rdfh.ch/0001/thing_with_richtext_with_markup. </p> </publicationStmt> <sourceDesc> <p>Representation of the resource's text as TEI/XML</p> </sourceDesc> </fileDesc> </teiHeader> <text> <body> <p>This is a test that contains marked up elements. This is <hi rend=\"italic\">interesting text</hi> in italics. This is <hi rend=\"italic\">boring text</hi> in italics.</p> </body> </text> </TEI> The body of the TEI document contains the standoff markup as XML. The header contains contains some basic metadata about the resource such as the rdfs:label an its IRI. However, this might not be sufficient for more advanced use cases like digital edition projects. In that case, a custom conversion has to be performed (see below). Custom Conversion If a project defines its own standoff entities, a custom conversion can be provided (body of the TEI document). Also for the TEI header, a custom conversion can be provided. For the custom conversion, additional configuration is required. TEI body: additional mapping from standoff to XML (URL parameter mappingIri ) XSL transformation to turn the XML into a valid TEI body (referred to by the mapping). The mapping has to refer to a defaultXSLTransformation that transforms the XML that was created from standoff markup (see XML To Standoff Mapping in API v1 ). This step is necessary because the mapping assumes a one to one relation between standoff classes and properties and XML elements and attributes. For example, we may want to convert a standoff:StandoffItalicTag into TEI/XML. TEI expresses this as <hi rend=\"italic\">...</hi> . In the mapping, the standoff:StandoffItalicTag may be mapped to a a temporary XML element that is going to be converted to <hi rend=\"italic\">...</hi> in a further step by the XSLT. For sample data, see webapi/_test_data/test_route/texts/beol/BEOLTEIMapping.xml (mapping) and webapi/_test_data/test_route/texts/beol/standoffToTEI.xsl . The standoff entities are defined in beol-onto.ttl . TEI header: Gravsearch template to query the resources metadata, results are serialized to RDF/XML (URL parameter gravsearchTemplateIri ) XSL transformation to turn that RDF/XML into a valid TEI header (URL parameter teiHeaderXSLTIri ) The Gravsearch template is expected to be of type knora-base:TextRepresentation and to contain a placeholder $resourceIri that is to be replaced by the actual resource Iri. The Gravsearch template is expected to contain a query involving the text property (URL parameter textProperty ) and more properties that are going to be mapped to the TEI header. The Gravsearch template is a simple text file with the files extension .txt . A Gravsearch template may look like this (see test_data/test_route/texts/beol/gravsearch.txt ): PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX xsd: <http://www.w3.org/2001/XMLSchema#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:creationDate ?date . ?letter beol:hasText ?text . ?letter beol:hasAuthor ?person1 . ?person1 beol:hasFamilyName ?name1 . ?person1 beol:hasGivenName ?givenName1 . ?person1 beol:hasIAFIdentifier ?iaf1 . ?letter beol:hasRecipient ?person2 . ?person2 beol:hasFamilyName ?name2 . ?person2 beol:hasGivenName ?givenName2 . ?person2 beol:hasIAFIdentifier ?iaf2 . } WHERE { BIND(<$resourceIri> as ?letter) ?letter a knora-api:Resource . ?letter a beol:letter . ?letter beol:creationDate ?date . beol:creationDate knora-api:objectType knora-api:Date . ?date a knora-api:Date . ?letter beol:hasText ?text . beol:hasText knora-api:objectType xsd:string . ?text a xsd:string . ?letter beol:hasAuthor ?person1 . ?person1 beol:hasFamilyName ?name1 . ?person1 beol:hasGivenName ?givenName1 . ?person1 beol:hasIAFIdentifier ?iaf1 . ?name1 a xsd:string . ?givenName1 a xsd:string . ?iaf1 a xsd:string . ?person2 beol:hasFamilyName ?name2 . ?person2 beol:hasGivenName ?givenName2 . ?person2 beol:hasIAFIdentifier ?iaf2 . ?name2 a xsd:string . ?givenName2 a xsd:string . ?iaf2 a xsd:string . beol:hasGivenName knora-api:objectType xsd:string . beol:hasFamilyName knora-api:objectType xsd:string . beol:hasIAFIdentifier knora-api:objectType xsd:string . beol:hasAuthor knora-api:objectType knora-api:Resource . ?letter beol:hasRecipient ?person2 . beol:hasRecipient knora-api:objectType knora-api:Resource . ?person1 a knora-api:Resource . ?person2 a knora-api:Resource . } Note the placeholder BIND(<$resourceIri> as ?letter) that is going to be replaced by the Iri of the resource the request is performed for. The query asks for information about the letter's text beol:hasText and information about its author and recipient. This information is converted to the TEI header in the format required by correspSearch . To write the XSLT, do the Gravsearch query and request the data as RDF/XML using content negotiation (see Introduction ). The Gravsearch query's result may look like this ( RDF/XML ): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <rdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\" xmlns:knora-api=\"http://api.knora.org/ontology/knora-api/v2#\" xmlns:beol=\"http://0.0.0.0:3333/ontology/0801/beol/v2#\"> <beol:letter rdf:about=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA\"> <beol:creationDate rdf:resource=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/Ob_1YRO_QmaDxTRI64vGOQ\"/> <beol:hasAuthorValue rdf:resource=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/zt4a3XoESTq9To4mSN8Dug\"/> <beol:hasRecipientValue rdf:resource=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/pVerHO_FRXePZQT9kgEp_Q\"/> <rdfs:label rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Testletter</rdfs:label> </beol:letter> <knora-api:DateValue rdf:about=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/Ob_1YRO_QmaDxTRI64vGOQ\"> <knora-api:dateValueHasCalendar rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">GREGORIAN</knora-api:dateValueHasCalendar> <knora-api:dateValueHasEndDay rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">10</knora-api:dateValueHasEndDay> <knora-api:dateValueHasEndEra rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">CE</knora-api:dateValueHasEndEra> <knora-api:dateValueHasEndMonth rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">6</knora-api:dateValueHasEndMonth> <knora-api:dateValueHasEndYear rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">1703</knora-api:dateValueHasEndYear> <knora-api:dateValueHasStartDay rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">10</knora-api:dateValueHasStartDay> <knora-api:dateValueHasStartEra rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">CE</knora-api:dateValueHasStartEra> <knora-api:dateValueHasStartMonth rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">6</knora-api:dateValueHasStartMonth> <knora-api:dateValueHasStartYear rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">1703</knora-api:dateValueHasStartYear> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">GREGORIAN:1703-06-10 CE</knora-api:valueAsString> </knora-api:DateValue> <knora-api:LinkValue rdf:about=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/zt4a3XoESTq9To4mSN8Dug\"> <knora-api:linkValueHasTarget> <beol:person rdf:about=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ\"> <beol:hasFamilyName rdf:resource=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/NG42jDqSTz2U35N6sJ8cqg\"/> <beol:hasGivenName rdf:resource=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/W2lVG1mvQU2MauAvCGB13w\"/> <beol:hasIAFIdentifier rdf:resource=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/N2TVtntdToqJQpdZhYPc5g\"/> <rdfs:label rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Johann Jacob Scheuchzer</rdfs:label> </beol:person> </knora-api:linkValueHasTarget> </knora-api:LinkValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/NG42jDqSTz2U35N6sJ8cqg\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Scheuchzer</knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/W2lVG1mvQU2MauAvCGB13w\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Johann Jacob</knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/N2TVtntdToqJQpdZhYPc5g\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">(DE-588)118607308</knora-api:valueAsString> </knora-api:TextValue> <knora-api:LinkValue rdf:about=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/pVerHO_FRXePZQT9kgEp_Q\"> <knora-api:linkValueHasTarget> <beol:person rdf:about=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw\"> <beol:hasFamilyName rdf:resource=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/k1Exqf93SsWi7LWK9ozXkw\"/> <beol:hasGivenName rdf:resource=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/gkqK5Ij_R7mtO59xfSDGJA\"/> <beol:hasIAFIdentifier rdf:resource=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/C-Dl15S-SV63L1KCCPFfew\"/> <rdfs:label rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Jacob Hermann</rdfs:label> </beol:person> </knora-api:linkValueHasTarget> </knora-api:LinkValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/k1Exqf93SsWi7LWK9ozXkw\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Hermann</knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/gkqK5Ij_R7mtO59xfSDGJA\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Jacob</knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/C-Dl15S-SV63L1KCCPFfew\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">(DE-588)119112450</knora-api:valueAsString> </knora-api:TextValue> </rdf:RDF> In order to convert the metadata (not the actual standoff markup), a knora-base:knora-base:XSLTransformation has to be provided. For our example, it looks like this (see test_data/test_route/texts/beol/header.xsl ): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <xsl:transform xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:xs=\"http://www.w3.org/2001/XMLSchema\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:rdfs1=\"http://www.w3.org/2000/01/rdf-schema#\" xmlns:beol=\"http://0.0.0.0:3333/ontology/0801/beol/v2#\" xmlns:knora-api=\"http://api.knora.org/ontology/knora-api/v2#\" exclude-result-prefixes=\"rdf beol knora-api xs rdfs1\" version=\"2.0\"> <xsl:output method=\"xml\" omit-xml-declaration=\"yes\" encoding=\"utf-8\" indent=\"yes\"/> <!-- make IAF id a URL --> <xsl:function name=\"knora-api:iaf\" as=\"xs:anyURI\"> <xsl:param name=\"input\" as=\"xs:string\"/> <xsl:value-of select=\"replace($input, '\\(DE-588\\)', 'http://d-nb.info/gnd/')\"/> </xsl:function> <!-- make a standard date (Gregorian calendar assumed) --> <xsl:function name=\"knora-api:dateformat\" as=\"element()*\"> <xsl:param name=\"input\" as=\"element()*\"/> <xsl:choose> <xsl:when test=\"$input/knora-api:dateValueHasStartYear/text() = $input/knora-api:dateValueHasEndYear/text() and $input/knora-api:dateValueHasStartMonth/text() = $input/knora-api:dateValueHasEndMonth/text() and $input/knora-api:dateValueHasStartDay/text() = $input/knora-api:dateValueHasEndDay/text()\"> <!-- no period, day precision --> <date> <xsl:attribute name=\"when\"> <xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartYear/text(), '0000')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\"/> </xsl:attribute> </date> </xsl:when> <xsl:otherwise> <!-- period --> <date> <xsl:attribute name=\"notBefore\"> <xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartYear/text(), '0000')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartDay/text(), '00')\"/> </xsl:attribute> <xsl:attribute name=\"notAfter\"> <xsl:value-of select=\"format-number($input/knora-api:dateValueHasEndYear/text(), '0000')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasEndMonth/text(), '00')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasEndDay/text(), '00')\"/> </xsl:attribute> </date> </xsl:otherwise> </xsl:choose> </xsl:function> <xsl:template match=\"rdf:RDF\"> <xsl:variable name=\"resourceIri\" select=\"beol:letter/@rdf:about\"/> <xsl:variable name=\"label\" select=\"beol:letter/rdfs1:label/text()\"/> <teiHeader> <fileDesc> <titleStmt> <title> <xsl:value-of select=\"$label\"/> </title> </titleStmt> <publicationStmt> <p> This is the TEI/XML representation of the resource identified by the Iri <xsl:value-of select=\"$resourceIri\"/>. </p> </publicationStmt> <sourceDesc> <p>Representation of the resource's text as TEI/XML</p> </sourceDesc> </fileDesc> <profileDesc> <correspDesc> <xsl:attribute name=\"ref\"> <xsl:value-of select=\"$resourceIri\"/> </xsl:attribute> <xsl:apply-templates/> </correspDesc> </profileDesc> </teiHeader> </xsl:template> <xsl:template match=\"beol:letter/beol:hasAuthorValue\"> <xsl:variable name=\"authorValue\" select=\"@rdf:resource\"/> <xsl:variable name=\"authorIAFValue\" select=\"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasIAFIdentifier/@rdf:resource\"/> <xsl:variable name=\"authorFamilyNameValue\" select=\"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasFamilyName/@rdf:resource\"/> <xsl:variable name=\"authorGivenNameValue\" select=\"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasGivenName/@rdf:resource\"/> <correspAction type=\"sent\"> <xsl:variable name=\"authorIAFText\" select=\"//knora-api:TextValue[@rdf:about=$authorIAFValue]/knora-api:valueAsString/text()\"/> <xsl:variable name=\"authorFamilyNameText\" select=\"//knora-api:TextValue[@rdf:about=$authorFamilyNameValue]/knora-api:valueAsString/text()\"/> <xsl:variable name=\"authorGivenNameText\" select=\"//knora-api:TextValue[@rdf:about=$authorGivenNameValue]/knora-api:valueAsString/text()\"/> <persName> <xsl:attribute name=\"ref\"><xsl:value-of select=\"knora-api:iaf($authorIAFText)\" /></xsl:attribute> <xsl:value-of select=\"$authorFamilyNameText\"/>, <xsl:value-of select=\"$authorGivenNameText\"/> </persName> <xsl:variable name=\"dateValue\" select=\"//beol:creationDate/@rdf:resource\"/> <xsl:variable name=\"dateObj\" select=\"//knora-api:DateValue[@rdf:about=$dateValue]\"/> <xsl:copy-of select=\"knora-api:dateformat($dateObj)\"/> </correspAction> </xsl:template> <xsl:template match=\"beol:letter/beol:hasRecipientValue\"> <xsl:variable name=\"recipientValue\" select=\"@rdf:resource\"/> <xsl:variable name=\"recipientIAFValue\" select=\"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasIAFIdentifier/@rdf:resource\"/> <xsl:variable name=\"recipientFamilyNameValue\" select=\"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasFamilyName/@rdf:resource\"/> <xsl:variable name=\"recipientGivenNameValue\" select=\"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasGivenName/@rdf:resource\"/> <correspAction type=\"received\"> <xsl:variable name=\"recipientIAFText\" select=\"//knora-api:TextValue[@rdf:about=$recipientIAFValue]/knora-api:valueAsString/text()\"/> <xsl:variable name=\"recipientFamilyNameText\" select=\"//knora-api:TextValue[@rdf:about=$recipientFamilyNameValue]/knora-api:valueAsString/text()\"/> <xsl:variable name=\"recipientGivenNameText\" select=\"//knora-api:TextValue[@rdf:about=$recipientGivenNameValue]/knora-api:valueAsString/text()\"/> <persName> <xsl:attribute name=\"ref\"><xsl:value-of select=\"knora-api:iaf($recipientIAFText)\" /></xsl:attribute> <xsl:value-of select=\"$recipientFamilyNameText\"/>, <xsl:value-of select=\"$recipientGivenNameText\"/> </persName> </correspAction> </xsl:template> <!-- ignore text if there is no template for the element containing it --> <xsl:template match=\"text()\"> </xsl:template> </xsl:transform> You can use the functions knora-api:iaf and knora-api:dateformat in your own XSLT in case you want to support correspSearch . The complete request looks like this: HTTP GET request to http://host/v2/tei/resourceIri&textProperty=textPropertyIri&mappingIri=mappingIri&gravsearchTemplateIri=gravsearchTemplateIri&teiHeaderXSLTIri=teiHeaderXSLTIri See webapi/src/it/scala/org/knora/webapi/e2e/v1/KnoraSipiIntegrationV1ITSpec.scala for a complete test case involving the sample data (\"create a mapping for standoff conversion to TEI referring to an XSLT and also create a Gravsearch template and an XSLT for transforming TEI header data\"). When you provide a custom conversion, it is up to you to ensure the validity of the TEI document. You can use this service to validate: TEI by example validator . Problems and bugs caused by XSL transformations are out of scope of the responsibility of the Knora software.","title":"TEI/XML"},{"location":"03-endpoints/api-v2/tei-xml/#teixml-converting-standoff-to-teixml","text":"","title":"TEI/XML: Converting Standoff to TEI/XML"},{"location":"03-endpoints/api-v2/tei-xml/#general","text":"Knora offers a way to convert standoff markup to TEI/XML. The conversion is based on the assumption that a whole resource is to be turned into a TEI document. There is a basic distinction between the body and the header of a TEI document. The resource's property that contains the text with standoff markup is mapped to the TEI document's body. Other of the resource's property may be mapped to the TEI header.","title":"General"},{"location":"03-endpoints/api-v2/tei-xml/#standard-standoff-to-tei-conversion","text":"Knora offers a built-in conversion form standard standoff entities (defined in the standoff ontology) tags to TEI. In order to obtain a resource as a TEI document, the following request has to be performed. Please note that the URL parameters have to be URL-encoded. HTTP GET to http://host/v2/tei/resourceIri?textProperty=textPropertyIri In addition to the resource's Iri, the Iri of the property containing the text with standoff has to be submitted. This will be converted to the TEI body. Please note that the resource can only have one instance of this property and the text must have standoff markup. The Knora test data contain the resource http://rdfh.ch/0001/thing_with_richtext_with_markup with the text property http://0.0.0.0:3333/ontology/0001/anything/v2#hasRichtext that can be converted to TEI as follows: HTTP GET to http://host/v2/tei/http%3A%2F%2Frdfh.ch%2F0001%2Fthing_with_richtext_with_markup?textProperty=http%3A%2F%2F0.0.0.0%3A3333%2Fontology%2F0001%2Fanything%2Fv2%23hasRichtext The answer to this request is a TEI XML document: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" version=\"3.3.0\"> <teiHeader> <fileDesc> <titleStmt> <title>test thing with markup</title> </titleStmt> <publicationStmt> <p> This is the TEI/XML representation of a resource identified by the Iri http://rdfh.ch/0001/thing_with_richtext_with_markup. </p> </publicationStmt> <sourceDesc> <p>Representation of the resource's text as TEI/XML</p> </sourceDesc> </fileDesc> </teiHeader> <text> <body> <p>This is a test that contains marked up elements. This is <hi rend=\"italic\">interesting text</hi> in italics. This is <hi rend=\"italic\">boring text</hi> in italics.</p> </body> </text> </TEI> The body of the TEI document contains the standoff markup as XML. The header contains contains some basic metadata about the resource such as the rdfs:label an its IRI. However, this might not be sufficient for more advanced use cases like digital edition projects. In that case, a custom conversion has to be performed (see below).","title":"Standard Standoff to TEI Conversion"},{"location":"03-endpoints/api-v2/tei-xml/#custom-conversion","text":"If a project defines its own standoff entities, a custom conversion can be provided (body of the TEI document). Also for the TEI header, a custom conversion can be provided. For the custom conversion, additional configuration is required. TEI body: additional mapping from standoff to XML (URL parameter mappingIri ) XSL transformation to turn the XML into a valid TEI body (referred to by the mapping). The mapping has to refer to a defaultXSLTransformation that transforms the XML that was created from standoff markup (see XML To Standoff Mapping in API v1 ). This step is necessary because the mapping assumes a one to one relation between standoff classes and properties and XML elements and attributes. For example, we may want to convert a standoff:StandoffItalicTag into TEI/XML. TEI expresses this as <hi rend=\"italic\">...</hi> . In the mapping, the standoff:StandoffItalicTag may be mapped to a a temporary XML element that is going to be converted to <hi rend=\"italic\">...</hi> in a further step by the XSLT. For sample data, see webapi/_test_data/test_route/texts/beol/BEOLTEIMapping.xml (mapping) and webapi/_test_data/test_route/texts/beol/standoffToTEI.xsl . The standoff entities are defined in beol-onto.ttl . TEI header: Gravsearch template to query the resources metadata, results are serialized to RDF/XML (URL parameter gravsearchTemplateIri ) XSL transformation to turn that RDF/XML into a valid TEI header (URL parameter teiHeaderXSLTIri ) The Gravsearch template is expected to be of type knora-base:TextRepresentation and to contain a placeholder $resourceIri that is to be replaced by the actual resource Iri. The Gravsearch template is expected to contain a query involving the text property (URL parameter textProperty ) and more properties that are going to be mapped to the TEI header. The Gravsearch template is a simple text file with the files extension .txt . A Gravsearch template may look like this (see test_data/test_route/texts/beol/gravsearch.txt ): PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> PREFIX xsd: <http://www.w3.org/2001/XMLSchema#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter beol:creationDate ?date . ?letter beol:hasText ?text . ?letter beol:hasAuthor ?person1 . ?person1 beol:hasFamilyName ?name1 . ?person1 beol:hasGivenName ?givenName1 . ?person1 beol:hasIAFIdentifier ?iaf1 . ?letter beol:hasRecipient ?person2 . ?person2 beol:hasFamilyName ?name2 . ?person2 beol:hasGivenName ?givenName2 . ?person2 beol:hasIAFIdentifier ?iaf2 . } WHERE { BIND(<$resourceIri> as ?letter) ?letter a knora-api:Resource . ?letter a beol:letter . ?letter beol:creationDate ?date . beol:creationDate knora-api:objectType knora-api:Date . ?date a knora-api:Date . ?letter beol:hasText ?text . beol:hasText knora-api:objectType xsd:string . ?text a xsd:string . ?letter beol:hasAuthor ?person1 . ?person1 beol:hasFamilyName ?name1 . ?person1 beol:hasGivenName ?givenName1 . ?person1 beol:hasIAFIdentifier ?iaf1 . ?name1 a xsd:string . ?givenName1 a xsd:string . ?iaf1 a xsd:string . ?person2 beol:hasFamilyName ?name2 . ?person2 beol:hasGivenName ?givenName2 . ?person2 beol:hasIAFIdentifier ?iaf2 . ?name2 a xsd:string . ?givenName2 a xsd:string . ?iaf2 a xsd:string . beol:hasGivenName knora-api:objectType xsd:string . beol:hasFamilyName knora-api:objectType xsd:string . beol:hasIAFIdentifier knora-api:objectType xsd:string . beol:hasAuthor knora-api:objectType knora-api:Resource . ?letter beol:hasRecipient ?person2 . beol:hasRecipient knora-api:objectType knora-api:Resource . ?person1 a knora-api:Resource . ?person2 a knora-api:Resource . } Note the placeholder BIND(<$resourceIri> as ?letter) that is going to be replaced by the Iri of the resource the request is performed for. The query asks for information about the letter's text beol:hasText and information about its author and recipient. This information is converted to the TEI header in the format required by correspSearch . To write the XSLT, do the Gravsearch query and request the data as RDF/XML using content negotiation (see Introduction ). The Gravsearch query's result may look like this ( RDF/XML ): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <rdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\" xmlns:knora-api=\"http://api.knora.org/ontology/knora-api/v2#\" xmlns:beol=\"http://0.0.0.0:3333/ontology/0801/beol/v2#\"> <beol:letter rdf:about=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA\"> <beol:creationDate rdf:resource=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/Ob_1YRO_QmaDxTRI64vGOQ\"/> <beol:hasAuthorValue rdf:resource=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/zt4a3XoESTq9To4mSN8Dug\"/> <beol:hasRecipientValue rdf:resource=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/pVerHO_FRXePZQT9kgEp_Q\"/> <rdfs:label rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Testletter</rdfs:label> </beol:letter> <knora-api:DateValue rdf:about=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/Ob_1YRO_QmaDxTRI64vGOQ\"> <knora-api:dateValueHasCalendar rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">GREGORIAN</knora-api:dateValueHasCalendar> <knora-api:dateValueHasEndDay rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">10</knora-api:dateValueHasEndDay> <knora-api:dateValueHasEndEra rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">CE</knora-api:dateValueHasEndEra> <knora-api:dateValueHasEndMonth rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">6</knora-api:dateValueHasEndMonth> <knora-api:dateValueHasEndYear rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">1703</knora-api:dateValueHasEndYear> <knora-api:dateValueHasStartDay rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">10</knora-api:dateValueHasStartDay> <knora-api:dateValueHasStartEra rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">CE</knora-api:dateValueHasStartEra> <knora-api:dateValueHasStartMonth rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">6</knora-api:dateValueHasStartMonth> <knora-api:dateValueHasStartYear rdf:datatype=\"http://www.w3.org/2001/XMLSchema#integer\">1703</knora-api:dateValueHasStartYear> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">GREGORIAN:1703-06-10 CE</knora-api:valueAsString> </knora-api:DateValue> <knora-api:LinkValue rdf:about=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/zt4a3XoESTq9To4mSN8Dug\"> <knora-api:linkValueHasTarget> <beol:person rdf:about=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ\"> <beol:hasFamilyName rdf:resource=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/NG42jDqSTz2U35N6sJ8cqg\"/> <beol:hasGivenName rdf:resource=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/W2lVG1mvQU2MauAvCGB13w\"/> <beol:hasIAFIdentifier rdf:resource=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/N2TVtntdToqJQpdZhYPc5g\"/> <rdfs:label rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Johann Jacob Scheuchzer</rdfs:label> </beol:person> </knora-api:linkValueHasTarget> </knora-api:LinkValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/NG42jDqSTz2U35N6sJ8cqg\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Scheuchzer</knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/W2lVG1mvQU2MauAvCGB13w\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Johann Jacob</knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/_9LEnLM7TFuPRjTshOTJpQ/values/N2TVtntdToqJQpdZhYPc5g\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">(DE-588)118607308</knora-api:valueAsString> </knora-api:TextValue> <knora-api:LinkValue rdf:about=\"http://rdfh.ch/0801/MbZdHVcsR_Ky5pZoytaiBA/values/pVerHO_FRXePZQT9kgEp_Q\"> <knora-api:linkValueHasTarget> <beol:person rdf:about=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw\"> <beol:hasFamilyName rdf:resource=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/k1Exqf93SsWi7LWK9ozXkw\"/> <beol:hasGivenName rdf:resource=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/gkqK5Ij_R7mtO59xfSDGJA\"/> <beol:hasIAFIdentifier rdf:resource=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/C-Dl15S-SV63L1KCCPFfew\"/> <rdfs:label rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Jacob Hermann</rdfs:label> </beol:person> </knora-api:linkValueHasTarget> </knora-api:LinkValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/k1Exqf93SsWi7LWK9ozXkw\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Hermann</knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/gkqK5Ij_R7mtO59xfSDGJA\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">Jacob</knora-api:valueAsString> </knora-api:TextValue> <knora-api:TextValue rdf:about=\"http://rdfh.ch/0801/JaQwPsYEQJ6GQrAgKC0Gkw/values/C-Dl15S-SV63L1KCCPFfew\"> <knora-api:valueAsString rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">(DE-588)119112450</knora-api:valueAsString> </knora-api:TextValue> </rdf:RDF> In order to convert the metadata (not the actual standoff markup), a knora-base:knora-base:XSLTransformation has to be provided. For our example, it looks like this (see test_data/test_route/texts/beol/header.xsl ): <?xml version=\"1.0\" encoding=\"UTF-8\"?> <xsl:transform xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:xs=\"http://www.w3.org/2001/XMLSchema\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:rdfs1=\"http://www.w3.org/2000/01/rdf-schema#\" xmlns:beol=\"http://0.0.0.0:3333/ontology/0801/beol/v2#\" xmlns:knora-api=\"http://api.knora.org/ontology/knora-api/v2#\" exclude-result-prefixes=\"rdf beol knora-api xs rdfs1\" version=\"2.0\"> <xsl:output method=\"xml\" omit-xml-declaration=\"yes\" encoding=\"utf-8\" indent=\"yes\"/> <!-- make IAF id a URL --> <xsl:function name=\"knora-api:iaf\" as=\"xs:anyURI\"> <xsl:param name=\"input\" as=\"xs:string\"/> <xsl:value-of select=\"replace($input, '\\(DE-588\\)', 'http://d-nb.info/gnd/')\"/> </xsl:function> <!-- make a standard date (Gregorian calendar assumed) --> <xsl:function name=\"knora-api:dateformat\" as=\"element()*\"> <xsl:param name=\"input\" as=\"element()*\"/> <xsl:choose> <xsl:when test=\"$input/knora-api:dateValueHasStartYear/text() = $input/knora-api:dateValueHasEndYear/text() and $input/knora-api:dateValueHasStartMonth/text() = $input/knora-api:dateValueHasEndMonth/text() and $input/knora-api:dateValueHasStartDay/text() = $input/knora-api:dateValueHasEndDay/text()\"> <!-- no period, day precision --> <date> <xsl:attribute name=\"when\"> <xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartYear/text(), '0000')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\"/> </xsl:attribute> </date> </xsl:when> <xsl:otherwise> <!-- period --> <date> <xsl:attribute name=\"notBefore\"> <xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartYear/text(), '0000')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartMonth/text(), '00')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasStartDay/text(), '00')\"/> </xsl:attribute> <xsl:attribute name=\"notAfter\"> <xsl:value-of select=\"format-number($input/knora-api:dateValueHasEndYear/text(), '0000')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasEndMonth/text(), '00')\"/>-<xsl:value-of select=\"format-number($input/knora-api:dateValueHasEndDay/text(), '00')\"/> </xsl:attribute> </date> </xsl:otherwise> </xsl:choose> </xsl:function> <xsl:template match=\"rdf:RDF\"> <xsl:variable name=\"resourceIri\" select=\"beol:letter/@rdf:about\"/> <xsl:variable name=\"label\" select=\"beol:letter/rdfs1:label/text()\"/> <teiHeader> <fileDesc> <titleStmt> <title> <xsl:value-of select=\"$label\"/> </title> </titleStmt> <publicationStmt> <p> This is the TEI/XML representation of the resource identified by the Iri <xsl:value-of select=\"$resourceIri\"/>. </p> </publicationStmt> <sourceDesc> <p>Representation of the resource's text as TEI/XML</p> </sourceDesc> </fileDesc> <profileDesc> <correspDesc> <xsl:attribute name=\"ref\"> <xsl:value-of select=\"$resourceIri\"/> </xsl:attribute> <xsl:apply-templates/> </correspDesc> </profileDesc> </teiHeader> </xsl:template> <xsl:template match=\"beol:letter/beol:hasAuthorValue\"> <xsl:variable name=\"authorValue\" select=\"@rdf:resource\"/> <xsl:variable name=\"authorIAFValue\" select=\"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasIAFIdentifier/@rdf:resource\"/> <xsl:variable name=\"authorFamilyNameValue\" select=\"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasFamilyName/@rdf:resource\"/> <xsl:variable name=\"authorGivenNameValue\" select=\"//knora-api:LinkValue[@rdf:about=$authorValue]//beol:hasGivenName/@rdf:resource\"/> <correspAction type=\"sent\"> <xsl:variable name=\"authorIAFText\" select=\"//knora-api:TextValue[@rdf:about=$authorIAFValue]/knora-api:valueAsString/text()\"/> <xsl:variable name=\"authorFamilyNameText\" select=\"//knora-api:TextValue[@rdf:about=$authorFamilyNameValue]/knora-api:valueAsString/text()\"/> <xsl:variable name=\"authorGivenNameText\" select=\"//knora-api:TextValue[@rdf:about=$authorGivenNameValue]/knora-api:valueAsString/text()\"/> <persName> <xsl:attribute name=\"ref\"><xsl:value-of select=\"knora-api:iaf($authorIAFText)\" /></xsl:attribute> <xsl:value-of select=\"$authorFamilyNameText\"/>, <xsl:value-of select=\"$authorGivenNameText\"/> </persName> <xsl:variable name=\"dateValue\" select=\"//beol:creationDate/@rdf:resource\"/> <xsl:variable name=\"dateObj\" select=\"//knora-api:DateValue[@rdf:about=$dateValue]\"/> <xsl:copy-of select=\"knora-api:dateformat($dateObj)\"/> </correspAction> </xsl:template> <xsl:template match=\"beol:letter/beol:hasRecipientValue\"> <xsl:variable name=\"recipientValue\" select=\"@rdf:resource\"/> <xsl:variable name=\"recipientIAFValue\" select=\"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasIAFIdentifier/@rdf:resource\"/> <xsl:variable name=\"recipientFamilyNameValue\" select=\"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasFamilyName/@rdf:resource\"/> <xsl:variable name=\"recipientGivenNameValue\" select=\"//knora-api:LinkValue[@rdf:about=$recipientValue]//beol:hasGivenName/@rdf:resource\"/> <correspAction type=\"received\"> <xsl:variable name=\"recipientIAFText\" select=\"//knora-api:TextValue[@rdf:about=$recipientIAFValue]/knora-api:valueAsString/text()\"/> <xsl:variable name=\"recipientFamilyNameText\" select=\"//knora-api:TextValue[@rdf:about=$recipientFamilyNameValue]/knora-api:valueAsString/text()\"/> <xsl:variable name=\"recipientGivenNameText\" select=\"//knora-api:TextValue[@rdf:about=$recipientGivenNameValue]/knora-api:valueAsString/text()\"/> <persName> <xsl:attribute name=\"ref\"><xsl:value-of select=\"knora-api:iaf($recipientIAFText)\" /></xsl:attribute> <xsl:value-of select=\"$recipientFamilyNameText\"/>, <xsl:value-of select=\"$recipientGivenNameText\"/> </persName> </correspAction> </xsl:template> <!-- ignore text if there is no template for the element containing it --> <xsl:template match=\"text()\"> </xsl:template> </xsl:transform> You can use the functions knora-api:iaf and knora-api:dateformat in your own XSLT in case you want to support correspSearch . The complete request looks like this: HTTP GET request to http://host/v2/tei/resourceIri&textProperty=textPropertyIri&mappingIri=mappingIri&gravsearchTemplateIri=gravsearchTemplateIri&teiHeaderXSLTIri=teiHeaderXSLTIri See webapi/src/it/scala/org/knora/webapi/e2e/v1/KnoraSipiIntegrationV1ITSpec.scala for a complete test case involving the sample data (\"create a mapping for standoff conversion to TEI referring to an XSLT and also create a Gravsearch template and an XSLT for transforming TEI header data\"). When you provide a custom conversion, it is up to you to ensure the validity of the TEI document. You can use this service to validate: TEI by example validator . Problems and bugs caused by XSL transformations are out of scope of the responsibility of the Knora software.","title":"Custom Conversion"},{"location":"03-endpoints/api-v2/xml-to-standoff-mapping/","text":"XML to Standoff Mapping in API v2 General Information Please see v1 documentation for general information about the XML to standoff mapping: XML To Standoff Mapping in API v1 . Validating a Mapping and sending it to Knora A mapping can be validated before sending it to Knora with the following XML Schema file: webapi/src/resources/mappingXMLToStandoff.xsd . Any mapping that does not conform to this XML Schema file will be rejected by Knora. The mapping has to be sent as a multipart request to the standoff route using the path segment mapping : HTTP POST http://host/v2/mapping The multipart request consists of two named parts: \"json\": { \"knora-api:mappingHasName\": \"My Mapping\", \"knora-api:attachedToProject\": \"projectIRI\", \"rdfs:label\": \"MappingNameSegment\", \"@context\": { \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } } \"xml\": <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> ... </mapping> A successful response returns the Iri of the mapping. However, the Iri of a mapping is predictable: it consists of the project Iri followed by /mappings/ and the knora-api:mappingHasName submitted in the JSON-LD (if the name already exists, the request will be rejected). Once created, a mapping can be used to create TextValues in Knora. The formats are documented in the v2 typescript interfaces AddMappingRequest and AddMappingResponse in module MappingFormats","title":"XML to Standoff Mapping"},{"location":"03-endpoints/api-v2/xml-to-standoff-mapping/#xml-to-standoff-mapping-in-api-v2","text":"","title":"XML to Standoff Mapping in API v2"},{"location":"03-endpoints/api-v2/xml-to-standoff-mapping/#general-information","text":"Please see v1 documentation for general information about the XML to standoff mapping: XML To Standoff Mapping in API v1 .","title":"General Information"},{"location":"03-endpoints/api-v2/xml-to-standoff-mapping/#validating-a-mapping-and-sending-it-to-knora","text":"A mapping can be validated before sending it to Knora with the following XML Schema file: webapi/src/resources/mappingXMLToStandoff.xsd . Any mapping that does not conform to this XML Schema file will be rejected by Knora. The mapping has to be sent as a multipart request to the standoff route using the path segment mapping : HTTP POST http://host/v2/mapping The multipart request consists of two named parts: \"json\": { \"knora-api:mappingHasName\": \"My Mapping\", \"knora-api:attachedToProject\": \"projectIRI\", \"rdfs:label\": \"MappingNameSegment\", \"@context\": { \"rdfs\": \"http://www.w3.org/2000/01/rdf-schema#\", \"knora-api\": \"http://api.knora.org/ontology/knora-api/v2#\" } } \"xml\": <?xml version=\"1.0\" encoding=\"UTF-8\"?> <mapping> ... </mapping> A successful response returns the Iri of the mapping. However, the Iri of a mapping is predictable: it consists of the project Iri followed by /mappings/ and the knora-api:mappingHasName submitted in the JSON-LD (if the name already exists, the request will be rejected). Once created, a mapping can be used to create TextValues in Knora. The formats are documented in the v2 typescript interfaces AddMappingRequest and AddMappingResponse in module MappingFormats","title":"Validating a Mapping and sending it to Knora"},{"location":"04-publishing-deployment/configuration/","text":"Configuration All configuration for Knora is done in application.conf . Besides the Knora application specific configuration, there we can also find configuration for the underlying Akka library. For optimal performance it is important to tune the configuration to the hardware used, mainly to the number of CPUs and cores per CPU. The relevant sections for tuning are: akka.actor.deployment knora-actor-dispatcher knora-blocking-dispatcher System Environment Variables A number of core settings is additionally configurable through system environment variables. These are: key in application.conf environment variable default value akka.log-config-on-start KNORA_AKKA_LOG_CONFIG_ON_START off akka.loglevel KNORA_AKKA_LOGLEVEL INFO akka.stdout-loglevel KNORA_AKKA_STDOUT_LOGLEVEL INFO app.print-extended-config KNORA_WEBAPI_PRINT_EXTENDED_CONFIG false app.bcrypt-password-strength KNORA_WEBAPI_BCRYPT_PASSWORD_STRENGTH 12 app.jwt-secret-key KNORA_WEBAPI_JWT_SECRET_KEY super-secret-key app.jwt-longevity KNORA_WEBAPI_JWT_LONGEVITY 30 days app.cookie-domain KNORA_WEBAPI_COOKIE_DOMAIN localhost app.allow-reload-over-http KNORA_WEBAPI_ALLOW_RELOAD_OVER_HTTP false app.ark.resolver KNORA_WEBAPI_ARK_RESOLVER_URL http://0.0.0.0:3336 app.ark.assigned-number KNORA_WEBAPI_ARK_NAAN 72163 app.knora-api.internal-host KNORA_WEBAPI_KNORA_API_INTERNAL_HOST 0.0.0.0 app.knora-api.internal-port KNORA_WEBAPI_KNORA_API_INTERNAL_PORT 3333 app.knora-api.external-protocol KNORA_WEBAPI_KNORA_API_EXTERNAL_PROTOCOL http app.knora-api.external-host KNORA_WEBAPI_KNORA_API_EXTERNAL_HOST 0.0.0.0 app.knora-api.external-port KNORA_WEBAPI_KNORA_API_EXTERNAL_PORT 3333 app.sipi.internal-protocol KNORA_WEBAPI_SIPI_INTERNAL_PROTOCOL http app.sipi.internal-host KNORA_WEBAPI_SIPI_INTERNAL_HOST localhost app.sipi.internal-port KNORA_WEBAPI_SIPI_INTERNAL_PORT 1024 app.sipi.external-protocol KNORA_WEBAPI_SIPI_EXTERNAL_PROTOCOL http app.sipi.external-host KNORA_WEBAPI_SIPI_EXTERNAL_HOST localhost app.sipi.external-port KNORA_WEBAPI_SIPI_EXTERNAL_PORT 443 app.ark.resolver KNORA_WEBAPI_ARK_RESOLVER_URL http://0.0.0.0:3336 app.ark.assigned-number KNORA_WEBAPI_ARK_NAAN 72163 app.salsah1.base-url KNORA_WEBAPI_SALSAH1_BASE_URL http://localhost:3335 app.triplestore.dbtype KNORA_WEBAPI_TRIPLESTORE_DBTYPE fuseki app.triplestore.use-https KNORA_WEBAPI_TRIPLESTORE_USE_HTTPS false app.triplestore.host KNORA_WEBAPI_TRIPLESTORE_HOST localhost app.triplestore.auto-init KNORA_WEBAPI_TRIPLESTORE_AUTOINIT false app.triplestore.fuseki.port KNORA_WEBAPI_TRIPLESTORE_FUSEKI_PORT 3030 app.triplestore.fuseki.repository-name KNORA_WEBAPI_TRIPLESTORE_FUSEKI_REPOSITORY_NAME knora-test app.triplestore.fuseki.username KNORA_WEBAPI_TRIPLESTORE_FUSEKI_USERNAME admin app.triplestore.fuseki.password KNORA_WEBAPI_TRIPLESTORE_FUSEKI_PASSWORD test app.cache-service.enabled KNORA_WEBAPI_CACHE_SERVICE_ENABLED true app.cache-service.redis.host KNORA_WEBAPI_CACHE_SERVICE_REDIS_HOST localhost app.cache-service.redis.port KNORA_WEBAPI_CACHE_SERVICE_REDIS_PORT 6379 Selectively Disabling Routes In application.conf the setting app.routes-to-reject contains a list of strings, representing routes which should be rejected. For Example, the string \"v1/users\" would lead to rejection of any route which contains this string. Startup Flags There is a number of flags that can be set on startup, they will override any value set in the application configuration file: loadDemoData , --loadDemoData , -d : Loads the demo data. allowReloadOverHTTP , --allow-reload-over-http , -r : Allows reloading of data over HTTP. -c : Print the configuration at startup. --help : Shows the help message with all startup flags.","title":"Configuration"},{"location":"04-publishing-deployment/configuration/#configuration","text":"All configuration for Knora is done in application.conf . Besides the Knora application specific configuration, there we can also find configuration for the underlying Akka library. For optimal performance it is important to tune the configuration to the hardware used, mainly to the number of CPUs and cores per CPU. The relevant sections for tuning are: akka.actor.deployment knora-actor-dispatcher knora-blocking-dispatcher","title":"Configuration"},{"location":"04-publishing-deployment/configuration/#system-environment-variables","text":"A number of core settings is additionally configurable through system environment variables. These are: key in application.conf environment variable default value akka.log-config-on-start KNORA_AKKA_LOG_CONFIG_ON_START off akka.loglevel KNORA_AKKA_LOGLEVEL INFO akka.stdout-loglevel KNORA_AKKA_STDOUT_LOGLEVEL INFO app.print-extended-config KNORA_WEBAPI_PRINT_EXTENDED_CONFIG false app.bcrypt-password-strength KNORA_WEBAPI_BCRYPT_PASSWORD_STRENGTH 12 app.jwt-secret-key KNORA_WEBAPI_JWT_SECRET_KEY super-secret-key app.jwt-longevity KNORA_WEBAPI_JWT_LONGEVITY 30 days app.cookie-domain KNORA_WEBAPI_COOKIE_DOMAIN localhost app.allow-reload-over-http KNORA_WEBAPI_ALLOW_RELOAD_OVER_HTTP false app.ark.resolver KNORA_WEBAPI_ARK_RESOLVER_URL http://0.0.0.0:3336 app.ark.assigned-number KNORA_WEBAPI_ARK_NAAN 72163 app.knora-api.internal-host KNORA_WEBAPI_KNORA_API_INTERNAL_HOST 0.0.0.0 app.knora-api.internal-port KNORA_WEBAPI_KNORA_API_INTERNAL_PORT 3333 app.knora-api.external-protocol KNORA_WEBAPI_KNORA_API_EXTERNAL_PROTOCOL http app.knora-api.external-host KNORA_WEBAPI_KNORA_API_EXTERNAL_HOST 0.0.0.0 app.knora-api.external-port KNORA_WEBAPI_KNORA_API_EXTERNAL_PORT 3333 app.sipi.internal-protocol KNORA_WEBAPI_SIPI_INTERNAL_PROTOCOL http app.sipi.internal-host KNORA_WEBAPI_SIPI_INTERNAL_HOST localhost app.sipi.internal-port KNORA_WEBAPI_SIPI_INTERNAL_PORT 1024 app.sipi.external-protocol KNORA_WEBAPI_SIPI_EXTERNAL_PROTOCOL http app.sipi.external-host KNORA_WEBAPI_SIPI_EXTERNAL_HOST localhost app.sipi.external-port KNORA_WEBAPI_SIPI_EXTERNAL_PORT 443 app.ark.resolver KNORA_WEBAPI_ARK_RESOLVER_URL http://0.0.0.0:3336 app.ark.assigned-number KNORA_WEBAPI_ARK_NAAN 72163 app.salsah1.base-url KNORA_WEBAPI_SALSAH1_BASE_URL http://localhost:3335 app.triplestore.dbtype KNORA_WEBAPI_TRIPLESTORE_DBTYPE fuseki app.triplestore.use-https KNORA_WEBAPI_TRIPLESTORE_USE_HTTPS false app.triplestore.host KNORA_WEBAPI_TRIPLESTORE_HOST localhost app.triplestore.auto-init KNORA_WEBAPI_TRIPLESTORE_AUTOINIT false app.triplestore.fuseki.port KNORA_WEBAPI_TRIPLESTORE_FUSEKI_PORT 3030 app.triplestore.fuseki.repository-name KNORA_WEBAPI_TRIPLESTORE_FUSEKI_REPOSITORY_NAME knora-test app.triplestore.fuseki.username KNORA_WEBAPI_TRIPLESTORE_FUSEKI_USERNAME admin app.triplestore.fuseki.password KNORA_WEBAPI_TRIPLESTORE_FUSEKI_PASSWORD test app.cache-service.enabled KNORA_WEBAPI_CACHE_SERVICE_ENABLED true app.cache-service.redis.host KNORA_WEBAPI_CACHE_SERVICE_REDIS_HOST localhost app.cache-service.redis.port KNORA_WEBAPI_CACHE_SERVICE_REDIS_PORT 6379","title":"System Environment Variables"},{"location":"04-publishing-deployment/configuration/#selectively-disabling-routes","text":"In application.conf the setting app.routes-to-reject contains a list of strings, representing routes which should be rejected. For Example, the string \"v1/users\" would lead to rejection of any route which contains this string.","title":"Selectively Disabling Routes"},{"location":"04-publishing-deployment/configuration/#startup-flags","text":"There is a number of flags that can be set on startup, they will override any value set in the application configuration file: loadDemoData , --loadDemoData , -d : Loads the demo data. allowReloadOverHTTP , --allow-reload-over-http , -r : Allows reloading of data over HTTP. -c : Print the configuration at startup. --help : Shows the help message with all startup flags.","title":"Startup Flags"},{"location":"04-publishing-deployment/getting-started/","text":"Getting Started with DSP-API Running DSP-API locally or on a server requires Docker , which can be freely downloaded. Please follow the instructions for installing Docker Desktop . Please visit the GitHub repository of DSP-API to get the latest information about how to install and run DSP-API. Choosing a Triplestore DSP-API requires a standards-compliant RDF triplestore. A number of triplestore implementations are available, including free software as well as proprietary options. DSP-API is designed to work with any standards-compliant triplestore. It is primarily tested with Apache Jena Fuseki , an open source triplestore. Running the DSP-Stack Use git to clone the DSP-API repository from Github . Then from inside the cloned DSP-API repository folder, run: $ make stack-up Creating Repositories and Loading Test Data To create a test repository called knora-test and load test data, run: $ make init-db-test The scripts called by make can be found under webapi/scripts . You can create your own scripts based on these scripts, to create new repositories and optionally to load existing DSP-compliant RDF data into them. If you need to reload the test data, you need to stop and delete the running Apache Fuseki instance. Make sure you don't delete important data. To stop the instance and delete the repository, run the following command: $ make stack-down-delete-volumes after which you can start the stack again with make stack-up , recreate the repository and load the data with make init-db-test .","title":"Getting Started with DSP-API"},{"location":"04-publishing-deployment/getting-started/#getting-started-with-dsp-api","text":"Running DSP-API locally or on a server requires Docker , which can be freely downloaded. Please follow the instructions for installing Docker Desktop . Please visit the GitHub repository of DSP-API to get the latest information about how to install and run DSP-API.","title":"Getting Started with DSP-API"},{"location":"04-publishing-deployment/getting-started/#choosing-a-triplestore","text":"DSP-API requires a standards-compliant RDF triplestore. A number of triplestore implementations are available, including free software as well as proprietary options. DSP-API is designed to work with any standards-compliant triplestore. It is primarily tested with Apache Jena Fuseki , an open source triplestore.","title":"Choosing a Triplestore"},{"location":"04-publishing-deployment/getting-started/#running-the-dsp-stack","text":"Use git to clone the DSP-API repository from Github . Then from inside the cloned DSP-API repository folder, run: $ make stack-up","title":"Running the DSP-Stack"},{"location":"04-publishing-deployment/getting-started/#creating-repositories-and-loading-test-data","text":"To create a test repository called knora-test and load test data, run: $ make init-db-test The scripts called by make can be found under webapi/scripts . You can create your own scripts based on these scripts, to create new repositories and optionally to load existing DSP-compliant RDF data into them. If you need to reload the test data, you need to stop and delete the running Apache Fuseki instance. Make sure you don't delete important data. To stop the instance and delete the repository, run the following command: $ make stack-down-delete-volumes after which you can start the stack again with make stack-up , recreate the repository and load the data with make init-db-test .","title":"Creating Repositories and Loading Test Data"},{"location":"04-publishing-deployment/publishing/","text":"Publishing DSP is published as a set of Docker images under the DaSCH Dockerhub Organization . The following Docker images are published: DSP-API: https://hub.docker.com/r/daschswiss/knora-api Sipi (includes DSP's specific Sipi scripts): https://hub.docker.com/r/daschswiss/knora-sipi DSP-APP: https://hub.docker.com/r/daschswiss/dsp-app DSP's Docker images are published automatically through Github CI each time a pull-request is merged into the main branch. Each image is tagged with a version number, which is derived by using the result of git describe . The describe version is built from the last tag + number of commits since tag + short hash , e.g., 8.0.0-7-ga7827e9 . The images can be published locally by running: $ make docker-build or to Dockerhub: $ make docker-publish","title":"Publishing"},{"location":"04-publishing-deployment/publishing/#publishing","text":"DSP is published as a set of Docker images under the DaSCH Dockerhub Organization . The following Docker images are published: DSP-API: https://hub.docker.com/r/daschswiss/knora-api Sipi (includes DSP's specific Sipi scripts): https://hub.docker.com/r/daschswiss/knora-sipi DSP-APP: https://hub.docker.com/r/daschswiss/dsp-app DSP's Docker images are published automatically through Github CI each time a pull-request is merged into the main branch. Each image is tagged with a version number, which is derived by using the result of git describe . The describe version is built from the last tag + number of commits since tag + short hash , e.g., 8.0.0-7-ga7827e9 . The images can be published locally by running: $ make docker-build or to Dockerhub: $ make docker-publish","title":"Publishing"},{"location":"04-publishing-deployment/updates/","text":"Updating Repositories When Upgrading Knora When a new version of Knora introduces changes that are not backwards-compatible with existing data, your repository will need to be updated. Upgrading from Knora Version 7.0.0 or Later In most cases, Knora will update your repository automatically when it starts. If manual changes are needed, these will be described in the release notes, and must be done first. Before starting a new version of Knora, back up your repository, so you can restore it in case the automatic repository update fails. For Fuseki use fuseki-dump-repository.sh script located in webapi/scripts . For information on command-line options, run the script with no arguments.","title":"Updating Repositories when Upgrading DSP-API"},{"location":"04-publishing-deployment/updates/#updating-repositories-when-upgrading-knora","text":"When a new version of Knora introduces changes that are not backwards-compatible with existing data, your repository will need to be updated.","title":"Updating Repositories When Upgrading Knora"},{"location":"04-publishing-deployment/updates/#upgrading-from-knora-version-700-or-later","text":"In most cases, Knora will update your repository automatically when it starts. If manual changes are needed, these will be described in the release notes, and must be done first. Before starting a new version of Knora, back up your repository, so you can restore it in case the automatic repository update fails. For Fuseki use fuseki-dump-repository.sh script located in webapi/scripts . For information on command-line options, run the script with no arguments.","title":"Upgrading from Knora Version 7.0.0 or Later"},{"location":"05-internals/design/adr/0001-record-architecture-decisions/","text":"1. Record architectural decisions Date: 2022-03-14 Status Accepted Context We need to record the architectural decisions made on this project. Decision We will use Architectural Decision Records, as described by Michael Nygard . Consequences See Michael Nygard's article, linked above. For a lightweight ADR toolset, see Nat Pryce's adr-tools .","title":"Record Architectural Decisions"},{"location":"05-internals/design/adr/0001-record-architecture-decisions/#1-record-architectural-decisions","text":"Date: 2022-03-14","title":"1. Record architectural decisions"},{"location":"05-internals/design/adr/0001-record-architecture-decisions/#status","text":"Accepted","title":"Status"},{"location":"05-internals/design/adr/0001-record-architecture-decisions/#context","text":"We need to record the architectural decisions made on this project.","title":"Context"},{"location":"05-internals/design/adr/0001-record-architecture-decisions/#decision","text":"We will use Architectural Decision Records, as described by Michael Nygard .","title":"Decision"},{"location":"05-internals/design/adr/0001-record-architecture-decisions/#consequences","text":"See Michael Nygard's article, linked above. For a lightweight ADR toolset, see Nat Pryce's adr-tools .","title":"Consequences"},{"location":"05-internals/design/adr/0002-change-cache-service-manager-from-akka-actor-to-zlayer/","text":"2. Change Cache Service Manager from Akka-Actor to ZLayer Date: 2022-04-06 Status Accepted Context The org.knora.webapi.store.cacheservice.CacheServiceManager was implemented as an Akka-Actor . Decision As part of the move from Akka to ZIO , it was decided that the CacheServiceManager and the whole implementation of the in-memory and Redis backed cache is refactored using ZIO. Consequences The usage from other actors stays the same. The actor messages and responses don't change.","title":"Change Cache Service Manager from Akka-Actor to ZLayer"},{"location":"05-internals/design/adr/0002-change-cache-service-manager-from-akka-actor-to-zlayer/#2-change-cache-service-manager-from-akka-actor-to-zlayer","text":"Date: 2022-04-06","title":"2. Change Cache Service Manager from Akka-Actor to ZLayer"},{"location":"05-internals/design/adr/0002-change-cache-service-manager-from-akka-actor-to-zlayer/#status","text":"Accepted","title":"Status"},{"location":"05-internals/design/adr/0002-change-cache-service-manager-from-akka-actor-to-zlayer/#context","text":"The org.knora.webapi.store.cacheservice.CacheServiceManager was implemented as an Akka-Actor .","title":"Context"},{"location":"05-internals/design/adr/0002-change-cache-service-manager-from-akka-actor-to-zlayer/#decision","text":"As part of the move from Akka to ZIO , it was decided that the CacheServiceManager and the whole implementation of the in-memory and Redis backed cache is refactored using ZIO.","title":"Decision"},{"location":"05-internals/design/adr/0002-change-cache-service-manager-from-akka-actor-to-zlayer/#consequences","text":"The usage from other actors stays the same. The actor messages and responses don't change.","title":"Consequences"},{"location":"05-internals/design/adr/0003-change-iiif-service-manager-and-sipi-implementation-to-zlayer/","text":"3. Change IIIF Service Manager and Sipi implementation to zlayer Date: 2022-04-29 Status Accepted Context Both org.knora.webapi.store.iiif.IIIFServiceManager and org.knora.webapi.store.iiif.impl.IIIFServiceSipiImpl where implemented as Akka-Actors Decision As part of the move from Akka to ZIO , it was decided that the IIIFServiceManager and the IIIFServiceSipiImpl is refactored using ZIO. Consequences The usage from other actors stays the same. The actor messages and responses don't change.","title":"Change IIIF Service Manager and Sipi implementation to zlayer"},{"location":"05-internals/design/adr/0003-change-iiif-service-manager-and-sipi-implementation-to-zlayer/#3-change-iiif-service-manager-and-sipi-implementation-to-zlayer","text":"Date: 2022-04-29","title":"3. Change IIIF Service Manager and Sipi implementation to zlayer"},{"location":"05-internals/design/adr/0003-change-iiif-service-manager-and-sipi-implementation-to-zlayer/#status","text":"Accepted","title":"Status"},{"location":"05-internals/design/adr/0003-change-iiif-service-manager-and-sipi-implementation-to-zlayer/#context","text":"Both org.knora.webapi.store.iiif.IIIFServiceManager and org.knora.webapi.store.iiif.impl.IIIFServiceSipiImpl where implemented as Akka-Actors","title":"Context"},{"location":"05-internals/design/adr/0003-change-iiif-service-manager-and-sipi-implementation-to-zlayer/#decision","text":"As part of the move from Akka to ZIO , it was decided that the IIIFServiceManager and the IIIFServiceSipiImpl is refactored using ZIO.","title":"Decision"},{"location":"05-internals/design/adr/0003-change-iiif-service-manager-and-sipi-implementation-to-zlayer/#consequences","text":"The usage from other actors stays the same. The actor messages and responses don't change.","title":"Consequences"},{"location":"05-internals/design/adr/0004-change-triplestore-service-manager-and-fuseki-implementation-to-zlayer/","text":"4. Change Triplestore Service Manager and Fuseki implementation to ZLayer Date: 2022-05-23 Status Accepted Context Both org.knora.webapi.store.triplestore.TriplestoreServiceManager and org.knora.webapi.store.triplestore.impl.TriplestoreServiceHttpConnectorImpl where implemented as Akka-Actors. Decision As part of the move from Akka to ZIO , it was decided that the TriplestoreServiceManager and the TriplestoreServiceHttpConnectorImpl is refactored using ZIO. Consequences The usage from other actors stays the same. The actor messages and responses don't change.","title":"Change Triplestore Service Manager and Fuseki implementation to ZLayer"},{"location":"05-internals/design/adr/0004-change-triplestore-service-manager-and-fuseki-implementation-to-zlayer/#4-change-triplestore-service-manager-and-fuseki-implementation-to-zlayer","text":"Date: 2022-05-23","title":"4. Change Triplestore Service Manager and Fuseki implementation to ZLayer"},{"location":"05-internals/design/adr/0004-change-triplestore-service-manager-and-fuseki-implementation-to-zlayer/#status","text":"Accepted","title":"Status"},{"location":"05-internals/design/adr/0004-change-triplestore-service-manager-and-fuseki-implementation-to-zlayer/#context","text":"Both org.knora.webapi.store.triplestore.TriplestoreServiceManager and org.knora.webapi.store.triplestore.impl.TriplestoreServiceHttpConnectorImpl where implemented as Akka-Actors.","title":"Context"},{"location":"05-internals/design/adr/0004-change-triplestore-service-manager-and-fuseki-implementation-to-zlayer/#decision","text":"As part of the move from Akka to ZIO , it was decided that the TriplestoreServiceManager and the TriplestoreServiceHttpConnectorImpl is refactored using ZIO.","title":"Decision"},{"location":"05-internals/design/adr/0004-change-triplestore-service-manager-and-fuseki-implementation-to-zlayer/#consequences","text":"The usage from other actors stays the same. The actor messages and responses don't change.","title":"Consequences"},{"location":"05-internals/design/adr/0005-change-respondermanager-to-a-simple-case-class/","text":"5. Change ResponderManager to a simple case class Date: 2022-06-06 Status Accepted Context The org.knora.webapi.responders.ResponderManager was implemented as an Akka-Actor. Decision In preparation of the move from Akka to ZIO , it was decided that the ResponderManager is refactored using plain case classes. Consequences The actor messages and responses don't change. All calls made previously to the ResponderManager and the StorageManager are now changed to the ApplicationActor which will route the calls to either the ResponderManager or the StorageManager based on the message type. The ApplicationActor is the only actor that is allowed to make calls to either the ResponderManager or the StorageManager . All requests from routes are now routed to the ApplicationActor .","title":"Change ResponderManager to a simple case class"},{"location":"05-internals/design/adr/0005-change-respondermanager-to-a-simple-case-class/#5-change-respondermanager-to-a-simple-case-class","text":"Date: 2022-06-06","title":"5. Change ResponderManager to a simple case class"},{"location":"05-internals/design/adr/0005-change-respondermanager-to-a-simple-case-class/#status","text":"Accepted","title":"Status"},{"location":"05-internals/design/adr/0005-change-respondermanager-to-a-simple-case-class/#context","text":"The org.knora.webapi.responders.ResponderManager was implemented as an Akka-Actor.","title":"Context"},{"location":"05-internals/design/adr/0005-change-respondermanager-to-a-simple-case-class/#decision","text":"In preparation of the move from Akka to ZIO , it was decided that the ResponderManager is refactored using plain case classes.","title":"Decision"},{"location":"05-internals/design/adr/0005-change-respondermanager-to-a-simple-case-class/#consequences","text":"The actor messages and responses don't change. All calls made previously to the ResponderManager and the StorageManager are now changed to the ApplicationActor which will route the calls to either the ResponderManager or the StorageManager based on the message type. The ApplicationActor is the only actor that is allowed to make calls to either the ResponderManager or the StorageManager . All requests from routes are now routed to the ApplicationActor .","title":"Consequences"},{"location":"05-internals/design/api-admin/administration/","text":"Administration (Users, Projects, Groups, Institutions, Permissions) Scope This Section includes management (creation, updating, deletion) of Users , Projects , Groups , Institutions , and Permissions . Implementation All administration functions will be implemented as part of the Knora API in the webapi codebase. There is also a separate web-application as part of DSP-APP and [DSP-TOOLS]{https://github.com/dasch-swiss/dsp-tools} using this API, allowing basic management operations. Overview During the initial deployment of a Knora server, the main administration user ( root ) is created. This root user has the right to do anything. DSP\u2019s concept of access control is that permissions can only be granted to groups and not to individual users. There are two distinct ways of granting permission. Firstly, an object (a resource or value) can grant permissions to groups of users, and secondly, permissions can be granted directly to a group of users (not bound to a specific object). There are six built-in groups: UnknownUser , KnownUser , Creator , ProjectMember , ProjectAdmin , and SystemAdmin . These groups can be used in the same way as normal user created groups for permission management, i.e. can be used to give certain groups of users, certain permissions, without the need to explicitly create them. A user becomes implicitly a member of such a group by satisfying certain conditions: knora-admin:UnknownUser : Any user who has not logged into Knora is automatically assigned to this group. knora-admin:KnownUser : Any user who has logged into Knora is automatically assigned to this group. knora-admin:Creator : When checking a user\u2019s permissions on an object, the user is automatically assigned to this group if he is the creator of the object. knora-admin:ProjectMember : When checking a user\u2019s permissions, the user is automatically assigned to this group by being a member of a project designated by the knora-admin:isInProject property. knora-admin:ProjectAdmin : When checking a user's permission, the user is automatically assigned to this group through the knora-admin:isInProjectAdminGroup property, which points to the project in question. knora-admin:SystemAdmin : Membership is received by setting the property knora-admin:isInSystemAdminGroup to true on a knora-admin:User . To use these build-in groups as values for properties (Object Access and Default Permissions), the IRI is constructed by appending the name of the built-in group to knora-admin , e.g., knora-admin:KnownUser where knora-admin corresponds to http://www.knora.org/ontology/knora-admin# . Permissions Up until know, we have mentioned two groups of permissions. The first called object access permissions , which contains permissions that point from explicit objects (resources/values) to groups. The second group of permissions called administrative permissions , and which contains permissions that are put on instances of knora-admin:Permission objects directly affecting groups. There is another, third group of permissions, called default object access permissions which is also put on instances of knora-admin:Permission , and which also directly affect groups. Object Access Permissions An object (resource / value) can grant the following permissions, which are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions : Restricted view permission (RV) : Allows a restricted view of the object, e.g. a view of an image with a watermark. View permission (V) : Allows an unrestricted view of the object. Having view permission on a resource only affects the user\u2019s ability to view information about the resource other than its values. To view a value, she must have view permission on the value itself. Modify permission (M) : For values, this permission allows a new version of a value to be created. For resources, this allows the user to create a new value (as opposed to a new version of an existing value), or to change information about the resource other than its values. When he wants to make a new version of a value, his permissions on the containing resource are not relevant. However, when he wants to change the target of a link, the old link must be deleted and a new one created, so he needs modify permission on the resource. Delete permission (D) : Allows the item to be marked as deleted. Change rights permission (CR) : Allows the permissions granted by the object to be changed. Each permission in the above list implies all lower-numbered permissions. A user\u2019s permission level on a particular object is calculated in the following way: Make a list of the groups that the user belongs to, including Creator and/or ProjectMember and/or ProjectAdmin if applicable. Make a list of the permissions that she can obtain on the object, by iterating over the permissions that the object grants. For each permission, if she is in the specified group, add the specified permission to the list of permissions she can obtain. From the resulting list, select the highest-level permission. If the result is that she would have no permissions, give her whatever permission UnknownUser would have. The format of the object of knora-base:hasPermissions is as follows: Each permission is represented by the one-letter or two-letter abbreviation given above. Each permission abbreviation is followed by a space, then a comma-separated list of groups that the permission is granted to. The IRIs of built-in groups are shortened using the knora-admin prefix. Multiple permissions are separated by a vertical bar (|). For example, if an object grants view permission to unknown and known users , and modify permission to project members , the resulting permission literal would be: : V knora-admin:UnknownUser,knora-admin:KnownUser|M knora-admin:ProjectMember Administrative Permissions The following permissions can be set via instances of knora-admin:AdministrativePermission on any group belonging to a project. For users that are members of a number of groups with administrative permissions attached, the final set of permissions is additive and most permissive. The administrative permissions are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions attached to an instance of the knora-admin:AdministrativePermission class. The following permission values can be used: Resource / Value Creation Permissions: 1) ProjectResourceCreateAllPermission : description: gives the permission to create resources inside the project. usage: used as a value for knora-base:hasPermissions . 2) ProjectResourceCreateRestrictedPermission : description: gives restricted resource creation permission inside the project. usage: used as a value for knora-base:hasPermissions . value: RestrictedProjectResourceCreatePermission followed by a comma-separated list of ResourceClasses the user should only be able to create instances of. Project Administration Permissions: 1) ProjectAdminAllPermission : description: gives the user the permission to do anything on project level, i.e. create new groups, modify all existing groups ( group info , group membership , resource creation permissions , project administration permissions , and default permissions ). usage: used as a value for knora-base:hasPermissions . 2) ProjectAdminGroupAllPermission : description: gives the user the permission to modify group info and group membership on all groups belonging to the project. usage: used as a value for the knora-base:hasPermissions property. 3) ProjectAdminGroupRestrictedPermission : description: gives the user the permission to modify group info and group membership on certain groups belonging to the project. usage: used as a value for knora-base:hasPermissions value: ProjectGroupAdminRestrictedPermission followed by a comma-separated list of knora-admin:UserGroup . 4) ProjectAdminRightsAllPermission : description: gives the user the permission to change the permissions on all objects belonging to the project (e.g., default permissions attached to groups and permissions on objects). usage: used as a value for the knora-base:hasPermissions property. Ontology Administration Permissions: 1) ProjectAdminOntologyAllPermission : description: gives the user the permission to administer the project ontologies usage: used as a value for the knora-base:hasPermissions property. The administrative permissions are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions attached to an instance of the knora-admin:AdministrativePermission class. The format of the object of knora-base:hasPermissions is as follows: Each permission is represented by the name given above. Each permission is followed by a space, then if applicable, by a comma separated list of IRIs, as defined above. The IRIs of built-in values (e.g., built-in groups, resource classes, etc.) are shortened using the knora-admin prefix knora-admin: . Multiple permissions are separated by a vertical bar (|). For example, if an administrative permission grants the knora-admin:ProjectMember group the permission to create all resources ( ProjectResourceCreateAllPermission ), the resulting administrative permission object with the compact form literal would be: : <http://rdfh.ch/permissions/001 rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA>; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission\"^^xsd:string . Default Object Access Permissions Default Object Access Permissions are used when new objects (resources and/or values) are created. They represent object access permissions with which the new object will be initially outfitted. As with administrative permissions, these default object access permissions can be defined for any number of groups. Additionally, they can be also defined for resource classes and properties. The following default object access permissions can be attached to groups, resource classes and/or properties via instances of knora-admin:DefaultObjectAccessPermission (described further bellow). The default object access permissions correspond to the earlier described object access permission: Default Restricted View Permission (RV) : description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: RV followed by a comma-separated list of knora-admin:UserGroup Default View Permission (V) : description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: V followed by a comma-separated list of knora-admin:UserGroup Default Modify Permission (M) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: M followed by a comma-separated list of knora-admin:UserGroup Default Delete Permission (D) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: D followed by a comma-separated list of knora-admin:UserGroup Default Change Rights Permission (CR) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: CR followed by a comma-separated list of knora-admin:UserGroup A single instance of knora-admin:DefaultObjectAccessPermission must always reference a project, but can only reference either a group ( knora-admin:forGroup property), a resource class ( knora-admin:forResourceClass ), a property ( knora-admin:forProperty ), or a combination of resource class and property. Example default object access permission instance: <http://rdfh.ch/permissions/002 rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA>; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:KnownUser\"^^xsd:string . This instance is setting default object access permissions to the project member group of a project, giving change right permission to the creator, modify permission to all project members, and view permission to known users. Further, this implicitly applies to all resource classes and all their properties inside the project. Permission Precedence Rules For both administrative permissions and default object access permissions, the resulting permissions are derived by applying precedence rules, for the case that the user is member of more than one group. The following list is sorted by the permission precedence level in descending order: permissions on knora-admin:ProjectAdmin (highest level) permissions on resource classes and property combination (own project) permissions on resource classes and property combination ( knora-admin:SystemProject ) permissions on resource classes / properties (own project) permissions on resource classes / properties ( knora-admin:SystemProject ) permissions on custom groups permissions on knora-admin:ProjectMember permissions on knora-admin:KnownUser (lowest level) The permissions on resource classes / properties are only relevant for default object access permissions. Administrative Permissions : When a user performs an operation requiring administrative permissions, then only the permissions from the highest level are taken into account. If a user is a member of more than one group on the same level (only possible for custom groups) then the defined permissions are summed up and all are taken into account. Default Object Access Permissions : When a user creates a resource or value, then only the default object permissions from the highest level are applied. If a user is a member of more than one group on the same level (only possible for custom groups) then the defined permissions are summed up and the most permissive are applied. In the case of the user belonging to the SystemAdmin group, but which is not member of a project and thus not member of any group belonging to the project, the default object access permissions from the ProjectAdmin , ProjectMember , or KnownUser group will be applied in the order of precedence. If no permissions are defined on either of these groups, then the resulting permission will be CR knora-admin:Creator . Implicit Permissions The knora-admin:SystemAdmin group receives implicitly the following permissions: receives implicitly ProjectAdminAllPermission for all projects. receives implicitly ProjectResourceCreateAllPermission for all projects. receives implicitly CR on all objects from all projects. Theses permissions are baked into the system, and cannot be changed. Default Permissions Matrix for new Projects The access control matrix defines what are the default operations a subject (i.e. User), being a member of a built-in group (represented by row headers), is permitted to perform on an object (represented by column headers). The different operation abbreviations used are defined as follows: C : Create - the subject inside the group is allowed to create the object. U : Update - the subject inside the group is allowed to update the object. R : Read - the subject inside the group is allowed to read all information about the object. D : Delete - the subject inside the group is allowed to delete the object. P : Permission - the subject inside the group is allowed to change the permissions on the object. - : none - none or not applicable Built-In Group Project Group User Resource Value SystemAdmin CRUD CRUDP CRUDP all CRUDP all CRUDP all ProjectAdmin -RUD CRUDP CRUDP +/- project CRUDP (in project) CRUDP (in project) ProjectMember ---- ----- ----- CRU-- (in project) ----- (in project) Creator ---- ----- ----- ----- (his resource) ----- (his value) KnownUser C--- C---- CRUD- himself ----- (in project) ----- (in project) Default Permissions Matrix for new Projects The explicitly defined default permissions for a new project are as follows: knora-admin:ProjectAdmin group: Administrative Permissions: ProjectResourceCreateAllPermission . ProjectAdminAllPermission . Default Object Access Permissions: CR for the knora-admin:ProjectAdmin group D for the knora-admin:ProjectAdmin group M for the knora-admin:ProjectAdmin group V for the knora-admin:ProjectAdmin group RV for the knora-admin:ProjectAdmin group The knora-admin:ProjectMember group: Administrative Permissions: ProjectResourceCreateAllPermission . Default Object Access Permissions: M for the knora-admin:ProjectMember group V for the knora-admin:ProjectMember group RV for the knora-admin:ProjectMember group Basic Workflows involving Permissions Creating a new Resource Accessing a Resource/Value Project / Group Administration Implementation The requirements for defining default permissions imposed by all the different use cases are very broad. Potentially, we need to be able to define default permissions per project, per group, per resource class, per resource property, and all their possible combinations. For this reason, we introduce the knora-admin:Permission class with two sub-classes, namely knora-admin:AdministrativePermission and knora-admin:DefaultObjectAccessPermission , which instances will carry all the necessary information. Permission Class Hierarchy and Structure The following graphs show the class hierarchy and the structure of each permission class. Permission Class Hierarchy Administrative Permission Structure : and the same as RDF: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission| ProjectResourceCreateRestrictedPermission \"<Resource Class IRI>\"| ProjectAdminAllPermission| ProjectAdminGroupAllPermission| ProjectAdminGroupRestrictedPermission \"<http://rdfh.ch/groups/[shortcode]/[UUID]>, <http://rdfh.ch/groups/[shortcode]/[UUID]>\"| ProjectAdminRightsAllPermission| ProjectAdminOntologyAllPermission\"^^xsd:string . Default Object Access Permission Structure : and the same as RDF: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-admin:forResourceClass \"Resource Class Name\" ; knora-admin:forProperty \"Resource Property Name\" ; knora-base:hasPermissions \"RV <http://rdfh.ch/groups/[shortcode]/[UUID]>| V <http://rdfh.ch/groups/[shortcode]/[UUID]>| M <http://rdfh.ch/groups/[shortcode]/[UUID]>| D <http://rdfh.ch/groups/[shortcode]/[UUID]>| CR <http://rdfh.ch/groups/[shortcode]/[UUID]>\"^^xsd:string . Querying Permission Instances The properties forProject and either of forGroup , forResourceClass , and forProperty form together a compound key , allowing finding existing permission instances, that address the same set of Project / Group / ResourceClass / Property combination, thus making it possible to extend or change the attached permissions. Administrative Permission Instances : For each group inside the project, there can be zero or one instance holding administrative permission information. Querying is straitforward by using the knora-admin:forProject and knora-admin:forGroup properties as the compound key. Default Object Access Permission Instances : For each group, resource class, or property inside the project, there can be zero or one instances holding default object access permission informations. Querying is straitforward by using the knora-admin:forProject and either knora-admin:forGroup , knora-admin:forResourceClass , or knora-admin:forProperty properties as part of the compound key. Example Data stored in the permissions graph Administrative permissions on a 'ProjectAdmin' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA> ; knora-admin:forGroup knora-admin:ProjectAdmin ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission| ProjectAdminAllPermission\"^^xsd:string . Administrative permissions on a 'ProjectMember' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA> ; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission\"^^xsd:string . Administrative permission restricting project admin permission on a group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:Permission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectGroupAdminRestrictedPermission <http://rdfh.ch/groups/[shortcode]/[UUID]>\"^^xsd:string . Administrative permission restricting resource creation for a group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectResourceCreateRestrictedPermission <http://www.knora.org/ontology/00FF/images#Person>\"^^xsd:string . Default object access permission on a 'ProjectMember' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA> ; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"CR knora-admin:Creator| M <http://rdfh.ch/groups/[shortcode]/[UUID]>| V knora-admin:KnownUser\"^^xsd:string . Default object access permission on a resource class: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forResourceClass <http://www.knora.org/ontology/00FF/images#person> ; knora-base:hasPermissions \"CR knora-admin:Creator,knora-admin:ProjectMember| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^xsd:string . Default object access permission on a resource property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forProperty <http://www.knora.org/ontology/00FF/images#lastname> ; knora-base:hasPermissions \"D knora-admin:ProjectMember,knora-admin:Creator| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^ . Default object access permission on a resource class and property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forResourceClass <http://www.knora.org/ontology/00FF/images#person> ; knora-admin:forProperty <http://www.knora.org/ontology/00FF/images#lastname> ; knora-base:hasPermissions \"CR knora-admin:Creator,knora-admin:ProjectMember| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^xsd:string . Default object access permission on a knora-admin property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject knora-admin:SystemProject ; knora-admin:forProperty <http://www.knora.org/ontology/knora-admin#hasStillImageFileValue> ; knora-base:hasPermissions \"RV knora-admin:UnknownUser| V knora-admin:KnownUser| M knora-admin:ProjectMember,knora-admin:Creator\"^^xsd:string . A the time the user's UserProfile is queried, all permissions for all projects and groups the user is a member of are also queried. This information is then stored as an easy accessible object inside the UserProfile , being readily available wherever needed. As this is a somewhat expensive operation, built-in caching mechanism at different levels (e.g., UsersResponder, PermissionsResponder), will be applied.","title":"Administration"},{"location":"05-internals/design/api-admin/administration/#administration-users-projects-groups-institutions-permissions","text":"","title":"Administration (Users, Projects, Groups, Institutions, Permissions)"},{"location":"05-internals/design/api-admin/administration/#scope","text":"This Section includes management (creation, updating, deletion) of Users , Projects , Groups , Institutions , and Permissions .","title":"Scope"},{"location":"05-internals/design/api-admin/administration/#implementation","text":"All administration functions will be implemented as part of the Knora API in the webapi codebase. There is also a separate web-application as part of DSP-APP and [DSP-TOOLS]{https://github.com/dasch-swiss/dsp-tools} using this API, allowing basic management operations.","title":"Implementation"},{"location":"05-internals/design/api-admin/administration/#overview","text":"During the initial deployment of a Knora server, the main administration user ( root ) is created. This root user has the right to do anything. DSP\u2019s concept of access control is that permissions can only be granted to groups and not to individual users. There are two distinct ways of granting permission. Firstly, an object (a resource or value) can grant permissions to groups of users, and secondly, permissions can be granted directly to a group of users (not bound to a specific object). There are six built-in groups: UnknownUser , KnownUser , Creator , ProjectMember , ProjectAdmin , and SystemAdmin . These groups can be used in the same way as normal user created groups for permission management, i.e. can be used to give certain groups of users, certain permissions, without the need to explicitly create them. A user becomes implicitly a member of such a group by satisfying certain conditions: knora-admin:UnknownUser : Any user who has not logged into Knora is automatically assigned to this group. knora-admin:KnownUser : Any user who has logged into Knora is automatically assigned to this group. knora-admin:Creator : When checking a user\u2019s permissions on an object, the user is automatically assigned to this group if he is the creator of the object. knora-admin:ProjectMember : When checking a user\u2019s permissions, the user is automatically assigned to this group by being a member of a project designated by the knora-admin:isInProject property. knora-admin:ProjectAdmin : When checking a user's permission, the user is automatically assigned to this group through the knora-admin:isInProjectAdminGroup property, which points to the project in question. knora-admin:SystemAdmin : Membership is received by setting the property knora-admin:isInSystemAdminGroup to true on a knora-admin:User . To use these build-in groups as values for properties (Object Access and Default Permissions), the IRI is constructed by appending the name of the built-in group to knora-admin , e.g., knora-admin:KnownUser where knora-admin corresponds to http://www.knora.org/ontology/knora-admin# .","title":"Overview"},{"location":"05-internals/design/api-admin/administration/#permissions","text":"Up until know, we have mentioned two groups of permissions. The first called object access permissions , which contains permissions that point from explicit objects (resources/values) to groups. The second group of permissions called administrative permissions , and which contains permissions that are put on instances of knora-admin:Permission objects directly affecting groups. There is another, third group of permissions, called default object access permissions which is also put on instances of knora-admin:Permission , and which also directly affect groups.","title":"Permissions"},{"location":"05-internals/design/api-admin/administration/#object-access-permissions","text":"An object (resource / value) can grant the following permissions, which are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions : Restricted view permission (RV) : Allows a restricted view of the object, e.g. a view of an image with a watermark. View permission (V) : Allows an unrestricted view of the object. Having view permission on a resource only affects the user\u2019s ability to view information about the resource other than its values. To view a value, she must have view permission on the value itself. Modify permission (M) : For values, this permission allows a new version of a value to be created. For resources, this allows the user to create a new value (as opposed to a new version of an existing value), or to change information about the resource other than its values. When he wants to make a new version of a value, his permissions on the containing resource are not relevant. However, when he wants to change the target of a link, the old link must be deleted and a new one created, so he needs modify permission on the resource. Delete permission (D) : Allows the item to be marked as deleted. Change rights permission (CR) : Allows the permissions granted by the object to be changed. Each permission in the above list implies all lower-numbered permissions. A user\u2019s permission level on a particular object is calculated in the following way: Make a list of the groups that the user belongs to, including Creator and/or ProjectMember and/or ProjectAdmin if applicable. Make a list of the permissions that she can obtain on the object, by iterating over the permissions that the object grants. For each permission, if she is in the specified group, add the specified permission to the list of permissions she can obtain. From the resulting list, select the highest-level permission. If the result is that she would have no permissions, give her whatever permission UnknownUser would have. The format of the object of knora-base:hasPermissions is as follows: Each permission is represented by the one-letter or two-letter abbreviation given above. Each permission abbreviation is followed by a space, then a comma-separated list of groups that the permission is granted to. The IRIs of built-in groups are shortened using the knora-admin prefix. Multiple permissions are separated by a vertical bar (|). For example, if an object grants view permission to unknown and known users , and modify permission to project members , the resulting permission literal would be: : V knora-admin:UnknownUser,knora-admin:KnownUser|M knora-admin:ProjectMember","title":"Object Access Permissions"},{"location":"05-internals/design/api-admin/administration/#administrative-permissions","text":"The following permissions can be set via instances of knora-admin:AdministrativePermission on any group belonging to a project. For users that are members of a number of groups with administrative permissions attached, the final set of permissions is additive and most permissive. The administrative permissions are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions attached to an instance of the knora-admin:AdministrativePermission class. The following permission values can be used: Resource / Value Creation Permissions: 1) ProjectResourceCreateAllPermission : description: gives the permission to create resources inside the project. usage: used as a value for knora-base:hasPermissions . 2) ProjectResourceCreateRestrictedPermission : description: gives restricted resource creation permission inside the project. usage: used as a value for knora-base:hasPermissions . value: RestrictedProjectResourceCreatePermission followed by a comma-separated list of ResourceClasses the user should only be able to create instances of. Project Administration Permissions: 1) ProjectAdminAllPermission : description: gives the user the permission to do anything on project level, i.e. create new groups, modify all existing groups ( group info , group membership , resource creation permissions , project administration permissions , and default permissions ). usage: used as a value for knora-base:hasPermissions . 2) ProjectAdminGroupAllPermission : description: gives the user the permission to modify group info and group membership on all groups belonging to the project. usage: used as a value for the knora-base:hasPermissions property. 3) ProjectAdminGroupRestrictedPermission : description: gives the user the permission to modify group info and group membership on certain groups belonging to the project. usage: used as a value for knora-base:hasPermissions value: ProjectGroupAdminRestrictedPermission followed by a comma-separated list of knora-admin:UserGroup . 4) ProjectAdminRightsAllPermission : description: gives the user the permission to change the permissions on all objects belonging to the project (e.g., default permissions attached to groups and permissions on objects). usage: used as a value for the knora-base:hasPermissions property. Ontology Administration Permissions: 1) ProjectAdminOntologyAllPermission : description: gives the user the permission to administer the project ontologies usage: used as a value for the knora-base:hasPermissions property. The administrative permissions are stored in a compact format in a single string, which is the object of the predicate knora-base:hasPermissions attached to an instance of the knora-admin:AdministrativePermission class. The format of the object of knora-base:hasPermissions is as follows: Each permission is represented by the name given above. Each permission is followed by a space, then if applicable, by a comma separated list of IRIs, as defined above. The IRIs of built-in values (e.g., built-in groups, resource classes, etc.) are shortened using the knora-admin prefix knora-admin: . Multiple permissions are separated by a vertical bar (|). For example, if an administrative permission grants the knora-admin:ProjectMember group the permission to create all resources ( ProjectResourceCreateAllPermission ), the resulting administrative permission object with the compact form literal would be: : <http://rdfh.ch/permissions/001 rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA>; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission\"^^xsd:string .","title":"Administrative Permissions"},{"location":"05-internals/design/api-admin/administration/#default-object-access-permissions","text":"Default Object Access Permissions are used when new objects (resources and/or values) are created. They represent object access permissions with which the new object will be initially outfitted. As with administrative permissions, these default object access permissions can be defined for any number of groups. Additionally, they can be also defined for resource classes and properties. The following default object access permissions can be attached to groups, resource classes and/or properties via instances of knora-admin:DefaultObjectAccessPermission (described further bellow). The default object access permissions correspond to the earlier described object access permission: Default Restricted View Permission (RV) : description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: RV followed by a comma-separated list of knora-admin:UserGroup Default View Permission (V) : description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: V followed by a comma-separated list of knora-admin:UserGroup Default Modify Permission (M) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: M followed by a comma-separated list of knora-admin:UserGroup Default Delete Permission (D) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: D followed by a comma-separated list of knora-admin:UserGroup Default Change Rights Permission (CR) accompanied by a list of groups. description: any object, created by a user inside a group holding this permission, is restricted to carry this permission value: CR followed by a comma-separated list of knora-admin:UserGroup A single instance of knora-admin:DefaultObjectAccessPermission must always reference a project, but can only reference either a group ( knora-admin:forGroup property), a resource class ( knora-admin:forResourceClass ), a property ( knora-admin:forProperty ), or a combination of resource class and property. Example default object access permission instance: <http://rdfh.ch/permissions/002 rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA>; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"CR knora-admin:Creator|M knora-admin:ProjectMember|V knora-admin:KnownUser\"^^xsd:string . This instance is setting default object access permissions to the project member group of a project, giving change right permission to the creator, modify permission to all project members, and view permission to known users. Further, this implicitly applies to all resource classes and all their properties inside the project.","title":"Default Object Access Permissions"},{"location":"05-internals/design/api-admin/administration/#permission-precedence-rules","text":"For both administrative permissions and default object access permissions, the resulting permissions are derived by applying precedence rules, for the case that the user is member of more than one group. The following list is sorted by the permission precedence level in descending order: permissions on knora-admin:ProjectAdmin (highest level) permissions on resource classes and property combination (own project) permissions on resource classes and property combination ( knora-admin:SystemProject ) permissions on resource classes / properties (own project) permissions on resource classes / properties ( knora-admin:SystemProject ) permissions on custom groups permissions on knora-admin:ProjectMember permissions on knora-admin:KnownUser (lowest level) The permissions on resource classes / properties are only relevant for default object access permissions. Administrative Permissions : When a user performs an operation requiring administrative permissions, then only the permissions from the highest level are taken into account. If a user is a member of more than one group on the same level (only possible for custom groups) then the defined permissions are summed up and all are taken into account. Default Object Access Permissions : When a user creates a resource or value, then only the default object permissions from the highest level are applied. If a user is a member of more than one group on the same level (only possible for custom groups) then the defined permissions are summed up and the most permissive are applied. In the case of the user belonging to the SystemAdmin group, but which is not member of a project and thus not member of any group belonging to the project, the default object access permissions from the ProjectAdmin , ProjectMember , or KnownUser group will be applied in the order of precedence. If no permissions are defined on either of these groups, then the resulting permission will be CR knora-admin:Creator .","title":"Permission Precedence Rules"},{"location":"05-internals/design/api-admin/administration/#implicit-permissions","text":"The knora-admin:SystemAdmin group receives implicitly the following permissions: receives implicitly ProjectAdminAllPermission for all projects. receives implicitly ProjectResourceCreateAllPermission for all projects. receives implicitly CR on all objects from all projects. Theses permissions are baked into the system, and cannot be changed.","title":"Implicit Permissions"},{"location":"05-internals/design/api-admin/administration/#default-permissions-matrix-for-new-projects","text":"The access control matrix defines what are the default operations a subject (i.e. User), being a member of a built-in group (represented by row headers), is permitted to perform on an object (represented by column headers). The different operation abbreviations used are defined as follows: C : Create - the subject inside the group is allowed to create the object. U : Update - the subject inside the group is allowed to update the object. R : Read - the subject inside the group is allowed to read all information about the object. D : Delete - the subject inside the group is allowed to delete the object. P : Permission - the subject inside the group is allowed to change the permissions on the object. - : none - none or not applicable Built-In Group Project Group User Resource Value SystemAdmin CRUD CRUDP CRUDP all CRUDP all CRUDP all ProjectAdmin -RUD CRUDP CRUDP +/- project CRUDP (in project) CRUDP (in project) ProjectMember ---- ----- ----- CRU-- (in project) ----- (in project) Creator ---- ----- ----- ----- (his resource) ----- (his value) KnownUser C--- C---- CRUD- himself ----- (in project) ----- (in project) Default Permissions Matrix for new Projects The explicitly defined default permissions for a new project are as follows: knora-admin:ProjectAdmin group: Administrative Permissions: ProjectResourceCreateAllPermission . ProjectAdminAllPermission . Default Object Access Permissions: CR for the knora-admin:ProjectAdmin group D for the knora-admin:ProjectAdmin group M for the knora-admin:ProjectAdmin group V for the knora-admin:ProjectAdmin group RV for the knora-admin:ProjectAdmin group The knora-admin:ProjectMember group: Administrative Permissions: ProjectResourceCreateAllPermission . Default Object Access Permissions: M for the knora-admin:ProjectMember group V for the knora-admin:ProjectMember group RV for the knora-admin:ProjectMember group","title":"Default Permissions Matrix for new Projects"},{"location":"05-internals/design/api-admin/administration/#basic-workflows-involving-permissions","text":"","title":"Basic Workflows involving Permissions"},{"location":"05-internals/design/api-admin/administration/#creating-a-new-resource","text":"","title":"Creating a new Resource"},{"location":"05-internals/design/api-admin/administration/#accessing-a-resourcevalue","text":"","title":"Accessing a Resource/Value"},{"location":"05-internals/design/api-admin/administration/#project-group-administration","text":"","title":"Project / Group Administration"},{"location":"05-internals/design/api-admin/administration/#implementation_1","text":"The requirements for defining default permissions imposed by all the different use cases are very broad. Potentially, we need to be able to define default permissions per project, per group, per resource class, per resource property, and all their possible combinations. For this reason, we introduce the knora-admin:Permission class with two sub-classes, namely knora-admin:AdministrativePermission and knora-admin:DefaultObjectAccessPermission , which instances will carry all the necessary information.","title":"Implementation"},{"location":"05-internals/design/api-admin/administration/#permission-class-hierarchy-and-structure","text":"The following graphs show the class hierarchy and the structure of each permission class. Permission Class Hierarchy Administrative Permission Structure : and the same as RDF: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission| ProjectResourceCreateRestrictedPermission \"<Resource Class IRI>\"| ProjectAdminAllPermission| ProjectAdminGroupAllPermission| ProjectAdminGroupRestrictedPermission \"<http://rdfh.ch/groups/[shortcode]/[UUID]>, <http://rdfh.ch/groups/[shortcode]/[UUID]>\"| ProjectAdminRightsAllPermission| ProjectAdminOntologyAllPermission\"^^xsd:string . Default Object Access Permission Structure : and the same as RDF: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-admin:forResourceClass \"Resource Class Name\" ; knora-admin:forProperty \"Resource Property Name\" ; knora-base:hasPermissions \"RV <http://rdfh.ch/groups/[shortcode]/[UUID]>| V <http://rdfh.ch/groups/[shortcode]/[UUID]>| M <http://rdfh.ch/groups/[shortcode]/[UUID]>| D <http://rdfh.ch/groups/[shortcode]/[UUID]>| CR <http://rdfh.ch/groups/[shortcode]/[UUID]>\"^^xsd:string .","title":"Permission Class Hierarchy and Structure"},{"location":"05-internals/design/api-admin/administration/#querying-permission-instances","text":"The properties forProject and either of forGroup , forResourceClass , and forProperty form together a compound key , allowing finding existing permission instances, that address the same set of Project / Group / ResourceClass / Property combination, thus making it possible to extend or change the attached permissions. Administrative Permission Instances : For each group inside the project, there can be zero or one instance holding administrative permission information. Querying is straitforward by using the knora-admin:forProject and knora-admin:forGroup properties as the compound key. Default Object Access Permission Instances : For each group, resource class, or property inside the project, there can be zero or one instances holding default object access permission informations. Querying is straitforward by using the knora-admin:forProject and either knora-admin:forGroup , knora-admin:forResourceClass , or knora-admin:forProperty properties as part of the compound key.","title":"Querying Permission Instances"},{"location":"05-internals/design/api-admin/administration/#example-data-stored-in-the-permissions-graph","text":"Administrative permissions on a 'ProjectAdmin' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA> ; knora-admin:forGroup knora-admin:ProjectAdmin ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission| ProjectAdminAllPermission\"^^xsd:string . Administrative permissions on a 'ProjectMember' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA> ; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"ProjectResourceCreateAllPermission\"^^xsd:string . Administrative permission restricting project admin permission on a group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:Permission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectGroupAdminRestrictedPermission <http://rdfh.ch/groups/[shortcode]/[UUID]>\"^^xsd:string . Administrative permission restricting resource creation for a group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:AdministrativePermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forGroup <http://rdfh.ch/groups/[shortcode]/[UUID]> ; knora-base:hasPermissions \"ProjectResourceCreateRestrictedPermission <http://www.knora.org/ontology/00FF/images#Person>\"^^xsd:string . Default object access permission on a 'ProjectMember' group: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/MTvoB0EJRrqovzRkWXqfkA> ; knora-admin:forGroup knora-admin:ProjectMember ; knora-base:hasPermissions \"CR knora-admin:Creator| M <http://rdfh.ch/groups/[shortcode]/[UUID]>| V knora-admin:KnownUser\"^^xsd:string . Default object access permission on a resource class: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forResourceClass <http://www.knora.org/ontology/00FF/images#person> ; knora-base:hasPermissions \"CR knora-admin:Creator,knora-admin:ProjectMember| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^xsd:string . Default object access permission on a resource property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forProperty <http://www.knora.org/ontology/00FF/images#lastname> ; knora-base:hasPermissions \"D knora-admin:ProjectMember,knora-admin:Creator| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^ . Default object access permission on a resource class and property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject <http://rdfh.ch/projects/[shortcode]> ; knora-admin:forResourceClass <http://www.knora.org/ontology/00FF/images#person> ; knora-admin:forProperty <http://www.knora.org/ontology/00FF/images#lastname> ; knora-base:hasPermissions \"CR knora-admin:Creator,knora-admin:ProjectMember| V knora-admin:KnownUser,knora-admin:UnknownUser\"^^xsd:string . Default object access permission on a knora-admin property: <http://rdfh.ch/permissions/[UUID]> rdf:type knora-admin:DefaultObjectAccessPermission ; knora-admin:forProject knora-admin:SystemProject ; knora-admin:forProperty <http://www.knora.org/ontology/knora-admin#hasStillImageFileValue> ; knora-base:hasPermissions \"RV knora-admin:UnknownUser| V knora-admin:KnownUser| M knora-admin:ProjectMember,knora-admin:Creator\"^^xsd:string . A the time the user's UserProfile is queried, all permissions for all projects and groups the user is a member of are also queried. This information is then stored as an easy accessible object inside the UserProfile , being readily available wherever needed. As this is a somewhat expensive operation, built-in caching mechanism at different levels (e.g., UsersResponder, PermissionsResponder), will be applied.","title":"Example Data stored in the permissions graph"},{"location":"05-internals/design/api-v1/how-to-add-a-route/","text":"How to Add an API v1 Route Write SPARQL templates Add any SPARQL templates you need to src/main/twirl/queries/sparql/v1 , using the Twirl template engine. Write Responder Request and Response Messages Add a file to the org.knora.webapi.messages.v2.responder package, containing case classes for your responder's request and response messages. Add a trait that the responder's request messages extend. Each request message type should contain a UserADM . Response message classes that represent a complete API response must extend KnoraResponseV1 , and must therefore have a toJsValue method that converts the response message to a JSON AST using spray-json . Write a Responder Write a class that extends org.knora.webapi.responders.Responder , and add it to the org.knora.webapi.responders.v1 package. Give your responder a receive(msg: YourCustomType) method that handles each of your request message types by generating a Future containing a response message. See Triplestore Access for details of how to access the triplestore in your responder. Add the path of your responder to the org.knora.webapi.responders package object, and add code to ResponderManager to instantiate an object for your responder class. Then add a case to the receive method in ResponderManager , to match messages that extend your request message trait, and pass them to the responder's receive method. The responder's resulting Future must be passed to the ActorUtil.future2Message . See Futures with Akka and Error Handling for details. Write a Route Add a class to the org.knora.webapi.routing.v1 package for your route, using the Akka HTTP Routing DSL . See the routes in that package for examples. Typically, each route route will construct a responder request message and pass it to RouteUtilV1.runRdfRouteWithFuture to handle the request. Finally, add your knoraApiPath function to the apiRoutes member variable in KnoraService . Any exception thrown inside the route will be handled by the KnoraExceptionHandler , so that the correct client response (including the HTTP status code) will be returned.","title":"How to Add an API v1 Route"},{"location":"05-internals/design/api-v1/how-to-add-a-route/#how-to-add-an-api-v1-route","text":"","title":"How to Add an API v1 Route"},{"location":"05-internals/design/api-v1/how-to-add-a-route/#write-sparql-templates","text":"Add any SPARQL templates you need to src/main/twirl/queries/sparql/v1 , using the Twirl template engine.","title":"Write SPARQL templates"},{"location":"05-internals/design/api-v1/how-to-add-a-route/#write-responder-request-and-response-messages","text":"Add a file to the org.knora.webapi.messages.v2.responder package, containing case classes for your responder's request and response messages. Add a trait that the responder's request messages extend. Each request message type should contain a UserADM . Response message classes that represent a complete API response must extend KnoraResponseV1 , and must therefore have a toJsValue method that converts the response message to a JSON AST using spray-json .","title":"Write Responder Request and Response Messages"},{"location":"05-internals/design/api-v1/how-to-add-a-route/#write-a-responder","text":"Write a class that extends org.knora.webapi.responders.Responder , and add it to the org.knora.webapi.responders.v1 package. Give your responder a receive(msg: YourCustomType) method that handles each of your request message types by generating a Future containing a response message. See Triplestore Access for details of how to access the triplestore in your responder. Add the path of your responder to the org.knora.webapi.responders package object, and add code to ResponderManager to instantiate an object for your responder class. Then add a case to the receive method in ResponderManager , to match messages that extend your request message trait, and pass them to the responder's receive method. The responder's resulting Future must be passed to the ActorUtil.future2Message . See Futures with Akka and Error Handling for details.","title":"Write a Responder"},{"location":"05-internals/design/api-v1/how-to-add-a-route/#write-a-route","text":"Add a class to the org.knora.webapi.routing.v1 package for your route, using the Akka HTTP Routing DSL . See the routes in that package for examples. Typically, each route route will construct a responder request message and pass it to RouteUtilV1.runRdfRouteWithFuture to handle the request. Finally, add your knoraApiPath function to the apiRoutes member variable in KnoraService . Any exception thrown inside the route will be handled by the KnoraExceptionHandler , so that the correct client response (including the HTTP status code) will be returned.","title":"Write a Route"},{"location":"05-internals/design/api-v1/json/","text":"JSON in API v1 DSP-API v1 parses and generates JSON using the spray-json library. The triplestore returns results in JSON, and these are parsed into SparqlSelectResponse objects in the store package (by SparqlUtils , which can be used by any actor in that package). A SparqlSelectResponse has a structure that's very close to the JSON returned by a triplestore via the SPARQL 1.1 Protocol : it contains a header (listing the variables that were used in the query) and a body (containing rows of query results). Each row of query results is represented by a VariableResultsRow , which contains a Map[String, String] of variable names to values. The Jsonable trait marks classes that can convert themselves into spray-json AST objects when you call their toJsValue method; it returns a JsValue object, which can then be converted to text by calling its prettyPrint or compactPrint methods. Case classes representing complete API responses extend the KnoraResponseV1 trait, which extends Jsonable . Case classes representing Knora values extend the ApiValueV1 trait, which also extends Jsonable . To make the responders reusable, the JSON for API responses is generated only at the last moment, by the RouteUtilV1.runJsonRoute() function.","title":"JSON in API v1"},{"location":"05-internals/design/api-v1/json/#json-in-api-v1","text":"DSP-API v1 parses and generates JSON using the spray-json library. The triplestore returns results in JSON, and these are parsed into SparqlSelectResponse objects in the store package (by SparqlUtils , which can be used by any actor in that package). A SparqlSelectResponse has a structure that's very close to the JSON returned by a triplestore via the SPARQL 1.1 Protocol : it contains a header (listing the variables that were used in the query) and a body (containing rows of query results). Each row of query results is represented by a VariableResultsRow , which contains a Map[String, String] of variable names to values. The Jsonable trait marks classes that can convert themselves into spray-json AST objects when you call their toJsValue method; it returns a JsValue object, which can then be converted to text by calling its prettyPrint or compactPrint methods. Case classes representing complete API responses extend the KnoraResponseV1 trait, which extends Jsonable . Case classes representing Knora values extend the ApiValueV1 trait, which also extends Jsonable . To make the responders reusable, the JSON for API responses is generated only at the last moment, by the RouteUtilV1.runJsonRoute() function.","title":"JSON in API v1"},{"location":"05-internals/design/api-v2/ark/","text":"Archival Resource Key (ARK) Identifiers Requirements Knora must produce an ARK URL for each resource and each value. The ARK identifiers used by Knora must respect the draft ARK specification . The format of Knora\u2019s ARK URLs must be able to change over time, while ensuring that previously generated ARK URLs still work. Design ARK URL Format The format of a Knora ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID[/VALUE_UUID][.TIMESTAMP] HOST : the hostname of the ARK resolver. NAAN : the Name Assigning Authority Number (NAAN) that the ARK resolver uses. VERSION : the version of the Knora ARK URL format being used (always 1 for now). PROJECT : the short code of the project that the resource belongs to. RESOURCE_UUID : the resource's unique ID, which is normally a base64url-encoded UUID, as described in IRIs for Data . VALUE_UUID : optionally, the knora-base:valueHasUUID of one of the resource's values, normally a base64url-encoded UUID, as described in IRIs for Data . TIMESTAMP : an optional timestamp indicating that the ARK URL represents the state of the resource at a specific time in the past. The format of the timestamp is an ISO 8601 date in Coordinated universal time (UTC), including date, time, and an optional nano-of-second field (of at most 9 digits), without the characters - , : , and . (because - and . are reserved characters in ARK, and : would have to be URL-encoded). Example: 20180528T155203897Z . Following the ARK ID spec, / represents object hierarchy and . represents an object variant . A value is thus contained in a resource, which is contained in its project, which is contained in a repository (represented by the URL version number). A timestamp is a type of variant. Since sub-objects are optional, there is also implicitly an ARK URL for each project, as well as for the repository as a whole. The RESOURCE_UUID and VALUE_UUID are processed as follows: A check digit is calculated, using the algorithm in the Scala class org.knora.webapi.util.Base64UrlCheckDigit , and appended to the UUID. Any - characters in the resulting string are replaced with = , because base64url encoding uses - , which is a reserved character in ARK URLs. For example, given a project with ID 0001 , and using the DaSCH's ARK resolver hostname and NAAN, the ARK URL for the project itself is: http://ark.dasch.swiss/ark:/72163/1/0001 Given the Knora resource IRI http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY.20180528T155203897Z Given a value with knora-api:valueHasUUID \"4OOf3qJUTnCDXlPNnygSzQ\" in the resource http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX.20180604T085622513Z Serving ARK URLs SmartIri converts Knora resource IRIs to ARK URLs. This conversion is invoked in ReadResourceV2.toJsonLD , when returning a resource's metadata in JSON-LD format. Resolving Knora ARK URLs A Knora ARK URL is intended to be resolved by the Knora ARK resolver .","title":"Archival Resource Key (ARK)"},{"location":"05-internals/design/api-v2/ark/#archival-resource-key-ark-identifiers","text":"","title":"Archival Resource Key (ARK) Identifiers"},{"location":"05-internals/design/api-v2/ark/#requirements","text":"Knora must produce an ARK URL for each resource and each value. The ARK identifiers used by Knora must respect the draft ARK specification . The format of Knora\u2019s ARK URLs must be able to change over time, while ensuring that previously generated ARK URLs still work.","title":"Requirements"},{"location":"05-internals/design/api-v2/ark/#design","text":"","title":"Design"},{"location":"05-internals/design/api-v2/ark/#ark-url-format","text":"The format of a Knora ARK URL is as follows: http://HOST/ark:/NAAN/VERSION/PROJECT/RESOURCE_UUID[/VALUE_UUID][.TIMESTAMP] HOST : the hostname of the ARK resolver. NAAN : the Name Assigning Authority Number (NAAN) that the ARK resolver uses. VERSION : the version of the Knora ARK URL format being used (always 1 for now). PROJECT : the short code of the project that the resource belongs to. RESOURCE_UUID : the resource's unique ID, which is normally a base64url-encoded UUID, as described in IRIs for Data . VALUE_UUID : optionally, the knora-base:valueHasUUID of one of the resource's values, normally a base64url-encoded UUID, as described in IRIs for Data . TIMESTAMP : an optional timestamp indicating that the ARK URL represents the state of the resource at a specific time in the past. The format of the timestamp is an ISO 8601 date in Coordinated universal time (UTC), including date, time, and an optional nano-of-second field (of at most 9 digits), without the characters - , : , and . (because - and . are reserved characters in ARK, and : would have to be URL-encoded). Example: 20180528T155203897Z . Following the ARK ID spec, / represents object hierarchy and . represents an object variant . A value is thus contained in a resource, which is contained in its project, which is contained in a repository (represented by the URL version number). A timestamp is a type of variant. Since sub-objects are optional, there is also implicitly an ARK URL for each project, as well as for the repository as a whole. The RESOURCE_UUID and VALUE_UUID are processed as follows: A check digit is calculated, using the algorithm in the Scala class org.knora.webapi.util.Base64UrlCheckDigit , and appended to the UUID. Any - characters in the resulting string are replaced with = , because base64url encoding uses - , which is a reserved character in ARK URLs. For example, given a project with ID 0001 , and using the DaSCH's ARK resolver hostname and NAAN, the ARK URL for the project itself is: http://ark.dasch.swiss/ark:/72163/1/0001 Given the Knora resource IRI http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY.20180528T155203897Z Given a value with knora-api:valueHasUUID \"4OOf3qJUTnCDXlPNnygSzQ\" in the resource http://rdfh.ch/0001/0C-0L1kORryKzJAJxxRyRQ , and using the DaSCH's ARK resolver hostname and NAAN, the corresponding ARK URL without a timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX The same ARK URL with an optional timestamp is: http://ark.dasch.swiss/ark:/72163/1/0001/0C=0L1kORryKzJAJxxRyRQY/4OOf3qJUTnCDXlPNnygSzQX.20180604T085622513Z","title":"ARK URL Format"},{"location":"05-internals/design/api-v2/ark/#serving-ark-urls","text":"SmartIri converts Knora resource IRIs to ARK URLs. This conversion is invoked in ReadResourceV2.toJsonLD , when returning a resource's metadata in JSON-LD format.","title":"Serving ARK URLs"},{"location":"05-internals/design/api-v2/ark/#resolving-knora-ark-urls","text":"A Knora ARK URL is intended to be resolved by the Knora ARK resolver .","title":"Resolving Knora ARK URLs"},{"location":"05-internals/design/api-v2/content-wrappers/","text":"Content Wrappers Whenever possible, the same data structures are used to represent the same types of data, regardless of the API operation (reading, creating, or modifying). However, often more data is available in output than in input. For example, when a value is read from the triplestore, its IRI is available, but when it is being created, it does not yet have an IRI. The implementation of API v2 therefore uses content wrappers. For each type, there is a case class that represents the lowest common denominator of the type, the data that will be present regardless of the API operation. For example, the trait ValueContentV2 represents a Knora value, regardless of whether it is received as input or returned as output. Case classes such as DateValueContentV2 and TextValueContentV2 implement this trait. An instance of this lowest-common-denominator class, or \"content class\", can then be wrapped in an instance of an operation-specific class that carries additional data. For example, when a Knora value is returned from the triplestore, a ValueContentV2 is wrapped in a ReadValueV2 , which additionally contains the value's IRI. When a value is created, it is wrapped in a CreateValueV2 , which has the resource IRI and the property IRI, but not the value IRI. A read wrapper can be wrapped in another read wrapper; for example, a ReadResourceV2 contains ReadValueV2 objects. In general, DSP-API v2 responders deal only with the internal schema. (The exception is OntologyResponderV2 , which can return ontology information that exists only in an external schema.) Therefore, a content class needs to be able to convert itself from the internal schema to an external schema (when it is being used for output) and vice versa (when it is being used for input). Each content class class should therefore extend KnoraContentV2 , and thus have a toOntologySchema method or converting itself between internal and external schemas, in either direction: /** * A trait for content classes that can convert themselves between internal and internal schemas. * * @tparam C the type of the content class that extends this trait. */ trait KnoraContentV2[C <: KnoraContentV2[C]] { this: C => def toOntologySchema(targetSchema: OntologySchema): C } Since read wrappers are used only for output, they need to be able convert themselves only from the internal schema to an external schema. Each read wrapper class should extend KnoraReadV2 , and thus have a method for doing this: /** * A trait for read wrappers that can convert themselves to external schemas. * * @tparam C the type of the read wrapper that extends this trait. */ trait KnoraReadV2[C <: KnoraReadV2[C]] { this: C => def toOntologySchema(targetSchema: ApiV2Schema): C }","title":"Content Wrappers"},{"location":"05-internals/design/api-v2/content-wrappers/#content-wrappers","text":"Whenever possible, the same data structures are used to represent the same types of data, regardless of the API operation (reading, creating, or modifying). However, often more data is available in output than in input. For example, when a value is read from the triplestore, its IRI is available, but when it is being created, it does not yet have an IRI. The implementation of API v2 therefore uses content wrappers. For each type, there is a case class that represents the lowest common denominator of the type, the data that will be present regardless of the API operation. For example, the trait ValueContentV2 represents a Knora value, regardless of whether it is received as input or returned as output. Case classes such as DateValueContentV2 and TextValueContentV2 implement this trait. An instance of this lowest-common-denominator class, or \"content class\", can then be wrapped in an instance of an operation-specific class that carries additional data. For example, when a Knora value is returned from the triplestore, a ValueContentV2 is wrapped in a ReadValueV2 , which additionally contains the value's IRI. When a value is created, it is wrapped in a CreateValueV2 , which has the resource IRI and the property IRI, but not the value IRI. A read wrapper can be wrapped in another read wrapper; for example, a ReadResourceV2 contains ReadValueV2 objects. In general, DSP-API v2 responders deal only with the internal schema. (The exception is OntologyResponderV2 , which can return ontology information that exists only in an external schema.) Therefore, a content class needs to be able to convert itself from the internal schema to an external schema (when it is being used for output) and vice versa (when it is being used for input). Each content class class should therefore extend KnoraContentV2 , and thus have a toOntologySchema method or converting itself between internal and external schemas, in either direction: /** * A trait for content classes that can convert themselves between internal and internal schemas. * * @tparam C the type of the content class that extends this trait. */ trait KnoraContentV2[C <: KnoraContentV2[C]] { this: C => def toOntologySchema(targetSchema: OntologySchema): C } Since read wrappers are used only for output, they need to be able convert themselves only from the internal schema to an external schema. Each read wrapper class should extend KnoraReadV2 , and thus have a method for doing this: /** * A trait for read wrappers that can convert themselves to external schemas. * * @tparam C the type of the read wrapper that extends this trait. */ trait KnoraReadV2[C <: KnoraReadV2[C]] { this: C => def toOntologySchema(targetSchema: ApiV2Schema): C }","title":"Content Wrappers"},{"location":"05-internals/design/api-v2/gravsearch/","text":"Gravsearch Design For a detailed overview of Gravsearch, see Gravsearch: Transforming SPARQL to query humanities data . Gravsearch Package The classes that process Gravsearch queries and results can be found in org.knora.webapi.messages.util.search.gravsearch . Type Inspection The code that converts Gravserch queries into SPARQL queries, and processes the query results, needs to know the types of the entities that are used in the input query. As explained in Type Inference , these types can be inferred, or they can be specified in the query using type annotations. Type inspection is implemented in the package org.knora.webapi.messages.util.search.gravsearch.types . The entry point to this package is GravsearchTypeInspectionRunner , which is instantiated by SearchResponderV2 . The result of type inspection is a GravsearchTypeInspectionResult , in which each typeable entity in the input query is associated with a GravsearchEntityTypeInfo , which can be either: A PropertyTypeInfo , which specifies the type of object that a property is expected to have. A NonPropertyTypeInfo , which specifies the type of a variable, or the type of an IRI representing a resource or value. Identifying Typeable Entities After parsing a Gravsearch query, SearchResponderV2 calls GravsearchTypeInspectionRunner.inspectTypes , passing the WHERE clause of the input query. This method first identifies the entities whose types need to be determined. Each of these entities is represented as a TypeableEntity . To do this, GravsearchTypeInspectionRunner uses QueryTraverser to traverse the WHERE clause, collecting typeable entities in a visitor called TypeableEntityCollectingWhereVisitor . The entities that are considered to need type information are: All variables. All IRIs except for those that represent type annotations or types. The Type Inspection Pipeline GravsearchTypeInspectionRunner contains a pipeline of type inspectors, each of which extends GravsearchTypeInspector . There are two type inspectors in the pipeline: AnnotationReadingGravsearchTypeInspector : reads type annotations included in a Gravsearch query. InferringGravsearchTypeInspector : infers the types of entities from the context in which they are used, as well as from ontology information that it requests from OntologyResponderV2 . Each type inspector takes as input, and returns as output, an IntermediateTypeInspectionResult , which associates each TypeableEntity with zero or more types. Initially, each TypeableEntity has no types. Each type inspector adds whatever types it finds for each entity. At the end of the pipeline, each entity should have exactly one type. Therefore, to only keep the most specific type for an entity, the method refineDeterminedTypes refines the determined types by removing those that are base classes of others. However, it can be that inconsistent types are determined for entities. For example, in cases where multiple resource class types are determined, but one is not a base class of the others. From the following statement { ?document a beol:manuscript . } UNION { ?document a beol:letter .} two inconsistent types can be inferred for ?document : beol:letter and beol:manuscript . In these cases, a sanitizer sanitizeInconsistentResourceTypes replaces the inconsistent resource types by their common base resource class (in the above example, it would be beol:writtenSource ). Lastly, an error is returned if An entity's type could not be determined. The client must add a type annotation to make the query work. Inconsistent types could not be sanitized (an entity appears to have more than one type). The client must correct the query. If there are no errors, GravsearchTypeInspectionRunner converts the pipeline's output to a GravsearchTypeInspectionResult , in which each entity is associated with exactly one type. AnnotationReadingGravsearchTypeInspector This inspector uses QueryTraverser to traverse the WHERE clause, collecting type annotations in a visitor called AnnotationCollectingWhereVisitor . It then converts each annotation to a GravsearchEntityTypeInfo . InferringGravsearchTypeInspector This inspector first uses QueryTraverser to traverse the WHERE clause, assembling an index of usage information about typeable entities in a visitor called UsageIndexCollectingWhereVisitor . The UsageIndex contains, for example, an index of all the entities that are used as subjects, predicates, or objects, along with the statements in which they are used. It also contains sets of all the Knora class and property IRIs that are used in the WHERE clause. InferringGravsearchTypeInspector then asks OntologyResponderV2 for information about those classes and properties, as well as about the classes that are subject types or object types of those properties. Next, the inspector runs inference rules (which extend InferenceRule ) on each TypeableEntity . Each rule takes as input a TypeableEntity , the usage index, the ontology information, and the IntermediateTypeInspectionResult , and returns a new IntermediateTypeInspectionResult . For example, TypeOfObjectFromPropertyRule infers an entity's type if the entity is used as the object of a statement and the predicate's knora-api:objectType is known. For each TypeableEntity , if a type is inferred from a property, the entity and the inferred type are added to IntermediateTypeInspectionResult.entitiesInferredFromProperty . The inference rules are run repeatedly, because the output of one rule may allow another rule to infer additional information. There are two pipelines of rules: a pipeline for the first iteration of type inference, and a pipeline for subsequent iterations. This is because some rules can return additional information if they are run more than once on the same entity, while others cannot. The number of iterations is limited to InferringGravsearchTypeInspector.MAX_ITERATIONS , but in practice two iterations are sufficient for most realistic queries, and it is difficult to design a query that requires more than six iterations. Transformation of a Gravsearch Query A Gravsearch query submitted by the client is parsed by GravsearchParser and preprocessed by GravsearchTypeInspector to get type information about the elements used in the query (resources, values, properties etc.) and do some basic sanity checks. In SearchResponderV2 , two queries are generated from a given Gravsearch query: a prequery and a main query. Query Transformers The Gravsearch query is passed to QueryTraverser along with a query transformer. Query transformers are classes that implement traits supported by QueryTraverser : WhereTransformer : instructions how to convert statements in the WHERE clause of a SPARQL query (to generate the prequery's Where clause). To improve query performance, this trait defines the method optimiseQueryPatterns whose implementation can call private methods to optimise the generated SPARQL. For example, before transformation of statements in WHERE clause, query pattern orders must be optimised by moving LuceneQueryPatterns to the beginning and isDeleted statement patterns to the end of the WHERE clause. ConstructToSelectTransformer (extends WhereTransformer ): instructions how to turn a Construct query into a Select query (converts a Gravsearch query into a prequery) SelectToSelectTransformer (extends WhereTransformer ): instructions how to turn a triplestore independent Select query into a triplestore dependent Select query (implementation of inference). ConstructToConstructTransformer (extends WhereTransformer ): instructions how to turn a triplestore independent Construct query into a triplestore dependent Construct query (implementation of inference). The traits listed above define methods that are implemented in the transformer classes and called by QueryTraverser to perform SPARQL to SPARQL conversions. When iterating over the statements of the input query, the transformer class' transformation methods are called to perform the conversion. Prequery The purpose of the prequery is to get an ordered collection of results representing only the IRIs of one page of matching resources and values. Sort criteria can be submitted by the user, but the result is always deterministic also without sort criteria. This is necessary to support paging. A prequery is a SPARQL SELECT query. The classes involved in generating prequeries can be found in org.knora.webapi.messages.util.search.gravsearch.prequery . If the client submits a count query, the prequery returns the overall number of hits, but not the results themselves. In a first step, before transforming the WHERE clause, query patterns must be further optimised by removing the rdfs:type statement for entities whose type could be inferred from their use with a property IRI, since there would be no need for explicit rdfs:type statements for them (unless the property IRI from which the type of an entity must be inferred from is wrapped in an OPTIONAL block). This optimisation takes the Gravsearch query as input (rather than the generated SPARQL), because it uses type information that refers to entities in the Gravsearch query, and the generated SPARQL might have different entities. Next, the Gravsearch query's WHERE clause is transformed and the prequery (SELECT and WHERE clause) is generated from this result. The transformation of the Gravsearch query's WHERE clause relies on the implementation of the abstract class AbstractPrequeryGenerator . AbstractPrequeryGenerator contains members whose state is changed during the iteration over the statements of the input query. They can then be used to create the converted query. mainResourceVariable: Option[QueryVariable] : SPARQL variable representing the main resource of the input query. Present in the prequery's SELECT clause. dependentResourceVariables: mutable.Set[QueryVariable] : a set of SPARQL variables representing dependent resources in the input query. Used in an aggregation function in the prequery's SELECT clause (see below). dependentResourceVariablesGroupConcat: Set[QueryVariable] : a set of SPARQL variables representing an aggregation of dependent resources. Present in the prequery's SELECT clause. valueObjectVariables: mutable.Set[QueryVariable] : a set of SPARQL variables representing value objects. Used in an aggregation function in the prequery's SELECT clause (see below). valueObjectVarsGroupConcat: Set[QueryVariable] : a set of SPARQL variables representing an aggregation of value objects. Present in the prequery's SELECT clause. The variables mentioned above are present in the prequery's result rows because they are part of the prequery's SELECT clause. The following example illustrates the handling of variables. The following Gravsearch query looks for pages with a sequence number of 10 that are part of a book: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?page knora-api:isMainResource true . ?page knora-api:isPartOf ?book . ?page incunabula:seqnum ?seqnum . } WHERE { ?page a incunabula:page . ?page knora-api:isPartOf ?book . ?book a incunabula:book . ?page incunabula:seqnum ?seqnum . FILTER(?seqnum = 10) } The prequery's SELECT clause is built by NonTriplestoreSpecificGravsearchToPrequeryTransformer.getSelectColumns , based on the variables used in the input query's CONSTRUCT clause. The resulting SELECT clause looks as follows: SELECT DISTINCT ?page (GROUP_CONCAT(DISTINCT(IF(BOUND(?book), STR(?book), \"\")); SEPARATOR='') AS ?book__Concat) (GROUP_CONCAT(DISTINCT(IF(BOUND(?seqnum), STR(?seqnum), \"\")); SEPARATOR='') AS ?seqnum__Concat) (GROUP_CONCAT(DISTINCT(IF(BOUND(?book__LinkValue), STR(?book__LinkValue), \"\")); SEPARATOR='') AS ?book__LinkValue__Concat) WHERE {...} GROUP BY ?page ORDER BY ASC(?page) LIMIT 25 ?page represents the main resource. When accessing the prequery's result rows, ?page contains the IRI of the main resource. The prequery's results are grouped by the main resource so that there is exactly one result row per matching main resource. ?page is also used as a sort criterion although none has been defined in the input query. This is necessary to make paging work: results always have to be returned in the same order (the prequery is always deterministic). Like this, results can be fetched page by page using LIMIT and OFFSET. Grouping by main resource requires other results to be aggregated using the function GROUP_CONCAT . ?book is used as an argument of the aggregation function. The aggregation's result is accessible in the prequery's result rows as ?book__Concat . The variable ?book is bound to an IRI. Since more than one IRI could be bound to a variable representing a dependent resource, the results have to be aggregated. GROUP_CONCAT takes two arguments: a collection of strings (IRIs in our use case) and a separator (we use the non-printing Unicode character INFORMATION SEPARATOR ONE ). When accessing ?book__Concat in the prequery's results containing the IRIs of dependent resources, the string has to be split with the separator used in the aggregation function. The result is a collection of IRIs representing dependent resources. The same logic applies to value objects. Each GROUP_CONCAT checks whether the concatenated variable is bound in each result in the group; if a variable is unbound, we concatenate an empty string. This is necessary because, in Apache Jena (and perhaps other triplestores), \"If GROUP_CONCAT has an unbound value in the list of values to concat, the overall result is 'error'\" (see this Jena issue ). If the input query contains a UNION , and a variable is bound in one branch of the UNION and not in another branch, it is possible that the prequery will return more than one row per main resource. To deal with this situation, SearchResponderV2 merges rows that contain the same main resource IRI. Main Query The purpose of the main query is to get all requested information about the main resource, dependent resources, and value objects. The IRIs of those resources and value objects were returned by the prequery. Since the prequery only returns resources and value objects matching the input query's criteria, the main query can specifically ask for more detailed information on these resources and values without having to reconsider these criteria. Generating the Main Query The classes involved in generating the main query can be found in org.knora.webapi.messages.util.search.gravsearch.mainquery . The main query is a SPARQL CONSTRUCT query. Its generation is handled by the method GravsearchMainQueryGenerator.createMainQuery . It takes three arguments: mainResourceIris: Set[IriRef], dependentResourceIris: Set[IriRef], valueObjectIris: Set[IRI] . These sets are constructed based on information about variables representing dependent resources and value objects in the prequery, which is provided by NonTriplestoreSpecificGravsearchToPrequeryTransformer : dependentResourceVariablesGroupConcat : Set(QueryVariable(book__Concat)) valueObjectVariablesGroupConcat : Set(QueryVariable(seqnum__Concat), QueryVariable(book__LinkValue__Concat)) From the given Iris, statements are generated that ask for complete information on exactly these resources and values. For any given resource Iri, only the values present in valueObjectIris are to be queried. This is achieved by using SPARQL's VALUES expression for the main resource and dependent resources as well as for values. Processing the Main Query's results To do the permission checking, the results of the main query are passed to ConstructResponseUtilV2.splitMainResourcesAndValueRdfData , which transforms a SparqlConstructResponse (a set of RDF triples) into a structure organized by main resource Iris. In this structure, dependent resources and values are nested and can be accessed via their main resource, and resources and values that the user does not have permission to see are filtered out. As a result, a page of results may contain fewer than the maximum allowed number of results per page, even if more pages of results are available. MainQueryResultProcessor.getRequestedValuesFromResultsWithFullGraphPattern then filters out values that the user did not explicitly ask for in the input query. Finally, ConstructResponseUtilV2.createApiResponse transforms the query results into an API response (a ReadResourcesSequenceV2 ). If the number of main resources found (even if filtered out because of permissions) is equal to the maximum allowed page size, the predicate knora-api:mayHaveMoreResults: true is included in the response. Inference Gravsearch queries support a subset of RDFS reasoning (see Inference in the API documentation on Gravsearch). This is implemented as follows: To simulate RDF inference, the API expands the prequery on basis of the available ontologies. For that reason, SparqlTransformer.transformStatementInWhereForNoInference expands all rdfs:subClassOf and rdfs:subPropertyOf statements using UNION statements for all subclasses and subproperties from the ontologies (equivalent to rdfs:subClassOf* and rdfs:subPropertyOf* ). Similarly, SparqlTransformer.transformStatementInWhereForNoInference replaces knora-api:standoffTagHasStartAncestor with knora-base:standoffTagHasStartParent* . Optimisation of generated SPARQL The triplestore-specific transformers in SparqlTransformer.scala can run optimisations on the generated SPARQL, in the method optimiseQueryPatterns inherited from WhereTransformer . For example, moveLuceneToBeginning moves Lucene queries to the beginning of the block in which they occur. Query Optimization by Topological Sorting of Statements In Jena Fuseki, the performance of a query highly depends on the order of the query statements. For example, a query such as the one below: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol:creationDate ?date . } WHERE { ?letter beol:creationDate ?date . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?person1 beol:hasIAFIdentifier ?gnd1 . ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?person2 beol:hasIAFIdentifier ?gnd2 . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . } ORDER BY ?date takes a very long time with Fuseki. The performance of this query can be improved by moving up the statements with literal objects that are not dependent on any other statement: ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . The rest of the query then reads: ?person1 beol:hasIAFIdentifier ?gnd1 . ?person2 beol:hasIAFIdentifier ?gnd2 . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?letter beol:creationDate ?date . Since users cannot be expected to know about performance of triplestores in order to write efficient queries, an optimization method to automatically rearrange the statements of the given queries has been implemented. Upon receiving the Gravsearch query, the algorithm converts the query to a graph. For each statement pattern, the subject of the statement is the origin node, the predicate is a directed edge, and the object is the target node. For the query above, this conversion would result in the following graph: The Graph for Scala library is used to construct the graph and sort it using Kahn's topological sorting algorithm . The algorithm returns the nodes of the graph ordered in several layers, where the root element ?letter is in layer 0, [?date, ?person1, ?person2] are in layer 1, [?gnd1, ?gnd2] in layer 2, and the leaf nodes [(DE-588)118531379, (DE-588)118696149] are given in the last layer (i.e. layer 3). According to Kahn's algorithm, there are multiple valid permutations of the topological order. The graph in the example above has 24 valid permutations of topological order. Here are two of them (nodes are ordered from left to right with the highest order to the lowest): (?letter, ?date, ?person2, ?person1, ?gnd2, ?gnd1, (DE-588)118696149, (DE-588)118531379) (?letter, ?date, ?person1, ?person2, ?gnd1, ?gnd2, (DE-588)118531379, (DE-588)118696149) . From all valid topological orders, one is chosen based on certain criteria; for example, the leaf node should not belong to a statement that has predicate rdf:type , since that could match all resources of the specified type. Once the best order is chosen, it is used to re-arrange the query statements. Starting from the last leaf node, i.e. (DE-588)118696149 , the method finds the statement pattern which has this node as its object, and brings this statement to the top of the query. This rearrangement continues so that the statements with the fewest dependencies on other statements are all brought to the top of the query. The resulting query is as follows: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol:creationDate ?date . } WHERE { ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?person2 beol:hasIAFIdentifier ?gnd2 . ?person1 beol:hasIAFIdentifier ?gnd1 . ?letter ?linkingProp2 ?person2 . ?letter ?linkingProp1 ?person1 . ?letter beol:creationDate ?date . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) } ORDER BY ?date Note that position of the FILTER statements does not play a significant role in the optimization. If a Gravsearch query contains statements in UNION , OPTIONAL , MINUS , or FILTER NOT EXISTS , they are reordered by defining a graph per block. For example, consider the following query with UNION : { ?thing anything:hasRichtext ?richtext . FILTER knora-api:matchText(?richtext, \"test\") ?thing anything:hasInteger ?int . ?int knora-api:intValueAsInt 1 . } UNION { ?thing anything:hasText ?text . FILTER knora-api:matchText(?text, \"test\") ?thing anything:hasInteger ?int . ?int knora-api:intValueAsInt 3 . } This would result in one graph per block of the UNION . Each graph is then sorted, and the statements of its block are rearranged according to the topological order of graph. This is the result: { ?int knora-api:intValueAsInt 1 . ?thing anything:hasRichtext ?richtext . ?thing anything:hasInteger ?int . FILTER(knora-api:matchText(?richtext, \"test\")) } UNION { ?int knora-api:intValueAsInt 3 . ?thing anything:hasText ?text . ?thing anything:hasInteger ?int . FILTER(knora-api:matchText(?text, \"test\")) } Cyclic Graphs The topological sorting algorithm can only be used for DAGs (directed acyclic graphs). However, a Gravsearch query can contains statements that result in a cyclic graph, e.g.: PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . } WHERE { ?thing anything:hasOtherThing ?thing1 . ?thing1 anything:hasOtherThing ?thing2 . ?thing2 anything:hasOtherThing ?thing . In this case, the algorithm tries to break the cycles in order to sort the graph. If this is not possible, the query statements are not reordered.","title":"Gravsearch Design"},{"location":"05-internals/design/api-v2/gravsearch/#gravsearch-design","text":"For a detailed overview of Gravsearch, see Gravsearch: Transforming SPARQL to query humanities data .","title":"Gravsearch Design"},{"location":"05-internals/design/api-v2/gravsearch/#gravsearch-package","text":"The classes that process Gravsearch queries and results can be found in org.knora.webapi.messages.util.search.gravsearch .","title":"Gravsearch Package"},{"location":"05-internals/design/api-v2/gravsearch/#type-inspection","text":"The code that converts Gravserch queries into SPARQL queries, and processes the query results, needs to know the types of the entities that are used in the input query. As explained in Type Inference , these types can be inferred, or they can be specified in the query using type annotations. Type inspection is implemented in the package org.knora.webapi.messages.util.search.gravsearch.types . The entry point to this package is GravsearchTypeInspectionRunner , which is instantiated by SearchResponderV2 . The result of type inspection is a GravsearchTypeInspectionResult , in which each typeable entity in the input query is associated with a GravsearchEntityTypeInfo , which can be either: A PropertyTypeInfo , which specifies the type of object that a property is expected to have. A NonPropertyTypeInfo , which specifies the type of a variable, or the type of an IRI representing a resource or value.","title":"Type Inspection"},{"location":"05-internals/design/api-v2/gravsearch/#identifying-typeable-entities","text":"After parsing a Gravsearch query, SearchResponderV2 calls GravsearchTypeInspectionRunner.inspectTypes , passing the WHERE clause of the input query. This method first identifies the entities whose types need to be determined. Each of these entities is represented as a TypeableEntity . To do this, GravsearchTypeInspectionRunner uses QueryTraverser to traverse the WHERE clause, collecting typeable entities in a visitor called TypeableEntityCollectingWhereVisitor . The entities that are considered to need type information are: All variables. All IRIs except for those that represent type annotations or types.","title":"Identifying Typeable Entities"},{"location":"05-internals/design/api-v2/gravsearch/#the-type-inspection-pipeline","text":"GravsearchTypeInspectionRunner contains a pipeline of type inspectors, each of which extends GravsearchTypeInspector . There are two type inspectors in the pipeline: AnnotationReadingGravsearchTypeInspector : reads type annotations included in a Gravsearch query. InferringGravsearchTypeInspector : infers the types of entities from the context in which they are used, as well as from ontology information that it requests from OntologyResponderV2 . Each type inspector takes as input, and returns as output, an IntermediateTypeInspectionResult , which associates each TypeableEntity with zero or more types. Initially, each TypeableEntity has no types. Each type inspector adds whatever types it finds for each entity. At the end of the pipeline, each entity should have exactly one type. Therefore, to only keep the most specific type for an entity, the method refineDeterminedTypes refines the determined types by removing those that are base classes of others. However, it can be that inconsistent types are determined for entities. For example, in cases where multiple resource class types are determined, but one is not a base class of the others. From the following statement { ?document a beol:manuscript . } UNION { ?document a beol:letter .} two inconsistent types can be inferred for ?document : beol:letter and beol:manuscript . In these cases, a sanitizer sanitizeInconsistentResourceTypes replaces the inconsistent resource types by their common base resource class (in the above example, it would be beol:writtenSource ). Lastly, an error is returned if An entity's type could not be determined. The client must add a type annotation to make the query work. Inconsistent types could not be sanitized (an entity appears to have more than one type). The client must correct the query. If there are no errors, GravsearchTypeInspectionRunner converts the pipeline's output to a GravsearchTypeInspectionResult , in which each entity is associated with exactly one type.","title":"The Type Inspection Pipeline"},{"location":"05-internals/design/api-v2/gravsearch/#annotationreadinggravsearchtypeinspector","text":"This inspector uses QueryTraverser to traverse the WHERE clause, collecting type annotations in a visitor called AnnotationCollectingWhereVisitor . It then converts each annotation to a GravsearchEntityTypeInfo .","title":"AnnotationReadingGravsearchTypeInspector"},{"location":"05-internals/design/api-v2/gravsearch/#inferringgravsearchtypeinspector","text":"This inspector first uses QueryTraverser to traverse the WHERE clause, assembling an index of usage information about typeable entities in a visitor called UsageIndexCollectingWhereVisitor . The UsageIndex contains, for example, an index of all the entities that are used as subjects, predicates, or objects, along with the statements in which they are used. It also contains sets of all the Knora class and property IRIs that are used in the WHERE clause. InferringGravsearchTypeInspector then asks OntologyResponderV2 for information about those classes and properties, as well as about the classes that are subject types or object types of those properties. Next, the inspector runs inference rules (which extend InferenceRule ) on each TypeableEntity . Each rule takes as input a TypeableEntity , the usage index, the ontology information, and the IntermediateTypeInspectionResult , and returns a new IntermediateTypeInspectionResult . For example, TypeOfObjectFromPropertyRule infers an entity's type if the entity is used as the object of a statement and the predicate's knora-api:objectType is known. For each TypeableEntity , if a type is inferred from a property, the entity and the inferred type are added to IntermediateTypeInspectionResult.entitiesInferredFromProperty . The inference rules are run repeatedly, because the output of one rule may allow another rule to infer additional information. There are two pipelines of rules: a pipeline for the first iteration of type inference, and a pipeline for subsequent iterations. This is because some rules can return additional information if they are run more than once on the same entity, while others cannot. The number of iterations is limited to InferringGravsearchTypeInspector.MAX_ITERATIONS , but in practice two iterations are sufficient for most realistic queries, and it is difficult to design a query that requires more than six iterations.","title":"InferringGravsearchTypeInspector"},{"location":"05-internals/design/api-v2/gravsearch/#transformation-of-a-gravsearch-query","text":"A Gravsearch query submitted by the client is parsed by GravsearchParser and preprocessed by GravsearchTypeInspector to get type information about the elements used in the query (resources, values, properties etc.) and do some basic sanity checks. In SearchResponderV2 , two queries are generated from a given Gravsearch query: a prequery and a main query.","title":"Transformation of a Gravsearch Query"},{"location":"05-internals/design/api-v2/gravsearch/#query-transformers","text":"The Gravsearch query is passed to QueryTraverser along with a query transformer. Query transformers are classes that implement traits supported by QueryTraverser : WhereTransformer : instructions how to convert statements in the WHERE clause of a SPARQL query (to generate the prequery's Where clause). To improve query performance, this trait defines the method optimiseQueryPatterns whose implementation can call private methods to optimise the generated SPARQL. For example, before transformation of statements in WHERE clause, query pattern orders must be optimised by moving LuceneQueryPatterns to the beginning and isDeleted statement patterns to the end of the WHERE clause. ConstructToSelectTransformer (extends WhereTransformer ): instructions how to turn a Construct query into a Select query (converts a Gravsearch query into a prequery) SelectToSelectTransformer (extends WhereTransformer ): instructions how to turn a triplestore independent Select query into a triplestore dependent Select query (implementation of inference). ConstructToConstructTransformer (extends WhereTransformer ): instructions how to turn a triplestore independent Construct query into a triplestore dependent Construct query (implementation of inference). The traits listed above define methods that are implemented in the transformer classes and called by QueryTraverser to perform SPARQL to SPARQL conversions. When iterating over the statements of the input query, the transformer class' transformation methods are called to perform the conversion.","title":"Query Transformers"},{"location":"05-internals/design/api-v2/gravsearch/#prequery","text":"The purpose of the prequery is to get an ordered collection of results representing only the IRIs of one page of matching resources and values. Sort criteria can be submitted by the user, but the result is always deterministic also without sort criteria. This is necessary to support paging. A prequery is a SPARQL SELECT query. The classes involved in generating prequeries can be found in org.knora.webapi.messages.util.search.gravsearch.prequery . If the client submits a count query, the prequery returns the overall number of hits, but not the results themselves. In a first step, before transforming the WHERE clause, query patterns must be further optimised by removing the rdfs:type statement for entities whose type could be inferred from their use with a property IRI, since there would be no need for explicit rdfs:type statements for them (unless the property IRI from which the type of an entity must be inferred from is wrapped in an OPTIONAL block). This optimisation takes the Gravsearch query as input (rather than the generated SPARQL), because it uses type information that refers to entities in the Gravsearch query, and the generated SPARQL might have different entities. Next, the Gravsearch query's WHERE clause is transformed and the prequery (SELECT and WHERE clause) is generated from this result. The transformation of the Gravsearch query's WHERE clause relies on the implementation of the abstract class AbstractPrequeryGenerator . AbstractPrequeryGenerator contains members whose state is changed during the iteration over the statements of the input query. They can then be used to create the converted query. mainResourceVariable: Option[QueryVariable] : SPARQL variable representing the main resource of the input query. Present in the prequery's SELECT clause. dependentResourceVariables: mutable.Set[QueryVariable] : a set of SPARQL variables representing dependent resources in the input query. Used in an aggregation function in the prequery's SELECT clause (see below). dependentResourceVariablesGroupConcat: Set[QueryVariable] : a set of SPARQL variables representing an aggregation of dependent resources. Present in the prequery's SELECT clause. valueObjectVariables: mutable.Set[QueryVariable] : a set of SPARQL variables representing value objects. Used in an aggregation function in the prequery's SELECT clause (see below). valueObjectVarsGroupConcat: Set[QueryVariable] : a set of SPARQL variables representing an aggregation of value objects. Present in the prequery's SELECT clause. The variables mentioned above are present in the prequery's result rows because they are part of the prequery's SELECT clause. The following example illustrates the handling of variables. The following Gravsearch query looks for pages with a sequence number of 10 that are part of a book: PREFIX incunabula: <http://0.0.0.0:3333/ontology/0803/incunabula/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?page knora-api:isMainResource true . ?page knora-api:isPartOf ?book . ?page incunabula:seqnum ?seqnum . } WHERE { ?page a incunabula:page . ?page knora-api:isPartOf ?book . ?book a incunabula:book . ?page incunabula:seqnum ?seqnum . FILTER(?seqnum = 10) } The prequery's SELECT clause is built by NonTriplestoreSpecificGravsearchToPrequeryTransformer.getSelectColumns , based on the variables used in the input query's CONSTRUCT clause. The resulting SELECT clause looks as follows: SELECT DISTINCT ?page (GROUP_CONCAT(DISTINCT(IF(BOUND(?book), STR(?book), \"\")); SEPARATOR='') AS ?book__Concat) (GROUP_CONCAT(DISTINCT(IF(BOUND(?seqnum), STR(?seqnum), \"\")); SEPARATOR='') AS ?seqnum__Concat) (GROUP_CONCAT(DISTINCT(IF(BOUND(?book__LinkValue), STR(?book__LinkValue), \"\")); SEPARATOR='') AS ?book__LinkValue__Concat) WHERE {...} GROUP BY ?page ORDER BY ASC(?page) LIMIT 25 ?page represents the main resource. When accessing the prequery's result rows, ?page contains the IRI of the main resource. The prequery's results are grouped by the main resource so that there is exactly one result row per matching main resource. ?page is also used as a sort criterion although none has been defined in the input query. This is necessary to make paging work: results always have to be returned in the same order (the prequery is always deterministic). Like this, results can be fetched page by page using LIMIT and OFFSET. Grouping by main resource requires other results to be aggregated using the function GROUP_CONCAT . ?book is used as an argument of the aggregation function. The aggregation's result is accessible in the prequery's result rows as ?book__Concat . The variable ?book is bound to an IRI. Since more than one IRI could be bound to a variable representing a dependent resource, the results have to be aggregated. GROUP_CONCAT takes two arguments: a collection of strings (IRIs in our use case) and a separator (we use the non-printing Unicode character INFORMATION SEPARATOR ONE ). When accessing ?book__Concat in the prequery's results containing the IRIs of dependent resources, the string has to be split with the separator used in the aggregation function. The result is a collection of IRIs representing dependent resources. The same logic applies to value objects. Each GROUP_CONCAT checks whether the concatenated variable is bound in each result in the group; if a variable is unbound, we concatenate an empty string. This is necessary because, in Apache Jena (and perhaps other triplestores), \"If GROUP_CONCAT has an unbound value in the list of values to concat, the overall result is 'error'\" (see this Jena issue ). If the input query contains a UNION , and a variable is bound in one branch of the UNION and not in another branch, it is possible that the prequery will return more than one row per main resource. To deal with this situation, SearchResponderV2 merges rows that contain the same main resource IRI.","title":"Prequery"},{"location":"05-internals/design/api-v2/gravsearch/#main-query","text":"The purpose of the main query is to get all requested information about the main resource, dependent resources, and value objects. The IRIs of those resources and value objects were returned by the prequery. Since the prequery only returns resources and value objects matching the input query's criteria, the main query can specifically ask for more detailed information on these resources and values without having to reconsider these criteria.","title":"Main Query"},{"location":"05-internals/design/api-v2/gravsearch/#generating-the-main-query","text":"The classes involved in generating the main query can be found in org.knora.webapi.messages.util.search.gravsearch.mainquery . The main query is a SPARQL CONSTRUCT query. Its generation is handled by the method GravsearchMainQueryGenerator.createMainQuery . It takes three arguments: mainResourceIris: Set[IriRef], dependentResourceIris: Set[IriRef], valueObjectIris: Set[IRI] . These sets are constructed based on information about variables representing dependent resources and value objects in the prequery, which is provided by NonTriplestoreSpecificGravsearchToPrequeryTransformer : dependentResourceVariablesGroupConcat : Set(QueryVariable(book__Concat)) valueObjectVariablesGroupConcat : Set(QueryVariable(seqnum__Concat), QueryVariable(book__LinkValue__Concat)) From the given Iris, statements are generated that ask for complete information on exactly these resources and values. For any given resource Iri, only the values present in valueObjectIris are to be queried. This is achieved by using SPARQL's VALUES expression for the main resource and dependent resources as well as for values.","title":"Generating the Main Query"},{"location":"05-internals/design/api-v2/gravsearch/#processing-the-main-querys-results","text":"To do the permission checking, the results of the main query are passed to ConstructResponseUtilV2.splitMainResourcesAndValueRdfData , which transforms a SparqlConstructResponse (a set of RDF triples) into a structure organized by main resource Iris. In this structure, dependent resources and values are nested and can be accessed via their main resource, and resources and values that the user does not have permission to see are filtered out. As a result, a page of results may contain fewer than the maximum allowed number of results per page, even if more pages of results are available. MainQueryResultProcessor.getRequestedValuesFromResultsWithFullGraphPattern then filters out values that the user did not explicitly ask for in the input query. Finally, ConstructResponseUtilV2.createApiResponse transforms the query results into an API response (a ReadResourcesSequenceV2 ). If the number of main resources found (even if filtered out because of permissions) is equal to the maximum allowed page size, the predicate knora-api:mayHaveMoreResults: true is included in the response.","title":"Processing the Main Query's results"},{"location":"05-internals/design/api-v2/gravsearch/#inference","text":"Gravsearch queries support a subset of RDFS reasoning (see Inference in the API documentation on Gravsearch). This is implemented as follows: To simulate RDF inference, the API expands the prequery on basis of the available ontologies. For that reason, SparqlTransformer.transformStatementInWhereForNoInference expands all rdfs:subClassOf and rdfs:subPropertyOf statements using UNION statements for all subclasses and subproperties from the ontologies (equivalent to rdfs:subClassOf* and rdfs:subPropertyOf* ). Similarly, SparqlTransformer.transformStatementInWhereForNoInference replaces knora-api:standoffTagHasStartAncestor with knora-base:standoffTagHasStartParent* .","title":"Inference"},{"location":"05-internals/design/api-v2/gravsearch/#optimisation-of-generated-sparql","text":"The triplestore-specific transformers in SparqlTransformer.scala can run optimisations on the generated SPARQL, in the method optimiseQueryPatterns inherited from WhereTransformer . For example, moveLuceneToBeginning moves Lucene queries to the beginning of the block in which they occur.","title":"Optimisation of generated SPARQL"},{"location":"05-internals/design/api-v2/gravsearch/#query-optimization-by-topological-sorting-of-statements","text":"In Jena Fuseki, the performance of a query highly depends on the order of the query statements. For example, a query such as the one below: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol:creationDate ?date . } WHERE { ?letter beol:creationDate ?date . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?person1 beol:hasIAFIdentifier ?gnd1 . ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?person2 beol:hasIAFIdentifier ?gnd2 . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . } ORDER BY ?date takes a very long time with Fuseki. The performance of this query can be improved by moving up the statements with literal objects that are not dependent on any other statement: ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . The rest of the query then reads: ?person1 beol:hasIAFIdentifier ?gnd1 . ?person2 beol:hasIAFIdentifier ?gnd2 . ?letter ?linkingProp1 ?person1 . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) ?letter ?linkingProp2 ?person2 . FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) ?letter beol:creationDate ?date . Since users cannot be expected to know about performance of triplestores in order to write efficient queries, an optimization method to automatically rearrange the statements of the given queries has been implemented. Upon receiving the Gravsearch query, the algorithm converts the query to a graph. For each statement pattern, the subject of the statement is the origin node, the predicate is a directed edge, and the object is the target node. For the query above, this conversion would result in the following graph: The Graph for Scala library is used to construct the graph and sort it using Kahn's topological sorting algorithm . The algorithm returns the nodes of the graph ordered in several layers, where the root element ?letter is in layer 0, [?date, ?person1, ?person2] are in layer 1, [?gnd1, ?gnd2] in layer 2, and the leaf nodes [(DE-588)118531379, (DE-588)118696149] are given in the last layer (i.e. layer 3). According to Kahn's algorithm, there are multiple valid permutations of the topological order. The graph in the example above has 24 valid permutations of topological order. Here are two of them (nodes are ordered from left to right with the highest order to the lowest): (?letter, ?date, ?person2, ?person1, ?gnd2, ?gnd1, (DE-588)118696149, (DE-588)118531379) (?letter, ?date, ?person1, ?person2, ?gnd1, ?gnd2, (DE-588)118531379, (DE-588)118696149) . From all valid topological orders, one is chosen based on certain criteria; for example, the leaf node should not belong to a statement that has predicate rdf:type , since that could match all resources of the specified type. Once the best order is chosen, it is used to re-arrange the query statements. Starting from the last leaf node, i.e. (DE-588)118696149 , the method finds the statement pattern which has this node as its object, and brings this statement to the top of the query. This rearrangement continues so that the statements with the fewest dependencies on other statements are all brought to the top of the query. The resulting query is as follows: PREFIX beol: <http://0.0.0.0:3333/ontology/0801/beol/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/v2#> CONSTRUCT { ?letter knora-api:isMainResource true . ?letter ?linkingProp1 ?person1 . ?letter ?linkingProp2 ?person2 . ?letter beol:creationDate ?date . } WHERE { ?gnd2 knora-api:valueAsString \"(DE-588)118696149\" . ?gnd1 knora-api:valueAsString \"(DE-588)118531379\" . ?person2 beol:hasIAFIdentifier ?gnd2 . ?person1 beol:hasIAFIdentifier ?gnd1 . ?letter ?linkingProp2 ?person2 . ?letter ?linkingProp1 ?person1 . ?letter beol:creationDate ?date . FILTER(?linkingProp1 = beol:hasAuthor || ?linkingProp1 = beol:hasRecipient ) FILTER(?linkingProp2 = beol:hasAuthor || ?linkingProp2 = beol:hasRecipient ) } ORDER BY ?date Note that position of the FILTER statements does not play a significant role in the optimization. If a Gravsearch query contains statements in UNION , OPTIONAL , MINUS , or FILTER NOT EXISTS , they are reordered by defining a graph per block. For example, consider the following query with UNION : { ?thing anything:hasRichtext ?richtext . FILTER knora-api:matchText(?richtext, \"test\") ?thing anything:hasInteger ?int . ?int knora-api:intValueAsInt 1 . } UNION { ?thing anything:hasText ?text . FILTER knora-api:matchText(?text, \"test\") ?thing anything:hasInteger ?int . ?int knora-api:intValueAsInt 3 . } This would result in one graph per block of the UNION . Each graph is then sorted, and the statements of its block are rearranged according to the topological order of graph. This is the result: { ?int knora-api:intValueAsInt 1 . ?thing anything:hasRichtext ?richtext . ?thing anything:hasInteger ?int . FILTER(knora-api:matchText(?richtext, \"test\")) } UNION { ?int knora-api:intValueAsInt 3 . ?thing anything:hasText ?text . ?thing anything:hasInteger ?int . FILTER(knora-api:matchText(?text, \"test\")) }","title":"Query Optimization by Topological Sorting of Statements"},{"location":"05-internals/design/api-v2/gravsearch/#cyclic-graphs","text":"The topological sorting algorithm can only be used for DAGs (directed acyclic graphs). However, a Gravsearch query can contains statements that result in a cyclic graph, e.g.: PREFIX anything: <http://0.0.0.0:3333/ontology/0001/anything/simple/v2#> PREFIX knora-api: <http://api.knora.org/ontology/knora-api/simple/v2#> CONSTRUCT { ?thing knora-api:isMainResource true . } WHERE { ?thing anything:hasOtherThing ?thing1 . ?thing1 anything:hasOtherThing ?thing2 . ?thing2 anything:hasOtherThing ?thing . In this case, the algorithm tries to break the cycles in order to sort the graph. If this is not possible, the query statements are not reordered.","title":"Cyclic Graphs"},{"location":"05-internals/design/api-v2/how-to-add-a-route/","text":"How to Add an API v2 Route Write SPARQL templates Add any SPARQL templates you need to src/main/twirl/queries/sparql/v2 , using the Twirl template engine. Write Responder Request and Response Messages Add a file to the org.knora.webapi.messages.v2.responder package, containing case classes for your responder's request and response messages. Add a trait that the responder's request messages extend. Each request message type should contain a UserADM . Request and response messages should be designed following the patterns described in JSON-LD Parsing and Formatting . Each responder's request messages should extend a responder-specific trait, so that ResponderManager will know which responder to route those messages to. Write a Responder Write an Akka actor class that extends org.knora.webapi.responders.Responder , and add it to the org.knora.webapi.responders.v2 package. Give your responder a receive(msg: YourCustomType) method that handles each of your request message types by generating a Future containing a response message. See Triplestore Access for details of how to access the triplestore in your responder. Add the path of your responder to the org.knora.webapi.responders package object, and add code to ResponderManager to instantiate the new responder. Then add a case to the receive method in ResponderManager , to match messages that extend your request message trait, and pass them them to that responder's receive method. The responder's resulting Future must be passed to the ActorUtil.future2Message . See Futures with Akka and Error Handling for details. Write a Route Add a class to the org.knora.webapi.routing.v2 package for your route, using the Akka HTTP Routing DSL . See the routes in that package for examples. Typically, each route route will construct a responder request message and pass it to RouteUtilV2.runRdfRouteWithFuture to handle the request. Finally, add your route's knoraApiPath function to the apiRoutes member variable in KnoraService . Any exception thrown inside the route will be handled by the KnoraExceptionHandler , so that the correct client response (including the HTTP status code) will be returned.","title":"How to Add an API v2 Route"},{"location":"05-internals/design/api-v2/how-to-add-a-route/#how-to-add-an-api-v2-route","text":"","title":"How to Add an API v2 Route"},{"location":"05-internals/design/api-v2/how-to-add-a-route/#write-sparql-templates","text":"Add any SPARQL templates you need to src/main/twirl/queries/sparql/v2 , using the Twirl template engine.","title":"Write SPARQL templates"},{"location":"05-internals/design/api-v2/how-to-add-a-route/#write-responder-request-and-response-messages","text":"Add a file to the org.knora.webapi.messages.v2.responder package, containing case classes for your responder's request and response messages. Add a trait that the responder's request messages extend. Each request message type should contain a UserADM . Request and response messages should be designed following the patterns described in JSON-LD Parsing and Formatting . Each responder's request messages should extend a responder-specific trait, so that ResponderManager will know which responder to route those messages to.","title":"Write Responder Request and Response Messages"},{"location":"05-internals/design/api-v2/how-to-add-a-route/#write-a-responder","text":"Write an Akka actor class that extends org.knora.webapi.responders.Responder , and add it to the org.knora.webapi.responders.v2 package. Give your responder a receive(msg: YourCustomType) method that handles each of your request message types by generating a Future containing a response message. See Triplestore Access for details of how to access the triplestore in your responder. Add the path of your responder to the org.knora.webapi.responders package object, and add code to ResponderManager to instantiate the new responder. Then add a case to the receive method in ResponderManager , to match messages that extend your request message trait, and pass them them to that responder's receive method. The responder's resulting Future must be passed to the ActorUtil.future2Message . See Futures with Akka and Error Handling for details.","title":"Write a Responder"},{"location":"05-internals/design/api-v2/how-to-add-a-route/#write-a-route","text":"Add a class to the org.knora.webapi.routing.v2 package for your route, using the Akka HTTP Routing DSL . See the routes in that package for examples. Typically, each route route will construct a responder request message and pass it to RouteUtilV2.runRdfRouteWithFuture to handle the request. Finally, add your route's knoraApiPath function to the apiRoutes member variable in KnoraService . Any exception thrown inside the route will be handled by the KnoraExceptionHandler , so that the correct client response (including the HTTP status code) will be returned.","title":"Write a Route"},{"location":"05-internals/design/api-v2/json-ld/","text":"JSON-LD Parsing and Formatting JsonLDUtil Knora provides a utility object called JsonLDUtil , which wraps the titanium-json-ld Java library , and parses JSON-LD text to a Knora data structure called JsonLDDocument . These classes provide commonly needed functionality for extracting and validating data from JSON-LD documents, as well as for constructing new documents. Parsing JSON-LD A route that expects a JSON-LD request must first parse the JSON-LD using JsonLDUtil . For example, this is how ValuesRouteV2 parses a JSON-LD request to create a value: post { entity(as[String]) { jsonRequest => requestContext => { val requestDoc: JsonLDDocument = JsonLDUtil.parseJsonLD(jsonRequest) The result is a JsonLDDocument in which all prefixes have been expanded to full IRIs, with an empty JSON-LD context. The next step is to convert the JsonLDDocument to a request message that can be sent to the Knora responder that will handle the request. val requestMessageFuture: Future[CreateValueRequestV2] = for { requestingUser <- getUserADM(requestContext) requestMessage: CreateValueRequestV2 <- CreateValueRequestV2.fromJsonLD( requestDoc, apiRequestID = UUID.randomUUID, requestingUser = requestingUser, responderManager = responderManager, storeManager = storeManager, settings = settings, log = log ) } yield requestMessage This is done in a Future , because the processing of JSON-LD input could in itself involve sending messages to responders. Each request message case class (in this case CreateValueRequestV2 ) has a companion object that implements the KnoraJsonLDRequestReaderV2 trait: /** * A trait for objects that can generate case class instances based on JSON-LD input. * * @tparam C the type of the case class that can be generated. */ trait KnoraJsonLDRequestReaderV2[C] { /** * Converts JSON-LD input into a case class instance. * * @param jsonLDDocument the JSON-LD input. * @param apiRequestID the UUID of the API request. * @param requestingUser the user making the request. * @param responderManager a reference to the responder manager. * @param storeManager a reference to the store manager. * @param settings the application settings. * @param log a logging adapter. * @param timeout a timeout for `ask` messages. * @param executionContext an execution context for futures. * @return a case class instance representing the input. */ def fromJsonLD(jsonLDDocument: JsonLDDocument, apiRequestID: UUID, requestingUser: UserADM, responderManager: ActorRef, storeManager: ActorRef, settings: KnoraSettingsImpl, log: LoggingAdapter)(implicit timeout: Timeout, executionContext: ExecutionContext): Future[C] } This means that the companion object has a method fromJsonLD that takes a JsonLDDocument and returns an instance of the case class. The fromJsonLD method can use the functionality of the JsonLDDocument data structure for extracting and validating the content of the request. For example, JsonLDObject.requireStringWithValidation gets a required member of a JSON-LD object, and validates it using a function that is passed as an argument. Here is an example of getting and validating a SmartIri : for { valueType: SmartIri <- Future(jsonLDObject.requireStringWithValidation(JsonLDConstants.TYPE, stringFormatter.toSmartIriWithErr)) The validation function (in this case stringFormatter.toSmartIriWithErr ) has to take two arguments: a string to be validated, and a function that that throws an exception if the string is invalid. The return value of requireStringWithValidation is the return value of the validation function, which in this case is a SmartIri . If the string is invalid, requireStringWithValidation throws BadRequestException . It is also possible to get and validate an optional JSON-LD object member: val maybeDateValueHasStartEra: Option[DateEraV2] = jsonLDObject.maybeStringWithValidation(OntologyConstants.KnoraApiV2Complex.DateValueHasStartEra, DateEraV2.parse) Here JsonLDObject.maybeStringWithValidation returns an Option that contains the return value of the validation function ( DateEraV2.parse ) if it was given, otherwise None . Returning a JSON-LD Response Each API response is represented by a message class that extends KnoraJsonLDResponseV2 , which has a method toJsonLDDocument that specifies the target ontology schema. The implementation of this method constructs a JsonLDDocument , in which all object keys are full IRIs (no prefixes are used), but in which the JSON-LD context also specifies the prefixes that will be used when the document is returned to the client. The function JsonLDUtil.makeContext is a convenient way to construct the JSON-LD context. Since toJsonLDDocument has to return an object that uses the specified ontology schema, the recommended design is to separate schema conversion as much as possible from JSON-LD generation. As a first step, schema conversion (or at the very least, the conversion of Knora type IRIs to the target schema) can be done via an implementation of KnoraReadV2 : /** * A trait for read wrappers that can convert themselves to external schemas. * * @tparam C the type of the read wrapper that extends this trait. */ trait KnoraReadV2[C <: KnoraReadV2[C]] { this: C => def toOntologySchema(targetSchema: ApiV2Schema): C } This means that the response message class has the method toOntologySchema , which returns a copy of the same message, with Knora type IRIs (and perhaps other content) adjusted for the target schema. (See Smart IRIs on how to convert Knora type IRIs to the target schema.) The response message class could then have a private method called generateJsonLD , which generates a JsonLDDocument that has the correct structure for the target schema, like this: private def generateJsonLD(targetSchema: ApiV2Schema, settings: KnoraSettingsImpl, schemaOptions: Set[SchemaOption]): JsonLDDocument This way, the implementation of toJsonLDDocument can call toOntologySchema , then construct a JsonLDDocument from the resulting object. For example: override def toJsonLDDocument(targetSchema: ApiV2Schema, settings: KnoraSettingsImpl, schemaOptions: Set[SchemaOption] = Set.empty): JsonLDDocument = { toOntologySchema(targetSchema).generateJsonLD( targetSchema = targetSchema, settings = settings, schemaOptions = schemaOptions ) } Selecting the Response Schema Most routes complete by calling RouteUtilV2.runRdfRouteWithFuture , which calls the response message's toJsonLDDocument method. The runRdfRouteWithFuture function has a parameter that enables the route to select the schema that should be used in the response. It is up to each route to determine what the appropriate response schema should be. Some routes support only one response schema. Others allow the client to choose. To use the schema requested by the client, the route can call RouteUtilV2.getOntologySchema : RouteUtilV2.runRdfRouteWithFuture( requestMessageF = requestMessageFuture, requestContext = requestContext, settings = settings, responderManager = responderManager, log = log, targetSchema = targetSchema, schemaOptions = schemaOptions ) If the route only supports one schema, it can specify the schema directly instead: RouteUtilV2.runRdfRouteWithFuture( requestMessageF = requestMessageFuture, requestContext = requestContext, settings = settings, responderManager = responderManager, log = log, targetSchema = ApiV2Complex, schemaOptions = RouteUtilV2.getSchemaOptions(requestContext) ) Generating Other RDF Formats RouteUtilV2.runRdfRouteWithFuture implements HTTP content negotiation . After determining the client's preferred format, it asks the KnoraResponseV2 to convert itself into that format. KnoraResponseV2 has an abstract format method, whose implementations select the most efficient conversion between the response message's internal representation (which could be JSON-LD or Turtle) and the requested format.","title":"JSON-LD Parsing and Formatting"},{"location":"05-internals/design/api-v2/json-ld/#json-ld-parsing-and-formatting","text":"","title":"JSON-LD Parsing and Formatting"},{"location":"05-internals/design/api-v2/json-ld/#jsonldutil","text":"Knora provides a utility object called JsonLDUtil , which wraps the titanium-json-ld Java library , and parses JSON-LD text to a Knora data structure called JsonLDDocument . These classes provide commonly needed functionality for extracting and validating data from JSON-LD documents, as well as for constructing new documents.","title":"JsonLDUtil"},{"location":"05-internals/design/api-v2/json-ld/#parsing-json-ld","text":"A route that expects a JSON-LD request must first parse the JSON-LD using JsonLDUtil . For example, this is how ValuesRouteV2 parses a JSON-LD request to create a value: post { entity(as[String]) { jsonRequest => requestContext => { val requestDoc: JsonLDDocument = JsonLDUtil.parseJsonLD(jsonRequest) The result is a JsonLDDocument in which all prefixes have been expanded to full IRIs, with an empty JSON-LD context. The next step is to convert the JsonLDDocument to a request message that can be sent to the Knora responder that will handle the request. val requestMessageFuture: Future[CreateValueRequestV2] = for { requestingUser <- getUserADM(requestContext) requestMessage: CreateValueRequestV2 <- CreateValueRequestV2.fromJsonLD( requestDoc, apiRequestID = UUID.randomUUID, requestingUser = requestingUser, responderManager = responderManager, storeManager = storeManager, settings = settings, log = log ) } yield requestMessage This is done in a Future , because the processing of JSON-LD input could in itself involve sending messages to responders. Each request message case class (in this case CreateValueRequestV2 ) has a companion object that implements the KnoraJsonLDRequestReaderV2 trait: /** * A trait for objects that can generate case class instances based on JSON-LD input. * * @tparam C the type of the case class that can be generated. */ trait KnoraJsonLDRequestReaderV2[C] { /** * Converts JSON-LD input into a case class instance. * * @param jsonLDDocument the JSON-LD input. * @param apiRequestID the UUID of the API request. * @param requestingUser the user making the request. * @param responderManager a reference to the responder manager. * @param storeManager a reference to the store manager. * @param settings the application settings. * @param log a logging adapter. * @param timeout a timeout for `ask` messages. * @param executionContext an execution context for futures. * @return a case class instance representing the input. */ def fromJsonLD(jsonLDDocument: JsonLDDocument, apiRequestID: UUID, requestingUser: UserADM, responderManager: ActorRef, storeManager: ActorRef, settings: KnoraSettingsImpl, log: LoggingAdapter)(implicit timeout: Timeout, executionContext: ExecutionContext): Future[C] } This means that the companion object has a method fromJsonLD that takes a JsonLDDocument and returns an instance of the case class. The fromJsonLD method can use the functionality of the JsonLDDocument data structure for extracting and validating the content of the request. For example, JsonLDObject.requireStringWithValidation gets a required member of a JSON-LD object, and validates it using a function that is passed as an argument. Here is an example of getting and validating a SmartIri : for { valueType: SmartIri <- Future(jsonLDObject.requireStringWithValidation(JsonLDConstants.TYPE, stringFormatter.toSmartIriWithErr)) The validation function (in this case stringFormatter.toSmartIriWithErr ) has to take two arguments: a string to be validated, and a function that that throws an exception if the string is invalid. The return value of requireStringWithValidation is the return value of the validation function, which in this case is a SmartIri . If the string is invalid, requireStringWithValidation throws BadRequestException . It is also possible to get and validate an optional JSON-LD object member: val maybeDateValueHasStartEra: Option[DateEraV2] = jsonLDObject.maybeStringWithValidation(OntologyConstants.KnoraApiV2Complex.DateValueHasStartEra, DateEraV2.parse) Here JsonLDObject.maybeStringWithValidation returns an Option that contains the return value of the validation function ( DateEraV2.parse ) if it was given, otherwise None .","title":"Parsing JSON-LD"},{"location":"05-internals/design/api-v2/json-ld/#returning-a-json-ld-response","text":"Each API response is represented by a message class that extends KnoraJsonLDResponseV2 , which has a method toJsonLDDocument that specifies the target ontology schema. The implementation of this method constructs a JsonLDDocument , in which all object keys are full IRIs (no prefixes are used), but in which the JSON-LD context also specifies the prefixes that will be used when the document is returned to the client. The function JsonLDUtil.makeContext is a convenient way to construct the JSON-LD context. Since toJsonLDDocument has to return an object that uses the specified ontology schema, the recommended design is to separate schema conversion as much as possible from JSON-LD generation. As a first step, schema conversion (or at the very least, the conversion of Knora type IRIs to the target schema) can be done via an implementation of KnoraReadV2 : /** * A trait for read wrappers that can convert themselves to external schemas. * * @tparam C the type of the read wrapper that extends this trait. */ trait KnoraReadV2[C <: KnoraReadV2[C]] { this: C => def toOntologySchema(targetSchema: ApiV2Schema): C } This means that the response message class has the method toOntologySchema , which returns a copy of the same message, with Knora type IRIs (and perhaps other content) adjusted for the target schema. (See Smart IRIs on how to convert Knora type IRIs to the target schema.) The response message class could then have a private method called generateJsonLD , which generates a JsonLDDocument that has the correct structure for the target schema, like this: private def generateJsonLD(targetSchema: ApiV2Schema, settings: KnoraSettingsImpl, schemaOptions: Set[SchemaOption]): JsonLDDocument This way, the implementation of toJsonLDDocument can call toOntologySchema , then construct a JsonLDDocument from the resulting object. For example: override def toJsonLDDocument(targetSchema: ApiV2Schema, settings: KnoraSettingsImpl, schemaOptions: Set[SchemaOption] = Set.empty): JsonLDDocument = { toOntologySchema(targetSchema).generateJsonLD( targetSchema = targetSchema, settings = settings, schemaOptions = schemaOptions ) }","title":"Returning a JSON-LD Response"},{"location":"05-internals/design/api-v2/json-ld/#selecting-the-response-schema","text":"Most routes complete by calling RouteUtilV2.runRdfRouteWithFuture , which calls the response message's toJsonLDDocument method. The runRdfRouteWithFuture function has a parameter that enables the route to select the schema that should be used in the response. It is up to each route to determine what the appropriate response schema should be. Some routes support only one response schema. Others allow the client to choose. To use the schema requested by the client, the route can call RouteUtilV2.getOntologySchema : RouteUtilV2.runRdfRouteWithFuture( requestMessageF = requestMessageFuture, requestContext = requestContext, settings = settings, responderManager = responderManager, log = log, targetSchema = targetSchema, schemaOptions = schemaOptions ) If the route only supports one schema, it can specify the schema directly instead: RouteUtilV2.runRdfRouteWithFuture( requestMessageF = requestMessageFuture, requestContext = requestContext, settings = settings, responderManager = responderManager, log = log, targetSchema = ApiV2Complex, schemaOptions = RouteUtilV2.getSchemaOptions(requestContext) )","title":"Selecting the Response Schema"},{"location":"05-internals/design/api-v2/json-ld/#generating-other-rdf-formats","text":"RouteUtilV2.runRdfRouteWithFuture implements HTTP content negotiation . After determining the client's preferred format, it asks the KnoraResponseV2 to convert itself into that format. KnoraResponseV2 has an abstract format method, whose implementations select the most efficient conversion between the response message's internal representation (which could be JSON-LD or Turtle) and the requested format.","title":"Generating Other RDF Formats"},{"location":"05-internals/design/api-v2/ontology-management/","text":"Ontology Management The core of Knora's ontology management logic is OntologyResponderV2 . It is responsible for: Loading ontologies from the triplestore when Knora starts. Maintaining an ontology cache to improve performance. Returning requested ontology entities from the cache. Requests for ontology information never access the triplestore. Creating and updating ontologies in response to API requests. Ensuring that all user-created ontologies are consistent and conform to knora-base . When Knora starts, the ontology responder receives a LoadOntologiesRequestV2 message. It then: Loads all ontologies found in the triplestore into suitable Scala data structures, which include indexes of relations between entities (e.g. rdfs:subClassOf relations), to facilitate validity checks. Checks user-created ontologies for consistency and conformance to knora-base , according to the rules described in Summary of Restrictions on User-Created Ontologies . Caches all the loaded ontologies using CacheUtil . The ontology responder assumes that nothing except itself modifies ontologies in the triplestore while Knora is running. Therefore, the ontology cache is updated only when the ontology responder processes a request to update an ontology. By design, the ontology responder can update only one ontology entity per request, to simplify the necessary validity checks. This requires the client to construct an ontology by submitting a sequence of requests in a certain order, as explained in Ontology Updates . The ontology responder mainly works with ontologies in the internal schema. However, it knows that some entities in built-in ontologies have hard-coded definitions in external schemas, and it checks the relevant transformation rules and returns those entities directly when they are requested (see Generation of Ontologies in External Schemas ).","title":"Ontology Management"},{"location":"05-internals/design/api-v2/ontology-management/#ontology-management","text":"The core of Knora's ontology management logic is OntologyResponderV2 . It is responsible for: Loading ontologies from the triplestore when Knora starts. Maintaining an ontology cache to improve performance. Returning requested ontology entities from the cache. Requests for ontology information never access the triplestore. Creating and updating ontologies in response to API requests. Ensuring that all user-created ontologies are consistent and conform to knora-base . When Knora starts, the ontology responder receives a LoadOntologiesRequestV2 message. It then: Loads all ontologies found in the triplestore into suitable Scala data structures, which include indexes of relations between entities (e.g. rdfs:subClassOf relations), to facilitate validity checks. Checks user-created ontologies for consistency and conformance to knora-base , according to the rules described in Summary of Restrictions on User-Created Ontologies . Caches all the loaded ontologies using CacheUtil . The ontology responder assumes that nothing except itself modifies ontologies in the triplestore while Knora is running. Therefore, the ontology cache is updated only when the ontology responder processes a request to update an ontology. By design, the ontology responder can update only one ontology entity per request, to simplify the necessary validity checks. This requires the client to construct an ontology by submitting a sequence of requests in a certain order, as explained in Ontology Updates . The ontology responder mainly works with ontologies in the internal schema. However, it knows that some entities in built-in ontologies have hard-coded definitions in external schemas, and it checks the relevant transformation rules and returns those entities directly when they are requested (see Generation of Ontologies in External Schemas ).","title":"Ontology Management"},{"location":"05-internals/design/api-v2/ontology-schemas/","text":"Ontology Schemas OntologySchema Type As explained in API Schema , Knora can represent the same RDF data in different forms: an \"internal schema\" for use in the triplestore, and different \"external schemas\" for use in Knora API v2. Different schemas use different IRIs, as explained in Knora IRIs . Internally, Knora uses a SmartIri class to convert IRIs between schemas. The data type representing a schema itself is OntologySchema , which uses the sealed trait pattern: package org.knora.webapi /** * Indicates the schema that a Knora ontology or ontology entity conforms to. */ sealed trait OntologySchema /** * The schema of DSP ontologies and entities that are used in the triplestore. */ case object InternalSchema extends OntologySchema /** * The schema of DSP ontologies and entities that are used in API v2. */ sealed trait ApiV2Schema extends OntologySchema /** * The simple schema for representing DSP ontologies and entities. This schema represents values as literals * when possible. */ case object ApiV2Simple extends ApiV2Schema /** * The default (or complex) schema for representing DSP ontologies and entities. This * schema always represents values as objects. */ case object ApiV2Complex extends ApiV2Schema /** * A trait representing options that can be submitted to configure an ontology schema. */ sealed trait SchemaOption /** * A trait representing options that affect the rendering of markup when text values are returned. */ sealed trait MarkupRendering extends SchemaOption /** * Indicates that markup should be rendered as XML when text values are returned. */ case object MarkupAsXml extends MarkupRendering /** * Indicates that markup should not be returned with text values, because it will be requested * separately as standoff. */ case object MarkupAsStandoff extends MarkupRendering /** * Indicates that no markup should be returned with text values. Used only internally. */ case object NoMarkup extends MarkupRendering /** * Utility functions for working with schema options. */ object SchemaOptions { /** * A set of schema options for querying all standoff markup along with text values. */ val ForStandoffWithTextValues: Set[SchemaOption] = Set(MarkupAsXml) /** * A set of schema options for querying standoff markup separately from text values. */ val ForStandoffSeparateFromTextValues: Set[SchemaOption] = Set(MarkupAsStandoff) /** * Determines whether standoff should be queried when a text value is queried. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if standoff should be queried. */ def queryStandoffWithTextValues(targetSchema: ApiV2Schema, schemaOptions: Set[SchemaOption]): Boolean = { targetSchema == ApiV2Complex && !schemaOptions.contains(MarkupAsStandoff) } /** * Determines whether markup should be rendered as XML. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if markup should be rendered as XML. */ def renderMarkupAsXml(targetSchema: ApiV2Schema, schemaOptions: Set[SchemaOption]): Boolean = { targetSchema == ApiV2Complex && !schemaOptions.contains(MarkupAsStandoff) } /** * Determines whether markup should be rendered as standoff, separately from text values. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if markup should be rendered as standoff. */ def renderMarkupAsStandoff(targetSchema: ApiV2Schema, schemaOptions: Set[SchemaOption]): Boolean = { targetSchema == ApiV2Complex && schemaOptions.contains(MarkupAsStandoff) } } This class hierarchy allows method declarations to restrict the schemas they accept. A method that can accept any schema can take a parameter of type OntologySchema , while a method that accepts only external schemas can take a parameter of type ApiV2Schema . For examples, see Content Wrappers . Generation of Ontologies in External Schemas Ontologies are stored only in the internal schema, and are converted on the fly to external schemas. For each external schema, there is a Scala object in org.knora.webapi.messages.v2.responder.ontologymessages that provides rules for this conversion: KnoraApiV2SimpleTransformationRules for the API v2 simple schema KnoraApiV2WithValueObjectsTransformationRules for the API v2 complex schema Since these are Scala objects rather than classes, they are initialised before the Akka ActorSystem starts, and therefore need a special instance of Knora's StringFormatter class (see Smart IRIs ). Each of these rule objects implements this trait: /** * A trait for objects that provide rules for converting an ontology from the internal schema to an external schema. * * See also [[OntologyConstants.CorrespondingIris]]. */ trait OntologyTransformationRules { /** * The metadata to be used for the transformed ontology. */ val ontologyMetadata: OntologyMetadataV2 /** * Properties to remove from the ontology before converting it to the target schema. * See also [[OntologyConstants.CorrespondingIris]]. */ val internalPropertiesToRemove: Set[SmartIri] /** * Classes to remove from the ontology before converting it to the target schema. */ val internalClassesToRemove: Set[SmartIri] /** * After the ontology has been converted to the target schema, these cardinalities must be * added to the specified classes. */ val externalCardinalitiesToAdd: Map[SmartIri, Map[SmartIri, KnoraCardinalityInfo]] /** * Classes that need to be added to the ontology after converting it to the target schema. */ val externalClassesToAdd: Map[SmartIri, ReadClassInfoV2] /** * Properties that need to be added to the ontology after converting it to the target schema. * See also [[OntologyConstants.CorrespondingIris]]. */ val externalPropertiesToAdd: Map[SmartIri, ReadPropertyInfoV2] } These rules are applied to knora-base as well as to user-created ontologies. For example, knora-base:Resource has different cardinalities depending on its schema ( knora-api:Resource has an additional cardinality on knora-api:hasIncomingLink ), and this is therefore also true of its user-created subclasses. The transformation is implemented: In the implementations of the toOntologySchema method in classes defined in OntologyMessagesV2.scala : ReadOntologyV2 , ReadClassInfoV2 , ClassInfoContentV2 , PropertyInfoContentV2 , and OntologyMetadataV2 . In OntologyResponderV2.getEntityInfoResponseV2 , which handles requests for specific ontology entities. If the requested entity is hard-coded in a transformation rule, this method returns the hard-coded external entity, otherwise it returns the relevant internal entity.","title":"Ontology Schemas"},{"location":"05-internals/design/api-v2/ontology-schemas/#ontology-schemas","text":"","title":"Ontology Schemas"},{"location":"05-internals/design/api-v2/ontology-schemas/#ontologyschema-type","text":"As explained in API Schema , Knora can represent the same RDF data in different forms: an \"internal schema\" for use in the triplestore, and different \"external schemas\" for use in Knora API v2. Different schemas use different IRIs, as explained in Knora IRIs . Internally, Knora uses a SmartIri class to convert IRIs between schemas. The data type representing a schema itself is OntologySchema , which uses the sealed trait pattern: package org.knora.webapi /** * Indicates the schema that a Knora ontology or ontology entity conforms to. */ sealed trait OntologySchema /** * The schema of DSP ontologies and entities that are used in the triplestore. */ case object InternalSchema extends OntologySchema /** * The schema of DSP ontologies and entities that are used in API v2. */ sealed trait ApiV2Schema extends OntologySchema /** * The simple schema for representing DSP ontologies and entities. This schema represents values as literals * when possible. */ case object ApiV2Simple extends ApiV2Schema /** * The default (or complex) schema for representing DSP ontologies and entities. This * schema always represents values as objects. */ case object ApiV2Complex extends ApiV2Schema /** * A trait representing options that can be submitted to configure an ontology schema. */ sealed trait SchemaOption /** * A trait representing options that affect the rendering of markup when text values are returned. */ sealed trait MarkupRendering extends SchemaOption /** * Indicates that markup should be rendered as XML when text values are returned. */ case object MarkupAsXml extends MarkupRendering /** * Indicates that markup should not be returned with text values, because it will be requested * separately as standoff. */ case object MarkupAsStandoff extends MarkupRendering /** * Indicates that no markup should be returned with text values. Used only internally. */ case object NoMarkup extends MarkupRendering /** * Utility functions for working with schema options. */ object SchemaOptions { /** * A set of schema options for querying all standoff markup along with text values. */ val ForStandoffWithTextValues: Set[SchemaOption] = Set(MarkupAsXml) /** * A set of schema options for querying standoff markup separately from text values. */ val ForStandoffSeparateFromTextValues: Set[SchemaOption] = Set(MarkupAsStandoff) /** * Determines whether standoff should be queried when a text value is queried. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if standoff should be queried. */ def queryStandoffWithTextValues(targetSchema: ApiV2Schema, schemaOptions: Set[SchemaOption]): Boolean = { targetSchema == ApiV2Complex && !schemaOptions.contains(MarkupAsStandoff) } /** * Determines whether markup should be rendered as XML. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if markup should be rendered as XML. */ def renderMarkupAsXml(targetSchema: ApiV2Schema, schemaOptions: Set[SchemaOption]): Boolean = { targetSchema == ApiV2Complex && !schemaOptions.contains(MarkupAsStandoff) } /** * Determines whether markup should be rendered as standoff, separately from text values. * * @param targetSchema the target API schema. * @param schemaOptions the schema options submitted with the request. * @return `true` if markup should be rendered as standoff. */ def renderMarkupAsStandoff(targetSchema: ApiV2Schema, schemaOptions: Set[SchemaOption]): Boolean = { targetSchema == ApiV2Complex && schemaOptions.contains(MarkupAsStandoff) } } This class hierarchy allows method declarations to restrict the schemas they accept. A method that can accept any schema can take a parameter of type OntologySchema , while a method that accepts only external schemas can take a parameter of type ApiV2Schema . For examples, see Content Wrappers .","title":"OntologySchema Type"},{"location":"05-internals/design/api-v2/ontology-schemas/#generation-of-ontologies-in-external-schemas","text":"Ontologies are stored only in the internal schema, and are converted on the fly to external schemas. For each external schema, there is a Scala object in org.knora.webapi.messages.v2.responder.ontologymessages that provides rules for this conversion: KnoraApiV2SimpleTransformationRules for the API v2 simple schema KnoraApiV2WithValueObjectsTransformationRules for the API v2 complex schema Since these are Scala objects rather than classes, they are initialised before the Akka ActorSystem starts, and therefore need a special instance of Knora's StringFormatter class (see Smart IRIs ). Each of these rule objects implements this trait: /** * A trait for objects that provide rules for converting an ontology from the internal schema to an external schema. * * See also [[OntologyConstants.CorrespondingIris]]. */ trait OntologyTransformationRules { /** * The metadata to be used for the transformed ontology. */ val ontologyMetadata: OntologyMetadataV2 /** * Properties to remove from the ontology before converting it to the target schema. * See also [[OntologyConstants.CorrespondingIris]]. */ val internalPropertiesToRemove: Set[SmartIri] /** * Classes to remove from the ontology before converting it to the target schema. */ val internalClassesToRemove: Set[SmartIri] /** * After the ontology has been converted to the target schema, these cardinalities must be * added to the specified classes. */ val externalCardinalitiesToAdd: Map[SmartIri, Map[SmartIri, KnoraCardinalityInfo]] /** * Classes that need to be added to the ontology after converting it to the target schema. */ val externalClassesToAdd: Map[SmartIri, ReadClassInfoV2] /** * Properties that need to be added to the ontology after converting it to the target schema. * See also [[OntologyConstants.CorrespondingIris]]. */ val externalPropertiesToAdd: Map[SmartIri, ReadPropertyInfoV2] } These rules are applied to knora-base as well as to user-created ontologies. For example, knora-base:Resource has different cardinalities depending on its schema ( knora-api:Resource has an additional cardinality on knora-api:hasIncomingLink ), and this is therefore also true of its user-created subclasses. The transformation is implemented: In the implementations of the toOntologySchema method in classes defined in OntologyMessagesV2.scala : ReadOntologyV2 , ReadClassInfoV2 , ClassInfoContentV2 , PropertyInfoContentV2 , and OntologyMetadataV2 . In OntologyResponderV2.getEntityInfoResponseV2 , which handles requests for specific ontology entities. If the requested entity is hard-coded in a transformation rule, this method returns the hard-coded external entity, otherwise it returns the relevant internal entity.","title":"Generation of Ontologies in External Schemas"},{"location":"05-internals/design/api-v2/overview/","text":"API v2 Design Overview General Principles DSP-API v2 requests and responses are RDF documents. Any API v2 response can be returned as JSON-LD , Turtle , or RDF/XML . Each class or property used in a request or response has a definition in an ontology, which Knora can serve. Response formats are reused for different requests whenever possible, to minimise the number of different response formats a client has to handle. For example, any request for one or more resources (such as a search result, or a request for one specific resource) returns a response in the same format. Response size is limited by design. Large amounts of data must be retrieved by requesting small pages of data, one after the other. Responses that provide data are distinct from responses that provide definitions (i.e. ontology entities). Data responses indicate which types are used, and the client can request information about these types separately. API Schemas The types used in the triplestore are not exposed directly in the API. Instead, they are mapped onto API 'schemas'. Two schemas are currently provided. A complex schema, which is suitable both for reading and for editing data. The complex schema represents values primarily as complex objects. A simple schema, which is suitable for reading data but not for editing it. The simple schema facilitates interoperability between DSP ontologies and non-DSP ontologies, since it represents values primarily as literals. Each schema has its own type IRIs, which are derived from the ones used in the triplestore. For details of these different IRI formats, see Knora IRIs . Implementation JSON-LD Parsing and Formatting Each API response is represented by a class that extends KnoraResponseV2 , which has a method toJsonLDDocument that specifies the target schema. It is currently up to each route to determine what the appropriate response schema should be. Some routes will support only one response schema. Others will allow the client to choose, and there will be one or more standard ways for the client to specify the desired response schema. A route calls RouteUtilV2.runRdfRoute , passing a request message and a response schema. When RouteUtilV2 gets the response message from the responder, it calls toJsonLDDocument on it, specifying that schema. The response message returns a JsonLDDocument , which is a simple data structure that is then converted to Java objects and passed to the JSON-LD Java library for formatting. In general, toJsonLDDocument is implemented in two stages: first the object converts itself to the target schema, and then the resulting object is converted to a JsonLDDocument . A route that receives JSON-LD requests should use JsonLDUtil.parseJsonLD to convert each request to a JsonLDDocument . Generation of Other RDF Formats RouteUtilV2.runRdfRoute implements HTTP content negotiation , and converts JSON-LD responses into Turtle or RDF/XML as appropriate. Operation Wrappers Whenever possible, the same data structures are used for input and output. Often more data is available in output than in input. For example, when a value is read from the triplestore, its IRI is available, but when it is being created, it does not yet have an IRI. In such cases, there is a class like ValueContentV2 , which represents the data that is used both for input and for output. When a value is read, a ValueContentV2 is wrapped in a ReadValueV2 , which additionally contains the value's IRI. When a value is created, it is wrapped in a CreateValueV2 , which has the resource IRI and the property IRI, but not the value IRI. A Read* wrapper can be wrapped in another Read* wrapper; for example, a ReadResourceV2 contains ReadValueV2 objects. Each *Content* class should extend KnoraContentV2 and thus have a toOntologySchema method or converting itself between internal and external schemas, in either direction. Each Read* wrapper class should have a method for converting itself to JSON-LD in a particular external schema. If the Read* wrapper is a KnoraResponseV2 , this method is toJsonLDDocument . Smart IRIs Usage The SmartIri trait can be used to parse and validate IRIs, and in particular for converting Knora type IRIs between internal and external schemas. It validates each IRI it parses. To use it, import the following: import org.knora.webapi.messages.{SmartIri, StringFormatter} import org.knora.webapi.messages.IriConversions._ Ensure that an implicit instance of StringFormatter is in scope: implicit val stringFormatter: StringFormatter = StringFormatter.getGeneralInstance Then, if iriStr is a string representing an IRI, you can can convert it to a SmartIri like this: val iri: SmartIri = iriStr.toSmartIri If the IRI came from a request, use this method to throw a specific exception if the IRI is invalid: val iri: SmartIri = iriStr.toSmartIriWithErr( () => throw BadRequestException(s\"Invalid IRI: $iriStr\") ) You can then use methods such as SmartIri.isKnoraApiV2EntityIri and SmartIri.getProjectCode to obtain information about the IRI. To convert it to another schema, call SmartIri.toOntologySchema . Converting a non-Knora IRI returns the same IRI. If the IRI represents a Knora internal value class such as knora-base:TextValue , converting it to the ApiV2Simple schema will return the corresponding simplified type, such as xsd:string . But this conversion is not performed in the other direction (external to internal), since this would require knowledge of the context in which the IRI is being used. The performance penalty for using a SmartIri instead of a string is very small. Instances are automatically cached once they are constructed. Parsing and caching a SmartIri instance takes about 10-20 \u00b5s, and retrieving a cached SmartIri takes about 1 \u00b5s. There is no advantage to using SmartIri for data IRIs, since they are not schema-specific (and are not cached). If a data IRI has been received from a client request, it is better just to validate it using StringFormatter.validateAndEscapeIri . Implementation The smart IRI implementation, SmartIriImpl , is nested in the StringFormatter class, because it uses Knora's hostname, which isn't available until the Akka ActorSystem has started. However, this means that the type of a SmartIriImpl instance is dependent on the instance of StringFormatter that constructed it. Therefore, instances of SmartIriImpl created by different instances of StringFormatter can't be compared directly. There are in fact two instances of StringFormatter : one returned by StringFormatter.getGeneralInstance which is available after Akka has started and has the API server's hostname (and can therefore provide SmartIri instances capable of parsing IRIs containing that hostname). This instance is used throughout the DSP-API server. one returned by StringFormatter.getInstanceForConstantOntologies , which is available before Akka has started, and is used only by the hard-coded constant knora-api ontologies. This is the reason for the existence of the SmartIri trait, which is a top-level definition and has its own equals and hashCode methods. Instances of SmartIri can thus be compared (e.g. to use them as unique keys in collections), regardless of which instance of StringFormatter created them.","title":"API v2 Design Overview"},{"location":"05-internals/design/api-v2/overview/#api-v2-design-overview","text":"","title":"API v2 Design Overview"},{"location":"05-internals/design/api-v2/overview/#general-principles","text":"DSP-API v2 requests and responses are RDF documents. Any API v2 response can be returned as JSON-LD , Turtle , or RDF/XML . Each class or property used in a request or response has a definition in an ontology, which Knora can serve. Response formats are reused for different requests whenever possible, to minimise the number of different response formats a client has to handle. For example, any request for one or more resources (such as a search result, or a request for one specific resource) returns a response in the same format. Response size is limited by design. Large amounts of data must be retrieved by requesting small pages of data, one after the other. Responses that provide data are distinct from responses that provide definitions (i.e. ontology entities). Data responses indicate which types are used, and the client can request information about these types separately.","title":"General Principles"},{"location":"05-internals/design/api-v2/overview/#api-schemas","text":"The types used in the triplestore are not exposed directly in the API. Instead, they are mapped onto API 'schemas'. Two schemas are currently provided. A complex schema, which is suitable both for reading and for editing data. The complex schema represents values primarily as complex objects. A simple schema, which is suitable for reading data but not for editing it. The simple schema facilitates interoperability between DSP ontologies and non-DSP ontologies, since it represents values primarily as literals. Each schema has its own type IRIs, which are derived from the ones used in the triplestore. For details of these different IRI formats, see Knora IRIs .","title":"API Schemas"},{"location":"05-internals/design/api-v2/overview/#implementation","text":"","title":"Implementation"},{"location":"05-internals/design/api-v2/overview/#json-ld-parsing-and-formatting","text":"Each API response is represented by a class that extends KnoraResponseV2 , which has a method toJsonLDDocument that specifies the target schema. It is currently up to each route to determine what the appropriate response schema should be. Some routes will support only one response schema. Others will allow the client to choose, and there will be one or more standard ways for the client to specify the desired response schema. A route calls RouteUtilV2.runRdfRoute , passing a request message and a response schema. When RouteUtilV2 gets the response message from the responder, it calls toJsonLDDocument on it, specifying that schema. The response message returns a JsonLDDocument , which is a simple data structure that is then converted to Java objects and passed to the JSON-LD Java library for formatting. In general, toJsonLDDocument is implemented in two stages: first the object converts itself to the target schema, and then the resulting object is converted to a JsonLDDocument . A route that receives JSON-LD requests should use JsonLDUtil.parseJsonLD to convert each request to a JsonLDDocument .","title":"JSON-LD Parsing and Formatting"},{"location":"05-internals/design/api-v2/overview/#generation-of-other-rdf-formats","text":"RouteUtilV2.runRdfRoute implements HTTP content negotiation , and converts JSON-LD responses into Turtle or RDF/XML as appropriate.","title":"Generation of Other RDF Formats"},{"location":"05-internals/design/api-v2/overview/#operation-wrappers","text":"Whenever possible, the same data structures are used for input and output. Often more data is available in output than in input. For example, when a value is read from the triplestore, its IRI is available, but when it is being created, it does not yet have an IRI. In such cases, there is a class like ValueContentV2 , which represents the data that is used both for input and for output. When a value is read, a ValueContentV2 is wrapped in a ReadValueV2 , which additionally contains the value's IRI. When a value is created, it is wrapped in a CreateValueV2 , which has the resource IRI and the property IRI, but not the value IRI. A Read* wrapper can be wrapped in another Read* wrapper; for example, a ReadResourceV2 contains ReadValueV2 objects. Each *Content* class should extend KnoraContentV2 and thus have a toOntologySchema method or converting itself between internal and external schemas, in either direction. Each Read* wrapper class should have a method for converting itself to JSON-LD in a particular external schema. If the Read* wrapper is a KnoraResponseV2 , this method is toJsonLDDocument .","title":"Operation Wrappers"},{"location":"05-internals/design/api-v2/overview/#smart-iris","text":"","title":"Smart IRIs"},{"location":"05-internals/design/api-v2/overview/#usage","text":"The SmartIri trait can be used to parse and validate IRIs, and in particular for converting Knora type IRIs between internal and external schemas. It validates each IRI it parses. To use it, import the following: import org.knora.webapi.messages.{SmartIri, StringFormatter} import org.knora.webapi.messages.IriConversions._ Ensure that an implicit instance of StringFormatter is in scope: implicit val stringFormatter: StringFormatter = StringFormatter.getGeneralInstance Then, if iriStr is a string representing an IRI, you can can convert it to a SmartIri like this: val iri: SmartIri = iriStr.toSmartIri If the IRI came from a request, use this method to throw a specific exception if the IRI is invalid: val iri: SmartIri = iriStr.toSmartIriWithErr( () => throw BadRequestException(s\"Invalid IRI: $iriStr\") ) You can then use methods such as SmartIri.isKnoraApiV2EntityIri and SmartIri.getProjectCode to obtain information about the IRI. To convert it to another schema, call SmartIri.toOntologySchema . Converting a non-Knora IRI returns the same IRI. If the IRI represents a Knora internal value class such as knora-base:TextValue , converting it to the ApiV2Simple schema will return the corresponding simplified type, such as xsd:string . But this conversion is not performed in the other direction (external to internal), since this would require knowledge of the context in which the IRI is being used. The performance penalty for using a SmartIri instead of a string is very small. Instances are automatically cached once they are constructed. Parsing and caching a SmartIri instance takes about 10-20 \u00b5s, and retrieving a cached SmartIri takes about 1 \u00b5s. There is no advantage to using SmartIri for data IRIs, since they are not schema-specific (and are not cached). If a data IRI has been received from a client request, it is better just to validate it using StringFormatter.validateAndEscapeIri .","title":"Usage"},{"location":"05-internals/design/api-v2/overview/#implementation_1","text":"The smart IRI implementation, SmartIriImpl , is nested in the StringFormatter class, because it uses Knora's hostname, which isn't available until the Akka ActorSystem has started. However, this means that the type of a SmartIriImpl instance is dependent on the instance of StringFormatter that constructed it. Therefore, instances of SmartIriImpl created by different instances of StringFormatter can't be compared directly. There are in fact two instances of StringFormatter : one returned by StringFormatter.getGeneralInstance which is available after Akka has started and has the API server's hostname (and can therefore provide SmartIri instances capable of parsing IRIs containing that hostname). This instance is used throughout the DSP-API server. one returned by StringFormatter.getInstanceForConstantOntologies , which is available before Akka has started, and is used only by the hard-coded constant knora-api ontologies. This is the reason for the existence of the SmartIri trait, which is a top-level definition and has its own equals and hashCode methods. Instances of SmartIri can thus be compared (e.g. to use them as unique keys in collections), regardless of which instance of StringFormatter created them.","title":"Implementation"},{"location":"05-internals/design/api-v2/query-design/","text":"SPARQL Query Design Inference DSP-API does not require the triplestore to perform inference, as different triplestores implement inference quite differently, so that taking advantage of inference would require triplestore specific code, which is not well maintainable. Instead, the API simulates inference for each Gravsearch query, so that the expected results are returned. Gravsearch queries currently need to do the following: Given a base property, find triples using a subproperty as predicate, and return the subproperty used in each case. Given a base class, find triples using an instance of subclass as subject or object, and return the subclass used in each case. Without inference, this can be done using property path syntax. CONSTRUCT { ?resource a ?resourceClass . ?resource ?resourceValueProperty ?valueObject. WHERE { ?resource a ?resourceClass . ?resourceType rdfs:subClassOf* knora-base:Resource . ?resource ?resourceValueProperty ?valueObject . ?resourceValueProperty rdfs:subPropertyOf* knora-base:hasValue . This query: Checks that the queried resource belongs to a subclass of knora-base:Resource . Returns the class that the resource explicitly belongs to. Finds the Knora values attached to the resource, and returns each value along with the property that explicitly attaches it to the resource. However, such a query is very inefficient. Instead, the API does inference on the query, so that the relevant information can be found in a timely manner. For this, the query is analyzed to check which project ontologies are relevant to the query. If an ontology is not relevant to a query, then all class and property definitions of this ontology are disregarded for inference. Then, each statement that requires inference (i.e. that could be phrased with property path syntax, as described above) is cross-referenced with the relevant ontologies, to see which property/class definitions would fit the statement according to the rules of RDF inference. And each of those definitions is added to the query as a separate UNION statement. E.g.: Given the resource class B is a subclass of A and the property hasY is a subproperty of hasX , then the following query SELECT { ?res ?prop . } WHERE { ?res a <A> . ?res <hasX> ?prop . } can be rewritten as SELECT { ?res ?prop . } WHERE { {?res a <A>} UNION {?res a <B>} . {?res <hasX> ?prop} UNION {?res <hasY> ?prop} . } Querying Past Value Versions Value versions are a linked list, starting with the current version. Each value points to the previous version via knora-base:previousValue . The resource points only to the current version. Past value versions are queried in getResourcePropertiesAndValues.scala.txt , which can take a timestamp argument. Given the current value version, we must find the most recent past version that existed at the target date. First, we get the set of previous values that were created on or before the target date: ?currentValue knora-base:previousValue* ?valueObject . ?valueObject knora-base:valueCreationDate ?valueObjectCreationDate . FILTER(?valueObjectCreationDate <= \"@versionDate\"^^xsd:dateTime) The resulting versions are now possible values of ?valueObject . Next, out of this set of versions, we exclude all versions except for the most recent one. We do this by checking, for each ?valueObject , whether there is another version, ?otherValueObject , that is more recent and was also created before the target date. If such a version exists, we exclude the one we are looking at. FILTER NOT EXISTS { ?currentValue knora-base:previousValue* ?otherValueObject . ?otherValueObject knora-base:valueCreationDate ?otherValueObjectCreationDate . FILTER( (?otherValueObjectCreationDate <= \"@versionDate\"^^xsd:dateTime) && (?otherValueObjectCreationDate > ?valueObjectCreationDate) ) } This excludes all past versions except the one we are interested in.","title":"SPARQL Query Design"},{"location":"05-internals/design/api-v2/query-design/#sparql-query-design","text":"","title":"SPARQL Query Design"},{"location":"05-internals/design/api-v2/query-design/#inference","text":"DSP-API does not require the triplestore to perform inference, as different triplestores implement inference quite differently, so that taking advantage of inference would require triplestore specific code, which is not well maintainable. Instead, the API simulates inference for each Gravsearch query, so that the expected results are returned. Gravsearch queries currently need to do the following: Given a base property, find triples using a subproperty as predicate, and return the subproperty used in each case. Given a base class, find triples using an instance of subclass as subject or object, and return the subclass used in each case. Without inference, this can be done using property path syntax. CONSTRUCT { ?resource a ?resourceClass . ?resource ?resourceValueProperty ?valueObject. WHERE { ?resource a ?resourceClass . ?resourceType rdfs:subClassOf* knora-base:Resource . ?resource ?resourceValueProperty ?valueObject . ?resourceValueProperty rdfs:subPropertyOf* knora-base:hasValue . This query: Checks that the queried resource belongs to a subclass of knora-base:Resource . Returns the class that the resource explicitly belongs to. Finds the Knora values attached to the resource, and returns each value along with the property that explicitly attaches it to the resource. However, such a query is very inefficient. Instead, the API does inference on the query, so that the relevant information can be found in a timely manner. For this, the query is analyzed to check which project ontologies are relevant to the query. If an ontology is not relevant to a query, then all class and property definitions of this ontology are disregarded for inference. Then, each statement that requires inference (i.e. that could be phrased with property path syntax, as described above) is cross-referenced with the relevant ontologies, to see which property/class definitions would fit the statement according to the rules of RDF inference. And each of those definitions is added to the query as a separate UNION statement. E.g.: Given the resource class B is a subclass of A and the property hasY is a subproperty of hasX , then the following query SELECT { ?res ?prop . } WHERE { ?res a <A> . ?res <hasX> ?prop . } can be rewritten as SELECT { ?res ?prop . } WHERE { {?res a <A>} UNION {?res a <B>} . {?res <hasX> ?prop} UNION {?res <hasY> ?prop} . }","title":"Inference"},{"location":"05-internals/design/api-v2/query-design/#querying-past-value-versions","text":"Value versions are a linked list, starting with the current version. Each value points to the previous version via knora-base:previousValue . The resource points only to the current version. Past value versions are queried in getResourcePropertiesAndValues.scala.txt , which can take a timestamp argument. Given the current value version, we must find the most recent past version that existed at the target date. First, we get the set of previous values that were created on or before the target date: ?currentValue knora-base:previousValue* ?valueObject . ?valueObject knora-base:valueCreationDate ?valueObjectCreationDate . FILTER(?valueObjectCreationDate <= \"@versionDate\"^^xsd:dateTime) The resulting versions are now possible values of ?valueObject . Next, out of this set of versions, we exclude all versions except for the most recent one. We do this by checking, for each ?valueObject , whether there is another version, ?otherValueObject , that is more recent and was also created before the target date. If such a version exists, we exclude the one we are looking at. FILTER NOT EXISTS { ?currentValue knora-base:previousValue* ?otherValueObject . ?otherValueObject knora-base:valueCreationDate ?otherValueObjectCreationDate . FILTER( (?otherValueObjectCreationDate <= \"@versionDate\"^^xsd:dateTime) && (?otherValueObjectCreationDate > ?valueObjectCreationDate) ) } This excludes all past versions except the one we are interested in.","title":"Querying Past Value Versions"},{"location":"05-internals/design/api-v2/sipi/","text":"DSP-API and Sipi Configuration The DSP-API specific configuration and scripts for Sipi are in the sipi subdirectory of the DSP-API source tree. See the README.md for instructions on how to start Sipi with DSP-API. Lua Scripts DSP-API v2 uses custom Lua scripts to control Sipi. These scripts can be found in sipi/scripts in the DSP-API source tree. Each of these scripts expects a JSON Web Token in the URL parameter token . In all cases, the token must be signed by DSP-API, it must have an expiration date and not have expired, its issuer must equal the hostname and port of the API, and its audience must include Sipi . The other contents of the expected tokens are described below. upload.lua The upload.lua script is available at Sipi's upload route. It processes one or more file uploads submitted to Sipi. It converts uploaded images to JPEG 2000 format, and stores them in Sipi's tmp directory. The usage of this script is described in Upload Files to Sipi . Each time upload.lua processes a request, it also deletes old temporary files from tmp and (recursively) from any subdirectories. The maximum allowed age of temporary files can be set in Sipi's configuration file, using the parameter max_temp_file_age , which takes a value in seconds, and defaults to 86400 (1 day). store.lua The store.lua script is available at Sipi's store route. It moves a file from temporary to permanent storage. It expects an HTTP POST request containing application/x-www-form-urlencoded data with the parameters prefix (the project shortcode) and filename (the internal Sipi-generated filename of the file to be moved). The JWT sent to this script must contain the key knora-data , whose value must be a JSON object containing: permission : must be StoreFile prefix : the project shortcode submitted in the form data filename : the filename submitted in the form data delete_temp_file.lua The delete_temp_file.lua script is available at Sipi's delete_temp_file route. It is used only if DSP-API rejects a file value update request. It expects an HTTP DELETE request, with a filename as the last component of the URL. The JWT sent to this script must contain the key knora-data , whose value must be a JSON object containing: permission : must be DeleteTempFile filename : must be the same as the filename submitted in the URL SipiConnector In DSP-API, the org.knora.webapi.iiif.SipiConnector handles all communication with Sipi. It blocks while processing each request, to ensure that the number of concurrent requests to Sipi is not greater than akka.actor.deployment./storeManager/iiifManager/sipiConnector.nr-of-instances . If it encounters an error, it returns SipiException . The Image File Upload Workflow The client uploads an image file to the upload route, which runs upload.lua . The image is converted to JPEG 2000 and stored in Sipi's tmp directory. In the response, the client receives the JPEG 2000's unique, randomly generated filename. The client submits a JSON-LD request to a DSP-API route ( /v2/values or /v2/resources ) to create or change a file value. The request includes Sipi's internal filename. During parsing of this JSON-LD request, a StillImageFileValueContentV2 is constructed to represent the file value. During the construction of this object, a GetFileMetadataRequestV2 is sent to SipiConnector , which uses Sipi's built-in knora.json route to get the rest of the file's metadata. A responder ( ResourcesResponderV2 or ValuesResponderV2 ) validates the request and updates the triplestore. (If it is ResourcesResponderV2 , it asks ValuesResponderV2 to generate SPARQL for the values.) The responder that did the update calls ValueUtilV2.doSipiPostUpdate . If the triplestore update was successful, this method sends MoveTemporaryFileToPermanentStorageRequestV2 to SipiConnector , which makes a request to Sipi's store route. Otherwise, the same method sends DeleteTemporaryFileRequestV2 to SipiConnector , which makes a request to Sipi's delete_temp_file route. If the request to DSP-API cannot be parsed, the temporary file is not deleted immediately, but it will be deleted during the processing of a subsequent request by Sipi's upload route. If Sipi's store route fails, DSP-API returns the SipiException to the client. In this case, manual intervention may be necessary to restore consistency between DSP-API and Sipi. If Sipi's delete_temp_file route fails, the error is not returned to the client, because there is already a DSP-API error that needs to be returned to the client. In this case, the Sipi error is simply logged.","title":"DSP-API and Sipi"},{"location":"05-internals/design/api-v2/sipi/#dsp-api-and-sipi","text":"","title":"DSP-API and Sipi"},{"location":"05-internals/design/api-v2/sipi/#configuration","text":"The DSP-API specific configuration and scripts for Sipi are in the sipi subdirectory of the DSP-API source tree. See the README.md for instructions on how to start Sipi with DSP-API.","title":"Configuration"},{"location":"05-internals/design/api-v2/sipi/#lua-scripts","text":"DSP-API v2 uses custom Lua scripts to control Sipi. These scripts can be found in sipi/scripts in the DSP-API source tree. Each of these scripts expects a JSON Web Token in the URL parameter token . In all cases, the token must be signed by DSP-API, it must have an expiration date and not have expired, its issuer must equal the hostname and port of the API, and its audience must include Sipi . The other contents of the expected tokens are described below.","title":"Lua Scripts"},{"location":"05-internals/design/api-v2/sipi/#uploadlua","text":"The upload.lua script is available at Sipi's upload route. It processes one or more file uploads submitted to Sipi. It converts uploaded images to JPEG 2000 format, and stores them in Sipi's tmp directory. The usage of this script is described in Upload Files to Sipi . Each time upload.lua processes a request, it also deletes old temporary files from tmp and (recursively) from any subdirectories. The maximum allowed age of temporary files can be set in Sipi's configuration file, using the parameter max_temp_file_age , which takes a value in seconds, and defaults to 86400 (1 day).","title":"upload.lua"},{"location":"05-internals/design/api-v2/sipi/#storelua","text":"The store.lua script is available at Sipi's store route. It moves a file from temporary to permanent storage. It expects an HTTP POST request containing application/x-www-form-urlencoded data with the parameters prefix (the project shortcode) and filename (the internal Sipi-generated filename of the file to be moved). The JWT sent to this script must contain the key knora-data , whose value must be a JSON object containing: permission : must be StoreFile prefix : the project shortcode submitted in the form data filename : the filename submitted in the form data","title":"store.lua"},{"location":"05-internals/design/api-v2/sipi/#delete_temp_filelua","text":"The delete_temp_file.lua script is available at Sipi's delete_temp_file route. It is used only if DSP-API rejects a file value update request. It expects an HTTP DELETE request, with a filename as the last component of the URL. The JWT sent to this script must contain the key knora-data , whose value must be a JSON object containing: permission : must be DeleteTempFile filename : must be the same as the filename submitted in the URL","title":"delete_temp_file.lua"},{"location":"05-internals/design/api-v2/sipi/#sipiconnector","text":"In DSP-API, the org.knora.webapi.iiif.SipiConnector handles all communication with Sipi. It blocks while processing each request, to ensure that the number of concurrent requests to Sipi is not greater than akka.actor.deployment./storeManager/iiifManager/sipiConnector.nr-of-instances . If it encounters an error, it returns SipiException .","title":"SipiConnector"},{"location":"05-internals/design/api-v2/sipi/#the-image-file-upload-workflow","text":"The client uploads an image file to the upload route, which runs upload.lua . The image is converted to JPEG 2000 and stored in Sipi's tmp directory. In the response, the client receives the JPEG 2000's unique, randomly generated filename. The client submits a JSON-LD request to a DSP-API route ( /v2/values or /v2/resources ) to create or change a file value. The request includes Sipi's internal filename. During parsing of this JSON-LD request, a StillImageFileValueContentV2 is constructed to represent the file value. During the construction of this object, a GetFileMetadataRequestV2 is sent to SipiConnector , which uses Sipi's built-in knora.json route to get the rest of the file's metadata. A responder ( ResourcesResponderV2 or ValuesResponderV2 ) validates the request and updates the triplestore. (If it is ResourcesResponderV2 , it asks ValuesResponderV2 to generate SPARQL for the values.) The responder that did the update calls ValueUtilV2.doSipiPostUpdate . If the triplestore update was successful, this method sends MoveTemporaryFileToPermanentStorageRequestV2 to SipiConnector , which makes a request to Sipi's store route. Otherwise, the same method sends DeleteTemporaryFileRequestV2 to SipiConnector , which makes a request to Sipi's delete_temp_file route. If the request to DSP-API cannot be parsed, the temporary file is not deleted immediately, but it will be deleted during the processing of a subsequent request by Sipi's upload route. If Sipi's store route fails, DSP-API returns the SipiException to the client. In this case, manual intervention may be necessary to restore consistency between DSP-API and Sipi. If Sipi's delete_temp_file route fails, the error is not returned to the client, because there is already a DSP-API error that needs to be returned to the client. In this case, the Sipi error is simply logged.","title":"The Image File Upload Workflow"},{"location":"05-internals/design/api-v2/smart-iris/","text":"Smart IRIs Usage The SmartIri trait can be used to parse and validate IRIs, and in particular for converting Knora type IRIs between internal and external schemas. It validates each IRI it parses. To use it, import the following: import org.knora.webapi.messages.SmartIri import org.knora.webapi.messages.IriConversions._ Ensure that an implicit instance of StringFormatter is in scope: import org.knora.webapi.messages.StringFormatter implicit val stringFormatter: StringFormatter = StringFormatter.getGeneralInstance Then, if you have a string representing an IRI, you can can convert it to a SmartIri like this: val propertyIri: SmartIri = \"http://0.0.0.0:3333/ontology/0001/anything/v2#hasInteger\".toSmartIri ```` If the IRI came from a request, use this method to throw a specific exception if the IRI is invalid: ```scala val propertyIri: SmartIri = propertyIriStr.toSmartIriWithErr(throw BadRequestException(s\"Invalid property IRI: <$propertyIriStr>\")) You can then use methods such as SmartIri.isKnoraApiV2EntityIri and SmartIri.getProjectCode to obtain information about the IRI. To convert it to another schema, call SmartIri.toOntologySchema . Converting a non-Knora IRI returns the same IRI. If the IRI represents a Knora internal value class such as knora-base:TextValue , converting it to the ApiV2Simple schema will return the corresponding simplified type, such as xsd:string . But this conversion is not performed in the other direction (external to internal), since this would require knowledge of the context in which the IRI is being used. The performance penalty for using a SmartIri instead of a string is very small. Instances are automatically cached once they are constructed. There is no advantage to using SmartIri for data IRIs, since they are not schema-specific (and are not cached). If a data IRI has been received from a client request, it is better just to validate it using StringFormatter.validateAndEscapeIri , and represent it as an org.knora.webapi.IRI (an alias for String ). Implementation The smart IRI implementation, SmartIriImpl , is nested in the StringFormatter class, because it uses Knora's hostname, which isn't available until the Akka ActorSystem has started. However, this means that the Scala type of a SmartIriImpl instance is dependent on the instance of StringFormatter that constructed it. Therefore, instances of SmartIriImpl created by different instances of StringFormatter can't be compared directly. There are in fact two instances of StringFormatter : one returned by StringFormatter.getGeneralInstance , which is available after Akka has started and has the API server's hostname (and can therefore provide SmartIri instances capable of parsing IRIs containing that hostname). This instance is used throughout the DSP-API server. one returned by StringFormatter.getInstanceForConstantOntologies , which is available before Akka has started, and is used only by the hard-coded constant knora-api ontologies (see Generation of Ontologies in External Schemas ). This is the reason for the existence of the SmartIri trait, which is a top-level definition and has its own equals and hashCode methods. Instances of SmartIri can thus be compared (e.g. to use them as unique keys in collections), regardless of which instance of StringFormatter created them.","title":"Smart IRIs"},{"location":"05-internals/design/api-v2/smart-iris/#smart-iris","text":"","title":"Smart IRIs"},{"location":"05-internals/design/api-v2/smart-iris/#usage","text":"The SmartIri trait can be used to parse and validate IRIs, and in particular for converting Knora type IRIs between internal and external schemas. It validates each IRI it parses. To use it, import the following: import org.knora.webapi.messages.SmartIri import org.knora.webapi.messages.IriConversions._ Ensure that an implicit instance of StringFormatter is in scope: import org.knora.webapi.messages.StringFormatter implicit val stringFormatter: StringFormatter = StringFormatter.getGeneralInstance Then, if you have a string representing an IRI, you can can convert it to a SmartIri like this: val propertyIri: SmartIri = \"http://0.0.0.0:3333/ontology/0001/anything/v2#hasInteger\".toSmartIri ```` If the IRI came from a request, use this method to throw a specific exception if the IRI is invalid: ```scala val propertyIri: SmartIri = propertyIriStr.toSmartIriWithErr(throw BadRequestException(s\"Invalid property IRI: <$propertyIriStr>\")) You can then use methods such as SmartIri.isKnoraApiV2EntityIri and SmartIri.getProjectCode to obtain information about the IRI. To convert it to another schema, call SmartIri.toOntologySchema . Converting a non-Knora IRI returns the same IRI. If the IRI represents a Knora internal value class such as knora-base:TextValue , converting it to the ApiV2Simple schema will return the corresponding simplified type, such as xsd:string . But this conversion is not performed in the other direction (external to internal), since this would require knowledge of the context in which the IRI is being used. The performance penalty for using a SmartIri instead of a string is very small. Instances are automatically cached once they are constructed. There is no advantage to using SmartIri for data IRIs, since they are not schema-specific (and are not cached). If a data IRI has been received from a client request, it is better just to validate it using StringFormatter.validateAndEscapeIri , and represent it as an org.knora.webapi.IRI (an alias for String ).","title":"Usage"},{"location":"05-internals/design/api-v2/smart-iris/#implementation","text":"The smart IRI implementation, SmartIriImpl , is nested in the StringFormatter class, because it uses Knora's hostname, which isn't available until the Akka ActorSystem has started. However, this means that the Scala type of a SmartIriImpl instance is dependent on the instance of StringFormatter that constructed it. Therefore, instances of SmartIriImpl created by different instances of StringFormatter can't be compared directly. There are in fact two instances of StringFormatter : one returned by StringFormatter.getGeneralInstance , which is available after Akka has started and has the API server's hostname (and can therefore provide SmartIri instances capable of parsing IRIs containing that hostname). This instance is used throughout the DSP-API server. one returned by StringFormatter.getInstanceForConstantOntologies , which is available before Akka has started, and is used only by the hard-coded constant knora-api ontologies (see Generation of Ontologies in External Schemas ). This is the reason for the existence of the SmartIri trait, which is a top-level definition and has its own equals and hashCode methods. Instances of SmartIri can thus be compared (e.g. to use them as unique keys in collections), regardless of which instance of StringFormatter created them.","title":"Implementation"},{"location":"05-internals/design/api-v2/standoff/","text":"Standoff Markup Requirements In Knora, text with markup is stored using standoff markup , i.e. markup that is stored separately from the content it applies to. Knora's standoff design is based on these requirements: Overlapping markup should be supported. Markup should be stored as RDF, so it can be searched and analysed using the same tools that are used with other data managed by Knora. In particular, Gravsearch queries should be able to specify search criteria that refer to the markup tags attached to a text, together with any other search criteria relating to the resource that contains the text. It should be possible to import any XML document into Knora, store the markup as standoff, and at any time export the document as an equivalent XML document. RDF Design See Text with Standoff Markup . Querying Standoff Since the number of standoff tags that can be attached to a text value is unlimited, standoff is queried in pages of a limited size, to avoid requesting huge SPARQL query results from the triplestore. When ResourcesResponderV2 or SearchResponderV2 need to return a text value with all its markup, they first query the text value with at most one page of standoff. If the text value has more than one page of standoff, ConstructResponseUtilV2.makeTextValueContentV2 then sends a GetRemainingStandoffFromTextValueRequestV2 message to StandoffResponderV2 , which queries the rest of the standoff in the text value, one page at a time. The resulting standoff is concatenated together and returned. To optimise query performance: Each text value with standoff has the predicate knora-base:valueHasMaxStandoffStartIndex , so that when Knora queries a page of standoff, it knows whether it has reached the last page. The last path component of the IRI of a standoff tag is the integer object of its knora-base:standoffTagHasStartIndex predicate. When querying standoff, it is necessary to convert the IRI objects of knora-base:standoffTagHasStartParent and knora-base:standoffTagHasEndParent to integer indexes (the start indexes of those tags). Including each tag's start index in its IRI makes it unnecessary to query the parent tags to determine their start indexes. Conversion Between Standoff and XML XMLToStandoffUtil does the low-level conversion of documents between standoff and XML, using a simple data structure to represent standoff. This data structure knows nothing about RDF, and each standoff tag contains its XML element name and namespace and those of its attributes. In Knora, it is possible to define mappings to control how standoff/RDF is converted to XML and vice versa. Different mappings can be used to convert the same standoff/RDF to different sorts of XML documents. StandoffTagUtilV2 converts between standoff/RDF and XML using mappings, delegating the lower-level work to XMLToStandoffUtil .","title":"Standoff Markup"},{"location":"05-internals/design/api-v2/standoff/#standoff-markup","text":"","title":"Standoff Markup"},{"location":"05-internals/design/api-v2/standoff/#requirements","text":"In Knora, text with markup is stored using standoff markup , i.e. markup that is stored separately from the content it applies to. Knora's standoff design is based on these requirements: Overlapping markup should be supported. Markup should be stored as RDF, so it can be searched and analysed using the same tools that are used with other data managed by Knora. In particular, Gravsearch queries should be able to specify search criteria that refer to the markup tags attached to a text, together with any other search criteria relating to the resource that contains the text. It should be possible to import any XML document into Knora, store the markup as standoff, and at any time export the document as an equivalent XML document.","title":"Requirements"},{"location":"05-internals/design/api-v2/standoff/#rdf-design","text":"See Text with Standoff Markup .","title":"RDF Design"},{"location":"05-internals/design/api-v2/standoff/#querying-standoff","text":"Since the number of standoff tags that can be attached to a text value is unlimited, standoff is queried in pages of a limited size, to avoid requesting huge SPARQL query results from the triplestore. When ResourcesResponderV2 or SearchResponderV2 need to return a text value with all its markup, they first query the text value with at most one page of standoff. If the text value has more than one page of standoff, ConstructResponseUtilV2.makeTextValueContentV2 then sends a GetRemainingStandoffFromTextValueRequestV2 message to StandoffResponderV2 , which queries the rest of the standoff in the text value, one page at a time. The resulting standoff is concatenated together and returned. To optimise query performance: Each text value with standoff has the predicate knora-base:valueHasMaxStandoffStartIndex , so that when Knora queries a page of standoff, it knows whether it has reached the last page. The last path component of the IRI of a standoff tag is the integer object of its knora-base:standoffTagHasStartIndex predicate. When querying standoff, it is necessary to convert the IRI objects of knora-base:standoffTagHasStartParent and knora-base:standoffTagHasEndParent to integer indexes (the start indexes of those tags). Including each tag's start index in its IRI makes it unnecessary to query the parent tags to determine their start indexes.","title":"Querying Standoff"},{"location":"05-internals/design/api-v2/standoff/#conversion-between-standoff-and-xml","text":"XMLToStandoffUtil does the low-level conversion of documents between standoff and XML, using a simple data structure to represent standoff. This data structure knows nothing about RDF, and each standoff tag contains its XML element name and namespace and those of its attributes. In Knora, it is possible to define mappings to control how standoff/RDF is converted to XML and vice versa. Different mappings can be used to convert the same standoff/RDF to different sorts of XML documents. StandoffTagUtilV2 converts between standoff/RDF and XML using mappings, delegating the lower-level work to XMLToStandoffUtil .","title":"Conversion Between Standoff and XML"},{"location":"05-internals/design/principles/authentication/","text":"Authentication in Knora Scope Authentication is the process of making sure that if someone is accessing something then this someone is actually also the someone he pretends to be. The process of making sure that someone is authorized, i.e. has the permission to access something, is handled as described in Authorisation ). Implementation The authentication in Knora is based on Basic Auth HTTP basic authentication , URL parameters, JSON Web Token , and cookies. This means that on every request (to any of the routes), credentials need to be sent either via authorization header, URL parameters or cookie header. All routes are always accessible and if there are no credentials provided, a default user is assumed. If credentials are sent and they are not correct (e.g., wrong username, password incorrect, token expired), then the request will end in an error message. There are some differences in V1 and V2 of the API regarding authentication. They differ mainly in the format of the response and that creation of session cookies are only supported in V1 and tokens in V2 . After login via either version, all routes ( V1 and V2 ) are accessible. Skipping Authentication There is the possibility to turn skipping authentication on and use a hardcoded user (Test User). In application.conf set the skip-authentication = true and Test User will be always assumed.","title":"Authentication"},{"location":"05-internals/design/principles/authentication/#authentication-in-knora","text":"","title":"Authentication in Knora"},{"location":"05-internals/design/principles/authentication/#scope","text":"Authentication is the process of making sure that if someone is accessing something then this someone is actually also the someone he pretends to be. The process of making sure that someone is authorized, i.e. has the permission to access something, is handled as described in Authorisation ).","title":"Scope"},{"location":"05-internals/design/principles/authentication/#implementation","text":"The authentication in Knora is based on Basic Auth HTTP basic authentication , URL parameters, JSON Web Token , and cookies. This means that on every request (to any of the routes), credentials need to be sent either via authorization header, URL parameters or cookie header. All routes are always accessible and if there are no credentials provided, a default user is assumed. If credentials are sent and they are not correct (e.g., wrong username, password incorrect, token expired), then the request will end in an error message. There are some differences in V1 and V2 of the API regarding authentication. They differ mainly in the format of the response and that creation of session cookies are only supported in V1 and tokens in V2 . After login via either version, all routes ( V1 and V2 ) are accessible.","title":"Implementation"},{"location":"05-internals/design/principles/authentication/#skipping-authentication","text":"There is the possibility to turn skipping authentication on and use a hardcoded user (Test User). In application.conf set the skip-authentication = true and Test User will be always assumed.","title":"Skipping Authentication"},{"location":"05-internals/design/principles/consistency-checking/","text":"Consistency Checking Attention! GraphDB is not supported anymore, therefore parts related to it in this document are redundant. Requirements Knora is designed to prevent inconsistencies in RDF data, as far as is practical, in a triplestore-independent way (see Triplestore Updates ). However, it is also useful to enforce consistency constraints in the triplestore itself, for two reasons: To prevent inconsistencies resulting from bugs in the DSP-API server. To prevent users from inserting inconsistent data directly into the triplestore, bypassing Knora. The design of the knora-base ontology supports two ways of specifying constraints on data (see knora-base: Consistency Checking for details): A property definition should specify the types that are allowed as subjects and objects of the property, using knora-base:subjectClassConstraint and (if it is an object property) knora-base:objectClassConstraint . Every subproperty of knora-base:hasValue or a knora-base:hasLinkTo (i.e. every property of a resource that points to a knora-base:Value or to another resource) is required have this constraint, because the DSP-API server relies on it to know what type of object to expect for the property. Use of knora-base:subjectClassConstraint is recommended but not required. A class definition should use OWL cardinalities (see OWL 2 Quick Reference Guide ) to indicate the properties that instances of the class are allowed to have, and to constrain the number of objects that each property can have. Subclasses of knora-base:Resource are required to have a cardinality for each subproperty of knora-base:hasValue or a knora-base:hasLinkTo that resources of that class can have. Specifically, consistency checking should prevent the following: An object property or datatype property has a subject of the wrong class, or an object property has an object of the wrong class (GraphDB's consistency checke cannot check the types of literals). An object property has an object that does not exist (i.e. the object is an IRI that is not used as the subject of any statements in the repository). This can be treated as if the object is of the wrong type (i.e. it can cause a violation of knora-base:objectClassConstraint , because there is no compatible rdf:type statement for the object). A class has owl:cardinality 1 or owl:minCardinality 1 on an object property or datatype property, and an instance of the class does not have that property. A class has owl:cardinality 1 or owl:maxCardinality 1 on an object property or datatype property, and an instance of the class has more than one object for that property. An instance of knora-base:Resource has an object property pointing to a knora-base:Value or to another Resource , and its class has no cardinality for that property. An instance of knora-base:Value has a subproperty of knora-base:valueHas , and its class has no cardinality for that property. A datatype property has an empty string as an object. Cardinalities in base classes are inherited by derived classes. Derived classes can override inherited cardinalities by making them more restrictive, i.e. by specifying a subproperty of the one specified in the original cardinality. Instances of Resource and Value can be marked as deleted, using the property isDeleted . This must be taken into account as follows: With owl:cardinality 1 or owl:maxCardinality 1 , if the object of the property can be marked as deleted, the property must not have more than one object that has not been marked as deleted. In other words, it's OK if there is more than one object, as long only one of them has knora-base:isDeleted false . With owl:cardinality 1 or owl:minCardinality 1 , the property must have an object, but it's OK if the property's only object is marked as deleted. We allow this because the subject and object may have different owners, and it may not be feasible for them to coordinate their work. The owner of the object should always be able to mark it as deleted. (It could be useful to notify the owner of the subject when this happens, but that is beyond the scope of consistency checking.) Design Ontotext GraphDB provides a mechanism for checking the consistency of data in a repository each time an update transaction is committed. Knora provides GraphDB-specific consistency rules that take advantage of this feature to provide an extra layer of consistency checks, in addition to the checks that are implemented in Knora. When a repository is created in GraphDB, a set of consistency rules can be provided, and GraphDB's consistency checker can be turned on to ensure that each update transaction respects these rules, as described in the section Reasoning of the GraphDB documentation. Like custom inference rules, consistency rules are defined in files with the .pie filename extension, in a GraphDB-specific syntax. We have added rules to the standard RDFS inference rules file builtin_RdfsRules.pie , to create the file KnoraRules.pie . The .ttl configuration file that is used to create the repository must contain these settings: owlim:ruleset \"/path/to/KnoraRules.pie\" ; owlim:check-for-inconsistencies \"true\" ; The path to KnoraRules.pie must be an absolute path. The scripts provided with Knora to create test repositories set this path automatically. Consistency checking in GraphDB relies on reasoning. GraphDB's reasoning is Forward-chaining , which means that reasoning is applied to the contents of each update, before the update transaction is committed, and the inferred statements are added to the repository. A GraphDB rules file can contain two types of rules: inference rules and consistency rules. Before committing an update transaction, GraphDB applies inference rules, then consistency rules. If any of the consistency rules are violated, the transaction is rolled back. An inference rule has this form: Id: <rule_name> <premises> <optional_constraints> ------------------------------- <consequences> <optional_constraints> The premises are a pattern that tries to match statements found in the data. Optional constraints, which are enclosed in square brackets, make it possible to specify the premises more precisely, or to specify a named graph (see examples below). Consequences are the statements that will be inferred if the premises match. A line of hyphens separates premises from consequences. A GraphDB consistency rule has a similar form: Consistency: <rule_name> <premises> <optional_constraints> ------------------------------- <consequences> <optional_constraints> The differences between inference rules and consistency rules are: A consistency rule begins with Consistency instead of Id . In a consistency rule, the consequences are optional. Instead of representing statements to be inferred, they represent statements that must exist if the premises are satisfied. In other words, if the premises are satisfied and the consequences are not found, the rule is violated. If a consistency rule doesn't specify any consequences, and the premises are satisfied, the rule is violated. Rules use variable names for subjects, predicates, and objects, and they can use actual property names. Empty string as object If subject i has a predicate p whose object is an empty string, the constraint is violated: Consistency: empty_string i p \"\" ------------------------------------ Subject and object class constraints If subject i has a predicate p that requires a subject of type t , and i is not a t , the constraint is violated: Consistency: subject_class_constraint p <knora-base:subjectClassConstraint> t i p j ------------------------------------ i <rdf:type> t If subject i has a predicate p that requires an object of type t , and the object of p is not a t , the constraint is violated: Consistency: object_class_constraint p <knora-base:objectClassConstraint> t i p j ------------------------------------ j <rdf:type> t Cardinality constraints A simple implementation of a consistency rule to check owl:maxCardinality 1 , for objects that can be marked as deleted, could look like this: Consistency: max_cardinality_1_with_deletion_flag i <rdf:type> r r <owl:maxCardinality> \"1\"^^xsd:nonNegativeInteger r <owl:onProperty> p i p j i p k [Constraint j != k] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ This means: if resource i is a subclass of an owl:Restriction r with owl:maxCardinality 1 on property p , and the resource has two different objects for that property, neither of which is marked as deleted, the rule is violated. Note that this takes advantage of the fact that Resource and Value have owl:cardinality 1 on isDeleted ( isDeleted must be present even if false), so we do not need to check whether i is actually something that can be marked as deleted. However, this implementation would be much too slow. We therefore use two optimisations suggested by Ontotext: Add custom inference rules to make tables (i.e. named graphs) of pre-calculated information about the cardinalities on properties of subjects, and use those tables to simplify the consistency rules. Use the [Cut] constraint to avoid generating certain redundant compiled rules (see Entailment rules ). For example, to construct a table of subjects belonging to classes that have owl:maxCardinality 1 on some property p , we use the following custom inference rule: Id: maxCardinality_1_table i <rdf:type> r r <owl:maxCardinality> \"1\"^^xsd:nonNegativeInteger r <owl:onProperty> p ------------------------------------ i p r [Context <onto:_maxCardinality_1_table>] The constraint [Context <onto:_maxCardinality_1_table>] means that the inferred triples are added to the context (i.e. the named graph) http://www.ontotext.com/_maxCardinality_1_table . (Note that we have defined the prefix onto as http://www.ontotext.com/ in the Prefices section of the rules file.) As the GraphDB documentation on Rules explains: If the context is provided, the statements produced as rule consequences are not \u2018visible\u2019 during normal query answering. Instead, they can only be used as input to this or other rules and only when the rule premise explicitly uses the given context. Now, to find out whether a subject belongs to a class with that cardinality on a given property, we only need to match one triple. The revised implementation of the rule max_cardinality_1_with_deletion_flag is as follows: Consistency: max_cardinality_1_with_deletion_flag i p r [Context <onto:_maxCardinality_1_table>] i p j [Constraint j != k] i p k [Cut] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ The constraint [Constraint j != k] means that the premises will be satisfied only if the variables j and k do not refer to the same thing. With these optimisations, the rule is faster by several orders of magnitude. Since properties whose objects can be marked as deleted must be handled differently to properties whose objects cannot be marked as deleted, the knora-base ontology provides a property called objectCannotBeMarkedAsDeleted . All properties in knora-base whose objects cannot take the isDeleted flag (including datatype properties) should be derived from this property. This is how it is used to check owl:maxCardinality 1 for objects that cannot be marked as deleted: Consistency: max_cardinality_1_without_deletion_flag i p r [Context <onto:_maxCardinality_1_table>] p <rdfs:subPropertyOf> <knora-base:objectCannotBeMarkedAsDeleted> i p j [Constraint j != k] i p k [Cut] ------------------------------------ To check owl:minCardinality 1 , we do not care whether the object can be marked as deleted, so we can use this simple rule: Consistency: min_cardinality_1_any_object i p r [Context <onto:_minCardinality_1_table>] ------------------------------------ i p j This means: if a subject i belongs to a class that has owl:minCardinality 1 on property p , and i has no object for p , the rule is violated. To check owl:cardinality 1 , we need two rules: one that checks whether there are too few objects, and one that checks whether there are too many. To check whether there are too few objects, we don't care whether the objects can be marked as deleted, so the rule is the same as min_cardinality_1_any_object , except for the cardinality: Consistency: cardinality_1_not_less_any_object i p r [Context <onto:_cardinality_1_table>] ------------------------------------ i p j To check whether there are too many objects, we need to know whether the objects can be marked as deleted or not. In the case where the objects can be marked as deleted, the rule is the same as max_cardinality_1_with_deletion_flag , except for the cardinality: Consistency: cardinality_1_not_greater_with_deletion_flag i p r [Context <onto:_cardinality_1_table>] i p j [Constraint j != k] i p k [Cut] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ In the case where the objects cannot be marked as deleted, the rule is the same as max_cardinality_1_without_deletion_flag , except for the cardinality: Consistency: cardinality_1_not_less_any_object i p r [Context <onto:_cardinality_1_table>] ------------------------------------ i p j Knora allows a subproperty of knora-base:hasValue or knora-base:hasLinkTo to be a predicate of a resource only if the resource's class has some cardinality for the property. For convenience, knora-base:hasValue and knora-base:hasLinkTo are subproperties of knora-base:resourceProperty , which is used to check this constraint in the following rule: Consistency: resource_prop_cardinality_any i <knora-base:resourceProperty> j ------------------------------------ i p j i <rdf:type> r r <owl:onProperty> p If resource i has a subproperty of knora-base:resourceProperty , and i is not a member of a subclass of an owl:Restriction r with a cardinality on that property (or on one of its base properties), the rule is violated. A similar rule, value_prop_cardinality_any , ensures that if a value has a subproperty of knora-base:valueHas , the value's class has some cardinality for that property.","title":"Consistency Checking"},{"location":"05-internals/design/principles/consistency-checking/#consistency-checking","text":"Attention! GraphDB is not supported anymore, therefore parts related to it in this document are redundant.","title":"Consistency Checking"},{"location":"05-internals/design/principles/consistency-checking/#requirements","text":"Knora is designed to prevent inconsistencies in RDF data, as far as is practical, in a triplestore-independent way (see Triplestore Updates ). However, it is also useful to enforce consistency constraints in the triplestore itself, for two reasons: To prevent inconsistencies resulting from bugs in the DSP-API server. To prevent users from inserting inconsistent data directly into the triplestore, bypassing Knora. The design of the knora-base ontology supports two ways of specifying constraints on data (see knora-base: Consistency Checking for details): A property definition should specify the types that are allowed as subjects and objects of the property, using knora-base:subjectClassConstraint and (if it is an object property) knora-base:objectClassConstraint . Every subproperty of knora-base:hasValue or a knora-base:hasLinkTo (i.e. every property of a resource that points to a knora-base:Value or to another resource) is required have this constraint, because the DSP-API server relies on it to know what type of object to expect for the property. Use of knora-base:subjectClassConstraint is recommended but not required. A class definition should use OWL cardinalities (see OWL 2 Quick Reference Guide ) to indicate the properties that instances of the class are allowed to have, and to constrain the number of objects that each property can have. Subclasses of knora-base:Resource are required to have a cardinality for each subproperty of knora-base:hasValue or a knora-base:hasLinkTo that resources of that class can have. Specifically, consistency checking should prevent the following: An object property or datatype property has a subject of the wrong class, or an object property has an object of the wrong class (GraphDB's consistency checke cannot check the types of literals). An object property has an object that does not exist (i.e. the object is an IRI that is not used as the subject of any statements in the repository). This can be treated as if the object is of the wrong type (i.e. it can cause a violation of knora-base:objectClassConstraint , because there is no compatible rdf:type statement for the object). A class has owl:cardinality 1 or owl:minCardinality 1 on an object property or datatype property, and an instance of the class does not have that property. A class has owl:cardinality 1 or owl:maxCardinality 1 on an object property or datatype property, and an instance of the class has more than one object for that property. An instance of knora-base:Resource has an object property pointing to a knora-base:Value or to another Resource , and its class has no cardinality for that property. An instance of knora-base:Value has a subproperty of knora-base:valueHas , and its class has no cardinality for that property. A datatype property has an empty string as an object. Cardinalities in base classes are inherited by derived classes. Derived classes can override inherited cardinalities by making them more restrictive, i.e. by specifying a subproperty of the one specified in the original cardinality. Instances of Resource and Value can be marked as deleted, using the property isDeleted . This must be taken into account as follows: With owl:cardinality 1 or owl:maxCardinality 1 , if the object of the property can be marked as deleted, the property must not have more than one object that has not been marked as deleted. In other words, it's OK if there is more than one object, as long only one of them has knora-base:isDeleted false . With owl:cardinality 1 or owl:minCardinality 1 , the property must have an object, but it's OK if the property's only object is marked as deleted. We allow this because the subject and object may have different owners, and it may not be feasible for them to coordinate their work. The owner of the object should always be able to mark it as deleted. (It could be useful to notify the owner of the subject when this happens, but that is beyond the scope of consistency checking.)","title":"Requirements"},{"location":"05-internals/design/principles/consistency-checking/#design","text":"Ontotext GraphDB provides a mechanism for checking the consistency of data in a repository each time an update transaction is committed. Knora provides GraphDB-specific consistency rules that take advantage of this feature to provide an extra layer of consistency checks, in addition to the checks that are implemented in Knora. When a repository is created in GraphDB, a set of consistency rules can be provided, and GraphDB's consistency checker can be turned on to ensure that each update transaction respects these rules, as described in the section Reasoning of the GraphDB documentation. Like custom inference rules, consistency rules are defined in files with the .pie filename extension, in a GraphDB-specific syntax. We have added rules to the standard RDFS inference rules file builtin_RdfsRules.pie , to create the file KnoraRules.pie . The .ttl configuration file that is used to create the repository must contain these settings: owlim:ruleset \"/path/to/KnoraRules.pie\" ; owlim:check-for-inconsistencies \"true\" ; The path to KnoraRules.pie must be an absolute path. The scripts provided with Knora to create test repositories set this path automatically. Consistency checking in GraphDB relies on reasoning. GraphDB's reasoning is Forward-chaining , which means that reasoning is applied to the contents of each update, before the update transaction is committed, and the inferred statements are added to the repository. A GraphDB rules file can contain two types of rules: inference rules and consistency rules. Before committing an update transaction, GraphDB applies inference rules, then consistency rules. If any of the consistency rules are violated, the transaction is rolled back. An inference rule has this form: Id: <rule_name> <premises> <optional_constraints> ------------------------------- <consequences> <optional_constraints> The premises are a pattern that tries to match statements found in the data. Optional constraints, which are enclosed in square brackets, make it possible to specify the premises more precisely, or to specify a named graph (see examples below). Consequences are the statements that will be inferred if the premises match. A line of hyphens separates premises from consequences. A GraphDB consistency rule has a similar form: Consistency: <rule_name> <premises> <optional_constraints> ------------------------------- <consequences> <optional_constraints> The differences between inference rules and consistency rules are: A consistency rule begins with Consistency instead of Id . In a consistency rule, the consequences are optional. Instead of representing statements to be inferred, they represent statements that must exist if the premises are satisfied. In other words, if the premises are satisfied and the consequences are not found, the rule is violated. If a consistency rule doesn't specify any consequences, and the premises are satisfied, the rule is violated. Rules use variable names for subjects, predicates, and objects, and they can use actual property names.","title":"Design"},{"location":"05-internals/design/principles/consistency-checking/#empty-string-as-object","text":"If subject i has a predicate p whose object is an empty string, the constraint is violated: Consistency: empty_string i p \"\" ------------------------------------","title":"Empty string as object"},{"location":"05-internals/design/principles/consistency-checking/#subject-and-object-class-constraints","text":"If subject i has a predicate p that requires a subject of type t , and i is not a t , the constraint is violated: Consistency: subject_class_constraint p <knora-base:subjectClassConstraint> t i p j ------------------------------------ i <rdf:type> t If subject i has a predicate p that requires an object of type t , and the object of p is not a t , the constraint is violated: Consistency: object_class_constraint p <knora-base:objectClassConstraint> t i p j ------------------------------------ j <rdf:type> t","title":"Subject and object class constraints"},{"location":"05-internals/design/principles/consistency-checking/#cardinality-constraints","text":"A simple implementation of a consistency rule to check owl:maxCardinality 1 , for objects that can be marked as deleted, could look like this: Consistency: max_cardinality_1_with_deletion_flag i <rdf:type> r r <owl:maxCardinality> \"1\"^^xsd:nonNegativeInteger r <owl:onProperty> p i p j i p k [Constraint j != k] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ This means: if resource i is a subclass of an owl:Restriction r with owl:maxCardinality 1 on property p , and the resource has two different objects for that property, neither of which is marked as deleted, the rule is violated. Note that this takes advantage of the fact that Resource and Value have owl:cardinality 1 on isDeleted ( isDeleted must be present even if false), so we do not need to check whether i is actually something that can be marked as deleted. However, this implementation would be much too slow. We therefore use two optimisations suggested by Ontotext: Add custom inference rules to make tables (i.e. named graphs) of pre-calculated information about the cardinalities on properties of subjects, and use those tables to simplify the consistency rules. Use the [Cut] constraint to avoid generating certain redundant compiled rules (see Entailment rules ). For example, to construct a table of subjects belonging to classes that have owl:maxCardinality 1 on some property p , we use the following custom inference rule: Id: maxCardinality_1_table i <rdf:type> r r <owl:maxCardinality> \"1\"^^xsd:nonNegativeInteger r <owl:onProperty> p ------------------------------------ i p r [Context <onto:_maxCardinality_1_table>] The constraint [Context <onto:_maxCardinality_1_table>] means that the inferred triples are added to the context (i.e. the named graph) http://www.ontotext.com/_maxCardinality_1_table . (Note that we have defined the prefix onto as http://www.ontotext.com/ in the Prefices section of the rules file.) As the GraphDB documentation on Rules explains: If the context is provided, the statements produced as rule consequences are not \u2018visible\u2019 during normal query answering. Instead, they can only be used as input to this or other rules and only when the rule premise explicitly uses the given context. Now, to find out whether a subject belongs to a class with that cardinality on a given property, we only need to match one triple. The revised implementation of the rule max_cardinality_1_with_deletion_flag is as follows: Consistency: max_cardinality_1_with_deletion_flag i p r [Context <onto:_maxCardinality_1_table>] i p j [Constraint j != k] i p k [Cut] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ The constraint [Constraint j != k] means that the premises will be satisfied only if the variables j and k do not refer to the same thing. With these optimisations, the rule is faster by several orders of magnitude. Since properties whose objects can be marked as deleted must be handled differently to properties whose objects cannot be marked as deleted, the knora-base ontology provides a property called objectCannotBeMarkedAsDeleted . All properties in knora-base whose objects cannot take the isDeleted flag (including datatype properties) should be derived from this property. This is how it is used to check owl:maxCardinality 1 for objects that cannot be marked as deleted: Consistency: max_cardinality_1_without_deletion_flag i p r [Context <onto:_maxCardinality_1_table>] p <rdfs:subPropertyOf> <knora-base:objectCannotBeMarkedAsDeleted> i p j [Constraint j != k] i p k [Cut] ------------------------------------ To check owl:minCardinality 1 , we do not care whether the object can be marked as deleted, so we can use this simple rule: Consistency: min_cardinality_1_any_object i p r [Context <onto:_minCardinality_1_table>] ------------------------------------ i p j This means: if a subject i belongs to a class that has owl:minCardinality 1 on property p , and i has no object for p , the rule is violated. To check owl:cardinality 1 , we need two rules: one that checks whether there are too few objects, and one that checks whether there are too many. To check whether there are too few objects, we don't care whether the objects can be marked as deleted, so the rule is the same as min_cardinality_1_any_object , except for the cardinality: Consistency: cardinality_1_not_less_any_object i p r [Context <onto:_cardinality_1_table>] ------------------------------------ i p j To check whether there are too many objects, we need to know whether the objects can be marked as deleted or not. In the case where the objects can be marked as deleted, the rule is the same as max_cardinality_1_with_deletion_flag , except for the cardinality: Consistency: cardinality_1_not_greater_with_deletion_flag i p r [Context <onto:_cardinality_1_table>] i p j [Constraint j != k] i p k [Cut] j <knora-base:isDeleted> \"false\"^^xsd:boolean k <knora-base:isDeleted> \"false\"^^xsd:boolean ------------------------------------ In the case where the objects cannot be marked as deleted, the rule is the same as max_cardinality_1_without_deletion_flag , except for the cardinality: Consistency: cardinality_1_not_less_any_object i p r [Context <onto:_cardinality_1_table>] ------------------------------------ i p j Knora allows a subproperty of knora-base:hasValue or knora-base:hasLinkTo to be a predicate of a resource only if the resource's class has some cardinality for the property. For convenience, knora-base:hasValue and knora-base:hasLinkTo are subproperties of knora-base:resourceProperty , which is used to check this constraint in the following rule: Consistency: resource_prop_cardinality_any i <knora-base:resourceProperty> j ------------------------------------ i p j i <rdf:type> r r <owl:onProperty> p If resource i has a subproperty of knora-base:resourceProperty , and i is not a member of a subclass of an owl:Restriction r with a cardinality on that property (or on one of its base properties), the rule is violated. A similar rule, value_prop_cardinality_any , ensures that if a value has a subproperty of knora-base:valueHas , the value's class has some cardinality for that property.","title":"Cardinality constraints"},{"location":"05-internals/design/principles/design-overview/","text":"DSP-API Server Design Overview Introduction DSP-API's responsibilites are: Querying, creating, updating, and deleting data Creating, updating and deleting data models (ontologies) Managing projects and users Authentication of clients Authorisation of clients' requests DSP-API is developed with Scala and uses the Akka framework for message-based concurrency. It is designed to work with the Apache Jena Fuseki triplestore which is compliant to the SPARQL 1.1 Protocol . For file storage, it uses Sipi . DSP-API Versions There are two versions of DSP-API: DSP-API v2, the latest DSP-API that should be used DSP-API v1, legacy API compatibile with applications that used the prototype software. There is also an Admin API for administering DSP projects. Internally, DSP-API v1 and v2 both use functionality in the admin API. DSP-API v1 uses some functionality from API v2, but API v2 does not depend on API v1. Error Handling The error-handling design has these aims: Simplify the error-handling code in actors as much as possible. Produce error messages that clearly indicate the context in which the error occurred (i.e. what the application was trying to do). Ensure that clients receive an appropriate error message when an error occurs. Ensure that ask requests are properly terminated with an akka.actor.Status.Failure message in the event of an error, without which they will simply time out (see Ask: Send and Receive Future ). When a actor encounters an error that isn't the client's fault (e.g. a triplestore failure), log it, but don't do this with errors caused by bad input. When logging errors, include the full JVM stack trace. A hierarchy of exception classes is defined in Exceptions.scala , representing different sorts of errors that could occur. The hierarchy has two main branches: RequestRejectedException , an abstract class for errors that are the client's fault. These errors are not logged. InternalServerException , an abstract class for errors that are not the client's fault. These errors are logged. Exception classes in this hierarchy can be defined to include a wrapped cause exception. When an exception is logged, its stack trace will be logged along with the stack trace of its cause . It is therefore recommended that low-level code should catch low-level exceptions, and wrap them in one of our higher-level exceptions, in order to clarify the context in which the error occurred. To simplify error-handling in responders, a utility method called future2Message is provided in ActorUtils . It is intended to be used in an actor's receive method to respond to messages in the ask pattern. If the responder's computation is successful, it is sent to the requesting actor as a response to the ask . If the computation fails, the exception representing the failure is wrapped in a Status.Failure , which is sent as a response to the ask . If the error is a subclass of RequestRejectedException , only the sender is notified of the error; otherwise, the error is also logged and rethrown (so that the KnoraExceptionHandler can handle the exception). In many cases, we transform data from the triplestore into a Map object. To simplify checking for required values in these collections, the class ErrorHandlingMap is provided. You can wrap any Map in an ErrorHandlingMap . You must provide a function that will generate an error message when a required value is missing, and optionally a function that throws a particular exception. Rows of SPARQL query results are already returned in ErrorHandlingMap objects. If you want to add a new exception class, see the comments in Exceptions.scala for instructions. Transformation of Exception to Client Responses The org.knora.webapi.KnoraExceptionHandler is brought implicitly into scope of akka-http , and by doing so registered and used to handle the transformation of all KnoraExceptions into HttpResponses . This handler handles only exceptions thrown inside the route and not the actors. However, the design of reply message passing from actors (by using future2Message ), makes sure that any exceptions thrown inside actors, will reach the route, where they will be handled. See also Fuures with Akka . API Routing The API routes in the routing package are defined using the DSL provided by the akka-http library. A routing function has to do the following: Authenticate the client. Figure out what the client is asking for. Construct an appropriate request message and send it to ResponderManagerV1 , using the ask pattern. Return a result to the client. To simplify the coding of routing functions, they are contained in objects that extend org.knora.webapi.routing.Authenticator . Each routing function performs the following operations: Authenticator.getUserADM is called to authenticate the user. The request parameters are interpreted and validated, and a request message is constructed to send to the responder. If the request is invalid, BadRequestException is thrown. If the request message is requesting an update operation, it must include a UUID generated by UUID.randomUUID , so the responder can obtain a write lock on the resource being updated. The routing function then passes the message to a function in an API-specific routing utility: RouteUtilV1 , RouteUtilV2 , or RouteUtilADM . This utility function sends the message to ResponderManager (which forwards it to the relevant responder), returns a response to the client in the appropriate format, and handles any errors. Logging Logging in DSP-API is configurable through logback.xml , allowing fine grain configuration of what classes / objects should be logged from which level. The Akka Actors use Akka Logging while logging inside plain Scala Objects and Classes is done through Scala Logging .","title":"Design Overview"},{"location":"05-internals/design/principles/design-overview/#dsp-api-server-design-overview","text":"","title":"DSP-API Server Design Overview"},{"location":"05-internals/design/principles/design-overview/#introduction","text":"DSP-API's responsibilites are: Querying, creating, updating, and deleting data Creating, updating and deleting data models (ontologies) Managing projects and users Authentication of clients Authorisation of clients' requests DSP-API is developed with Scala and uses the Akka framework for message-based concurrency. It is designed to work with the Apache Jena Fuseki triplestore which is compliant to the SPARQL 1.1 Protocol . For file storage, it uses Sipi .","title":"Introduction"},{"location":"05-internals/design/principles/design-overview/#dsp-api-versions","text":"There are two versions of DSP-API: DSP-API v2, the latest DSP-API that should be used DSP-API v1, legacy API compatibile with applications that used the prototype software. There is also an Admin API for administering DSP projects. Internally, DSP-API v1 and v2 both use functionality in the admin API. DSP-API v1 uses some functionality from API v2, but API v2 does not depend on API v1.","title":"DSP-API Versions"},{"location":"05-internals/design/principles/design-overview/#error-handling","text":"The error-handling design has these aims: Simplify the error-handling code in actors as much as possible. Produce error messages that clearly indicate the context in which the error occurred (i.e. what the application was trying to do). Ensure that clients receive an appropriate error message when an error occurs. Ensure that ask requests are properly terminated with an akka.actor.Status.Failure message in the event of an error, without which they will simply time out (see Ask: Send and Receive Future ). When a actor encounters an error that isn't the client's fault (e.g. a triplestore failure), log it, but don't do this with errors caused by bad input. When logging errors, include the full JVM stack trace. A hierarchy of exception classes is defined in Exceptions.scala , representing different sorts of errors that could occur. The hierarchy has two main branches: RequestRejectedException , an abstract class for errors that are the client's fault. These errors are not logged. InternalServerException , an abstract class for errors that are not the client's fault. These errors are logged. Exception classes in this hierarchy can be defined to include a wrapped cause exception. When an exception is logged, its stack trace will be logged along with the stack trace of its cause . It is therefore recommended that low-level code should catch low-level exceptions, and wrap them in one of our higher-level exceptions, in order to clarify the context in which the error occurred. To simplify error-handling in responders, a utility method called future2Message is provided in ActorUtils . It is intended to be used in an actor's receive method to respond to messages in the ask pattern. If the responder's computation is successful, it is sent to the requesting actor as a response to the ask . If the computation fails, the exception representing the failure is wrapped in a Status.Failure , which is sent as a response to the ask . If the error is a subclass of RequestRejectedException , only the sender is notified of the error; otherwise, the error is also logged and rethrown (so that the KnoraExceptionHandler can handle the exception). In many cases, we transform data from the triplestore into a Map object. To simplify checking for required values in these collections, the class ErrorHandlingMap is provided. You can wrap any Map in an ErrorHandlingMap . You must provide a function that will generate an error message when a required value is missing, and optionally a function that throws a particular exception. Rows of SPARQL query results are already returned in ErrorHandlingMap objects. If you want to add a new exception class, see the comments in Exceptions.scala for instructions.","title":"Error Handling"},{"location":"05-internals/design/principles/design-overview/#transformation-of-exception-to-client-responses","text":"The org.knora.webapi.KnoraExceptionHandler is brought implicitly into scope of akka-http , and by doing so registered and used to handle the transformation of all KnoraExceptions into HttpResponses . This handler handles only exceptions thrown inside the route and not the actors. However, the design of reply message passing from actors (by using future2Message ), makes sure that any exceptions thrown inside actors, will reach the route, where they will be handled. See also Fuures with Akka .","title":"Transformation of Exception to Client Responses"},{"location":"05-internals/design/principles/design-overview/#api-routing","text":"The API routes in the routing package are defined using the DSL provided by the akka-http library. A routing function has to do the following: Authenticate the client. Figure out what the client is asking for. Construct an appropriate request message and send it to ResponderManagerV1 , using the ask pattern. Return a result to the client. To simplify the coding of routing functions, they are contained in objects that extend org.knora.webapi.routing.Authenticator . Each routing function performs the following operations: Authenticator.getUserADM is called to authenticate the user. The request parameters are interpreted and validated, and a request message is constructed to send to the responder. If the request is invalid, BadRequestException is thrown. If the request message is requesting an update operation, it must include a UUID generated by UUID.randomUUID , so the responder can obtain a write lock on the resource being updated. The routing function then passes the message to a function in an API-specific routing utility: RouteUtilV1 , RouteUtilV2 , or RouteUtilADM . This utility function sends the message to ResponderManager (which forwards it to the relevant responder), returns a response to the client in the appropriate format, and handles any errors.","title":"API Routing"},{"location":"05-internals/design/principles/design-overview/#logging","text":"Logging in DSP-API is configurable through logback.xml , allowing fine grain configuration of what classes / objects should be logged from which level. The Akka Actors use Akka Logging while logging inside plain Scala Objects and Classes is done through Scala Logging .","title":"Logging"},{"location":"05-internals/design/principles/futures-with-akka/","text":"Futures with Akka Introduction Scala's documentation on futures introduces them in this way: Futures provide a nice way to reason about performing many operations in parallel \u2013 in an efficient and non-blocking way. The idea is simple, a Future is a sort of a placeholder object that you can create for a result that does not yet exist. Generally, the result of the Future is computed concurrently and can be later collected. Composing concurrent tasks in this way tends to result in faster, asynchronous, non-blocking parallel code. The rest of that page is well worth reading to get an overview of how futures work and what you can do with them. In Akka , one of the standard patterns for communication between actors is the ask pattern , in which you send a message to an actor and you expect a reply. When you call the ask function (which can be written as a question mark, ? , which acts as an infix operator), it immediately returns a Future , which will complete when the reply is sent. As the Akka documentation explains in Use with Actors , it is possible to block the calling thread until the future completes, using Await.result . However, they say: 'Blocking is discouraged though as it will cause performance problems.' In particular, by not blocking, you can do several ask requests in parallel. One way to avoid blocking is to register a callback on the future, which will be called when it completes (perhaps by another thread), like this: future.onComplete { case Success(result) => println(result) case Failure(ex) => ex.printStackTrace() } But this won't work if you're writing a method that needs return a value based on the result of a future. In this case, you can register a callback that transforms the result of a future into another future: val newFuture = future.map(x => x + 1) However, registering callbacks explicitly gets cumbersome when you need to work with several futures together. In this case, the most convenient alternative to blocking is to use Future as a monad. The links above explain what this means in detail, but the basic idea is that a special syntax, called a for -comprehension, allows you to write code that uses futures as if they were complete, without blocking. In reality, a for -comprehension is syntactic sugar for calling methods like map , but it's much easier to write and to read. You can do things like this: val fooFuture = (fooActor ? GetFoo(\"foo\")).mapTo[Foo] val barFuture = (barActor ? GetBar(\"bar\")).mapTo[Bar] val totalFuture = for { foo: Foo <- fooFuture bar: Bar <- barFuture total = foo.getCount + bar.getCount } yield total Here the messages to fooActor and barActor are sent and processed in parallel, but you're guaranteed that total won't be calculated until the values it needs are available. Note that if you construct fooFuture and barFuture inside the for comprehension, they won't be run in parallel (see Scala for-comprehension with concurrently running futures ). Handling Errors with Futures The constructors and methods of Future (like those of Try ) catch exceptions, which cause the future to fail. This very useful property of futures means that you usually don't need try - catch blocks when using the Future monad (although it is sometimes helpful to include them, in order to catch low-level exceptions and wrap them in higher-level ones). Any exception thrown in code that's being run asynchronously by Future (including in the yield expression of a for comprehension) will be caught, and the result will be a Future containing a Failure . Also, in the previous example, if fooActor or barActor returns a Status.Failure message, the for -comprehension will also yield a failed future. However, you need to be careful with the first line of the for -comprehension. For example, this code doesn't handle exceptions correctly: private def doFooQuery(iri: IRI): Future[String] = { for { queryResponse <- (storeManager ? SparqlSelectRequest(queries.sparql.v1.txt.getFoo(iri).toString())).mapTo[SparqlSelectResponse] ... } yield ... } The getFoo() method calls a Twirl template function to generate SPARQL. The ? operator returns a Future . However, the template function is not run asynchronously , because it is called before the Future constructor is called. So if the template function throws an exception, it won't be caught here. Instead, you can do this: private def doFooQuery(iri: IRI): Future[String] = { for { queryString <- Future(queries.sparql.v1.txt.getFoo(iri).toString()) queryResponse <- (storeManager ? SparqlSelectRequest(queryString)).mapTo[SparqlSelectResponse] ... } yield ... } Here the Future constructor will call the template function asynchronously, and catch any exceptions it throws. This is only necessary if you need to call the template function at the very beginning of a for -comprehension. In the rest of the for comprehension, you'll already implicitly have a Future object. Using recover on Futures By using recover on a Future , an apt error message can be thrown if the Future fails. This is particularly useful when an an error message should be made more clear depending on the context the Future is used in. For example, we are asking the resources responder to query for a certain resource in order to process it in a special way. However, the client does not know that the resources responder is sent a request and in case the resource cannot be found, the message sent back from the resources responder ( NotFoundException ) would not make sense to it. Instead, we would like to handle the message in a way so that it makes sense for the operation the client actually executed. We can do this by calling recover on a Future . private def mySpecialResourceRequest(iri: IRI, userProfile: UserProfileV1): Future[...] = { val resourceRequestFuture = for { resResponse: ResourceFullResponseV1 <- (responderManager ? ResourceFullGetRequestV1(iri = iri, userProfile = userProfile, getIncoming = false)).mapTo[ResourceFullResponseV1] } yield resResponse val resourceRequestFutureRecovered = resourceRequestFuture.recover { case notFound: NotFoundException => throw BadRequestException(s\"Special resource handling failed because the resource could not be found: ${notFound.message}\") } for { res <- resourceRequestFutureRecovered ... } yield ... } Please note that the content of the Future has to be accessed using <- to make this work correctly. Otherwise the content will never be looked at. Designing with Futures In the current design, Knora almost never blocks to wait for a future to complete. The normal flow of control works like this: Incoming HTTP requests are handled by an actor called KnoraService , which delegates them to routing functions (in the routing package). For each request, a routing function gets an Akka HTTP RequestContext , and calls RouteUtilV1.runJsonRoute (in API v1) or RouteUtilV2.runRdfRouteWithFuture (in API v2) to send a message to a supervisor actor to fulfil the request. This creates a Future that will complete when the relevant responder sends its reply. The routing utility registers a callback on this Future to handle the reply message when it becomes available. The supervisor forwards the message to be handled by the appropriate responder. The responder's receive method receives the message, and calls some private method that produces a reply message inside a Future . This may involve sending messages to other actors using ask , getting futures back, and combining them into a single future containing the reply message. The responder passes that future to ActorUtils.future2Message , which registers a callback on it. When the future completes (perhaps in another thread), the callback sends the reply message. In the meantime, the responder doesn't block, so it can start handling the next request. When the responder's reply becomes available, the routing utility's callback registered in (2) calls complete on the RequestContext , which sends an HTTP response to the client. The basic rule of thumb is this: if you're writing a method in an actor, and anything in the method needs to come from a future (e.g. because you need to use ask to get some information from another actor), have the method return a future. Mixing Futures with non-Futures If you have a match ... case or if expression, and one branch obtains some data in a future, but another branch can produce the data immediately, you can wrap the result of the latter branch in a future, so that both branches have the same type. Here we use an alternative implementation of scala.concurrent.Future , found in akka.http.scaladsl.util.FastFuture , which tries to avoid scheduling to an scala.concurrent.ExecutionContext if possible, i.e. if the given future value is already present: def getTotalOfFooAndBar(howToGetFoo: String): Future[Int] = { for { foo <- howToGetFoo match { case \"askForIt\" => (fooActor ? GetFoo(\"foo\")).mapTo[Foo] case \"createIt\" => FastFuture.successful(new Foo()) } bar <- (barActor ? GetBar(\"bar\")).mapTo[Bar] total = foo.getCount + bar.getCount } yield total } How to Write For-Comprehensions Here are some basic rules for writing for -comprehensions: The first line of a for -comprehension has to be a \"generator\", i.e. it has to use the <- operator. If you want to write an assignment (using = ) as the first line, the workaround is to wrap the right-hand side in a monad (like Future ) and use <- instead. Assignments (using = ) are written without val . You're not allowed to write statements that throw away their return values, so if you want to call something like println that returns Unit , you have to assign its return value to _ . The yield returns an object of the same type as the generators, which all have to produce the same type (e.g. Future ). Execution Contexts Whenever you use a future, there has to be an implicit 'execution context' in scope. Scala's documentation on futures says, 'you can think of execution contexts as thread pools'. If you don't have an execution context in scope, you'll get a compile error asking you to include one, and suggesting that you could use import scala.concurrent.ExecutionContext.Implicits.global . Don't do this, because the global Scala execution context is not the most efficient option. Instead, use Knora's custom execution context like so: implicit val executionContext: ExecutionContext = system.dispatchers.lookup(KnoraDispatchers.KnoraActorDispatcher)","title":"Futures with Akka"},{"location":"05-internals/design/principles/futures-with-akka/#futures-with-akka","text":"","title":"Futures with Akka"},{"location":"05-internals/design/principles/futures-with-akka/#introduction","text":"Scala's documentation on futures introduces them in this way: Futures provide a nice way to reason about performing many operations in parallel \u2013 in an efficient and non-blocking way. The idea is simple, a Future is a sort of a placeholder object that you can create for a result that does not yet exist. Generally, the result of the Future is computed concurrently and can be later collected. Composing concurrent tasks in this way tends to result in faster, asynchronous, non-blocking parallel code. The rest of that page is well worth reading to get an overview of how futures work and what you can do with them. In Akka , one of the standard patterns for communication between actors is the ask pattern , in which you send a message to an actor and you expect a reply. When you call the ask function (which can be written as a question mark, ? , which acts as an infix operator), it immediately returns a Future , which will complete when the reply is sent. As the Akka documentation explains in Use with Actors , it is possible to block the calling thread until the future completes, using Await.result . However, they say: 'Blocking is discouraged though as it will cause performance problems.' In particular, by not blocking, you can do several ask requests in parallel. One way to avoid blocking is to register a callback on the future, which will be called when it completes (perhaps by another thread), like this: future.onComplete { case Success(result) => println(result) case Failure(ex) => ex.printStackTrace() } But this won't work if you're writing a method that needs return a value based on the result of a future. In this case, you can register a callback that transforms the result of a future into another future: val newFuture = future.map(x => x + 1) However, registering callbacks explicitly gets cumbersome when you need to work with several futures together. In this case, the most convenient alternative to blocking is to use Future as a monad. The links above explain what this means in detail, but the basic idea is that a special syntax, called a for -comprehension, allows you to write code that uses futures as if they were complete, without blocking. In reality, a for -comprehension is syntactic sugar for calling methods like map , but it's much easier to write and to read. You can do things like this: val fooFuture = (fooActor ? GetFoo(\"foo\")).mapTo[Foo] val barFuture = (barActor ? GetBar(\"bar\")).mapTo[Bar] val totalFuture = for { foo: Foo <- fooFuture bar: Bar <- barFuture total = foo.getCount + bar.getCount } yield total Here the messages to fooActor and barActor are sent and processed in parallel, but you're guaranteed that total won't be calculated until the values it needs are available. Note that if you construct fooFuture and barFuture inside the for comprehension, they won't be run in parallel (see Scala for-comprehension with concurrently running futures ).","title":"Introduction"},{"location":"05-internals/design/principles/futures-with-akka/#handling-errors-with-futures","text":"The constructors and methods of Future (like those of Try ) catch exceptions, which cause the future to fail. This very useful property of futures means that you usually don't need try - catch blocks when using the Future monad (although it is sometimes helpful to include them, in order to catch low-level exceptions and wrap them in higher-level ones). Any exception thrown in code that's being run asynchronously by Future (including in the yield expression of a for comprehension) will be caught, and the result will be a Future containing a Failure . Also, in the previous example, if fooActor or barActor returns a Status.Failure message, the for -comprehension will also yield a failed future. However, you need to be careful with the first line of the for -comprehension. For example, this code doesn't handle exceptions correctly: private def doFooQuery(iri: IRI): Future[String] = { for { queryResponse <- (storeManager ? SparqlSelectRequest(queries.sparql.v1.txt.getFoo(iri).toString())).mapTo[SparqlSelectResponse] ... } yield ... } The getFoo() method calls a Twirl template function to generate SPARQL. The ? operator returns a Future . However, the template function is not run asynchronously , because it is called before the Future constructor is called. So if the template function throws an exception, it won't be caught here. Instead, you can do this: private def doFooQuery(iri: IRI): Future[String] = { for { queryString <- Future(queries.sparql.v1.txt.getFoo(iri).toString()) queryResponse <- (storeManager ? SparqlSelectRequest(queryString)).mapTo[SparqlSelectResponse] ... } yield ... } Here the Future constructor will call the template function asynchronously, and catch any exceptions it throws. This is only necessary if you need to call the template function at the very beginning of a for -comprehension. In the rest of the for comprehension, you'll already implicitly have a Future object.","title":"Handling Errors with Futures"},{"location":"05-internals/design/principles/futures-with-akka/#using-recover-on-futures","text":"By using recover on a Future , an apt error message can be thrown if the Future fails. This is particularly useful when an an error message should be made more clear depending on the context the Future is used in. For example, we are asking the resources responder to query for a certain resource in order to process it in a special way. However, the client does not know that the resources responder is sent a request and in case the resource cannot be found, the message sent back from the resources responder ( NotFoundException ) would not make sense to it. Instead, we would like to handle the message in a way so that it makes sense for the operation the client actually executed. We can do this by calling recover on a Future . private def mySpecialResourceRequest(iri: IRI, userProfile: UserProfileV1): Future[...] = { val resourceRequestFuture = for { resResponse: ResourceFullResponseV1 <- (responderManager ? ResourceFullGetRequestV1(iri = iri, userProfile = userProfile, getIncoming = false)).mapTo[ResourceFullResponseV1] } yield resResponse val resourceRequestFutureRecovered = resourceRequestFuture.recover { case notFound: NotFoundException => throw BadRequestException(s\"Special resource handling failed because the resource could not be found: ${notFound.message}\") } for { res <- resourceRequestFutureRecovered ... } yield ... } Please note that the content of the Future has to be accessed using <- to make this work correctly. Otherwise the content will never be looked at.","title":"Using recover on Futures"},{"location":"05-internals/design/principles/futures-with-akka/#designing-with-futures","text":"In the current design, Knora almost never blocks to wait for a future to complete. The normal flow of control works like this: Incoming HTTP requests are handled by an actor called KnoraService , which delegates them to routing functions (in the routing package). For each request, a routing function gets an Akka HTTP RequestContext , and calls RouteUtilV1.runJsonRoute (in API v1) or RouteUtilV2.runRdfRouteWithFuture (in API v2) to send a message to a supervisor actor to fulfil the request. This creates a Future that will complete when the relevant responder sends its reply. The routing utility registers a callback on this Future to handle the reply message when it becomes available. The supervisor forwards the message to be handled by the appropriate responder. The responder's receive method receives the message, and calls some private method that produces a reply message inside a Future . This may involve sending messages to other actors using ask , getting futures back, and combining them into a single future containing the reply message. The responder passes that future to ActorUtils.future2Message , which registers a callback on it. When the future completes (perhaps in another thread), the callback sends the reply message. In the meantime, the responder doesn't block, so it can start handling the next request. When the responder's reply becomes available, the routing utility's callback registered in (2) calls complete on the RequestContext , which sends an HTTP response to the client. The basic rule of thumb is this: if you're writing a method in an actor, and anything in the method needs to come from a future (e.g. because you need to use ask to get some information from another actor), have the method return a future.","title":"Designing with Futures"},{"location":"05-internals/design/principles/futures-with-akka/#mixing-futures-with-non-futures","text":"If you have a match ... case or if expression, and one branch obtains some data in a future, but another branch can produce the data immediately, you can wrap the result of the latter branch in a future, so that both branches have the same type. Here we use an alternative implementation of scala.concurrent.Future , found in akka.http.scaladsl.util.FastFuture , which tries to avoid scheduling to an scala.concurrent.ExecutionContext if possible, i.e. if the given future value is already present: def getTotalOfFooAndBar(howToGetFoo: String): Future[Int] = { for { foo <- howToGetFoo match { case \"askForIt\" => (fooActor ? GetFoo(\"foo\")).mapTo[Foo] case \"createIt\" => FastFuture.successful(new Foo()) } bar <- (barActor ? GetBar(\"bar\")).mapTo[Bar] total = foo.getCount + bar.getCount } yield total }","title":"Mixing Futures with non-Futures"},{"location":"05-internals/design/principles/futures-with-akka/#how-to-write-for-comprehensions","text":"Here are some basic rules for writing for -comprehensions: The first line of a for -comprehension has to be a \"generator\", i.e. it has to use the <- operator. If you want to write an assignment (using = ) as the first line, the workaround is to wrap the right-hand side in a monad (like Future ) and use <- instead. Assignments (using = ) are written without val . You're not allowed to write statements that throw away their return values, so if you want to call something like println that returns Unit , you have to assign its return value to _ . The yield returns an object of the same type as the generators, which all have to produce the same type (e.g. Future ).","title":"How to Write For-Comprehensions"},{"location":"05-internals/design/principles/futures-with-akka/#execution-contexts","text":"Whenever you use a future, there has to be an implicit 'execution context' in scope. Scala's documentation on futures says, 'you can think of execution contexts as thread pools'. If you don't have an execution context in scope, you'll get a compile error asking you to include one, and suggesting that you could use import scala.concurrent.ExecutionContext.Implicits.global . Don't do this, because the global Scala execution context is not the most efficient option. Instead, use Knora's custom execution context like so: implicit val executionContext: ExecutionContext = system.dispatchers.lookup(KnoraDispatchers.KnoraActorDispatcher)","title":"Execution Contexts"},{"location":"05-internals/design/principles/http-module/","text":"HTTP Module The http module holds only a convenience method for adding CORS support to api routes. The CORS implementation uses the akka-http-cors directives implementation.","title":"HTTP Module"},{"location":"05-internals/design/principles/http-module/#http-module","text":"The http module holds only a convenience method for adding CORS support to api routes. The CORS implementation uses the akka-http-cors directives implementation.","title":"HTTP Module"},{"location":"05-internals/design/principles/rdf-api/","text":"RDF Processing API DSP provides an API for parsing and formatting RDF data and for working with RDF graphs. This allows DSP developers to use a single, idiomatic Scala API as a fa\u00e7ade for a Java RDF library. Overview The API is in the package org.knora.webapi.messages.util.rdf . It includes: RdfModel , which represents a set of RDF graphs (a default graph and/or one or more named graphs). A model can be constructed from scratch, modified, and searched. RdfNode and its subclasses, which represent RDF nodes (IRIs, blank nodes, and literals). Statement , which represents a triple or quad. RdfNodeFactory , which creates nodes and statements. RdfModelFactory , which creates empty RDF models. RdfFormatUtil , which parses and formats RDF models. JsonLDUtil , which provides specialised functionality for working with RDF in JSON-LD format, and for converting between RDF models and JSON-LD documents. RdfFormatUtil uses JsonLDUtil when appropriate. ShaclValidator , which validates RDF models using SHACL shapes. To work with RDF models, start with RdfFeatureFactory , which returns instances of RdfNodeFactory , RdfModelFactory , RdfFormatUtil , and ShaclValidator . JsonLDUtil does not need a feature factory. To iterate efficiently over the statements in an RdfModel , use its iterator method. An RdfModel cannot be modified while you are iterating over it. If you are iterating to look for statements to modify, you can collect a Set of statements to remove and a Set of statements to add, and perform these update operations after you have finished the iteration. RDF stream processing To read or write a large amount of RDF data without generating a large string object, you can use the stream processing methods in RdfFormatUtil . To parse an InputStream to an RdfModel , use inputStreamToRdfModel . To format an RdfModel to an OutputStream , use rdfModelToOutputStream . To parse RDF data from an InputStream and process it one statement at a time, you can write a class that implements the RdfStreamProcessor trait, and use it with the RdfFormatUtil.parseWithStreamProcessor method. Your RdfStreamProcessor can also send one statement at a time to a formatting stream processor, which knows how to write RDF to an OutputStream in a particular format. Use RdfFormatUtil.makeFormattingStreamProcessor to construct one of these. SPARQL queries In tests, it can be useful to run SPARQL queries to check the content of an RdfModel . To do this, use the RdfModel.asRepository method, which returns an RdfRepository that can run SELECT queries. The configuration of the default graph depends on which underlying RDF library is used. If you are querying data in named graphs, use FROM or quad patterns rather than the default graph. SHACL validation On startup, graphs of SHACL shapes are loaded from Turtle files in a directory specified by app.shacl.shapes-dir in application.conf , and in subdirectories of that directory. To validate the default graph of an RdfModel using a graph of SHACL shapes, call ShaclValidator.validate , specifying the relative path of the Turtle file containing the graph of shapes. Implementations The Jena-based implementation, in package org.knora.webapi.messages.util.rdf.jenaimpl . The RDF4J-based implementation, in package org.knora.webapi.messages.util.rdf.rdf4jimpl . TODO SHACL validation.","title":"RDF Processing API"},{"location":"05-internals/design/principles/rdf-api/#rdf-processing-api","text":"DSP provides an API for parsing and formatting RDF data and for working with RDF graphs. This allows DSP developers to use a single, idiomatic Scala API as a fa\u00e7ade for a Java RDF library.","title":"RDF Processing API"},{"location":"05-internals/design/principles/rdf-api/#overview","text":"The API is in the package org.knora.webapi.messages.util.rdf . It includes: RdfModel , which represents a set of RDF graphs (a default graph and/or one or more named graphs). A model can be constructed from scratch, modified, and searched. RdfNode and its subclasses, which represent RDF nodes (IRIs, blank nodes, and literals). Statement , which represents a triple or quad. RdfNodeFactory , which creates nodes and statements. RdfModelFactory , which creates empty RDF models. RdfFormatUtil , which parses and formats RDF models. JsonLDUtil , which provides specialised functionality for working with RDF in JSON-LD format, and for converting between RDF models and JSON-LD documents. RdfFormatUtil uses JsonLDUtil when appropriate. ShaclValidator , which validates RDF models using SHACL shapes. To work with RDF models, start with RdfFeatureFactory , which returns instances of RdfNodeFactory , RdfModelFactory , RdfFormatUtil , and ShaclValidator . JsonLDUtil does not need a feature factory. To iterate efficiently over the statements in an RdfModel , use its iterator method. An RdfModel cannot be modified while you are iterating over it. If you are iterating to look for statements to modify, you can collect a Set of statements to remove and a Set of statements to add, and perform these update operations after you have finished the iteration.","title":"Overview"},{"location":"05-internals/design/principles/rdf-api/#rdf-stream-processing","text":"To read or write a large amount of RDF data without generating a large string object, you can use the stream processing methods in RdfFormatUtil . To parse an InputStream to an RdfModel , use inputStreamToRdfModel . To format an RdfModel to an OutputStream , use rdfModelToOutputStream . To parse RDF data from an InputStream and process it one statement at a time, you can write a class that implements the RdfStreamProcessor trait, and use it with the RdfFormatUtil.parseWithStreamProcessor method. Your RdfStreamProcessor can also send one statement at a time to a formatting stream processor, which knows how to write RDF to an OutputStream in a particular format. Use RdfFormatUtil.makeFormattingStreamProcessor to construct one of these.","title":"RDF stream processing"},{"location":"05-internals/design/principles/rdf-api/#sparql-queries","text":"In tests, it can be useful to run SPARQL queries to check the content of an RdfModel . To do this, use the RdfModel.asRepository method, which returns an RdfRepository that can run SELECT queries. The configuration of the default graph depends on which underlying RDF library is used. If you are querying data in named graphs, use FROM or quad patterns rather than the default graph.","title":"SPARQL queries"},{"location":"05-internals/design/principles/rdf-api/#shacl-validation","text":"On startup, graphs of SHACL shapes are loaded from Turtle files in a directory specified by app.shacl.shapes-dir in application.conf , and in subdirectories of that directory. To validate the default graph of an RdfModel using a graph of SHACL shapes, call ShaclValidator.validate , specifying the relative path of the Turtle file containing the graph of shapes.","title":"SHACL validation"},{"location":"05-internals/design/principles/rdf-api/#implementations","text":"The Jena-based implementation, in package org.knora.webapi.messages.util.rdf.jenaimpl . The RDF4J-based implementation, in package org.knora.webapi.messages.util.rdf.rdf4jimpl .","title":"Implementations"},{"location":"05-internals/design/principles/rdf-api/#todo","text":"SHACL validation.","title":"TODO"},{"location":"05-internals/design/principles/store-module/","text":"Store Module Overview GraphDB and embedded Jena TDB triplestores support is deprecated since v20.1.1 of DSP-API. The store module houses the different types of data stores supported by Knora. At the moment, only triplestores and IIIF servers (Sipi) are supported. The triplestore support is implemented in the org.knora.webapi.store.triplestore package and the IIIF server support in org.knora.webapi.store.iiif package. Lifecycle At the top level, the store package houses the StoreManager -Actor which is started when Knora starts. The StoreManager then starts the TriplestoreManager and IIIFManager , which each in turn starts their correct actor implementation. Triplestores Currently, the only supported triplestore is Apache Jena Fuseki , a HTTP-based triplestore. HTTP-based triplestore support is implemented in the org.knora.webapi.triplestore.http package. An HTTP-based triplestore is one that is accessed remotely over the HTTP protocol. HttpTriplestoreConnector supports the open source triplestore Apache Jena Fuseki . IIIF Servers Currently, only support for SIPI is implemented in org.knora.webapi.store.iiifSipiConnector .","title":"Store Module"},{"location":"05-internals/design/principles/store-module/#store-module","text":"","title":"Store Module"},{"location":"05-internals/design/principles/store-module/#overview","text":"GraphDB and embedded Jena TDB triplestores support is deprecated since v20.1.1 of DSP-API. The store module houses the different types of data stores supported by Knora. At the moment, only triplestores and IIIF servers (Sipi) are supported. The triplestore support is implemented in the org.knora.webapi.store.triplestore package and the IIIF server support in org.knora.webapi.store.iiif package.","title":"Overview"},{"location":"05-internals/design/principles/store-module/#lifecycle","text":"At the top level, the store package houses the StoreManager -Actor which is started when Knora starts. The StoreManager then starts the TriplestoreManager and IIIFManager , which each in turn starts their correct actor implementation.","title":"Lifecycle"},{"location":"05-internals/design/principles/store-module/#triplestores","text":"Currently, the only supported triplestore is Apache Jena Fuseki , a HTTP-based triplestore. HTTP-based triplestore support is implemented in the org.knora.webapi.triplestore.http package. An HTTP-based triplestore is one that is accessed remotely over the HTTP protocol. HttpTriplestoreConnector supports the open source triplestore Apache Jena Fuseki .","title":"Triplestores"},{"location":"05-internals/design/principles/store-module/#iiif-servers","text":"Currently, only support for SIPI is implemented in org.knora.webapi.store.iiifSipiConnector .","title":"IIIF Servers"},{"location":"05-internals/design/principles/triplestore-updates/","text":"Triplestore Updates Requirements General The supported update operations are: Create a new resource with its initial values. Add a new value. Change a value. Delete a value (i.e. mark it as deleted). Delete a resource (i.e. mark it as deleted). Users must be able to edit the same data concurrently. Each update must be atomic and leave the database in a consistent, meaningful state, respecting ontology constraints and permissions. The application must not use any sort of long-lived locks, because they tend to hinder concurrent edits, and it is difficult to ensure that they are released when they are no longer needed. Instead, if a user requests an update based on outdated information (because another user has just changed something, and the first user has not found out yet), the update must be not performed, and the application must notify the user who requested it, suggesting that the user should check the relevant data and try again if necessary. (We may eventually provide functionality to help users merge edits in such a situation. The application can also encourage users to coordinate with one another when they are working on the same data, and may eventually provide functionality to facilitate this coordination.) We can assume that each SPARQL update operation will run in its own database transaction with an isolation level of 'read committed'. We cannot assume that it is possible to run more than one SPARQL update in a single database transaction. The SPARQL 1.1 Protocol does not provide a way to do this, and currently it can be done only by embedding the triplestore in the application and using a vendor-specific API, but we cannot require this in Knora.) Permissions To create a new value (as opposed to a new version of an existing value), the user must have permission to modify the containing resource. To create a new version of an existing value, the user needs only to have permission to modify the current version of the value; no permissions on the resource are needed. Since changing a link requires deleting the old link and creating a new one (as described in Linking ), a user wishing to change a link must have modify permission on both the containing resource and the knora-base:LinkValue for the existing link. When a new resource or value is created, it can be given default permissions specified the project's admin data, or (only in API v2) custom permissions can be specified. Ontology Constraints Knora must not allow an update that would violate an ontology constraint. When creating a new value (as opposed to adding a new version of an existing value), Knora must not allow the update if the containing resource's OWL class does not contain a cardinality restriction for the submitted property, or if the new value would violate the cardinality restriction. It must also not allow the update if the type of the submitted value does not match the knora-base:objectClassConstraint of the property, or if the property has no knora-base:objectClassConstraint . In the case of a property that points to a resource, Knora must ensure that the target resource belongs to the OWL class specified in the property's knora-base:objectClassConstraint , or to a subclass of that class. Duplicate and Redundant Values When creating a new value, or changing an existing value, Knora checks whether the submitted value would duplicate an existing value for the same property in the resource. The definition of 'duplicate' depends on the type of value; it does not necessarily mean that the two values are strictly equal. For example, if two text values contain the same Unicode string, they are considered duplicates, even if they have different Standoff markup. If resource R has property P with value V1 , and V1 is a duplicate of V2 , the API server must not add another instance of property P with value V2 . However, if the requesting user does not have permission to see V2 , the duplicate is allowed, because forbidding it would reveal the contents of V2 to the user. When creating a new version of a value, Knora also checks whether the new version is redundant, given the existing value. It is possible for the definition of 'redundant' can depend on the type of value, but in practice, it means that the values are strictly equal: any change, however trivial, is allowed. Versioning Each Knora value (i.e. something belonging to an OWL class derived from knora-base:Value ) is versioned. This means that once created, a value is never modified. Instead, 'changing' a value means creating a new version of the value --- actually a new value --- that points to the previous version using knora-base:previousValue . The versions of a value are a singly-linked list, pointing backwards into the past. When a new version of a value is made, the triple that points from the resource to the old version (using a subproperty of knora-base:hasValue ) is removed, and a triple is added to point from the resource to the new version. Thus the resource always points only to the current version of the value, and the older versions are available only via the current version's knora-base:previousValue predicate. Unlike values, resources (members of OWL classes derived from knora-base:Resource ) are not versioned. The data that is attached to a resource, other than its values, can be modified. Deleting Knora does not actually delete resources or values; it only marks them as deleted. Deleted data is normally hidden. All resources and values must have the predicate knora- base:isDeleted , whose object is a boolean. If a resource or value has been marked as deleted, it has knora-base:isDeleted true and has a knora-base:deleteDate . An optional knora-base:deleteComment may be added to explain why the resource or value has been marked as deleted. Normally, a value is marked as deleted without creating a new version of it. However, link values must be treated as a special case. Before a LinkValue can be marked as deleted, its reference count must be decremented to 0. Therefore, a new version of the LinkValue is made, with a reference count of 0, and it is this new version that is marked as deleted. Since it is necessary to be able to find out when a resource was deleted, it is not possible to undelete a resource. Moreover, to simplify the checking of cardinality constraints, and for consistency with resources, it is not possible to undelete a value, and no new versions of a deleted value can be made. Instead, if desired, a new resource or value can be created by copying data from a deleted resource or value. Linking Links must be treated differently to other types of values. Knora needs to maintain information about the link, including permissions and a version history. Since the link does not have a unique IRI of its own, Knora uses RDF reifications for this purpose. Each link between two resources has exactly one (non-deleted) knora-base:LinkValue . The resource itself has a predicate that points to the LinkValue , using a naming convention in which the word Value is appended to the name of the link predicate to produce the link value predicate. For example, if a resource representing a book has a predicate called hasAuthor that points to another resource, it must also have a predicate called hasAuthorValue that points to the LinkValue in which information about the link is stored. To find a particular LinkValue , one can query it either by using its IRI (if known), or by using its rdf:subject , rdf:predicate , and rdf:object (and excluding link values that are marked as deleted). Like other values, link values are versioned. The link value predicate always points from the resource to the current version of the link value, and previous versions are available only via the current version's knora-base:previousValue predicate. Deleting a link means deleting the triple that links the two resources, and making a new version of the link value, marked with knora-base:isDeleted . A triple then points from the resource to this new, deleted version (using the link value property). The API allows a link to be 'changed' so that it points to a different target resource. This is implemented as follows: the existing triple connecting the two resources is removed, and a new triple is added using the same link property and pointing to the new target resource. A new version of the old link's LinkValue is made, marked with knora-base:isDeleted . A new LinkValue is made for the new link. The new LinkValue has no connection to the old one. When a resource contains knora-base:TextValue with Standoff markup that includes a reference to another resource, this reference is materialised as a direct link between the two resources, to make it easier to query. A special link property, knora-base:hasStandoffLinkTo , is used for this purpose. The corresponding link value property, knora-base:hasStandoffLinkToValue , points to a LinkValue . This LinkValue contains a reference count, indicated by knora-base:valueHasRefCount , that represents the number of text values in the containing resource that include one or more Standoff references to the specified target resource. Each time this number changes, a new version of this LinkValue is made. When the reference count reaches zero, the triple with knora-base:hasStandoffLinkTo is removed, and a new version of the LinkValue is made and marked with knora-base:isDeleted . If the same resource reference later appears again in a text value, a new triple is added using knora-base:hasStandoffLinkTo , and a new LinkValue is made, with no connection to the old one. For consistency, every LinkValue contains a reference count. If the link property is not knora-base:hasStandoffLinkTo , the reference count will always be either 1 (if the link exists) or 0 (if it has been deleted, in which case the link value will also be marked with knora-base:isDeleted ). When a LinkValue is created for a standoff resource reference, it is given the same permissions as the text value containing the reference. Design Responsibilities of Responders The resources responder ( ResourcesResponderV1 in API v1, ResourcesResponderV2 in API v2) has sole responsibility for generating SPARQL to create and updating resources, and the values responder ( ValuesResponderV1 or ValuesResponderV2 ) has sole responsibility for generating SPARQL to create and update values. When a new resource is created with its values, the values responder generates SPARQL statements that can be included in the INSERT clause of a SPARQL update to create the values, and the resources responder adds these statements to the SPARQL update that creates the resource. This ensures that the resource and its values are created in a single SPARQL update operation, and hence in a single triplestore transaction. Application-level Locking The 'read committed' isolation level cannot prevent a scenario where two users want to add the same data at the same time. It is possible that both requests would do pre-update checks and simultaneously find that it is OK to add the data, and that both updates would then succeed, inserting redundant data and possibly violating ontology constraints. Therefore, Knora uses short-lived, application-level write locks on resources, to ensure that only one request at a time can update a given resource. Before each update, the application acquires a lock on a resource. To prevent deadlocks, Knora locks only one resource per API operation. It then does the pre-update checks and the update, then releases the lock. The lock implementation (in IriLocker ) requires each API request message to include a random UUID, which is generated in the API Routing package. Using application-level locks allows us to do pre-update checks in their own transactions, and finally to do the SPARQL update in its own transaction. Ensuring Data Consistency Knora enforces consistency constraints using three redundant mechanisms: By doing pre-update checks using SPARQL SELECT queries and cached ontology data. By doing checks in the WHERE clauses of SPARQL updates. Deprecated : By using GraphDB's built-in consistency checker (see Consistency Checking ). We take the view that redundant consistency checks are a good thing. Pre-update checks are SPARQL SELECT queries that are executed while holding an application-level lock on the resource to be updated. These checks should work with any triplestore, and can return helpful, Knora-specific error messages to the client if the request would violate a consistency constraint. However, the SPARQL update itself is our only chance to do pre-update checks in the same transaction that will perform the update. The design of the SPARQL 1.1 Update standard makes it possible to ensure that if certain conditions are not met, the update will not be performed. In our SPARQL update code, each update contains a WHERE clause, possibly a DELETE clause, and an INSERT clause. The WHERE clause is executed first. It performs consistency checks and provides values for variables that are used in the DELETE and/or INSERT clauses. In our updates, if the expectations of the WHERE clause are not met (e.g. because the data to be updated does not exist), the WHERE clause should return no results; as a result, the update will not be performed. Regardless of whether the update changes the contents of the triplestore, it returns nothing. If the update did nothing because the conditions of the WHERE clause were not met, the only way to find out is to do a SELECT afterwards. Moreover, in this case, there is no straightforward way to find out which conditions was not met. This is one reason why Knora does pre-update checks using separate SELECT queries and/or cached ontology data, before performing the update. This makes it possible to return specific error messages to the user to indicate why an update cannot be performed. Moreover, while some checks are easy to do in a SPARQL update, others are difficult, impractical, or impossible. Easy checks include checking whether a resource or value exists or is deleted, and checking that the knora-base:objectClassConstraint of a predicate matches the rdf:type of its intended object. Cardinality checks are not very difficult, but they perform poorly on Jena. Knora does not do permission checks in SPARQL, because its permission-checking algorithm is too complex to be implemented in SPARQL. For this reason, Knora's check for duplicate values cannot be done in SPARQL update code, because it relies on permission checks. In a bulk import operation, which can create a large number of resources in a single SPARQL update, a WHERE clause can become very expensive for the triplestore, in terms of memory as well as execution time. Moreover, RDF4J (and hence GraphDB) uses a recursive algorithm to parse SPARQL queries with WHERE clauses, so the size of a WHERE clause is limited by the stack space available to the Java Virtual Machine. Therefore, in bulk import operations, Knora uses INSERT DATA , which does not involve a WHERE clause. Bulk imports thus rely on checks (1) and (3) above. SPARQL Update Examples The following sample SPARQL update code is simpler than what Knora actually does. It is included here to illustrate the way Knora's SPARQL updates are structured and how concurrent updates are handled. Finding a value IRI in a value's version history We will need this query below. If a value is present in a resource property's version history, the query returns everything known about the value, or nothing otherwise: prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> SELECT ?p ?o WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") as ?searchValue) ?resource ?property ?currentValue . ?currentValue knora-base:previousValue* ?searchValue . ?searchValue ?p ?o . } Creating the initial version of a value prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> WITH <http://www.knora.org/ontology/0803/incunabula> INSERT { ?newValue rdf:type ?valueType ; knora-base:valueHasString \"\"\"Comment 1\"\"\" ; knora-base:attachedToUser <http://rdfh.ch/users/91e19f1e01> ; knora-base:attachedToProject <http://rdfh.ch/projects/77275339> ; knora-base:hasPermissions \"V knora-admin:KnownUser,knora-admin:UnknownUser|M knora-admin:ProjectMember\" ; knora-base:valueTimestamp ?currentTime . ?resource ?property ?newValue . } WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment001\") AS ?newValue) BIND(IRI(\"http://www.knora.org/ontology/knora-base#TextValue\") AS ?valueType) BIND(NOW() AS ?currentTime) # Do nothing if the resource doesn't exist. ?resource rdf:type ?resourceClass . # Do nothing if the submitted value has the wrong type. ?property knora-base:objectClassConstraint ?valueType . } To find out whether the insert succeeded, the application can use the query in Finding a value IRI in a value's version history to look for the new IRI in the property's version history. Adding a new version of a value prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> WITH <http://www.knora.org/ontology/0803/incunabula> DELETE { ?resource ?property ?currentValue . } INSERT { ?newValue rdf:type ?valueType ; knora-base:valueHasString \"\"\"Comment 2\"\"\" ; knora-base:previousValue ?currentValue ; knora-base:attachedToUser <http://rdfh.ch/users/91e19f1e01> ; knora-base:attachedToProject <http://rdfh.ch/projects/77275339> ; knora-base:hasPermissions \"V knora-admin:KnownUser,knora-admin:UnknownUser|M knora-admin:ProjectMember\" ; knora-base:valueTimestamp ?currentTime . ?resource ?property ?newValue . } WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment001\") AS ?currentValue) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") AS ?newValue) BIND(IRI(\"http://www.knora.org/ontology/knora-base#TextValue\") AS ?valueType) BIND(NOW() AS ?currentTime) ?resource ?property ?currentValue . ?property knora-base:objectClassConstraint ?valueType . } The update request must contain the IRI of the most recent version of the value ( http://rdfh.ch/c5058f3a/values/c3295339 ). If this is not in fact the most recent version (because someone else has done an update), this operation will do nothing (because the WHERE clause will return no rows). To find out whether the update succeeded, the application will then need to do a SELECT query using the query in Finding a value IRI in a value's version history . In the case of concurrent updates, there are two possibilities: Users A and B are looking at version 1. User A submits an update and it succeeds, creating version 2, which user A verifies using a SELECT. User B then submits an update to version 1 but it fails, because version 1 is no longer the latest version. User B's SELECT will find that user B's new value IRI is absent from the value's version history. Users A and B are looking at version 1. User A submits an update and it succeeds, creating version 2. Before User A has time to do a SELECT, user B reads the new value and updates it again. Both users then do a SELECT, and find that both their new value IRIs are present in the value's version history. Getting all versions of a value prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> SELECT ?value ?valueTimestamp ?previousValue WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") AS ?currentValue) ?resource ?property ?currentValue . ?currentValue knora-base:previousValue* ?value . OPTIONAL { ?value knora-base:valueTimestamp ?valueTimestamp . } OPTIONAL { ?value knora-base:previousValue ?previousValue . } } This assumes that we know the current version of the value. If the version we have is not actually the current version, this query will return no rows.","title":"Triplestore Updates"},{"location":"05-internals/design/principles/triplestore-updates/#triplestore-updates","text":"","title":"Triplestore Updates"},{"location":"05-internals/design/principles/triplestore-updates/#requirements","text":"","title":"Requirements"},{"location":"05-internals/design/principles/triplestore-updates/#general","text":"The supported update operations are: Create a new resource with its initial values. Add a new value. Change a value. Delete a value (i.e. mark it as deleted). Delete a resource (i.e. mark it as deleted). Users must be able to edit the same data concurrently. Each update must be atomic and leave the database in a consistent, meaningful state, respecting ontology constraints and permissions. The application must not use any sort of long-lived locks, because they tend to hinder concurrent edits, and it is difficult to ensure that they are released when they are no longer needed. Instead, if a user requests an update based on outdated information (because another user has just changed something, and the first user has not found out yet), the update must be not performed, and the application must notify the user who requested it, suggesting that the user should check the relevant data and try again if necessary. (We may eventually provide functionality to help users merge edits in such a situation. The application can also encourage users to coordinate with one another when they are working on the same data, and may eventually provide functionality to facilitate this coordination.) We can assume that each SPARQL update operation will run in its own database transaction with an isolation level of 'read committed'. We cannot assume that it is possible to run more than one SPARQL update in a single database transaction. The SPARQL 1.1 Protocol does not provide a way to do this, and currently it can be done only by embedding the triplestore in the application and using a vendor-specific API, but we cannot require this in Knora.)","title":"General"},{"location":"05-internals/design/principles/triplestore-updates/#permissions","text":"To create a new value (as opposed to a new version of an existing value), the user must have permission to modify the containing resource. To create a new version of an existing value, the user needs only to have permission to modify the current version of the value; no permissions on the resource are needed. Since changing a link requires deleting the old link and creating a new one (as described in Linking ), a user wishing to change a link must have modify permission on both the containing resource and the knora-base:LinkValue for the existing link. When a new resource or value is created, it can be given default permissions specified the project's admin data, or (only in API v2) custom permissions can be specified.","title":"Permissions"},{"location":"05-internals/design/principles/triplestore-updates/#ontology-constraints","text":"Knora must not allow an update that would violate an ontology constraint. When creating a new value (as opposed to adding a new version of an existing value), Knora must not allow the update if the containing resource's OWL class does not contain a cardinality restriction for the submitted property, or if the new value would violate the cardinality restriction. It must also not allow the update if the type of the submitted value does not match the knora-base:objectClassConstraint of the property, or if the property has no knora-base:objectClassConstraint . In the case of a property that points to a resource, Knora must ensure that the target resource belongs to the OWL class specified in the property's knora-base:objectClassConstraint , or to a subclass of that class.","title":"Ontology Constraints"},{"location":"05-internals/design/principles/triplestore-updates/#duplicate-and-redundant-values","text":"When creating a new value, or changing an existing value, Knora checks whether the submitted value would duplicate an existing value for the same property in the resource. The definition of 'duplicate' depends on the type of value; it does not necessarily mean that the two values are strictly equal. For example, if two text values contain the same Unicode string, they are considered duplicates, even if they have different Standoff markup. If resource R has property P with value V1 , and V1 is a duplicate of V2 , the API server must not add another instance of property P with value V2 . However, if the requesting user does not have permission to see V2 , the duplicate is allowed, because forbidding it would reveal the contents of V2 to the user. When creating a new version of a value, Knora also checks whether the new version is redundant, given the existing value. It is possible for the definition of 'redundant' can depend on the type of value, but in practice, it means that the values are strictly equal: any change, however trivial, is allowed.","title":"Duplicate and Redundant Values"},{"location":"05-internals/design/principles/triplestore-updates/#versioning","text":"Each Knora value (i.e. something belonging to an OWL class derived from knora-base:Value ) is versioned. This means that once created, a value is never modified. Instead, 'changing' a value means creating a new version of the value --- actually a new value --- that points to the previous version using knora-base:previousValue . The versions of a value are a singly-linked list, pointing backwards into the past. When a new version of a value is made, the triple that points from the resource to the old version (using a subproperty of knora-base:hasValue ) is removed, and a triple is added to point from the resource to the new version. Thus the resource always points only to the current version of the value, and the older versions are available only via the current version's knora-base:previousValue predicate. Unlike values, resources (members of OWL classes derived from knora-base:Resource ) are not versioned. The data that is attached to a resource, other than its values, can be modified.","title":"Versioning"},{"location":"05-internals/design/principles/triplestore-updates/#deleting","text":"Knora does not actually delete resources or values; it only marks them as deleted. Deleted data is normally hidden. All resources and values must have the predicate knora- base:isDeleted , whose object is a boolean. If a resource or value has been marked as deleted, it has knora-base:isDeleted true and has a knora-base:deleteDate . An optional knora-base:deleteComment may be added to explain why the resource or value has been marked as deleted. Normally, a value is marked as deleted without creating a new version of it. However, link values must be treated as a special case. Before a LinkValue can be marked as deleted, its reference count must be decremented to 0. Therefore, a new version of the LinkValue is made, with a reference count of 0, and it is this new version that is marked as deleted. Since it is necessary to be able to find out when a resource was deleted, it is not possible to undelete a resource. Moreover, to simplify the checking of cardinality constraints, and for consistency with resources, it is not possible to undelete a value, and no new versions of a deleted value can be made. Instead, if desired, a new resource or value can be created by copying data from a deleted resource or value.","title":"Deleting"},{"location":"05-internals/design/principles/triplestore-updates/#linking","text":"Links must be treated differently to other types of values. Knora needs to maintain information about the link, including permissions and a version history. Since the link does not have a unique IRI of its own, Knora uses RDF reifications for this purpose. Each link between two resources has exactly one (non-deleted) knora-base:LinkValue . The resource itself has a predicate that points to the LinkValue , using a naming convention in which the word Value is appended to the name of the link predicate to produce the link value predicate. For example, if a resource representing a book has a predicate called hasAuthor that points to another resource, it must also have a predicate called hasAuthorValue that points to the LinkValue in which information about the link is stored. To find a particular LinkValue , one can query it either by using its IRI (if known), or by using its rdf:subject , rdf:predicate , and rdf:object (and excluding link values that are marked as deleted). Like other values, link values are versioned. The link value predicate always points from the resource to the current version of the link value, and previous versions are available only via the current version's knora-base:previousValue predicate. Deleting a link means deleting the triple that links the two resources, and making a new version of the link value, marked with knora-base:isDeleted . A triple then points from the resource to this new, deleted version (using the link value property). The API allows a link to be 'changed' so that it points to a different target resource. This is implemented as follows: the existing triple connecting the two resources is removed, and a new triple is added using the same link property and pointing to the new target resource. A new version of the old link's LinkValue is made, marked with knora-base:isDeleted . A new LinkValue is made for the new link. The new LinkValue has no connection to the old one. When a resource contains knora-base:TextValue with Standoff markup that includes a reference to another resource, this reference is materialised as a direct link between the two resources, to make it easier to query. A special link property, knora-base:hasStandoffLinkTo , is used for this purpose. The corresponding link value property, knora-base:hasStandoffLinkToValue , points to a LinkValue . This LinkValue contains a reference count, indicated by knora-base:valueHasRefCount , that represents the number of text values in the containing resource that include one or more Standoff references to the specified target resource. Each time this number changes, a new version of this LinkValue is made. When the reference count reaches zero, the triple with knora-base:hasStandoffLinkTo is removed, and a new version of the LinkValue is made and marked with knora-base:isDeleted . If the same resource reference later appears again in a text value, a new triple is added using knora-base:hasStandoffLinkTo , and a new LinkValue is made, with no connection to the old one. For consistency, every LinkValue contains a reference count. If the link property is not knora-base:hasStandoffLinkTo , the reference count will always be either 1 (if the link exists) or 0 (if it has been deleted, in which case the link value will also be marked with knora-base:isDeleted ). When a LinkValue is created for a standoff resource reference, it is given the same permissions as the text value containing the reference.","title":"Linking"},{"location":"05-internals/design/principles/triplestore-updates/#design","text":"","title":"Design"},{"location":"05-internals/design/principles/triplestore-updates/#responsibilities-of-responders","text":"The resources responder ( ResourcesResponderV1 in API v1, ResourcesResponderV2 in API v2) has sole responsibility for generating SPARQL to create and updating resources, and the values responder ( ValuesResponderV1 or ValuesResponderV2 ) has sole responsibility for generating SPARQL to create and update values. When a new resource is created with its values, the values responder generates SPARQL statements that can be included in the INSERT clause of a SPARQL update to create the values, and the resources responder adds these statements to the SPARQL update that creates the resource. This ensures that the resource and its values are created in a single SPARQL update operation, and hence in a single triplestore transaction.","title":"Responsibilities of Responders"},{"location":"05-internals/design/principles/triplestore-updates/#application-level-locking","text":"The 'read committed' isolation level cannot prevent a scenario where two users want to add the same data at the same time. It is possible that both requests would do pre-update checks and simultaneously find that it is OK to add the data, and that both updates would then succeed, inserting redundant data and possibly violating ontology constraints. Therefore, Knora uses short-lived, application-level write locks on resources, to ensure that only one request at a time can update a given resource. Before each update, the application acquires a lock on a resource. To prevent deadlocks, Knora locks only one resource per API operation. It then does the pre-update checks and the update, then releases the lock. The lock implementation (in IriLocker ) requires each API request message to include a random UUID, which is generated in the API Routing package. Using application-level locks allows us to do pre-update checks in their own transactions, and finally to do the SPARQL update in its own transaction.","title":"Application-level Locking"},{"location":"05-internals/design/principles/triplestore-updates/#ensuring-data-consistency","text":"Knora enforces consistency constraints using three redundant mechanisms: By doing pre-update checks using SPARQL SELECT queries and cached ontology data. By doing checks in the WHERE clauses of SPARQL updates. Deprecated : By using GraphDB's built-in consistency checker (see Consistency Checking ). We take the view that redundant consistency checks are a good thing. Pre-update checks are SPARQL SELECT queries that are executed while holding an application-level lock on the resource to be updated. These checks should work with any triplestore, and can return helpful, Knora-specific error messages to the client if the request would violate a consistency constraint. However, the SPARQL update itself is our only chance to do pre-update checks in the same transaction that will perform the update. The design of the SPARQL 1.1 Update standard makes it possible to ensure that if certain conditions are not met, the update will not be performed. In our SPARQL update code, each update contains a WHERE clause, possibly a DELETE clause, and an INSERT clause. The WHERE clause is executed first. It performs consistency checks and provides values for variables that are used in the DELETE and/or INSERT clauses. In our updates, if the expectations of the WHERE clause are not met (e.g. because the data to be updated does not exist), the WHERE clause should return no results; as a result, the update will not be performed. Regardless of whether the update changes the contents of the triplestore, it returns nothing. If the update did nothing because the conditions of the WHERE clause were not met, the only way to find out is to do a SELECT afterwards. Moreover, in this case, there is no straightforward way to find out which conditions was not met. This is one reason why Knora does pre-update checks using separate SELECT queries and/or cached ontology data, before performing the update. This makes it possible to return specific error messages to the user to indicate why an update cannot be performed. Moreover, while some checks are easy to do in a SPARQL update, others are difficult, impractical, or impossible. Easy checks include checking whether a resource or value exists or is deleted, and checking that the knora-base:objectClassConstraint of a predicate matches the rdf:type of its intended object. Cardinality checks are not very difficult, but they perform poorly on Jena. Knora does not do permission checks in SPARQL, because its permission-checking algorithm is too complex to be implemented in SPARQL. For this reason, Knora's check for duplicate values cannot be done in SPARQL update code, because it relies on permission checks. In a bulk import operation, which can create a large number of resources in a single SPARQL update, a WHERE clause can become very expensive for the triplestore, in terms of memory as well as execution time. Moreover, RDF4J (and hence GraphDB) uses a recursive algorithm to parse SPARQL queries with WHERE clauses, so the size of a WHERE clause is limited by the stack space available to the Java Virtual Machine. Therefore, in bulk import operations, Knora uses INSERT DATA , which does not involve a WHERE clause. Bulk imports thus rely on checks (1) and (3) above.","title":"Ensuring Data Consistency"},{"location":"05-internals/design/principles/triplestore-updates/#sparql-update-examples","text":"The following sample SPARQL update code is simpler than what Knora actually does. It is included here to illustrate the way Knora's SPARQL updates are structured and how concurrent updates are handled.","title":"SPARQL Update Examples"},{"location":"05-internals/design/principles/triplestore-updates/#finding-a-value-iri-in-a-values-version-history","text":"We will need this query below. If a value is present in a resource property's version history, the query returns everything known about the value, or nothing otherwise: prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> SELECT ?p ?o WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") as ?searchValue) ?resource ?property ?currentValue . ?currentValue knora-base:previousValue* ?searchValue . ?searchValue ?p ?o . }","title":"Finding a value IRI in a value's version history"},{"location":"05-internals/design/principles/triplestore-updates/#creating-the-initial-version-of-a-value","text":"prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> WITH <http://www.knora.org/ontology/0803/incunabula> INSERT { ?newValue rdf:type ?valueType ; knora-base:valueHasString \"\"\"Comment 1\"\"\" ; knora-base:attachedToUser <http://rdfh.ch/users/91e19f1e01> ; knora-base:attachedToProject <http://rdfh.ch/projects/77275339> ; knora-base:hasPermissions \"V knora-admin:KnownUser,knora-admin:UnknownUser|M knora-admin:ProjectMember\" ; knora-base:valueTimestamp ?currentTime . ?resource ?property ?newValue . } WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment001\") AS ?newValue) BIND(IRI(\"http://www.knora.org/ontology/knora-base#TextValue\") AS ?valueType) BIND(NOW() AS ?currentTime) # Do nothing if the resource doesn't exist. ?resource rdf:type ?resourceClass . # Do nothing if the submitted value has the wrong type. ?property knora-base:objectClassConstraint ?valueType . } To find out whether the insert succeeded, the application can use the query in Finding a value IRI in a value's version history to look for the new IRI in the property's version history.","title":"Creating the initial version of a value"},{"location":"05-internals/design/principles/triplestore-updates/#adding-a-new-version-of-a-value","text":"prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> WITH <http://www.knora.org/ontology/0803/incunabula> DELETE { ?resource ?property ?currentValue . } INSERT { ?newValue rdf:type ?valueType ; knora-base:valueHasString \"\"\"Comment 2\"\"\" ; knora-base:previousValue ?currentValue ; knora-base:attachedToUser <http://rdfh.ch/users/91e19f1e01> ; knora-base:attachedToProject <http://rdfh.ch/projects/77275339> ; knora-base:hasPermissions \"V knora-admin:KnownUser,knora-admin:UnknownUser|M knora-admin:ProjectMember\" ; knora-base:valueTimestamp ?currentTime . ?resource ?property ?newValue . } WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment001\") AS ?currentValue) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") AS ?newValue) BIND(IRI(\"http://www.knora.org/ontology/knora-base#TextValue\") AS ?valueType) BIND(NOW() AS ?currentTime) ?resource ?property ?currentValue . ?property knora-base:objectClassConstraint ?valueType . } The update request must contain the IRI of the most recent version of the value ( http://rdfh.ch/c5058f3a/values/c3295339 ). If this is not in fact the most recent version (because someone else has done an update), this operation will do nothing (because the WHERE clause will return no rows). To find out whether the update succeeded, the application will then need to do a SELECT query using the query in Finding a value IRI in a value's version history . In the case of concurrent updates, there are two possibilities: Users A and B are looking at version 1. User A submits an update and it succeeds, creating version 2, which user A verifies using a SELECT. User B then submits an update to version 1 but it fails, because version 1 is no longer the latest version. User B's SELECT will find that user B's new value IRI is absent from the value's version history. Users A and B are looking at version 1. User A submits an update and it succeeds, creating version 2. Before User A has time to do a SELECT, user B reads the new value and updates it again. Both users then do a SELECT, and find that both their new value IRIs are present in the value's version history.","title":"Adding a new version of a value"},{"location":"05-internals/design/principles/triplestore-updates/#getting-all-versions-of-a-value","text":"prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> prefix knora-base: <http://www.knora.org/ontology/knora-base#> SELECT ?value ?valueTimestamp ?previousValue WHERE { BIND(IRI(\"http://rdfh.ch/c5058f3a\") as ?resource) BIND(IRI(\"http://www.knora.org/ontology/0803/incunabula#book_comment\") as ?property) BIND(IRI(\"http://rdfh.ch/c5058f3a/values/testComment002\") AS ?currentValue) ?resource ?property ?currentValue . ?currentValue knora-base:previousValue* ?value . OPTIONAL { ?value knora-base:valueTimestamp ?valueTimestamp . } OPTIONAL { ?value knora-base:previousValue ?previousValue . } } This assumes that we know the current version of the value. If the version we have is not actually the current version, this query will return no rows.","title":"Getting all versions of a value"},{"location":"05-internals/development/building-and-running/","text":"Building and Running Running the stack With Docker installed, Run the following: $ make init-db-test to create the knora-test repository and initialize it with loading some test data into the triplestore (Fuseki). Start the entire knora-stack (fuseki (db), sipi, redis, api, salsah1) with the following command: $ make stack-up Then try opening http://localhost:3333/v1/resources/http%3A%2F%2Frdfh.ch%2F0803%2Fc5058f3a in a web browser. You should see a response in JSON describing a book. Note : To delete the existing containers and for a clean start, before creating the knora-test repository explained in the first step above, run the following: $ make stack-down-delete-volumes This stops the knora-stack and deletes any created volumes (deletes the database!). To only shut down the Knora-Stack without deleting the containers: $ make stack-down To restart the knora-api use the following command: $ make stack-restart-api If a change is made to knora-api code, only its image needs to be rebuilt. In that case, use $ make stack-up-fast which starts the knora-stack by skipping rebuilding most of the images (only api image is rebuilt). To work on Metadata, use $ make stack-up-with-metadata which will put three example metadata sets to the projects anything , images and dokubib . This data can then be consumed from localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001 , localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F00FF and localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F0804 . Managing Containers in Docker Dashboard The Docker Desktop is installed on your computer during the installation of docker, it enables easy management of docker containers and access to Docker Hub. To manage your docker containers, docker desktop provides a dashbord. In docker dashboard, you can see all the running containers, stop, start, restart, or completely delete them. For example, when you start the knora-stack as explained above, in the docker dashboard you will see following: Access the logs To read information logged out of any container (db, api, etc.), click on the container in the dashboard and choose logs . The example, below shows the logs of the database (db) container that includes the last SPARQL query sent to the triplestore. Note that, you can also print out the log information directly from the command line. For example, the same logs of the database container can be printed out using the following command: $ make stack-logs-db Similarly, the logs of the other containers can be printed out by running make with stack-logs-api , stack-logs-sipi , or stack-logs-redis . These commands print out and follow the logs, to only print the logs out without following, use -no-follow version of the commands for example: $ make stack-logs-db-no-follow Lastly, to print out the entire logs of the running knora-stack, use $ make stack-logs With the Docker plugin installed, you can attach a terminal to the docker container within VS Code. This will stream the docker logs to the terminal window of the editor. The docker plugin also allows for a number of other useful features, like inspecting the container's file system or attaching a shell to the container. Running the automated tests To run all test targets, use the following in the command line: $ make test To run a single test from the command line, for example SearchV1R2RSpec , run the following: bash $ sbt \" webapi / testOnly *SearchV1R2RSpec* \" Note: to run tests, the api container must be stopped first! Build and Publish Documentation First, you need to install the requirements through: $ make docs-install-requirements Then, to build docs into the local site folder, run the following command: $ make docs-build At this point, you can serve the docs to view them locally using $ make docs-serve Lastly, to build and publish docs to Github Pages, use $ make docs-publish Build and Publish Docker Images To build and publish all Docker images locally $ make docker-build To publish all Docker images to Dockerhub $ make docker-publish Load Testing on Mac OS X To test Knora with many concurrent connections on Mac OS X, you will need to adjust some kernel parameters to allow more open connections, to recycle ephemeral ports more quickly, and to use a wider range of ephemeral port numbers. The script webapi/scripts/macOS-kernel-test-config.sh will do this. Continuous Integration For continuous integration testing, we use Github CI Actions. Every commit pushed to the git repository or every pull request, triggers the build. Additionally, in Github there is a small checkmark beside every commit, signaling the status of the build (successful, unsuccessful, ongoing). The build that is executed on Github CI Actions is defined in .github/workflows/main.yml . Webapi Server Startup-Flags The Webapi-Server can be started with a number of flags. loadDemoData - Flag When the webapi-server is started with the loadDemoData flag, then at startup, the data which is configured in application.conf under the app.triplestore.rdf-data key is loaded into the triplestore, and any data in the triplestore is removed beforehand. allowReloadOverHTTP - Flag When the webapi.server is started with the allowReloadOverHTTP flag ( reStart -r ), then the v1/store/ResetTriplestoreContent route is activated. This route accepts a POST request, with a JSON payload consisting of the following example content: [ { \"path\": \"knora-ontologies/knora-base.ttl\", \"name\": \"http://www.knora.org/ontology/knora-base\" }, { \"path\": \"knora-ontologies/salsah-gui.ttl\", \"name\": \"http://www.knora.org/ontology/salsah-gui\" }, { \"path\": \"test_data/ontologies/incunabula-onto.ttl\", \"name\": \"http://www.knora.org/ontology/0803/incunabula\" }, { \"path\": \"test_data/all_data/incunabula-data.ttl\", \"name\": \"http://www.knora.org/data/incunabula\" } ] This content corresponds to the payload sent with the ResetTriplestoreContent message, defined inside the org.knora.webapi.messages.v1.store.triplestoremessages package. The path being the relative path to the ttl file which will be loaded into a named graph by the name of name .","title":"Build and Running"},{"location":"05-internals/development/building-and-running/#building-and-running","text":"","title":"Building and Running"},{"location":"05-internals/development/building-and-running/#running-the-stack","text":"With Docker installed, Run the following: $ make init-db-test to create the knora-test repository and initialize it with loading some test data into the triplestore (Fuseki). Start the entire knora-stack (fuseki (db), sipi, redis, api, salsah1) with the following command: $ make stack-up Then try opening http://localhost:3333/v1/resources/http%3A%2F%2Frdfh.ch%2F0803%2Fc5058f3a in a web browser. You should see a response in JSON describing a book. Note : To delete the existing containers and for a clean start, before creating the knora-test repository explained in the first step above, run the following: $ make stack-down-delete-volumes This stops the knora-stack and deletes any created volumes (deletes the database!). To only shut down the Knora-Stack without deleting the containers: $ make stack-down To restart the knora-api use the following command: $ make stack-restart-api If a change is made to knora-api code, only its image needs to be rebuilt. In that case, use $ make stack-up-fast which starts the knora-stack by skipping rebuilding most of the images (only api image is rebuilt). To work on Metadata, use $ make stack-up-with-metadata which will put three example metadata sets to the projects anything , images and dokubib . This data can then be consumed from localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F0001 , localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F00FF and localhost:3333/v2/metadata/http%3A%2F%2Frdfh.ch%2Fprojects%2F0804 .","title":"Running the stack"},{"location":"05-internals/development/building-and-running/#managing-containers-in-docker-dashboard","text":"The Docker Desktop is installed on your computer during the installation of docker, it enables easy management of docker containers and access to Docker Hub. To manage your docker containers, docker desktop provides a dashbord. In docker dashboard, you can see all the running containers, stop, start, restart, or completely delete them. For example, when you start the knora-stack as explained above, in the docker dashboard you will see following:","title":"Managing Containers in Docker Dashboard"},{"location":"05-internals/development/building-and-running/#access-the-logs","text":"To read information logged out of any container (db, api, etc.), click on the container in the dashboard and choose logs . The example, below shows the logs of the database (db) container that includes the last SPARQL query sent to the triplestore. Note that, you can also print out the log information directly from the command line. For example, the same logs of the database container can be printed out using the following command: $ make stack-logs-db Similarly, the logs of the other containers can be printed out by running make with stack-logs-api , stack-logs-sipi , or stack-logs-redis . These commands print out and follow the logs, to only print the logs out without following, use -no-follow version of the commands for example: $ make stack-logs-db-no-follow Lastly, to print out the entire logs of the running knora-stack, use $ make stack-logs With the Docker plugin installed, you can attach a terminal to the docker container within VS Code. This will stream the docker logs to the terminal window of the editor. The docker plugin also allows for a number of other useful features, like inspecting the container's file system or attaching a shell to the container.","title":"Access the logs"},{"location":"05-internals/development/building-and-running/#running-the-automated-tests","text":"To run all test targets, use the following in the command line: $ make test To run a single test from the command line, for example SearchV1R2RSpec , run the following: bash $ sbt \" webapi / testOnly *SearchV1R2RSpec* \" Note: to run tests, the api container must be stopped first!","title":"Running the automated tests"},{"location":"05-internals/development/building-and-running/#build-and-publish-documentation","text":"First, you need to install the requirements through: $ make docs-install-requirements Then, to build docs into the local site folder, run the following command: $ make docs-build At this point, you can serve the docs to view them locally using $ make docs-serve Lastly, to build and publish docs to Github Pages, use $ make docs-publish","title":"Build and Publish Documentation"},{"location":"05-internals/development/building-and-running/#build-and-publish-docker-images","text":"To build and publish all Docker images locally $ make docker-build To publish all Docker images to Dockerhub $ make docker-publish","title":"Build and Publish Docker Images"},{"location":"05-internals/development/building-and-running/#load-testing-on-mac-os-x","text":"To test Knora with many concurrent connections on Mac OS X, you will need to adjust some kernel parameters to allow more open connections, to recycle ephemeral ports more quickly, and to use a wider range of ephemeral port numbers. The script webapi/scripts/macOS-kernel-test-config.sh will do this.","title":"Load Testing on Mac OS X"},{"location":"05-internals/development/building-and-running/#continuous-integration","text":"For continuous integration testing, we use Github CI Actions. Every commit pushed to the git repository or every pull request, triggers the build. Additionally, in Github there is a small checkmark beside every commit, signaling the status of the build (successful, unsuccessful, ongoing). The build that is executed on Github CI Actions is defined in .github/workflows/main.yml .","title":"Continuous Integration"},{"location":"05-internals/development/building-and-running/#webapi-server-startup-flags","text":"The Webapi-Server can be started with a number of flags.","title":"Webapi Server Startup-Flags"},{"location":"05-internals/development/building-and-running/#loaddemodata-flag","text":"When the webapi-server is started with the loadDemoData flag, then at startup, the data which is configured in application.conf under the app.triplestore.rdf-data key is loaded into the triplestore, and any data in the triplestore is removed beforehand.","title":"loadDemoData - Flag"},{"location":"05-internals/development/building-and-running/#allowreloadoverhttp-flag","text":"When the webapi.server is started with the allowReloadOverHTTP flag ( reStart -r ), then the v1/store/ResetTriplestoreContent route is activated. This route accepts a POST request, with a JSON payload consisting of the following example content: [ { \"path\": \"knora-ontologies/knora-base.ttl\", \"name\": \"http://www.knora.org/ontology/knora-base\" }, { \"path\": \"knora-ontologies/salsah-gui.ttl\", \"name\": \"http://www.knora.org/ontology/salsah-gui\" }, { \"path\": \"test_data/ontologies/incunabula-onto.ttl\", \"name\": \"http://www.knora.org/ontology/0803/incunabula\" }, { \"path\": \"test_data/all_data/incunabula-data.ttl\", \"name\": \"http://www.knora.org/data/incunabula\" } ] This content corresponds to the payload sent with the ResetTriplestoreContent message, defined inside the org.knora.webapi.messages.v1.store.triplestoremessages package. The path being the relative path to the ttl file which will be loaded into a named graph by the name of name .","title":"allowReloadOverHTTP - Flag"},{"location":"05-internals/development/docker-cheat-sheet/","text":"Docker Cheat Sheet A complete cheat sheet can be found here Lifecycle docker create creates a container but does not start it. docker run creates and starts a container in one operation. docker rename allows the container to be renamed. docker rm deletes a container. docker update updates a container's resource limits. If you want a transient container, docker run --rm will remove the container after it stops. If you want to map a directory on the host to a docker container, docker run -v $HOSTDIR:$DOCKERDIR . Starting and Stopping docker start starts a container so it is running. docker stop stops a running container. docker restart stops and starts a container. docker pause pauses a running container, \"freezing\" it in place. docker attach will connect to a running container. Info docker ps shows running containers. docker logs gets logs from container. (You can use a custom log driver, but logs is only available for json-file and journald in 1.10) docker inspect looks at all the info on a container (including IP address). docker events gets events from container. docker port shows public facing port of container. docker top shows running processes in container. docker stats shows containers' resource usage statistics. docker diff shows changed files in the container's FS. docker ps -a shows running and stopped containers. docker stats --all shows a running list of containers. Executing Commands docker exec to execute a command in container. To enter a running container, attach a new shell process to a running container called foo, use: docker exec -it foo /bin/bash . Images docker images shows all images. docker build creates image from Dockerfile.","title":"Docker Cheat Sheet"},{"location":"05-internals/development/docker-cheat-sheet/#docker-cheat-sheet","text":"A complete cheat sheet can be found here","title":"Docker Cheat Sheet"},{"location":"05-internals/development/docker-cheat-sheet/#lifecycle","text":"docker create creates a container but does not start it. docker run creates and starts a container in one operation. docker rename allows the container to be renamed. docker rm deletes a container. docker update updates a container's resource limits. If you want a transient container, docker run --rm will remove the container after it stops. If you want to map a directory on the host to a docker container, docker run -v $HOSTDIR:$DOCKERDIR .","title":"Lifecycle"},{"location":"05-internals/development/docker-cheat-sheet/#starting-and-stopping","text":"docker start starts a container so it is running. docker stop stops a running container. docker restart stops and starts a container. docker pause pauses a running container, \"freezing\" it in place. docker attach will connect to a running container.","title":"Starting and Stopping"},{"location":"05-internals/development/docker-cheat-sheet/#info","text":"docker ps shows running containers. docker logs gets logs from container. (You can use a custom log driver, but logs is only available for json-file and journald in 1.10) docker inspect looks at all the info on a container (including IP address). docker events gets events from container. docker port shows public facing port of container. docker top shows running processes in container. docker stats shows containers' resource usage statistics. docker diff shows changed files in the container's FS. docker ps -a shows running and stopped containers. docker stats --all shows a running list of containers.","title":"Info"},{"location":"05-internals/development/docker-cheat-sheet/#executing-commands","text":"docker exec to execute a command in container. To enter a running container, attach a new shell process to a running container called foo, use: docker exec -it foo /bin/bash .","title":"Executing Commands"},{"location":"05-internals/development/docker-cheat-sheet/#images","text":"docker images shows all images. docker build creates image from Dockerfile.","title":"Images"},{"location":"05-internals/development/docker-compose/","text":"Starting the Knora Stack inside Docker Container To run Knora locally, we provide docker-compose.yml which can be used to start Fuseki, Sipi, Webapi running each in its own Docker container. To run the whole stack: $ make stack-up For additional information please see the Docker Compose documentation","title":"Starting the DSP-Stack inside Docker Container"},{"location":"05-internals/development/docker-compose/#starting-the-knora-stack-inside-docker-container","text":"To run Knora locally, we provide docker-compose.yml which can be used to start Fuseki, Sipi, Webapi running each in its own Docker container. To run the whole stack: $ make stack-up For additional information please see the Docker Compose documentation","title":"Starting the Knora Stack inside Docker Container"},{"location":"05-internals/development/generating-client-test-data/","text":"Generating Client Test Data Requirements Generate test requests and responses for Knora's routes, to be used in testing client code without the need for a running Knora instance. Implementation Client test data is generated as a side effect of running E2E tests. E2E tests use ClientTestDataCollector to collect API requests and responses. The implementation of ClientTestDataCollector collects these in a Redis hash. When the E2E tests have completed, the script webapi/scripts/dump-client-test-data.sh saves the collected test data in a Zip file. It then checks the filenames in the Zip file by comparing them with the list in webapi/scripts/expected-client-test-data.txt . Usage On macOS, you will need to install Redis in order to have the redis-cli command-line tool: brew install redis To generate client test data, type: make client-test-data When the tests have finished running, you will find the file client-test-data.zip in the current directory. Then, run this script to update the list of expected test data files: webapi/scripts/update-expected-client-test-data.sh client-test-data.zip","title":"Generating Client Test Data"},{"location":"05-internals/development/generating-client-test-data/#generating-client-test-data","text":"","title":"Generating Client Test Data"},{"location":"05-internals/development/generating-client-test-data/#requirements","text":"Generate test requests and responses for Knora's routes, to be used in testing client code without the need for a running Knora instance.","title":"Requirements"},{"location":"05-internals/development/generating-client-test-data/#implementation","text":"Client test data is generated as a side effect of running E2E tests. E2E tests use ClientTestDataCollector to collect API requests and responses. The implementation of ClientTestDataCollector collects these in a Redis hash. When the E2E tests have completed, the script webapi/scripts/dump-client-test-data.sh saves the collected test data in a Zip file. It then checks the filenames in the Zip file by comparing them with the list in webapi/scripts/expected-client-test-data.txt .","title":"Implementation"},{"location":"05-internals/development/generating-client-test-data/#usage","text":"On macOS, you will need to install Redis in order to have the redis-cli command-line tool: brew install redis To generate client test data, type: make client-test-data When the tests have finished running, you will find the file client-test-data.zip in the current directory. Then, run this script to update the list of expected test data files: webapi/scripts/update-expected-client-test-data.sh client-test-data.zip","title":"Usage"},{"location":"05-internals/development/monitoring/","text":"Monitoring Knora Monitoring is implemented by using the Prometheus / Grafana stack. Usage: 1) Start webapi with the necessary -p option (e.g., from inside sbt: run -p or reStart -p 2) Start the monitoring stack by executing the following line inside the monitoring folder: $ WEBAPIHOST=<YourLocalIP> ADMIN_USER=admin ADMIN_PASSWORD=admin docker-compose up -d 3) Head over to localhost:3000, log in using the admin username and password, and open the \"Webapi Akka Actor System\" dashboard. 4) To shut down the monitoring stack, run the following line inside the monitoring folder: $ docker-compose down","title":"Monitoring DSP-API"},{"location":"05-internals/development/monitoring/#monitoring-knora","text":"Monitoring is implemented by using the Prometheus / Grafana stack.","title":"Monitoring Knora"},{"location":"05-internals/development/monitoring/#usage","text":"1) Start webapi with the necessary -p option (e.g., from inside sbt: run -p or reStart -p 2) Start the monitoring stack by executing the following line inside the monitoring folder: $ WEBAPIHOST=<YourLocalIP> ADMIN_USER=admin ADMIN_PASSWORD=admin docker-compose up -d 3) Head over to localhost:3000, log in using the admin username and password, and open the \"Webapi Akka Actor System\" dashboard. 4) To shut down the monitoring stack, run the following line inside the monitoring folder: $ docker-compose down","title":"Usage:"},{"location":"05-internals/development/overview/","text":"Overview Developing for DSP-API requires a complete local installation of Knora. The different parts are: The cloned DSP-API Github repository Fuseki - supplied triplestore in the DSP-API Github repository. Sipi by building from source or using the docker image Knora Github Repository $ git clone https://github.com/dasch-swiss/dsp-api Triplestore A number of triplestore implementations are available, including free software as well as proprietary options. DSP-API is designed to work with any standards-compliant triplestore. It is primarily tested with Apache Jena Fuseki . Sipi Build Sipi Docker Image The Sipi docker image needs to be build by hand, as it requires the Kakadu distribution. To build the image, and push it to the docker hub, follow the following steps: $ git clone https://github.com/dhlab-basel/docker-sipi (copy the Kakadu distribution ``v7_8-01382N.zip`` to the ``docker-sipi`` directory) $ docker build -t daschswiss/sipi $ docker run --name sipi --rm -it -p 1024:1024 daschswiss/sipi (Ctrl-c out of terminal will stop and delete container) $ docker push daschswiss/sipi Pushing the image to the docker hub requires prior authentication with $ docker login . The user needs to be registered on hub.docker.com . Also, the user needs to be allowed to push to the dblabbasel organisation. Running Sipi To use the docker image stored locally or on the docker hub repository type: $ docker run --name sipi -d -p 1024:1024 daschswiss/sipi This will create and start a docker container with the daschswiss/sipi image in the background. The default behaviour is to start Sipi by calling the following command: $ /sipi/local/bin/sipi -config /sipi/config/sipi.test-config.lua To override this default behaviour, start the container by supplying another config file: $ docker run --name sipi \\ -d \\ -p 1024:1024 \\ daschswiss/sipi \\ /sipi/local/bin/sipi -config /sipi/config/sipi.config.lua You can also mount a directory (the local directory in this example), and use a config file that is outside of the docker container: $ docker run --name sipi \\ -d \\ -p 1024:1024 \\ -v $PWD:/localdir \\ daschswiss/sipi \\ /sipi/local/bin/sipi -config /localdir/sipi.test-config.lua Redis Server The DSP-API server uses Redis for caching. On macOS you can install Redis through Homebrew : $ brew install redis If you don't want to use Redis, you can disable caching in application.conf via the app.use-redis-cache key, by setting it to false .","title":"Overview"},{"location":"05-internals/development/overview/#overview","text":"Developing for DSP-API requires a complete local installation of Knora. The different parts are: The cloned DSP-API Github repository Fuseki - supplied triplestore in the DSP-API Github repository. Sipi by building from source or using the docker image","title":"Overview"},{"location":"05-internals/development/overview/#knora-github-repository","text":"$ git clone https://github.com/dasch-swiss/dsp-api","title":"Knora Github Repository"},{"location":"05-internals/development/overview/#triplestore","text":"A number of triplestore implementations are available, including free software as well as proprietary options. DSP-API is designed to work with any standards-compliant triplestore. It is primarily tested with Apache Jena Fuseki .","title":"Triplestore"},{"location":"05-internals/development/overview/#sipi","text":"","title":"Sipi"},{"location":"05-internals/development/overview/#build-sipi-docker-image","text":"The Sipi docker image needs to be build by hand, as it requires the Kakadu distribution. To build the image, and push it to the docker hub, follow the following steps: $ git clone https://github.com/dhlab-basel/docker-sipi (copy the Kakadu distribution ``v7_8-01382N.zip`` to the ``docker-sipi`` directory) $ docker build -t daschswiss/sipi $ docker run --name sipi --rm -it -p 1024:1024 daschswiss/sipi (Ctrl-c out of terminal will stop and delete container) $ docker push daschswiss/sipi Pushing the image to the docker hub requires prior authentication with $ docker login . The user needs to be registered on hub.docker.com . Also, the user needs to be allowed to push to the dblabbasel organisation.","title":"Build Sipi Docker Image"},{"location":"05-internals/development/overview/#running-sipi","text":"To use the docker image stored locally or on the docker hub repository type: $ docker run --name sipi -d -p 1024:1024 daschswiss/sipi This will create and start a docker container with the daschswiss/sipi image in the background. The default behaviour is to start Sipi by calling the following command: $ /sipi/local/bin/sipi -config /sipi/config/sipi.test-config.lua To override this default behaviour, start the container by supplying another config file: $ docker run --name sipi \\ -d \\ -p 1024:1024 \\ daschswiss/sipi \\ /sipi/local/bin/sipi -config /sipi/config/sipi.config.lua You can also mount a directory (the local directory in this example), and use a config file that is outside of the docker container: $ docker run --name sipi \\ -d \\ -p 1024:1024 \\ -v $PWD:/localdir \\ daschswiss/sipi \\ /sipi/local/bin/sipi -config /localdir/sipi.test-config.lua","title":"Running Sipi"},{"location":"05-internals/development/overview/#redis-server","text":"The DSP-API server uses Redis for caching. On macOS you can install Redis through Homebrew : $ brew install redis If you don't want to use Redis, you can disable caching in application.conf via the app.use-redis-cache key, by setting it to false .","title":"Redis Server"},{"location":"05-internals/development/testing/","text":"Testing How to Write Unit Tests 1) Inside a test, at the beginning, add the following (change the paths to the test data as needed): val rdfDataObjects = List ( RdfDataObject(path = \"test_data/responders.v1.ValuesResponderV1Spec/incunabula-data.ttl\", name = \"http://www.knora.org/data/incunabula\") ) The data will be automatically loaded before any tests are executed. These tests should be stored inside the src/test folder hierarchy. 2) Call the test from terminal: $ make test-unit $ make test-e2e How to Write Integration Tests The only difference between Integration and Unit tests is the location where they are stored and the way how they are called: 1) Store tests inside the src/it folder hierarchy. 2) Call the tests from the terminal: make test-it","title":"Testing"},{"location":"05-internals/development/testing/#testing","text":"","title":"Testing"},{"location":"05-internals/development/testing/#how-to-write-unit-tests","text":"1) Inside a test, at the beginning, add the following (change the paths to the test data as needed): val rdfDataObjects = List ( RdfDataObject(path = \"test_data/responders.v1.ValuesResponderV1Spec/incunabula-data.ttl\", name = \"http://www.knora.org/data/incunabula\") ) The data will be automatically loaded before any tests are executed. These tests should be stored inside the src/test folder hierarchy. 2) Call the test from terminal: $ make test-unit $ make test-e2e","title":"How to Write Unit Tests"},{"location":"05-internals/development/testing/#how-to-write-integration-tests","text":"The only difference between Integration and Unit tests is the location where they are stored and the way how they are called: 1) Store tests inside the src/it folder hierarchy. 2) Call the tests from the terminal: make test-it","title":"How to Write Integration Tests"},{"location":"05-internals/development/third-party/","text":"Third-Party Dependencies Third party libraries are managed by SBT. Defining Dependencies in Dependencies.scala Within the build.sbt file, the Dependencies package is referenced, which is located in project/Dependencies.scala . All third party dependencies need to be declared there. Referencing a third party library There is an object Dependencies where each library should be declared in a val . val akkaHttpCors = \"ch.megard\" %% \"akka-http-cors\" % \"1.0.0\" The first string corresponds to the group/organization in the library's maven artefact, the second string corresponds to the artefact ID and the third string defines the version. The strings are combined with % or %% operators, the latter fixing the dependency to the specified scala-version. It is also possible to use variables in these definitions, e.g. if multiple dependencies share a version number: val ZioVersion = \"2.0.0-RC2\" val zio = \"dev.zio\" %% \"zio\" % ZioVersion val zioTest = \"dev.zio\" %% \"zio-test\" % ZioVersion Assigning the dependencies to a specific subproject For each SBT project, there is one Seq in the Dependencies object. In order to make use of the declared dependencies, they must be referred to in the Seq of the respective subproject. val webapiLibraryDependencies = Seq( akkaActor, akkaHttp, akkaSlf4j % Runtime, akkaHttpTestkit % Test, ... ) By default, the dependencies will be scoped to compile time. But it's possible to override this to Runtime or Test . Docker Image Versions The required Docker image versions of Sipi and Fuseki are also defined in the Dependencies.scala file.","title":"Third-Party Dependencies"},{"location":"05-internals/development/third-party/#third-party-dependencies","text":"Third party libraries are managed by SBT.","title":"Third-Party Dependencies"},{"location":"05-internals/development/third-party/#defining-dependencies-in-dependenciesscala","text":"Within the build.sbt file, the Dependencies package is referenced, which is located in project/Dependencies.scala . All third party dependencies need to be declared there.","title":"Defining Dependencies in Dependencies.scala"},{"location":"05-internals/development/third-party/#referencing-a-third-party-library","text":"There is an object Dependencies where each library should be declared in a val . val akkaHttpCors = \"ch.megard\" %% \"akka-http-cors\" % \"1.0.0\" The first string corresponds to the group/organization in the library's maven artefact, the second string corresponds to the artefact ID and the third string defines the version. The strings are combined with % or %% operators, the latter fixing the dependency to the specified scala-version. It is also possible to use variables in these definitions, e.g. if multiple dependencies share a version number: val ZioVersion = \"2.0.0-RC2\" val zio = \"dev.zio\" %% \"zio\" % ZioVersion val zioTest = \"dev.zio\" %% \"zio-test\" % ZioVersion","title":"Referencing a third party library"},{"location":"05-internals/development/third-party/#assigning-the-dependencies-to-a-specific-subproject","text":"For each SBT project, there is one Seq in the Dependencies object. In order to make use of the declared dependencies, they must be referred to in the Seq of the respective subproject. val webapiLibraryDependencies = Seq( akkaActor, akkaHttp, akkaSlf4j % Runtime, akkaHttpTestkit % Test, ... ) By default, the dependencies will be scoped to compile time. But it's possible to override this to Runtime or Test .","title":"Assigning the dependencies to a specific subproject"},{"location":"05-internals/development/third-party/#docker-image-versions","text":"The required Docker image versions of Sipi and Fuseki are also defined in the Dependencies.scala file.","title":"Docker Image Versions"},{"location":"05-internals/development/updating-repositories/","text":"Updating Repositories Requirements When a new version of Knora requires an existing repository to be updated, do this automatically when Knora starts, if possible. Make the update process as fast as possible, with some indication of progress as it runs. Design As explained in Knora Ontology Versions , the knora-base ontology contains a version string to ensure compatibility between a repository and a given version of Knora. The same version string is therefore hard-coded in the Knora source code, in the string constant org.knora.webapi.KnoraBaseVersion . For new pull requests, the format of this string is knora-base vN , where N is an integer that is incremented for each version. During Knora's startup process, ApplicationActor sends an UpdateRepositoryRequest message to the StoreManager , which forwards it to TriplestoreManager , which delegates it to org.knora.webapi.store.triplestore.upgrade.RepositoryUpdater . RepositoryUpdater does the following procedure: Check the knora-base version string in the repository. Consult org.knora.webapi.store.triplestore.upgrade.RepositoryUpdatePlan to see which transformations are needed. Download the entire repository from the triplestore into an N-Quads file. Read the N-Quads file into an RdfModel . Update the RdfModel by running the necessary transformations, and replacing the built-in DSP ontologies with the current ones. Save the RdfModel to a new N-Quads file. Empty the repository in the triplestore. Upload the transformed repository file to the triplestore. To update the RdfModel , RepositoryUpdater runs a sequence of upgrade plugins, each of which is a class in org.knora.webapi.store.triplestore.upgrade.plugins and is registered in RepositoryUpdatePlan . Design Rationale We tried and rejected several other designs: Running SPARQL updates in the triplestore: too slow, and no way to report progress during the update. Downloading the repository and transforming it in Python using rdflib : too slow. Downloading the repository and transforming it in C++ using Redland : also too slow. The Scala implementation is the fastest by far. The whole repository is uploaded in a single transaction, rather than uploading one named graph at a time, because GraphDB's consistency checker can enforce dependencies between named graphs. Adding an Upgrade Plugin Each time a pull request introduces changes that are not compatible with existing data, the following must happen: The knora-base version number must be incremented in knora-base.ttl and in the string constant org.knora.webapi.KnoraBaseVersion . A plugin must be added in the package org.knora.webapi.store.triplestore.upgrade.plugins , to transform existing repositories so that they are compatible with the code changes introduced in the pull request. Each new plugin must be registered by adding it to the sequence returned by RepositoryUpdatePlan.makePluginsForVersions . The order of version numbers (and the plugins) must correspond to the order in which the pull requests are merged. An upgrade plugin is a Scala class that extends UpgradePlugin . The name of the plugin class should refer to the pull request that made the transformation necessary, using the format UpgradePluginPRNNNN , where NNNN is the number of the pull request. A plugin's transform method takes an RdfModel (a mutable object representing the repository) and modifies it as needed. Before transforming the data, a plugin can check whether a required manual transformation has been carried out. If the requirement is not met, the plugin can throw InconsistentRepositoryDataException to abort the upgrade process. Testing Update Plugins Each plugin should have a unit test that extends UpgradePluginSpec . A typical test loads a file containing RDF test data into a RdfModel , runs the plugin, makes an RdfRepository containing the transformed RdfModel , and uses SPARQL to check the result.","title":"Updating Repositories"},{"location":"05-internals/development/updating-repositories/#updating-repositories","text":"","title":"Updating Repositories"},{"location":"05-internals/development/updating-repositories/#requirements","text":"When a new version of Knora requires an existing repository to be updated, do this automatically when Knora starts, if possible. Make the update process as fast as possible, with some indication of progress as it runs.","title":"Requirements"},{"location":"05-internals/development/updating-repositories/#design","text":"As explained in Knora Ontology Versions , the knora-base ontology contains a version string to ensure compatibility between a repository and a given version of Knora. The same version string is therefore hard-coded in the Knora source code, in the string constant org.knora.webapi.KnoraBaseVersion . For new pull requests, the format of this string is knora-base vN , where N is an integer that is incremented for each version. During Knora's startup process, ApplicationActor sends an UpdateRepositoryRequest message to the StoreManager , which forwards it to TriplestoreManager , which delegates it to org.knora.webapi.store.triplestore.upgrade.RepositoryUpdater . RepositoryUpdater does the following procedure: Check the knora-base version string in the repository. Consult org.knora.webapi.store.triplestore.upgrade.RepositoryUpdatePlan to see which transformations are needed. Download the entire repository from the triplestore into an N-Quads file. Read the N-Quads file into an RdfModel . Update the RdfModel by running the necessary transformations, and replacing the built-in DSP ontologies with the current ones. Save the RdfModel to a new N-Quads file. Empty the repository in the triplestore. Upload the transformed repository file to the triplestore. To update the RdfModel , RepositoryUpdater runs a sequence of upgrade plugins, each of which is a class in org.knora.webapi.store.triplestore.upgrade.plugins and is registered in RepositoryUpdatePlan .","title":"Design"},{"location":"05-internals/development/updating-repositories/#design-rationale","text":"We tried and rejected several other designs: Running SPARQL updates in the triplestore: too slow, and no way to report progress during the update. Downloading the repository and transforming it in Python using rdflib : too slow. Downloading the repository and transforming it in C++ using Redland : also too slow. The Scala implementation is the fastest by far. The whole repository is uploaded in a single transaction, rather than uploading one named graph at a time, because GraphDB's consistency checker can enforce dependencies between named graphs.","title":"Design Rationale"},{"location":"05-internals/development/updating-repositories/#adding-an-upgrade-plugin","text":"Each time a pull request introduces changes that are not compatible with existing data, the following must happen: The knora-base version number must be incremented in knora-base.ttl and in the string constant org.knora.webapi.KnoraBaseVersion . A plugin must be added in the package org.knora.webapi.store.triplestore.upgrade.plugins , to transform existing repositories so that they are compatible with the code changes introduced in the pull request. Each new plugin must be registered by adding it to the sequence returned by RepositoryUpdatePlan.makePluginsForVersions . The order of version numbers (and the plugins) must correspond to the order in which the pull requests are merged. An upgrade plugin is a Scala class that extends UpgradePlugin . The name of the plugin class should refer to the pull request that made the transformation necessary, using the format UpgradePluginPRNNNN , where NNNN is the number of the pull request. A plugin's transform method takes an RdfModel (a mutable object representing the repository) and modifies it as needed. Before transforming the data, a plugin can check whether a required manual transformation has been carried out. If the requirement is not met, the plugin can throw InconsistentRepositoryDataException to abort the upgrade process.","title":"Adding an Upgrade Plugin"},{"location":"05-internals/development/updating-repositories/#testing-update-plugins","text":"Each plugin should have a unit test that extends UpgradePluginSpec . A typical test loads a file containing RDF test data into a RdfModel , runs the plugin, makes an RdfRepository containing the transformed RdfModel , and uses SPARQL to check the result.","title":"Testing Update Plugins"},{"location":"05-internals/development/vscode-config/","text":"Setup Visual Studio Code for development of DSP-API To have full functionality, the Scala Metals plugin should be installed. Additionally, a number of plugins can be installed for convenience, but are not required. Those include but are by no means limited to: - Docker - to attach to running docker containers - Stardog RDF grammar - TTL syntax highlighting - Lua - REST client - ... Formatter As a formatter, we use Scalafmt . Metals automatically recognizes the formatting configuration in the .scalafmt.conf file in the root directory. VSCode should be configured so that it austomatically formats (e.g. on file saved). Running Tests The tests can be run through make commands or through SBT. The most convenient way to run the tests is through VSCode. Metals recognizes scalatest suits and lets you run them in the text explorer: Or with the setting \"metals.testUserInterface\": \"Code Lenses\" directly in the text: Debugger It is currently not possible to start the stack in debug mode. Tests can be run in debug mode by running them as described above but choosing debug test instead of test .","title":"Setup Visual Studio Code for development of DSP-API"},{"location":"05-internals/development/vscode-config/#setup-visual-studio-code-for-development-of-dsp-api","text":"To have full functionality, the Scala Metals plugin should be installed. Additionally, a number of plugins can be installed for convenience, but are not required. Those include but are by no means limited to: - Docker - to attach to running docker containers - Stardog RDF grammar - TTL syntax highlighting - Lua - REST client - ...","title":"Setup Visual Studio Code for development of DSP-API"},{"location":"05-internals/development/vscode-config/#formatter","text":"As a formatter, we use Scalafmt . Metals automatically recognizes the formatting configuration in the .scalafmt.conf file in the root directory. VSCode should be configured so that it austomatically formats (e.g. on file saved).","title":"Formatter"},{"location":"05-internals/development/vscode-config/#running-tests","text":"The tests can be run through make commands or through SBT. The most convenient way to run the tests is through VSCode. Metals recognizes scalatest suits and lets you run them in the text explorer: Or with the setting \"metals.testUserInterface\": \"Code Lenses\" directly in the text:","title":"Running Tests"},{"location":"05-internals/development/vscode-config/#debugger","text":"It is currently not possible to start the stack in debug mode. Tests can be run in debug mode by running them as described above but choosing debug test instead of test .","title":"Debugger"},{"location":"06-sipi/","text":"The Sipi Media Server Sipi is a high-performance media server written in C++, for serving and converting binary media files such as images and video. Sipi can efficiently convert between many different formats on demand, preserving embedded metadata, and implements the International Image Interoperability Framework (IIIF) . DSP-API is designed to use Sipi for converting and serving media files. Setting Up Sipi for DSP-API Interaction Between Sipi and DSP-API","title":"Index"},{"location":"06-sipi/#the-sipi-media-server","text":"Sipi is a high-performance media server written in C++, for serving and converting binary media files such as images and video. Sipi can efficiently convert between many different formats on demand, preserving embedded metadata, and implements the International Image Interoperability Framework (IIIF) . DSP-API is designed to use Sipi for converting and serving media files. Setting Up Sipi for DSP-API Interaction Between Sipi and DSP-API","title":"The Sipi Media Server"},{"location":"06-sipi/setup-sipi-for-dsp-api/","text":"Setting Up Sipi for DSP-API Setup and Execution In order to serve files to the client application like the Salsah GUI, Sipi must be set up and running. Sipi can be downloaded from its own GitHub repository: https://github.com/dasch-swiss/sipi (which requires building from source), or the published docker image . can be used. To start Sipi, run the following command from inside the sipi/ folder: $ export DOCKERHOST=LOCAL_IP_ADDRESS $ docker image rm --force daschswiss/sipi:main // deletes cached image and needs only to be used when newer image is available on dockerhub $ docker run --rm -it --add-host webapihost:$DOCKERHOST -v $PWD/config:/sipi/config -v $PWD/scripts:/sipi/scripts -v /tmp:/tmp -v $HOME:$HOME -p 1024:1024 daschswiss/sipi:main --config=/sipi/config/sipi.docker-config.lua where LOCAL_IP_ADDRESS is the IP of the host running DSP-API . --config=/sipi/config/sipi.docker-config.lua . Please see sipi.docker-config.lua for the settings like URL, port number etc. These settings need to be set according to DSP-API's application.conf . If you use the default settings both in Sipi and DSP-API, there is no need to change these settings. Whenever a file is requested from Sipi (e.g. a browser trying to dereference an image link served by DSP-API), a preflight function is called. This function is defined in sipi.init.lua present in the Sipi root directory. It takes three parameters: prefix , identifier (the name of the requested file), and cookie . The prefix is the shortcode of the project that the resource containing the file value belongs to. Given this information, Sipi asks the API about the current user's permissions on the given file. The cookie contains the current user's session id, so the API can match Sipi's request with a given user profile and determine the permissions this user has on the file. If the response grants sufficient permissions, the file is served in the requested quality. If the user has preview rights, Sipi serves the file in reduced quality or integrates a watermark. If the user has no permissions, Sipi refuses to serve the file. However, all of this behaviour is defined in the preflight function in Sipi and not controlled by the API. DSP-API only provides the permission code. See Authentication of Users with Sipi for more information about sharing the session ID. Using Sipi in Test Mode If you just want to test Sipi with DSP-API without serving the actual files (e.g. when executing browser tests), you can simply start Sipi like this: $ export DOCKERHOST=LOCAL_IP_ADDRESS $ docker image rm --force daschswiss/sipi:main // deletes cached image and needs only to be used when newer image is available on dockerhub $ docker run --rm -it --add-host webapihost:$DOCKERHOST -v $PWD/config:/sipi/config -v $PWD/scripts:/sipi/scripts -v /tmp:/tmp -v $HOME:$HOME -p 1024:1024 daschswiss/sipi:main --config=/sipi/config/sipi.docker-test-config.lua Then always the same test file will be served which is delivered with Sipi. In test mode, Sipi will not ask DSP-API about the user's permission on the requested file. Additional Sipi Environment Variables Additionally, these environment variables can be used to further configure Sipi: SIPI_WEBAPI_HOSTNAME=localhost : overrides knora_path in Sipi's config SIPI_WEBAPI_PORT=3333 : overrides knora_port in Sipi's config These variables need to be explicitly used like in sipi.init.lua : -- -- Allows to set SIPI_WEBAPI_HOSTNAME environment variable and use its value. -- local webapi_hostname = os.getenv(\"SIPI_WEBAPI_HOSTNAME\") if webapi_hostname == nil then webapi_hostname = config.knora_path end server.log(\"webapi_hostname: \" .. webapi_hostname, server.loglevel.LOG_DEBUG) -- -- Allows to set SIPI_WEBAPI_PORT environment variable and use its value. -- local webapi_port = os.getenv(\"SIPI_WEBAPI_PORT\") if webapi_port == nil then webapi_port = config.knora_port end server.log(\"webapi_port: \" .. webapi_port, server.loglevel.LOG_DEBUG) knora_url = 'http://' .. webapi_hostname .. ':' .. webapi_port .. '/admin/files/' .. prefix .. '/' .. identifier","title":"Setting Up Sipi for DSP-API"},{"location":"06-sipi/setup-sipi-for-dsp-api/#setting-up-sipi-for-dsp-api","text":"","title":"Setting Up Sipi for DSP-API"},{"location":"06-sipi/setup-sipi-for-dsp-api/#setup-and-execution","text":"In order to serve files to the client application like the Salsah GUI, Sipi must be set up and running. Sipi can be downloaded from its own GitHub repository: https://github.com/dasch-swiss/sipi (which requires building from source), or the published docker image . can be used. To start Sipi, run the following command from inside the sipi/ folder: $ export DOCKERHOST=LOCAL_IP_ADDRESS $ docker image rm --force daschswiss/sipi:main // deletes cached image and needs only to be used when newer image is available on dockerhub $ docker run --rm -it --add-host webapihost:$DOCKERHOST -v $PWD/config:/sipi/config -v $PWD/scripts:/sipi/scripts -v /tmp:/tmp -v $HOME:$HOME -p 1024:1024 daschswiss/sipi:main --config=/sipi/config/sipi.docker-config.lua where LOCAL_IP_ADDRESS is the IP of the host running DSP-API . --config=/sipi/config/sipi.docker-config.lua . Please see sipi.docker-config.lua for the settings like URL, port number etc. These settings need to be set according to DSP-API's application.conf . If you use the default settings both in Sipi and DSP-API, there is no need to change these settings. Whenever a file is requested from Sipi (e.g. a browser trying to dereference an image link served by DSP-API), a preflight function is called. This function is defined in sipi.init.lua present in the Sipi root directory. It takes three parameters: prefix , identifier (the name of the requested file), and cookie . The prefix is the shortcode of the project that the resource containing the file value belongs to. Given this information, Sipi asks the API about the current user's permissions on the given file. The cookie contains the current user's session id, so the API can match Sipi's request with a given user profile and determine the permissions this user has on the file. If the response grants sufficient permissions, the file is served in the requested quality. If the user has preview rights, Sipi serves the file in reduced quality or integrates a watermark. If the user has no permissions, Sipi refuses to serve the file. However, all of this behaviour is defined in the preflight function in Sipi and not controlled by the API. DSP-API only provides the permission code. See Authentication of Users with Sipi for more information about sharing the session ID.","title":"Setup and Execution"},{"location":"06-sipi/setup-sipi-for-dsp-api/#using-sipi-in-test-mode","text":"If you just want to test Sipi with DSP-API without serving the actual files (e.g. when executing browser tests), you can simply start Sipi like this: $ export DOCKERHOST=LOCAL_IP_ADDRESS $ docker image rm --force daschswiss/sipi:main // deletes cached image and needs only to be used when newer image is available on dockerhub $ docker run --rm -it --add-host webapihost:$DOCKERHOST -v $PWD/config:/sipi/config -v $PWD/scripts:/sipi/scripts -v /tmp:/tmp -v $HOME:$HOME -p 1024:1024 daschswiss/sipi:main --config=/sipi/config/sipi.docker-test-config.lua Then always the same test file will be served which is delivered with Sipi. In test mode, Sipi will not ask DSP-API about the user's permission on the requested file.","title":"Using Sipi in Test Mode"},{"location":"06-sipi/setup-sipi-for-dsp-api/#additional-sipi-environment-variables","text":"Additionally, these environment variables can be used to further configure Sipi: SIPI_WEBAPI_HOSTNAME=localhost : overrides knora_path in Sipi's config SIPI_WEBAPI_PORT=3333 : overrides knora_port in Sipi's config These variables need to be explicitly used like in sipi.init.lua : -- -- Allows to set SIPI_WEBAPI_HOSTNAME environment variable and use its value. -- local webapi_hostname = os.getenv(\"SIPI_WEBAPI_HOSTNAME\") if webapi_hostname == nil then webapi_hostname = config.knora_path end server.log(\"webapi_hostname: \" .. webapi_hostname, server.loglevel.LOG_DEBUG) -- -- Allows to set SIPI_WEBAPI_PORT environment variable and use its value. -- local webapi_port = os.getenv(\"SIPI_WEBAPI_PORT\") if webapi_port == nil then webapi_port = config.knora_port end server.log(\"webapi_port: \" .. webapi_port, server.loglevel.LOG_DEBUG) knora_url = 'http://' .. webapi_hostname .. ':' .. webapi_port .. '/admin/files/' .. prefix .. '/' .. identifier","title":"Additional Sipi Environment Variables"},{"location":"06-sipi/sipi-and-dsp-api/","text":"Interaction Between Sipi and DSP-API General Remarks DSP-API and Sipi (Simple Image Presentation Interface) are two complementary software projects. Whereas DSP-API deals with data that is written to and read from a triplestore (metadata and annotations), Sipi takes care of storing, converting and serving image files as well as other types of files such as audio, video, or documents (binary files it just stores and serves). DSP-API and Sipi stick to a clear division of responsibility regarding files: DSP-API knows about the names of files that are attached to resources as well as some metadata and is capable of creating the URLs for the client to request them from Sipi, but the whole handling of files (storing, naming, organization of the internal directory structure, format conversions, and serving) is taken care of by Sipi. Adding Files to DSP A file is first uploaded to Sipi, then its metadata is submitted to DSP. The implementation of this procedure is described in DSP-API and Sipi . Instructions for the client are given in Creating File Values (for DSP-API v2) and in Adding Resources with Image Files (for API v1). Retrieving Files from Sipi File URLs in API v2 In DSP-API v2, image file URLs are provided in IIIF format. In the simple ontology schema , a file value is simply a IIIF URL that can be used to retrieve the file from Sipi. In the complex schema, it is a StillImageFileValue with additional properties that the client can use to construct different IIIF URLs, e.g. at different resolutions. See the knora-api ontology for details. File URLs in API v1 In API v1, for each file value, DSP-API creates several Sipi URLs for accessing the file at different resolutions: \"resinfo\": { \"locations\": [ { \"duration\": \u200b0, \"nx\": \u200b95, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jpg/full/max/0/default.jpg\", \"ny\": \u200b128, \"fps\": \u200b0, \"format_name\": \"JPEG\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" }, { \"duration\": \u200b0, \"nx\": \u200b82, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jp2/full/82,110/0/default.jpg\", \"ny\": \u200b110, \"fps\": \u200b0, \"format_name\": \"JPEG2000\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" }, { \"duration\": \u200b0, \"nx\": \u200b163, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jp2/full/163,219/0/default.jpg\", \"ny\": \u200b219, \"fps\": \u200b0, \"format_name\": \"JPEG2000\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" } ... ], \"restype_label\": \"Seite\", \"resclass_has_location\": true, Each of these paths has to be handled by the browser by making a call to Sipi, obtaining the binary representation in the desired quality. Authentication of Users with Sipi Whenever a file is requested, Sipi asks the DSP-API about the current user's permissions on the given file. This is achieved by sharing the session cookie with Sipi. When the user logs in to DSP using his browser (using either V1 or V2 authentication route), a session cookie containing a JWT token representing the user is stored in the user's client. This session cookie is then read by Sipi and used to ask DSP-API for the user's image permissions. For the session cookie to be sent to Sipi, both the DSP-API and Sipi endpoints need to be under the same domain, e.g., api.example.com and iiif.example.com .","title":"Interaction between Sipi and DSP-API"},{"location":"06-sipi/sipi-and-dsp-api/#interaction-between-sipi-and-dsp-api","text":"","title":"Interaction Between Sipi and DSP-API"},{"location":"06-sipi/sipi-and-dsp-api/#general-remarks","text":"DSP-API and Sipi (Simple Image Presentation Interface) are two complementary software projects. Whereas DSP-API deals with data that is written to and read from a triplestore (metadata and annotations), Sipi takes care of storing, converting and serving image files as well as other types of files such as audio, video, or documents (binary files it just stores and serves). DSP-API and Sipi stick to a clear division of responsibility regarding files: DSP-API knows about the names of files that are attached to resources as well as some metadata and is capable of creating the URLs for the client to request them from Sipi, but the whole handling of files (storing, naming, organization of the internal directory structure, format conversions, and serving) is taken care of by Sipi.","title":"General Remarks"},{"location":"06-sipi/sipi-and-dsp-api/#adding-files-to-dsp","text":"A file is first uploaded to Sipi, then its metadata is submitted to DSP. The implementation of this procedure is described in DSP-API and Sipi . Instructions for the client are given in Creating File Values (for DSP-API v2) and in Adding Resources with Image Files (for API v1).","title":"Adding Files to DSP"},{"location":"06-sipi/sipi-and-dsp-api/#retrieving-files-from-sipi","text":"","title":"Retrieving Files from Sipi"},{"location":"06-sipi/sipi-and-dsp-api/#file-urls-in-api-v2","text":"In DSP-API v2, image file URLs are provided in IIIF format. In the simple ontology schema , a file value is simply a IIIF URL that can be used to retrieve the file from Sipi. In the complex schema, it is a StillImageFileValue with additional properties that the client can use to construct different IIIF URLs, e.g. at different resolutions. See the knora-api ontology for details.","title":"File URLs in API v2"},{"location":"06-sipi/sipi-and-dsp-api/#file-urls-in-api-v1","text":"In API v1, for each file value, DSP-API creates several Sipi URLs for accessing the file at different resolutions: \"resinfo\": { \"locations\": [ { \"duration\": \u200b0, \"nx\": \u200b95, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jpg/full/max/0/default.jpg\", \"ny\": \u200b128, \"fps\": \u200b0, \"format_name\": \"JPEG\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" }, { \"duration\": \u200b0, \"nx\": \u200b82, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jp2/full/82,110/0/default.jpg\", \"ny\": \u200b110, \"fps\": \u200b0, \"format_name\": \"JPEG2000\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" }, { \"duration\": \u200b0, \"nx\": \u200b163, \"path\": \"http://sipiserver:port/knora/incunabula_0000000002.jp2/full/163,219/0/default.jpg\", \"ny\": \u200b219, \"fps\": \u200b0, \"format_name\": \"JPEG2000\", \"origname\": \"ad+s167_druck1=0001.tif\", \"protocol\": \"file\" } ... ], \"restype_label\": \"Seite\", \"resclass_has_location\": true, Each of these paths has to be handled by the browser by making a call to Sipi, obtaining the binary representation in the desired quality.","title":"File URLs in API v1"},{"location":"06-sipi/sipi-and-dsp-api/#authentication-of-users-with-sipi","text":"Whenever a file is requested, Sipi asks the DSP-API about the current user's permissions on the given file. This is achieved by sharing the session cookie with Sipi. When the user logs in to DSP using his browser (using either V1 or V2 authentication route), a session cookie containing a JWT token representing the user is stored in the user's client. This session cookie is then read by Sipi and used to ask DSP-API for the user's image permissions. For the session cookie to be sent to Sipi, both the DSP-API and Sipi endpoints need to be under the same domain, e.g., api.example.com and iiif.example.com .","title":"Authentication of Users with Sipi"},{"location":"07-lucene/lucene-query-parser-syntax/","text":"Lucene The Lucene full-text index provided by the triplestore is used to perform full-text searches in Knora. The exact behavior can be different depending on the triplestore. Lucene Query Parser Syntax Full-text searches in Knora are based on Lucene. Therefore, full-text searches support the Lucene Query Parser Syntax . A full-text search consists of a single word in the simplest case, but could also be composed of several words combined with Boolean operators . By default, Lucene combines two or more terms separated by space with a logical OR. For examples, see Lucene Query Parser Syntax .","title":"Lucene Query Parser Syntax"},{"location":"07-lucene/lucene-query-parser-syntax/#lucene","text":"The Lucene full-text index provided by the triplestore is used to perform full-text searches in Knora. The exact behavior can be different depending on the triplestore.","title":"Lucene"},{"location":"07-lucene/lucene-query-parser-syntax/#lucene-query-parser-syntax","text":"Full-text searches in Knora are based on Lucene. Therefore, full-text searches support the Lucene Query Parser Syntax . A full-text search consists of a single word in the simplest case, but could also be composed of several words combined with Boolean operators . By default, Lucene combines two or more terms separated by space with a logical OR. For examples, see Lucene Query Parser Syntax .","title":"Lucene Query Parser Syntax"},{"location":"08-faq/","text":"Frequently Asked Questions File Formats What file formats does Knora store? See File Formats in Knora . Does Knora store XML files? XML files do not lend themselves to searching and linking. Knora's RDF storage is better suited to its goal of facilitating data reuse. If your XML files represent text with markup (e.g. TEI/XML ), the recommended approach is to allow Knora to store it as Standoff/RDF . This will allow both text and markup to be searched using Gravsearch . Knora can also regenerate, at any time, an XML document that is equivalent to the original one. If you have XML that simply represents structured data (rather than text documents), we recommend converting it to Knora resources, which are stored as RDF. Triplestores Which triplestores can be used with DSP-API? DSP-API is tested with Apache Jena Fuseki . DSP Ontologies Can a project use classes or properties defined in another project's ontology? DSP-API does not allow this to be done with project-specific ontologies. Each project must be free to change its own ontologies, but this is not possible if they have been used in ontologies or data created by other projects. However, an ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators promise not to change it in ways that could affect other ontologies or data that are based on it. See Shared Ontologies for details. There will be a standardisation process for shared ontologies (issue #523 ). Why doesn't DSP-API use rdfs:domain and rdfs:range for consistency checking? DSP-API's consistency checking uses specific properties, which are called knora-base:subjectClassConstraint and knora-base:objectClassConstraint in the knora-base ontology, and knora-api:subjectType and knora-api:objectType in the knora-api ontologies. These properties express restrictions on the possible subjects and objects of a property. If a property's subject or object does not conform to the specified restrictions, DSP-API considers it an error. In contrast, the RDF Schema specification says that rdfs:domain and rdfs:range can be used to \"infer additional information\" about the subjects and objects of properties, rather than to enforce restrictions. This is, in fact, what RDFS reasoners do in practice. For example, consider these statements: example:hasAuthor rdfs:range example:Person . data:book1 example:hasAuthor data:oxygen . To an RDFS reasoner, the first statement means: if something is used as the object of example:hasAuthor , we can infer that it's an example:Person . The second statement is a mistake; oxygen is not a person. But an RDFS reasoner would infer that data:oxygen is actually an example:Person , since it is used as the object of example:hasAuthor . Queries looking for persons would then get data:oxygen in their results, which would be incorrect. Therefore, rdfs:domain and rdfs:range are not suitable for consistency checking. DSP-API therefore uses its own properties, along with OWL cardinalities, which it interprets according to a \"closed world\" assumption. DSP-API performs its own consistency checks to enforce these restrictions. DSP-API repositories can also take advantage of triplestore-specific consistency checking mechanisms. The constraint language SHACL may someday provide a standard, triplestore-independent way to implement consistency checks, if the obstacles to its adoption can be overcome (see Diverging views of SHACL ). For further discussion of these issues, see SHACL and OWL Compared . Can a user-created property be an owl:TransitiveProperty ? No, because in DSP-API, a resource controls its properties. This basic assumption is what allows DSP-API to enforce permissions and transaction integrity. The concept of a transitive property would break this assumption. Consider a link property hasLinkToFoo that is defined as an owl:TransitiveProperty , and is used to link resource Foo1 to resource Foo2 : Suppose that Foo1 and Foo2 are owned by different users, and that the owner of Foo2 does not have permission to change Foo1 . Now suppose that the owner of Foo2 adds a link from Foo2 to Foo3 , using the transitive property: Since the property is transitive, a link from Foo1 to Foo3 is now inferred. But this should not be allowed, because the owner of Foo2 does not have permission to add a link to Foo1 . Moreover, even if the owner of Foo2 did have that permission, the inferred link would not have a knora-base:LinkValue (a reification), which every link must have. The LinkValue is what stores metadata about the creator of the link, its creation date, its permissions, and so on (see LinkValue ). Finally, if an update to a resource could modify another resource, this would violate DSP-API's model of transaction integrity, in which each transaction can modify only one resource (see Application-level Locking ). DSP-API would then be unable to ensure that concurrent transactions do not interfere with each other. General Why should I use 0.0.0.0 instead of localhost when running the DSP stack locally? When running locally with the default configuration, if you want authorization cookies to be shared between webapi and sipi , then both webapi and sipi must be accessed over 0.0.0.0 , or otherwise, the cookie will not be sent to sipi . If no authorization cookie sharing is necessary, then both 0.0.0.0 and localhost will work.","title":"Frequently Asked Questions"},{"location":"08-faq/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"08-faq/#file-formats","text":"","title":"File Formats"},{"location":"08-faq/#what-file-formats-does-knora-store","text":"See File Formats in Knora .","title":"What file formats does Knora store?"},{"location":"08-faq/#does-knora-store-xml-files","text":"XML files do not lend themselves to searching and linking. Knora's RDF storage is better suited to its goal of facilitating data reuse. If your XML files represent text with markup (e.g. TEI/XML ), the recommended approach is to allow Knora to store it as Standoff/RDF . This will allow both text and markup to be searched using Gravsearch . Knora can also regenerate, at any time, an XML document that is equivalent to the original one. If you have XML that simply represents structured data (rather than text documents), we recommend converting it to Knora resources, which are stored as RDF.","title":"Does Knora store XML files?"},{"location":"08-faq/#triplestores","text":"","title":"Triplestores"},{"location":"08-faq/#which-triplestores-can-be-used-with-dsp-api","text":"DSP-API is tested with Apache Jena Fuseki .","title":"Which triplestores can be used with DSP-API?"},{"location":"08-faq/#dsp-ontologies","text":"","title":"DSP Ontologies"},{"location":"08-faq/#can-a-project-use-classes-or-properties-defined-in-another-projects-ontology","text":"DSP-API does not allow this to be done with project-specific ontologies. Each project must be free to change its own ontologies, but this is not possible if they have been used in ontologies or data created by other projects. However, an ontology can be defined as shared, meaning that it can be used by multiple projects, and that its creators promise not to change it in ways that could affect other ontologies or data that are based on it. See Shared Ontologies for details. There will be a standardisation process for shared ontologies (issue #523 ).","title":"Can a project use classes or properties defined in another project's ontology?"},{"location":"08-faq/#why-doesnt-dsp-api-use-rdfsdomain-and-rdfsrange-for-consistency-checking","text":"DSP-API's consistency checking uses specific properties, which are called knora-base:subjectClassConstraint and knora-base:objectClassConstraint in the knora-base ontology, and knora-api:subjectType and knora-api:objectType in the knora-api ontologies. These properties express restrictions on the possible subjects and objects of a property. If a property's subject or object does not conform to the specified restrictions, DSP-API considers it an error. In contrast, the RDF Schema specification says that rdfs:domain and rdfs:range can be used to \"infer additional information\" about the subjects and objects of properties, rather than to enforce restrictions. This is, in fact, what RDFS reasoners do in practice. For example, consider these statements: example:hasAuthor rdfs:range example:Person . data:book1 example:hasAuthor data:oxygen . To an RDFS reasoner, the first statement means: if something is used as the object of example:hasAuthor , we can infer that it's an example:Person . The second statement is a mistake; oxygen is not a person. But an RDFS reasoner would infer that data:oxygen is actually an example:Person , since it is used as the object of example:hasAuthor . Queries looking for persons would then get data:oxygen in their results, which would be incorrect. Therefore, rdfs:domain and rdfs:range are not suitable for consistency checking. DSP-API therefore uses its own properties, along with OWL cardinalities, which it interprets according to a \"closed world\" assumption. DSP-API performs its own consistency checks to enforce these restrictions. DSP-API repositories can also take advantage of triplestore-specific consistency checking mechanisms. The constraint language SHACL may someday provide a standard, triplestore-independent way to implement consistency checks, if the obstacles to its adoption can be overcome (see Diverging views of SHACL ). For further discussion of these issues, see SHACL and OWL Compared .","title":"Why doesn't DSP-API use rdfs:domain and rdfs:range for consistency checking?"},{"location":"08-faq/#can-a-user-created-property-be-an-owltransitiveproperty","text":"No, because in DSP-API, a resource controls its properties. This basic assumption is what allows DSP-API to enforce permissions and transaction integrity. The concept of a transitive property would break this assumption. Consider a link property hasLinkToFoo that is defined as an owl:TransitiveProperty , and is used to link resource Foo1 to resource Foo2 : Suppose that Foo1 and Foo2 are owned by different users, and that the owner of Foo2 does not have permission to change Foo1 . Now suppose that the owner of Foo2 adds a link from Foo2 to Foo3 , using the transitive property: Since the property is transitive, a link from Foo1 to Foo3 is now inferred. But this should not be allowed, because the owner of Foo2 does not have permission to add a link to Foo1 . Moreover, even if the owner of Foo2 did have that permission, the inferred link would not have a knora-base:LinkValue (a reification), which every link must have. The LinkValue is what stores metadata about the creator of the link, its creation date, its permissions, and so on (see LinkValue ). Finally, if an update to a resource could modify another resource, this would violate DSP-API's model of transaction integrity, in which each transaction can modify only one resource (see Application-level Locking ). DSP-API would then be unable to ensure that concurrent transactions do not interfere with each other.","title":"Can a user-created property be an owl:TransitiveProperty?"},{"location":"08-faq/#general","text":"","title":"General"},{"location":"08-faq/#why-should-i-use-0000-instead-of-localhost-when-running-the-dsp-stack-locally","text":"When running locally with the default configuration, if you want authorization cookies to be shared between webapi and sipi , then both webapi and sipi must be accessed over 0.0.0.0 , or otherwise, the cookie will not be sent to sipi . If no authorization cookie sharing is necessary, then both 0.0.0.0 and localhost will work.","title":"Why should I use 0.0.0.0 instead of localhost when running the DSP stack locally?"},{"location":"09-release-notes/","text":"Changelog 24.0.8 (2022-10-18) Bug Fixes User can be project admin without being project member (DEV-1383) ( #2248 ) ( c1aa8f0 ) Maintenance automatically clean sipi image files (DEV-1395) ( #2237 ) ( eddb34d ) fix project name ( #2239 ) ( 5af65eb ) update dependencies ( #2247 ) ( 2eefcbc ) 24.0.7 (2022-10-07) Bug Fixes DSP-API project IRI validation fails for BEOL project IRI ( #2240 ) ( 4b63a72 ) 24.0.6 (2022-10-06) Bug Fixes Ask timeouts when requesting projects (DEV-1386) ( #2235 ) ( 1820367 ) User can't be edited by project admin (DEV-1373) ( #2232 ) ( e0b1433 ) 24.0.5 (2022-10-05) Bug Fixes Timeout for multiple Gravsearch queries (DEV-1379) ( #2234 ) ( c63567b ) Maintenance app actor cleanup ( #2230 ) ( a67c98f ) 24.0.4 (2022-09-29) Bug Fixes API returns invalid file URLs, due to including the port ( #2223 ) ( 1a0b09c ) Value update or deletion doesn't work for properties of other ontology (DEV-1367) ( #2222 ) ( 472b375 ) 24.0.3 (2022-09-21) Maintenance application actor (DEV-956) ( #2166 ) ( 4852425 ) remove swagger route and docs annotations (DEV-1335) ( #2203 ) ( bec5b8a ) Replace Settings with AppConfig (DEV-1312) ( #2202 ) ( 9b76417 ) update dependencies ( #2214 ) ( 3706acd ) 24.0.2 (2022-09-08) Bug Fixes sipi: remove support for audio/mp4 file format (DEV-1300) ( #2195 ) ( 122bf52 ) Maintenance Adjust GitHub template (DEV-1313) ( #2183 ) ( 5782494 ) bump dependencies ( #2196 ) ( 2fbf664 ) Ignore push on certain branches from tests (DEV-1112) ( #2187 ) ( e0a0fbb ) Improve GitHub actions (DEV-1112) ( #2182 ) ( 71c772f ) Skip tests with success (DEV-1112) ( #2188 ) ( 82703d7 ) v3: add project slice (DEV-1009) ( #2076 ) ( bd2d31e ) 24.0.1 (2022-08-26) Bug Fixes cardinality: Check cardinality with multiple inherited classes (DEV-1189) ( #2164 ) ( f183d7d ) Fuseki doesn't stop after client's timeout (DEV-1190) ( #2175 ) ( 90f86b5 ) v2 test: fix test data collection ( #2174 ) ( 468df8f ) Documentation update file formats (DEV-1185) ( #2158 ) ( 4fab193 ) Maintenance add codacy coverage reporter ( #2177 ) ( c30390f ) add code coverage ( #2135 ) ( 1a02f49 ) add code coverage ( #2163 ) ( b026442 ) add coverage upload to codecov ( #2179 ) ( 5d4e57e ) feature-toggles: remove remnants of feature toggles (DEV-217) ( #2176 ) ( ed1cbd0 ) remove github action for deploying docs (DEV-824) ( #2155 ) ( a55eef4 ) update dependencies ( #2173 ) ( 79b88d2 ) 24.0.0 (2022-08-08) \u26a0 BREAKING CHANGES add isSequenceOf to knora-base ontology (DEV-745) (#2061) Bug Fixes sipi: SIPI returns 404 instead of images if cookie is invalid (DEV-1135) ( #2142 ) ( eb797f0 ) Enhancements add isSequenceOf to knora-base ontology (DEV-745) ( #2061 ) ( 74366d4 ) Maintenance dependencies: bulk upgrade dependencies ( #2144 ) ( 4602150 ) update dependencies ( 4cd9812 ) 23.0.3 (2022-08-02) Bug Fixes triplestore-connector: stack crashes on invalid search (DEV-1154) ( #2140 ) ( e5426dc ) Maintenance dependencies: update akka-http-cors to 1.1.3 ( #2103 ) ( 5d0d522 ) dependencies: update jwt-spray-json to 9.0.2 ( #2111 ) ( 6e54443 ) dependencies: update Saxon-HE to 11.4 ( #2137 ) ( 08c9f68 ) dependencies: update scalatest to 3.2.13 ( #2138 ) ( a345079 ) dependencies: update spring-security-core to 5.6.6 ( #2130 ) ( c83645d ) dependencies: update spring-security-core to 5.7.2 ( #2139 ) ( 3a12562 ) dependencies: update titanium-json-ld to 1.3.1 ( #2104 ) ( 4850525 ) 23.0.2 (2022-07-29) Bug Fixes ontology: link value property is still not editable after updating the property metadata (DEV-1116) ( #2133 ) ( d5b48db ) sipi: cookie parsing can cause an error which leads to 404 for images (DEV-1135) ( #2134 ) ( bd023a5 ) Maintenance add dependency checking ( #2100 ) ( 8017b1f ) add dependency checking ( #2102 ) ( 856277b ) Improve validation of GUI elements and GUI attributes (DEV-1082) ( #2098 ) ( 5cec8ba ) v3: add role slice (DEV-1010) ( #2099 ) ( 6920716 ) 23.0.1 (2022-07-19) Bug Fixes ontology: Don't accept list values without gui attribute (DEV-775) ( #2089 ) ( 74a14e1 ) 23.0.0 (2022-07-14) \u26a0 BREAKING CHANGES transform valueHasUri values from node to string type (DEV-1047) (#2094) Bug Fixes authentication: make cookie name unique between environments ( #2095 ) ( 7d420a4 ) ontology: existing cardinalities get duplicated in the triplestore when adding a new cardinality to a class (DEV-937) ( #2092 ) ( 9fa26db ) transform valueHasUri values from node to string type (DEV-1047) ( #2094 ) ( e1d8d95 ) 22.0.1 (2022-07-08) Bug Fixes authentication: make cookie name unique between environments ( #2091 ) ( 680021e ) value: make impossible to set list root node as a value (DEV-973) ( #2088 ) ( 94d2b46 ) Maintenance triplestore: ZIO-fying triplestore service (DSP-904) ( #2059 ) ( 9e038ec ) v3: finish user slice (DEV-671) ( #2078 ) ( 48592ad ) 22.0.0 (2022-06-30) \u26a0 BREAKING CHANGES add upgrade plugin that fixes invalid date serialisations (#2081) Bug Fixes add upgrade plugin that fixes invalid date serialisations ( #2081 ) ( 3a0902e ) ontology: link value property is not editable after editing the property metadata (DEV-1037) ( #2084 ) ( 09688f5 ) Maintenance temporarily ignore KnoraSipiIntegrationV2ITSpec ( #2085 ) ( 59f93b3 ) 21.0.1 (2022-06-23) Bug Fixes fix RepositoryUpdater by removing old way of adding plugins ( #2082 ) ( 6599b68 ) 21.0.0 (2022-06-23) \u26a0 BREAKING CHANGES fix valueHasUri bad values and missing types (DEV-1036) (#2079) Bug Fixes fix valueHasUri bad values and missing types (DEV-1036) ( #2079 ) ( de1e5a4 ) 20.4.1 (2022-06-16) Bug Fixes admin: return list labels and comments sorted by language ( #2074 ) ( f3a66cb ) Maintenance add missing client test data (DEV-979) ( #2072 ) ( 54446bc ) audio: remove not required properties ( #2070 ) ( 96362f4 ) exceptions: Create sbt project \"shared\" and move exceptions (DEV-990) ( #2075 ) ( c09392d ) move value objects to separate project (DEV-615) ( #2069 ) ( b55eb12 ) responder manager as plain case class ( #2073 ) ( 7f55697 ) user: add user project (DEV-586) ( #2063 ) ( 0c5ec03 ) 20.4.0 (2022-05-25) Bug Fixes cache: cache does not update correctly when an ontology is modified (DEV-939) ( #2068 ) ( 8541519 ) Enhancements admin: add list child node deletion route (DEV-729) ( #2064 ) ( 179ad19 ) 20.3.1 (2022-05-12) Bug Fixes authentication: Add bouncyCastle dependency (DEV-922) ( #2065 ) ( 4ac799d ) 20.3.0 (2022-05-12) Bug Fixes Problem with updating cache after deleting comments (DEV-508) ( #2060 ) ( a9fda7e ) Maintenance check that the expected Fuseki version is present (DEV-331) ( #2057 ) ( 2a695ec ) deps: bump ZIO version (DEV-893) ( #2056 ) ( 933f91e ) Enhancements add Romansh as supported language (DEV-557) ( #2053 ) ( 58971c8 ) gravsearch: improve gravsearch performance by using unions in prequery (DEV-492) ( #2045 ) ( 40354a7 ) 20.2.1 (2022-05-05) Bug Fixes projectsADM: fix cache issue in getSingleProjectADM ( #2054 ) ( 77bfadc ) Maintenance IIIFService: zio-fying iiif service (DEV-801) ( #2044 ) ( 224b664 ) 20.2.0 (2022-04-28) Bug Fixes Cleaning sipi tmp folder results in an error when there are lots of files (DEV-316) ( #2052 ) ( 33e6896 ) Enhancements error-handling: return status 504 instead of 500 for triplestore timeout exception (DEV-749) ( #2046 ) ( a47096e ) ontology: allow deleting comments of classes (DEV-804) ( #2048 ) ( eca9206 ) ontology: allow deleting comments of properties (DEV-696) ( #2042 ) ( 985c5fd ) Maintenance formatting-logging: reformat scala code and change logging policy (DEV-839) ( #2051 ) ( 5e4e914 ) formatting: reformat turtle files (DEV-430) ( #2050 ) ( 0389e52 ) triplestore: remove embedded-jena-tdb related code ( #2043 ) ( a5ea62e ) 20.1.1 (2022-04-14) Bug Fixes sipi: extract frames from video even without aspect ratio (DEV-802) ( #2041 ) ( 57d40f7 ) Documentation ingest: Add accepted file formats to documentation (DEV-677) ( #2038 ) ( f72e7a0 ) Maintenance cacheservice: use ZIO (DEV-546) ( #2022 ) ( 521150f ) triplestore: remove graphDB support ( #2037 ) ( bf17bca ) 20.1.0 (2022-04-07) Bug Fixes docs/requirements.txt to reduce vulnerabilities ( #2034 ) ( b07600d ) Maintenance distinguish between compile, runtime and test dependencies ( #2028 ) ( 7cb326f ) inventory and upgrade of dependencies (DEV-478) ( #2033 ) ( 470b77f ) Documentation replace Bazel and Intellij documentation with SBT and VSCode (DEV-607) ( #2035 ) ( 603efef ) Enhancements ontology: Add support for additional ontologies (DEV-512) ( #2029 ) ( 50e3186 ) sipi: upload video support (DEV-771 / DEV-207) ( #1952 ) ( 47f2e28 ) 20.0.0 (2022-03-31) \u26a0 BREAKING CHANGES ontology: make knora-base:lastModificationDate required property (#2018) Maintenance fix docker containers timezone ( #2027 ) ( 6bbb3fe ) Enhancements ontology: make knora-base:lastModificationDate required property ( #2018 ) ( 64cdce9 ) 19.0.0 (2022-03-24) \u26a0 BREAKING CHANGES authentication: add server specific issuer to JWT token (DEV-555) (#2024) Bug Fixes authentication: add server specific issuer to JWT token (DEV-555) ( #2024 ) ( 4bd5b2f ) version: fix displayed versions ( #2026 ) ( 566285c ) Maintenance improve logging (DEV-634) ( #2021 ) ( 85d1057 ) remove warnings (DEV-621) ( #2015 ) ( 70630f1 ) test: get tests to run in vs code (DEV-601) ( #2020 ) ( 747d13d ) 18.0.0 (2022-03-08) \u26a0 BREAKING CHANGES standoff: return XML alongside HTML for textValue with custom standoff mapping and default XSL transformation (DEV-201) (#1991) Bug Fixes Use correct docker image tag after publishing (DEV-614) ( #2016 ) ( 7649515 ) Maintenance improve code structure (DEV-612) ( #2012 ) ( eac0049 ) Enhancements standoff: return XML alongside HTML for textValue with custom standoff mapping and default XSL transformation (DEV-201) ( #1991 ) ( 2548b8f ) 17.5.3 (2022-03-04) Bug Fixes RepositoryUpdater: make sure temp directories are deleted ( #2010 ) ( 9c9a1bd ) Documentation fix permissions design documentation (DEV-495) ( #1997 ) ( 5154adc ) Maintenance fix docker image name (DEV-574) ( #2007 ) ( 7a186ba ) remove fuseki image creation and change sipi image creation to sbt (DEV-544) ( #2011 ) ( eed2767 ) start on a functional domain design implementation for ontologies (DEV-227) ( #2009 ) ( 54cee7a ) 17.5.2 (2022-02-23) Bug Fixes permissions: Update default object access permissions (DEV-514) ( #2004 ) ( 04a8d3d ) timeout: Increase timeouts (DEV-536) ( #2005 ) ( f1f8005 ) Maintenance BAZEL to SBT migration (DEV-508) ( #2002 ) ( 38faa9e ) 17.5.1 (2022-02-16) Maintenance deps: upgrade Jena Fuseki docker image to v2.0.8 ( #2001 ) ( 3e2eccc ) deps: upgrate Jena API to v4.4.0 ( #1999 ) ( 3eecc69 ) Documentation fix markdown issues in documentation (DEV-504) ( #2003 ) ( ff6b4cf ) 17.5.0 (2022-02-11) Enhancements ontologies: make comments optional for property and class creation (DEV-342) ( #1996 ) ( a3c286c ) 17.4.1 (2022-02-07) Maintenance deps: upgrade Jena to v4.3.2 (DEV-473) ( #1995 ) ( 216dcb4 ) deps: upgrade titanium-json-ld to v1.2.0 & jakarta-json to v2.0.1 (DEV-335) ( #1993 ) ( ad01bf9 ) 17.4.0 (2022-02-04) Bug Fixes version-upgrade: add upgrade plugin for ArchiveRepresentation and DeletedResource (DEV-467) ( #1992 ) ( e1566e9 ) Maintenance add support for building native API and Fuseki Docker images on Apple M1 (DEV-435) ( #1987 ) ( ab80e72 ) refactor test models (DEV-264) ( #1975 ) ( 65952f9 ) Enhancements resource: add ArchiveRepresentation to API V1 (DEV-393) (DEV-394) ( #1984 ) ( 65b88a2 ) UUID: add IRI validation that allows only to create IRIs using UUID version 4 and 5 (DEV-402) ( #1990 ) ( 74d4344 ) 17.3.1 (2022-01-28) Bug Fixes ontology: Sub-properties of link values aren't created correctly (DEV-426) ( #1985 ) ( 70a8b08 ) Maintenance deps: bump fuseki image to 2.0.7 (DEV-389) ( #1983 ) ( fcbfb1d ) license: update the license (DEV-374) ( #1981 ) ( 044fdc5 ) 17.3.0 (2022-01-17) Bug Fixes ontology: DSP-API creates wrong partOfValue property (DEV-216) ( #1978 ) ( 27b5c86 ) resource: return sensible CreationDate for DeletedResource ( #1979 ) ( 1658103 ) Enhancements resource: add support for 7z files in ArchiveRepresentation (DEV-322) ( #1977 ) ( 729689c ) Maintenance admin: refactor projects & users value objects (DEV-240) ( #1976 ) ( 563d252 ) CI: add disk cache and other cleanup (DEV-388) ( #1982 ) ( e590d12 ) 17.2.0 (2022-01-10) Bug Fixes search: Return matching sub-nodes when searching for list label (DEV-158) ( #1973 ) ( 7e8c759 ) Enhancements return a DeletedResource or DeletedValue instead of 404 if a deleted resource or value is requested (DEV-226) ( #1960 ) ( c78e252 ) 17.1.0 (2021-12-20) Enhancements listsADM: add canDeleteList route ( #1968 ) ( c276625 ) Maintenance deps: bump log4j to 2.17.0 and Fuseki to 4.3.2 (DEV-334) ( #1972 ) ( afb6587 ) 17.0.4 (2021-12-17) Bug Fixes authentication: delete cookie (in chrome) on logout (DEV-325) ( #1970 ) ( b2c9204 ) candeletecardinalities: return canDoResponse of false instead of throwing an exception for inherited cardinalities (DEV-314) ( #1966 ) ( 55b5d4b ) ontology: cardinality of one can be added to classes as long as not used in data ( #1958 ) ( 2cebac7 ) Maintenance bump logging libraries (DEV-333) ( #1969 ) ( f680c4f ) 17.0.3 (2021-12-14) Maintenance bump Fuseki (log4shell fix) (IT-4) ( #1965 ) ( 86fa251 ) projectMetadataV2: remove projectMetadataV2 implementation ( #1962 ) ( 7b95d66 ) 17.0.2 (2021-12-10) Maintenance bump db version (add shiro.ini)(DEV-302)( #1961 ) ( d147bf6 ) 17.0.1 (2021-12-06) Maintenance fix issues with fuseki (DEV-277) ( #1953 ) ( 4c1a5f1 ) Documentation Updated readme ( #1956 ) ( 774b68d ) 17.0.0 (2021-11-25) \u26a0 BREAKING CHANGES add archive representation to DSP-API (DEV-17) (#1926) Maintenance bump fuseki base container version ( #1946 ) ( cf8bdec ) bump java and sipi version (only security updates) (DEV-263) ( #1950 ) ( fe6106f ) Enhancements add archive representation to DSP-API (DEV-17) ( #1926 ) ( 0123a8f ) 16.0.1 (2021-11-22) Bug Fixes canDeleteCardinalities: canDeleteCardinalities checks too eagerly (DEV-187) ( #1941 ) ( 298ba47 ) 16.0.0 (2021-11-19) \u26a0 BREAKING CHANGES listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd ) Bug Fixes projectsADM: clear cache after changing project (DEV-239) ( #1943 ) ( 17c5c09 ) Maintenance groupsADM: improve value objects implementation (DEV-160) ( #1932 ) ( 24e34dd ) listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd ) release v16.0.0 ( 8e5f494 ) release v16.0.0 ( ba6923d ) 15.1.3 (2021-11-19) \u26a0 BREAKING CHANGES listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd ) Bug Fixes projectsADM: clear cache after changing project (DEV-239) ( #1943 ) ( 17c5c09 ) Maintenance groupsADM: improve value objects implementation (DEV-160) ( #1932 ) ( 24e34dd ) listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd ) 15.1.2 (2021-11-12) Maintenance bump bazel ( #1938 ) ( 39417e6 ) improve validation handling (DEV-228) ( #1937 ) ( 94d7d3f ) 15.1.1 (2021-11-09) Bug Fixes list: add support for special characters in list update (DEV-200) ( #1934 ) ( 3c2865c ) Maintenance init-db: init db test data from test server (DEV-198) ( #1936 ) ( 1c24bea ) 15.1.0 (2021-11-03) Bug Fixes users: fix bug adding user to group or project (DEV-184) ( #1925 ) ( a24a320 ) Enhancements add value objects to list routes - old and new (DEV-65) ( #1917 ) ( 7752a36 ) Maintenance bump sipi version (DEV-188) ( #1931 ) ( d302b5e ) change license to Apache 2.0 (DEV-82) ( #1924 ) ( 2d39a1f ) deps: bump mkdocs from 1.1.2 to 1.2.3 in /docs ( #1927 ) ( cbbf1b6 ) fix warnings (DEV-80) ( #1929 ) ( 1368769 ) 15.0.3 (2021-10-21) Bug Fixes list: find list labels in full-text search ( #1922 ) ( cc3b06c ) 15.0.2 (2021-10-14) Bug Fixes authenticator: improve performance ( #1914 ) ( d6a0d27 ) groups: update test data and documentation to use language specific group descriptions (DEV-123) ( #1921 ) ( 0f45b51 ) removing cardinality of a link property (DEV-90) ( #1919 ) ( c79c194 ) Maintenance groups: refactor groups route using value objects (DEV-66) ( #1913 ) ( 1cd98e6 ) knora-base: fix typo ( #1918 ) ( 720aa65 ) projects: cleaner value objects usage in addProject route (DEV-119) ( #1920 ) ( 32b9e49 ) 15.0.1 (2021-09-29) Bug Fixes candeletecardinalities: return correct response on route negative case (DEV-36) ( #1910 ) ( 652c747 ) escape-special-characters: escape special characters in user routes (DSP-1557) ( #1902 ) ( 689d92a ) Maintenance contributors: remove contributors file (DEV-77) ( #1911 ) ( 7d925b6 ) projects: refactor projects route with value objects (DEV-64) ( #1909 ) ( 172cf77 ) reformatting Scala files (DSP-1897) ( #1908 ) ( 8df70a2 ) 15.0.0 (2021-09-14) \u26a0 BREAKING CHANGES ontology: use patch instead of delete for deleting cardinalities (DSP-1700) (#1903) Documentation add username to changeable attributes (DSP-1895) ( #1904 ) ( 719cd0d ) Maintenance ontology: use patch instead of delete for deleting cardinalities (DSP-1700) ( #1903 ) ( 91ef4ec ) 14.1.0 (2021-08-19) Bug Fixes ontology V2: use internal iri when updating a property (DSP-1868) ( #1898 ) ( a746f65 ) Enhancements v2-ontologies: add remove cardinalities from class if property not used in resources (DSP-1700) ( #1869 ) ( a30668b ) 14.0.1 (2021-08-04) Bug Fixes add-test-file: add response file for test case (DSP-1841) ( #1894 ) ( 028e685 ) 14.0.0 (2021-08-02) \u26a0 BREAKING CHANGES projects: Change shortname to xsd:NCName forma, Escape special character in payloads of projects endpoints (DSP-1555 ) (#1886) Bug Fixes api-v2, api-admin: ontology name and project name should be URL safe (DSP-1749) ( #1889 ) ( 17601a7 ) permissions: reject malformed doap and ap create/update request (DSP-1328) ( #1890 ) ( 3e3a3ce ) Enhancements customIRIs: custom IRIs must contain a UUID (DSP-1763) ( #1884 ) ( 593d9cb ) projects: Change shortname to xsd:NCName forma, Escape special character in payloads of projects endpoints (DSP-1555 ) ( #1886 ) ( b3c2d5f ) resource-metadata: return resource metadata after metadata update request (DSP-1828) ( #1893 ) ( a4e878a ) video: add support for video/mp4 to both v1 and v2 (DSP-1204) ( #1891 ) ( 83fb4b8 ) 13.12.0 (2021-06-24) Enhancements resourceHistoryEvents: route for resource history events (DSP-1749) ( #1882 ) ( f86de53 ) 13.11.0 (2021-06-17) Enhancements events: update resource last modification date event ( #1877 ) ( d5e70ba ) Maintenance build: cleanup ( #1880 ) ( 749e8ea ) cache-service: add in-memory implementation ( #1870 ) ( 61531ab ) gh-ci: update docs deployment (DSP-1741) ( #1878 ) ( ff65323 ) 13.10.0 (2021-06-09) Enhancements gravsearch: use layer info for topological order permutations (DSP-1389) ( #1872 ) ( b49d5ba ) Documentation prepare documentation for docs.dasch.swiss (DSP-1721) ( #1873 ) ( 66751a0 ) 13.9.2 (2021-06-02) Maintenance sipi: add comments ( #1864 ) ( 06e8b0c ) Documentation ontology: update term ( #1865 ) ( cd37580 ) 13.9.1 (2021-05-28) Maintenance bazel: bump bazel version ( #1866 ) ( c754cbf ) 13.9.0 (2021-05-25) Enhancements api-v2: Add routes for checking whether ontology entities can be changed (DSP-1621) ( #1861 ) ( fdd098f ) 13.8.0 (2021-05-19) Bug Fixes api-v2: Update subclasses in ontology cache when base class changes (DSP-1643) ( #1860 ) ( beb951d ) gravsearch: don't move the patterns with resource IRI after topological sorting (DSP-1620) ( #1856 ) ( 6022c91 ) Maintenance documentation: bug fix in documentation deployment (DSP-1605) ( bb852c9 ) documentation: bug fix in documentation deployment (DSP-1605) ( #1854 ) ( 999a2bb ) Enhancements api-v2: Change GUI element and attribute of a property (DSP-1600) ( #1855 ) ( ce9ba3a ) api-v2: Generate IIIF manifest (DSP-50) ( #1784 ) ( 74feb2c ) conf: Rule to dump prod data and load locally (DSP-1485) ( #1857 ) ( 161ea31 ) ontology: Allow adding new property to a resource class in use (DSP-1629) ( #1859 ) ( 061875e ) 13.7.0 (2021-05-06) Bug Fixes doc: correct remaining incorrect copyright dates ( #1847 ) ( d1473ed ) gravsearch: Keep rdf:type knora-api:Resource when needed. ( #1835 ) ( e561d94 ) lists: Escape special characters in comment, label, and name of a list node (DSP-1529) ( #1846 ) ( f96c069 ) test-data: change webern shortcode in test data (DSP-1520) ( #1843 ) ( 5f06a10 ) values v1 route: fix geoname case (DSP-1487) ( #1839 ) ( 9d0e93e ) Documentation replace knora by dsp or dsp-api in documentation (DSP-1469) ( #1836 ) ( 923abe8 ) v1: improve search docs ( #1848 ) ( 5a81f73 ) Enhancements api-v2: Add route for changing GUI order of cardinalities ( #1850 ) ( d8dbb4f ) api-v2: Return events describing version history of resources and values of a project ordered by data (DSP-1528) ( #1844 ) ( 84f7c14 ) ext search v1: add support for URI values (DSP-1522) ( #1842 ) ( b119757 ) Maintenance bumb Bazel to version with apple silicon support ( #1852 ) ( 286d289 ) bump scala to 2.13 ( #1851 ) ( 5feb915 ) deps: bump versions (DSP-1569) ( #1849 ) ( f69f008 ) 13.6.0 (2021-03-16) Enhancements api-v2: Improve error message when an XSLT transformation file is not found (DSP-1404) ( #1831 ) ( 153a674 ) 13.5.1 (2021-03-11) Bug Fixes OntologiesRouteV2: Reject internal ontology names in external schema (DSP-1394) ( #1827 ) ( e392bf1 ) OntologyResponderV2: Fix check when updating ontology label and comment (DSP-1390) ( #1826 ) ( 26cce48 ) 13.5.0 (2021-03-08) Bug Fixes replaceCardinalities.scala.txt: Fix blank node insertion. ( #1829 ) ( d24c5d2 ) Maintenance gh-ci: update release please configuration (DSP-1382) ( #1825 ) ( 7ce4b65 ) Enhancements Add support for audio files (DSP-1343) ( #1818 ) ( 7497023 ) gravsearch: Optimise Gravsearch queries using topological sort (DSP-1327) ( #1813 ) ( efbecee ) store: Return 404 if the triplestore returns 404. ( #1828 ) ( 5250f6d ) 13.4.0 (2021-02-17) Bug Fixes Lists: fix bug in shifting the second of two children after deletion of the first one. ( #1820 ) ( d92bb01 ) Enhancements projects: add default set of permissions when creating new project (DSP-1347) ( #1822 ) ( b7c71ca ) 13.3.1 (2021-02-09) Bug Fixes Lists: fix bug in deleting the single child of a node (DSP-1355) ( #1816 ) ( 1d06572 ) 13.3.0 (2021-02-05) Enhancements sipi: add storing of original and sidecar (DSP-1318) ( #1808 ) ( 022ed7e ) 13.2.0 (2021-02-04) Bug Fixes api-v1: Optimise SPARQL queries. ( #1814 ) ( 4edc27c ) Lists: Repositioning the node when new position equals length of new parent's children (DSP-1322) ( #1811 ) ( 3fead13 ) Enhancements api-v1: Add support for PDF files (DSP-1267) ( #1797 ) ( c3b2e84 ) api-v2: Allow resubmitting existing class/property lablels/comments. ( #1812 ) ( 6a13852 ) Maintenance make targets for adding metadata (DSP-1289) ( #1810 ) ( 9c1a70a ) salsah1: delete from repository ( #1805 )(DSP-1294) ( 3251a74 ) 13.1.1 (2021-01-30) Maintenance gh-ci: Bring back the client-test-data command to github actions ( #1804 ) ( e6b0fbf ) revert release 13.1.0 ( #1800 ) ( 565e5ac ) 13.1.0 (2021-01-29) Bug Fixes api-v1: Optimise link value queries for Fuseki (DSP-1243) ( #1791 ) ( b1e1b9e ) api-v2: Don't allow an invalid cardinality on a boolean property (DSP-1236) ( #1788 ) ( 3d5f802 ) gravsearch: Handle UNION scopes with FILTER correctly (DSP-1240) ( #1790 ) ( 61d2e86 ) HttpTriplestoreConnector: Always parse triplestore responses as UTF-8. ( #1789 ) ( 61d2e86 ) permissions : fix getting builtin groups while creating a permission (DSP-1296 ) ( #1799 ) ( d390014 ) Maintenance gh-ci: fix issue in the release process ( #1782 ) ( afe61b7 ) ghi-ci: google chat release notification ( #1785 ) ( 4718cdc ) Enhancements permissions: add delete permissions: (DSP-1169) ( #1787 ) ( 3fe8c14 ) store: Return a clearer exception when a triplestore read timeout occurs. ( #1795 ) ( 0eeb3b3 ) 13.0.0 (2021-01-11) \u26a0 BREAKING CHANGES New features and refactoring (#1779) Bug Fixes (dependencies) add the missing dependency ( #1755 ) ( 0e37d21 ) api-v2: Change link value comment ( #1582 ) ( faa2e55 ) api-v2: Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) ( #1749 ) ( 905766f ) api-v2: Fix custom datatypes in knora-api simple ontology ( #1601 ) ( e0cfd4e ) api-v2: Fix generated SPARQL for updating property comment ( #1693 ) ( 7b70339 ) api-v2: Fix ontology deletion ( #1584 ) ( 70b0841 ) api-v2: Fix post-update check for resource with standoff link (DSP-841) ( #1728 ) ( 35d449f ) failing repository upgrade at startup (DSP-654) ( #1712 ) ( 0d6b4ee ) gravsearch: Prevent duplicate results ( #1626 ) ( 9313b88 ) gravsearch: When link property compared in filter, don't compare link value property, too ( #1699 ) ( a3b1665 ) init db scripts (DSP-511) ( #1681 ) ( d4505ce ) loading of data (DSP-445) ( #1669 ) ( 3f8d406 ) OntologyResponderV2: Add a global ontology cache lock ( #1637 ) ( 1853865 ) OntologyResponderV2: Fix ontology cache update when ontology metadata changed ( #1709 ) ( 4f57977 ) server header (DSP-537) ( #1691 ) ( 8d7bee8 ) sipi makefile ( #1616 ) ( 73a0afe ) sipi: Don't expect API v1 status code (DSP-1114) ( #1763 ) ( 3236d25 ) sipi: Improve performance of file value query ( #1697 ) ( 8214877 ) test: Fix typos in IRIs in anything-data.ttl. ( #1625 ) ( 23d51ce ) upgrade: Fix log output. ( #1774 ) ( b43fab0 ) webapi: unique username/email check on change user ( #1561 ) ( 4f26e22 ) rdf-api : Use the Jena RDF API implementation by default (DSP-1153) ( 1772 ) ( 389feb4 ) Documentation api-v2: Document what happens when a resource has a link to a deleted resource ( #1685 ) ( 1c88651 ) fix broken links ( #1688 ) ( 9c0292c ) fix make targets docker-build and docker-publish ( #1694 ) ( d06b6a6 ) Update README (DSP-1142) ( #1771 ) ( 7ba7fc6 ) Update required mkdocs package ( #1725 ) ( 27de65e ) Maintenance api-v2: Delete obsolete files. ( #1634 ) ( e80bf52 ) api-v2: Switch from JSONLD-Java to Titanium ( #1715 ) ( 9e28e5b ) build: Bump testcontainers version. ( #1723 ) ( 24ae1d3 ) build: Update ScalaTest (DSP-919) ( #1745 ) ( bbaeadd ) build: Upgrade Sipi to 3.0.0-rc.8 (DSP-916) ( #1743 ) ( 23395fc ) bump sipi to rc.7 (DSP-733) ( #1721 ) ( b635495 ) gh-ci: Fix gren issue ( #1666 ) ( 2dc5361 ) gh-ci: Publish on release only ( #1662 ) ( 787dca8 ) rdf-api: Use the Jena RDF API implementation by default (DSP-1153) ( #1772 ) ( 389feb4 ) Remove obsolete functions from StringFormatter. ( #1640 ) ( 5fa6de4 ) Update ci workflow release notes ( #1707 ) ( d8e0b39 ) gh-ci CI is failing to test upgrade correctly (DSP-667) ( #1073 ) ( 13cbdab ) bazel Update Bazel maven rules to see if it fixes problems with macOS Big Sur (DSP-1099) ( #1761 ) ( a2c9941 ) Enhancements Add an RDF processing fa\u00e7ade (2nd iteration) (DSP-1083) ( #1759 ) ( 346873d ) Add feature toggles (DSP-910) ( #1742 ) ( 2e6db2e ) Add time value type ( #1403 ) ( d925c85 ) api-v1: Change API v1 file uploads to work like API v2 (DSP-41, PR 3) ( #1722 ) ( a824bcc ) api-v2: Accept custom new value IRI when updating value ( #1698 ) ( 4d8f867 ) api-v2: Accept custom timestamps in update/delete requests ( #1686 ) ( 0fbe5a8 ) api-v2: Add an RDF processing fa\u00e7ade (DSP-1020) ( #1754 ) ( 9170419 ) api-v2: Add metadata routes (DSP-662) ( #1734 ) ( bf48968 ) api-v2: Add support for text file upload (DSP-44) ( #1664 ) ( a88d20d ) api-v2: Add test data. ( #1704 ) ( de14ab1 ) api-v2: Allow querying for rdfs:label in Gravsearch ( #1649 ) ( d56004b ) api-v2: Control JSON-LD nesting via an HTTP header (DSP-1084) ( #1758 ) ( b13eecf ) api-v2: Make inference optional in Gravsearch ( #1696 ) ( 166a260 ) api-v2: Optionally return file values in full-text search results (DSP-1191) ( #1776 ) ( 01f59bd ) api-v2: Remove client code generation ( #1610 ) ( 6977ab3 ) api-v2: Remove ForbiddenResource ( #1615 ) ( 992596e ) api-v2: Return value UUID on value creation and update ( #1602 ) ( cbed601 ) api-v2: Specify custom IRIs when creating resources/values ( #1646 ) ( 135b039 ) clientapi: Change method signature. ( #1583 ) ( c2a2559 ) gh-ci: Release please and update gh actions (DSP-1168) ( #1777 ) ( 593ffab ) gravsearch: Allow comparing variables representing resource IRIs ( #1713 ) ( f359c8e ) gravsearch: Remove deprecated functions ( #1660 ) ( 5d3af46 ) New features and refactoring ( #1779 ) ( 9a5fb77 ) rdf-api: Add a general-purpose SHACL validation utility (DSP-930) ( #1762 ) ( bfd3192 ) sipi: Improve error message if XSL file not found ( #1590 ) ( bbb42f6 ) triplestores: Support Apache Jena Fuseki ( #1375 ) ( 82f8a55 ) upgrade: Update repository on startup ( #1643 ) ( 0127dca ) v13.0.0-rc.25 (08/12/2020) Enhancements #1768 | DSP-1106 Update Permission #1767 | enhancement(triplestore): Use N-Quads instead of TriG for repository upgrade (DSP-1129) #1764 | DSP-1033 Reposition List Nodes #1762 | feat(rdf-api): Add a general-purpose SHACL validation utility (DSP-930) #1759 | feat: Add an RDF processing fa\u00e7ade (2nd iteration) (DSP-1083) #1760 | (DSP-1031) Delete list items #1753 | Edit lists routes (DSP-597 ) #1758 | feat(api-v2): Control JSON-LD nesting via an HTTP header (DSP-1084) Bug fixes #1763 | fix(sipi): Don't expect API v1 status code (DSP-1114) Documentation #1771 | docs: Update README (DSP-1142) Maintenance #1770 | refactor: Use java.nio.file.Path instead of java.io.File (DSP-1124) #1765 | DSP-1094 Upgrade Swagger version #1766 | style: Add Scalafmt config file #1769 | style: Reformat code with Scalafmt (DSP-1137) #1754 | feat(api-v2): Add an RDF processing fa\u00e7ade (DSP-1020) #1757 | build: bazel workspace cleanup v13.0.0-rc.24 (13/11/2020) #1756 | DSP-1052 : Migration task to replace empty strings with dummy \"FIXME\" v13.0.0-rc.23 (09/11/2020) Bug fixes #1755 | DSP-1029: Add the missing dependency v13.0.0-rc.22 (09/11/2020) Breaking changes #1724 | test: Collect client test data from E2E tests (DSP-724) #1727 | DSP-740 Update List Name #1722 | feat(api-v1): Change API v1 file uploads to work like API v2 (DSP-41, PR 3) #1233 | feat(api-v1): Change API v1 file uploads to work like API v2 #1708 | Get Project Permissions Enhancements #1403 | feat: Add time value type #1537 | build: Add env var to set triplestore actor pool #1649 | feat(api-v2): Allow querying for rdfs:label in Gravsearch #1742 | feat: Add feature toggles (DSP-910) #1741 | DSP-804: create a child node with a custom IRI #1734 | feat(api-v2): Add metadata routes (DSP-662) #1739 | enhancement(api-v2): Optimise checking isDeleted (DSP-848) #1664 | feat(api-v2): Add support for text file upload (DSP-44) #1652 | DSP-377 Support Islamic calendar #1717 | enhancement(gravsearch): Optimise queries by moving up statements with resource IRIs #1713 | feat(gravsearch): Allow comparing variables representing resource IRIs #1710 | update ontology metadata with a comment #1704 | feat(api-v2): Add test data #1703 | Add comments to ontology metadata #1686 | feat(api-v2): Accept custom timestamps in update/delete requests #1692 | Create Permissions #1696 | feat(api-v2): Make inference optional in Gravsearch #1697 | fix(sipi): Improve performance of file value query #1698 | feat(api-v2): Accept custom new value IRI when updating value #1700 | hierarchically ordered Sequence of base classes #1689 | build: bump SIPI to v3.0.0-rc.5 (DSP-547) #1679 | Gravsearch optimisations #1663 | build: add support for SIPI v3.0.0-rc.3 (DSP-433) #1660 | feat(gravsearch): Remove deprecated functions #1653 | build: dockerize fuseki (dsp-30) Bug Fixes #1626 | fix(gravsearch): Prevent duplicate results #1587 | fix (webapi): Add enforcing of restrictions for username and email #1576 | Add missing env var #1571 | fixed date string format #1564 | enable click on save button in case of recoverable error #1751 | DSP-1022 SIPI_EXTERNAL_HOSTNAME doesn't contain the external hostname #1749 | fix(api-v2): Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) #1748 | DSP-756 Tests failing because Knora version header and route are incorrect #1746 | DSP-932: Don't allow missing StringLiteralV2 value if language tag given #1744 | DSP-917 Releases pushed to Dockerhub from DSP-API are \"dirty\" #1733 | DSP-470 Intermittent bind errors #1728 | fix(api-v2): Fix post-update check for resource with standoff link (DSP-841) #1723 | chore(build): Bump testcontainers version (DSP-755) #1706 | Fix of update of list node info and update of project info #1712 | fix: failing repository upgrade at startup (DSP-654) #1709 | fix(OntologyResponderV2): Fix ontology cache update when ontology metadata changed #1701 | reverse change of Permission JSONs #1693 | fix(api-v2): Fix generated SPARQL for updating property comment #1699 | fix(gravsearch): When link property compared in filter, don't compare link value property, too #1691 | fix: server header (DSP-537) #1681 | fix: init db scripts (DSP-511) #1669 | fix: loading of data (DSP-445) Documentation #1598 | doc: fix sipi docs link #1609 | fix complex schema url #1568 | fixed the URI for the query #1726 | PersmissionsDocs: remove the attribute #1725 | docs: Update required mkdocs package #1711 | update developer and create resource docs #1684 | developer guideline #1685 | docs(api-v2): Document what happens when a resource has a link to a deleted resource #1688 | docs: fix broken links #1694 | docs: fix publishing #1621 | fixing typos for list rendering Other #1750 | Update README.md #1747 | DSP-920 Renaming default github branch to \"main\" ; Move to the same base branch #1740 | DSP-877 Upload api-client-test-data to GitHub release #1738 | DSP-877 Upload api-client-test-data to GitHub release #1736 | DSP-877 Upload api-client-test-data to GitHub release #1730 | DSP-816: Generate client test data for health route #1719 | change possibly conflictual env var USERNAME (DSP-706) #1720 | DSP-620 Update release process #1714 | test: fix generation of test data (DSP-665) #1716 | bulid: fix sipi image version (DSP-677) #1718 | DSP-702 Add template for PRs #1715 | chore(api-v2): Switch from JSONLD-Java to Titanium #1707 | chore: Update ci workflow #1702 | Add PR labels (DSP-607) #1695 | refactor(gravsearch): Clarify optimisations #1678 | refactor: first steps towards more independent packages (DSP-513) #1680 | build: bump rules_docker and instructions for installing bazelisk #1674 | build: add mkdocs for documentation generation (DSP-460) #1480 | build: add bazel (DSP-437) #1666 | Fix gren issue in github actions workflow #1662 | Publish on release only #1661 | Automated release notes Dependencies #1721 | chore: bump sipi to rc.7 (DSP-733) #1735 | DSP-496 Bump Apache Jena Fuseki and Apache Jena Libraries to 3.16 #1737 | DSP-842 Bump used Bazel version to newly released 3.7.0 #1743 | chore(build): Upgrade Sipi to 3.0.0-rc.8 (DSP-916) #1745 | chore(build): Update ScalaTest (DSP-919) #1752 | DSP-1017 Upgrade to Sipi v3.0.0-rc.9 v13.0.0-rc.21 (09/11/2020) Breaking changes #1724 | test: Collect client test data from E2E tests (DSP-724) #1727 | DSP-740 Update List Name #1722 | feat(api-v1): Change API v1 file uploads to work like API v2 (DSP-41, PR 3) #1233 | feat(api-v1): Change API v1 file uploads to work like API v2 #1708 | Get Project Permissions Enhancements #1403 | feat: Add time value type #1649 | feat(api-v2): Allow querying for rdfs:label in Gravsearch #1742 | feat: Add feature toggles (DSP-910) #1741 | DSP-804: create a child node with a custom IRI #1734 | feat(api-v2): Add metadata routes (DSP-662) #1739 | enhancement(api-v2): Optimise checking isDeleted (DSP-848) #1664 | feat(api-v2): Add support for text file upload (DSP-44) #1652 | DSP-377 Support Islamic calendar #1717 | enhancement(gravsearch): Optimise queries by moving up statements with resource IRIs #1713 | feat(gravsearch): Allow comparing variables representing resource IRIs #1710 | update ontology metadata with a comment #1704 | feat(api-v2): Add test data #1703 | Add comments to ontology metadata #1686 | feat(api-v2): Accept custom timestamps in update/delete requests #1692 | Create Permissions #1696 | feat(api-v2): Make inference optional in Gravsearch #1697 | fix(sipi): Improve performance of file value query #1698 | feat(api-v2): Accept custom new value IRI when updating value #1700 | hierarchically ordered Sequence of base classes #1689 | build: bump SIPI to v3.0.0-rc.5 (DSP-547) #1679 | Gravsearch optimisations #1663 | build: add support for SIPI v3.0.0-rc.3 (DSP-433) #1660 | feat(gravsearch): Remove deprecated functions #1653 | build: dockerize fuseki (dsp-30) Bug Fixes #1626 | fix(gravsearch): Prevent duplicate results #1587 | fix (webapi): Add enforcing of restrictions for username and email #1751 | DSP-1022 SIPI_EXTERNAL_HOSTNAME doesn't contain the external hostname #1749 | fix(api-v2): Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) #1748 | DSP-756 Tests failing because Knora version header and route are incorrect #1746 | DSP-932: Don't allow missing StringLiteralV2 value if language tag given #1744 | DSP-917 Releases pushed to Dockerhub from DSP-API are \"dirty\" #1733 | DSP-470 Intermittent bind errors #1728 | fix(api-v2): Fix post-update check for resource with standoff link (DSP-841) #1723 | chore(build): Bump testcontainers version (DSP-755) #1706 | Fix of update of list node info and update of project info #1712 | fix: failing repository upgrade at startup (DSP-654) #1709 | fix(OntologyResponderV2): Fix ontology cache update when ontology metadata changed #1701 | reverse change of Permission JSONs #1693 | fix(api-v2): Fix generated SPARQL for updating property comment #1699 | fix(gravsearch): When link property compared in filter, don't compare link value property, too #1691 | fix: server header (DSP-537) #1681 | fix: init db scripts (DSP-511) #1669 | fix: loading of data (DSP-445) Documentation #1598 | doc: fix sipi docs link #1609 | fix complex schema url #1568 | fixed the URI for the query #1726 | PersmissionsDocs: remove the attribute #1725 | docs: Update required mkdocs package #1711 | update developer and create resource docs #1684 | developer guideline #1685 | docs(api-v2): Document what happens when a resource has a link to a deleted resource #1688 | docs: fix broken links #1694 | docs: fix publishing #1621 | fixing typos for list rendering Other #1750 | Update README.md #1747 | DSP-920 Renaming default github branch to \"main\" ; Move to the same base branch #1740 | DSP-877 Upload api-client-test-data to GitHub release #1738 | DSP-877 Upload api-client-test-data to GitHub release #1736 | DSP-877 Upload api-client-test-data to GitHub release #1730 | DSP-816: Generate client test data for health route #1719 | change possibly conflictual env var USERNAME (DSP-706) #1720 | DSP-620 Update release process #1714 | test: fix generation of test data (DSP-665) #1716 | bulid: fix sipi image version (DSP-677) #1718 | DSP-702 Add template for PRs #1715 | chore(api-v2): Switch from JSONLD-Java to Titanium #1707 | chore: Update ci workflow #1702 | Add PR labels (DSP-607) #1695 | refactor(gravsearch): Clarify optimisations #1678 | refactor: first steps towards more independent packages (DSP-513) #1680 | build: bump rules_docker and instructions for installing bazelisk #1674 | build: add mkdocs for documentation generation (DSP-460) #1480 | build: add bazel (DSP-437) #1666 | Fix gren issue in github actions workflow #1662 | Publish on release only #1661 | Automated release notes v12.0.0 (27/01/2020) Breaking API Changes #1439 JSON-LD Serialization of an xsd:dateTimeStamp New Features and Enhancements #1509 Support lists admin endpoint #1466 Optimise generated SPARQL Bug Fixes #1569 broken ark #1559 Admin lists: createChildNode should send a httpPost request, not httpPut v11.0.0 (16/12/2019) Breaking Changes #1344 Gravsearch ForbiddenResource result and permissions of linked resources #1202 Implement upload of PDF and text files in API v2. Users with files in Sipi under /server must move them to /images when upgrading. Bug Fixes #1531 Sipi's mimetype_consistency fails with .bin file #1430 Creating the first resource with an image inside a project fails with Sipi not finding the project folder #924 Get dependent resources Iris v10.1.1 (27/11/2019) v10.1.0 (27/11/2019) v10.0.0 (22/10/2019) Breaking Changes #1346 Richtext/HTML in page anchor link Enhancements #1457 Upgrade sipi to 2.0.1 Bug Fixes #1460 Build banner in README is broken Documentation #1481 build badge in README has broken link Other #1449 Add Makefile-based task execution #1401 Enable testing docs generation in Travis v9.1.0 (26/09/2019) Enhancements #1421 Physically deleting a resource Documentation #1407 Document ARK URLs for projects v9.0.0 (29/08/2019) Breaking Changes #1411 Moved /admin/groups/members/GROUP_IRI to /admin/groups/GROUP_IRI/members #1231 Change value permissions #763 refactor splitMainResourcesAndValueRdfData so it uses SparqlExtendedConstructResponse Enhancements #1373 The startup ends in a thrown exception if the triplestore is not up-to-date #1364 Add support for Redis cache #1360 Build and publish Knora version specific docker images for GraphDB Free and SE #1358 Add admin route to dump project data Bug Fixes #1394 Using dockerComposeUp to start the stack, fails to find Redis at startup Documentation #1386 Add lists admin API documentation Other #1412 Change release notes to be based on issues v8.0.0 (14/06/2019) feature(webapi): Add GraphDB-Free startup support (#1351) - @subotic feature(webapi): Add returning of fixed public user information (#1348) - @subotic feat(api-v2): No custom permissions higher than defaults (#1337) - @benjamingeer feat(upgrade): Improve upgrade framework (#1345) - @benjamingeer test(webapi): Add new user authentication (#1201) - @subotic chore(webapi): Add request duration logging (#1347) - @subotic feat(api-v2): Make values citable (#1322) - @benjamingeer Leibniz ontology (#1326) - @SepidehAlassi feature(webapi): add CORS allow header (#1340) - @subotic fix(sipi): Return permissions for a previous version of a file value. (#1339) - @benjamingeer fix(scripts): add admin ontology data to correct graph (#1333) - @subotic fix(sipi): Don't try to read a file value in a deleted resource. (#1329) - @benjamingeer docs(api-v2): Fix sample responses. (#1327) - @benjamingeer fix(api-v2): Fix typo. (#1325) - @benjamingeer Handle List Nodes in Response (#1321) - @tobiasschweizer feat(api-v2): Return standoff markup separately from text values (#1307) - @benjamingeer BEOL: Import comments for Meditationes (#1281) - @tobiasschweizer feat(triplestore): Log SPARQL query if triplestore doesn't respond. (#1292) - @benjamingeer Support list nodes in Gravsearch (#1314) - @tobiasschweizer v7.0.0 (03/05/2019) fix(api-v2): Cache base class IRIs correctly when creating/updating class (#1311) - @benjamingeer chore(standoff): Use Base64-encoded UUIDs in standoff tags. (#1301) - @benjamingeer feat(api-v2): Allow a resource to be created as a specified user (#1306) - @benjamingeer feat(admin): Give the admin ontology an external schema (#1291) - @benjamingeer fix(api-v2): Remove INFORMATION SEPARATOR TWO from text in the simple schema. (#1299) - @benjamingeer test: Compare Knora response with its class definition (#1297) - @benjamingeer docs(api-admin): fix description of the change password payload (#1285) - @loicjaouen fix(api-v1): Fix double escaping of newline. (#1296) - @benjamingeer fix (tei beol): fix problems in XSLT (#1260) - @tobiasschweizer refactor(ontology): Make knora-admin a separate ontology (#1263) - @benjamingeer a handfull of changes in documentation and error messages (#1278) - @loicjaouen docs: fix missing username (#1269) - @loicjaouen feat(api-v2): Get resources in a particular class from a project (#1251) - @benjamingeer fix(sipi): Improve error checking of Sipi's knora.json response. (#1279) - @benjamingeer feat(api-v2): Return user's permission on resources and values (#1257) - @benjamingeer fix(api-v1): Escape rdfs:label in bulk import. (#1276) - @benjamingeer chore(webapi): Remove persistent map code (#1254) - @benjamingeer docs (api-v2): Update outdated ARK documentation. (#1252) - @benjamingeer Update build.properties (#1265) - @subotic v6.0.1 (22/03/2019) chore: releasing-v6.0.1 (#1270) - @subotic chore(webapi): Add script for loading of a minimal set of data (#1267) - @subotic fix (beolPersonLabel) typo in label of hasBirthPlace (#1248) - @SepidehAlassi fix (webapi): message typo (#1244) - @subotic Unescape standoff string attributes when verifying text value update (#1242) - @benjamingeer docs: fix user admin api (#1237) - @subotic v6.0.0 (28/02/2019) Release Notes MAJOR: Use HTTP POST to mark resources and values as deleted (#1203) MAJOR: Reorganize user and project routes (#1209) FEATURE: Secure routes returning user information (#961) MAJOR: Change all xsd:dateTimeStamp to xsd:dateTime in the triplestore (#1211). Existing data must be updated; see upgrade/1211-datetime for instructions. FIX: Ignore order of attributes when comparing standoff (#1224). FEATURE: Query version history (#1214) FIX: Don't allow conflicting cardinalities (#1229) MAJOR: Remove preview file values (#1230). Existing data must be updated; see upgrade/1230-delete-previews for instructions. v5.0.0 (05/02/2019) Release Notes MAJOR: Fix property names for incoming links (#1144)) MAJOR: Generate and resolve ARK URLs for resources (#1161). Projects that have resource IRIs that do not conform to the format specified in https://docs.knora.org/paradox/03-endpoints/api-v2/knora-iris.html#iris-for-data must update them. MAJOR: Use project shortcode in IIIF URLs (#1191). If you have file value IRIs containing the substring /reps/ , you must replace /reps/ with /values/ . FEATURE: Update resource metadata in API v2 (#1131) FEATURE: Allow setting resource creation date in bulk import #1151) FEATURE: The v2/authentication route now also initiates cookie creation (the same as v1/authentication ) (#1159) FEATURE: Allow to specify restricted view settings for a project which Sipi will adhere to (#690). FIX: Triplestore connection error when using dockerComposeUp (#1122) FIX: Reject link value properties in Gravsearch queries in the simple schema (#1145) FIX: Fix error-checking when updating cardinalities in ontology API (#1142) FIX: Allow hasRepresentation in an ontology used in a bulk import (#1171) FIX: Set cookie domain to the value specified in application.conf with the setting cookie-domain (#1169) FIX: Fix processing of shared property in bulk import (#1182) v4.0.0 (12/12/2018) v4.0.0 Release Notes MAJOR CHANGE: mapping creation request and response formats have changed (#1094) MINOR CHANGE: Update technical user docs (#1085) BUGFIX CHANGE: Fix permission checking in API v2 resource creation (#1104) v3.0.0 (30/11/2018) v3.0.0 Release Notes [BREAKING ONTOLOGY CHANGE] The property knora-base:username was added and is required for knora-base:User . (#1047) [BREAKING API CHANGE] The /admin/user API has changed due to adding the username property. (#1047) [FIX] Incorrect standoff to XML conversion if empty tag has empty child tag (#1054) [FEATURE] Add default permission caching (#1062) [FIX] Fix unescaping in update check and reading standoff URL (#1074) [FIX] Incorrect standoff to XML conversion if empty tag has empty child tag (#1054) [FEATURE] Create image file values in API v2 (#1011). Requires Sipi with tagged commit v1.4.1-SNAPSHOT or later. v2.1.0 (02/11/2018) New features Implement graph query in API v2 (#1009) Expose additional webapi settings as environment variables. Please see the Configuration section in the documentation for more information (#1025) Bugfixes sipi container config / sipi not able to talk to knora (#994) v2.1.0-snapshot (22/10/2018) v2.0.0 (13/09/2018) This is the first release with the new version numbering convention. From now on, if any changes to the existing data are necessary for a release, then this release will have its major number increased. Please see the Release Versioning Convention description. Required changes to existing data a knora-base:ListNode must have at least one rdfs:label . (@github #991 ) New features add developer-centric docker-compose.yml for starting the Knora / GraphDB / Sipi / Salsah1 (@github #979 ) configure webapi and salsah1 thorough environment variables (@github #979 ) update for Java 10 (@github #979 ) comment out the generation of fat jars from KnoraBuild.sbt (for now) (@github #979 ) update ehcache (@github #979 ) update sbt to 1.2.1 (@github #979 ) remove Kamon monitoring (for now) since we don't see anything meaningful there. We probably will have to instrument Knora by hand and then use Kamon for access. (@github #979 ) update Dockerfiles for webapi and salsah1 (@github #979 ) follow subClassOf when including ontologies in XML import schemas (@github #991 ) add support for adding list child nodes (@github #991 ) add support for shared ontologies (@github #987 ) Bugfixes trouble with xml-checker and/or consistency-checker during bulk import (@github #978 ) ontology API error with link values (@github #988 ) v1.7.1 (29/08/2018) Knora-Stack compatible versions Knora v1.7.1 - Salsah v2.1.2 - Sipi v1.4.0 - GraphDB v8.5.0 doc (webapi): add yourkit acknowledgment (#983) Don't allow class with cardinalities on P and on a subproperty of P (#982) doc (webapi): add LHTT project shortcode (#981) feature (webapi): not return or allow changing of built-in users (#975) fix (webapi): startup check does not detect running triplestore (#969) Fix bulk import parsing bug and limit concurrent client connections (#973) v1.7.0 (16/08/2018) See the closed tickets on the v1.7.0 milestone . Knora-Stack compatible versions Knora v1.7.0 - Salsah v2.1.0 - Sipi v1.4.0 - GraphDB v8.5.0 Required changes to existing data To use the inferred Gravsearch predicate knora-api:standoffTagHasStartAncestor , you must recreate your repository with the updated KnoraRules.pie . New features Gravsearch queries can now match standoff markup (#910). Add Graphdb-Free initialization scripts for local and docker installation (#955). Create temp dirs at startup (#951) Update versions of monitoring tools (#951) Bugfixes timeout or java.lang.OutOfMemoryError when using /v1/resources/xmlimportschemas/ for some ontologies (#944) Timeout cleanup (#951) Add separate dispatchers (#945) v1.6.0 (29/06/2018) v1.6.0 Release Notes See the release and closed tickets on the v1.6.0 milestone on Github. Required changes to existing data A project is now required to have at least one description, so potentially a description will need to be added to those projects that don't have one. New features General: Added a /health endpoint KnoraService waits on startup for a triplestore before trying to load the ontologies Gravsearch enhancements: Accept queries in POST requests (@github #650 ). Allow a Gravsearch query to specify the IRI of the main resource (@github #871 ) (by allowing BIND ). Allow lang to be used with != . A UNION or OPTIONAL can now be nested in an OPTIONAL (@github #882 ). Gravsearch now does type inference (@github #884 ). The Knora API v2 complex schema can now be used in Gravsearch, making it possible to search for list nodes (@github #899 ). Admin API: Make project description required (@github #875 ). Conversion to TEI: Conversion of standard standoff entities to TEI Custom conversion of project specific standoff entities and metadata to TEI Sipi integration: The Knora specific Sipi configuration and scripts can now be found under the sipi/ directory (@github #404 ). Documentation on how Sipi can be started changed (@github #404 ). Bugfixes Allow a class or property definition to have more than one object for rdf:type (@github #885 ). Exclude list values from v2 fulltext search (@github #906 ). Gravsearch fixes: Allow the lang function to be used in a comparison inside AND/OR (@github #846 ). Fix the processing of resources with multiple incoming links that use the same property (@github #878 ). Fix the parsing of a FILTER inside an OPTIONAL (@github #879 ). Require the match function to be the top-level expression in a FILTER . v1.5.0 (31/05/2018) See v1.5.0 milestone for a full list of closed tickets. New features Resources can be returned in the simple ontology schema (#833). Text values can specify the language of the text (#819). Responses can be returned in Turtle and RDF/XML (#851). Bugfixes Incorrect representation of IRI object values in JSON-LD (#835) GenerateContributorsFile broken (#797) v1.4.0 (30/04/2018) Required changes to existing data Every ontology must now have the property knora-base:attachedToProject , which points to the IRI of the project that is responsible for the ontology. This must be added to each project-specific ontology in existing repositories. All built-in ontologies have been updated to have this property, and must, therefore, be reloaded into existing repositories. The property knora-base:projectOntology has been removed, and must be removed from project definitions in existing repositories. Every project now needs to have the property knora-base:projectShortcode set. New features Added OpenAPI / Swagger API documentation route The Knora API server now checks the validity of ontologies on startup. The property knora-base:projectShortcode is now a required property (was optional). Bugfixes API v1 extended search was not properly handling multiple conditions on list values (issue #800) Fix image orientation in SALSAH 1 (issue #726) v1.3.1 (06/04/2018) v1.3.0 (28/03/2018) Required changes to existing data 1. Replace salsah-gui ontology You must replace the salsah-gui ontology that you have in the triplestore with the one in salsah-gui.ttl . New features More support for salsah-gui elements and attributes in ontologies Serve the salsah-gui ontology in API v2 in the default schema. Show salsah-gui:guiElement and salsah-gui:guiAttribute when serving ontologies in API v2 in the default schema. Allow salsah-gui:guiElement and salsah-gui:guiAttribute to be included in new property definitions created via API v2. Change salsah-gui so that GraphDB's consistency checker can check the use of guiElement and guiAttribute . Changes to application.conf . The sipi and web-api sections have received a big update, adding separate settings for internal and external host settings: app { knora-api { // relevant for direct communication inside the knora stack internal-host = \"0.0.0.0\" internal-port = 3333 // relevant for the client, i.e. browser external-protocol = \"http\" // optional ssl termination needs to be done by the proxy external-host = \"0.0.0.0\" external-port = 3333 } sipi { // relevant for direct communication inside the knora stack internal-protocol = \"http\" internal-host = \"localhost\" internal-port = 1024 // relevant for the client, i.e. browser external-protocol = \"http\" external-host = \"localhost\" external-port = 1024 prefix = \"knora\" file-server-path = \"server\" path-conversion-route = \"convert_from_binaries\" file-conversion-route = \"convert_from_file\" image-mime-types = [\"image/tiff\", \"image/jpeg\", \"image/png\", \"image/jp2\"] movie-mime-types = [] sound-mime-types = [] } salsah1 { base-url = \"http://localhost:3335/\" project-icons-basepath = \"project-icons/\" } } Bugfixes When API v2 served knora-api (default schema), salsah-gui:guiElement and salsah-gui:guiAttribute were not shown in properties in that ontology. The predicate salsah-gui:guiOrder was not accepted when creating a property via API v2.","title":"Changelog"},{"location":"09-release-notes/#changelog","text":"","title":"Changelog"},{"location":"09-release-notes/#2408-2022-10-18","text":"","title":"24.0.8 (2022-10-18)"},{"location":"09-release-notes/#bug-fixes","text":"User can be project admin without being project member (DEV-1383) ( #2248 ) ( c1aa8f0 )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance","text":"automatically clean sipi image files (DEV-1395) ( #2237 ) ( eddb34d ) fix project name ( #2239 ) ( 5af65eb ) update dependencies ( #2247 ) ( 2eefcbc )","title":"Maintenance"},{"location":"09-release-notes/#2407-2022-10-07","text":"","title":"24.0.7 (2022-10-07)"},{"location":"09-release-notes/#bug-fixes_1","text":"DSP-API project IRI validation fails for BEOL project IRI ( #2240 ) ( 4b63a72 )","title":"Bug Fixes"},{"location":"09-release-notes/#2406-2022-10-06","text":"","title":"24.0.6 (2022-10-06)"},{"location":"09-release-notes/#bug-fixes_2","text":"Ask timeouts when requesting projects (DEV-1386) ( #2235 ) ( 1820367 ) User can't be edited by project admin (DEV-1373) ( #2232 ) ( e0b1433 )","title":"Bug Fixes"},{"location":"09-release-notes/#2405-2022-10-05","text":"","title":"24.0.5 (2022-10-05)"},{"location":"09-release-notes/#bug-fixes_3","text":"Timeout for multiple Gravsearch queries (DEV-1379) ( #2234 ) ( c63567b )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_1","text":"app actor cleanup ( #2230 ) ( a67c98f )","title":"Maintenance"},{"location":"09-release-notes/#2404-2022-09-29","text":"","title":"24.0.4 (2022-09-29)"},{"location":"09-release-notes/#bug-fixes_4","text":"API returns invalid file URLs, due to including the port ( #2223 ) ( 1a0b09c ) Value update or deletion doesn't work for properties of other ontology (DEV-1367) ( #2222 ) ( 472b375 )","title":"Bug Fixes"},{"location":"09-release-notes/#2403-2022-09-21","text":"","title":"24.0.3 (2022-09-21)"},{"location":"09-release-notes/#maintenance_2","text":"application actor (DEV-956) ( #2166 ) ( 4852425 ) remove swagger route and docs annotations (DEV-1335) ( #2203 ) ( bec5b8a ) Replace Settings with AppConfig (DEV-1312) ( #2202 ) ( 9b76417 ) update dependencies ( #2214 ) ( 3706acd )","title":"Maintenance"},{"location":"09-release-notes/#2402-2022-09-08","text":"","title":"24.0.2 (2022-09-08)"},{"location":"09-release-notes/#bug-fixes_5","text":"sipi: remove support for audio/mp4 file format (DEV-1300) ( #2195 ) ( 122bf52 )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_3","text":"Adjust GitHub template (DEV-1313) ( #2183 ) ( 5782494 ) bump dependencies ( #2196 ) ( 2fbf664 ) Ignore push on certain branches from tests (DEV-1112) ( #2187 ) ( e0a0fbb ) Improve GitHub actions (DEV-1112) ( #2182 ) ( 71c772f ) Skip tests with success (DEV-1112) ( #2188 ) ( 82703d7 ) v3: add project slice (DEV-1009) ( #2076 ) ( bd2d31e )","title":"Maintenance"},{"location":"09-release-notes/#2401-2022-08-26","text":"","title":"24.0.1 (2022-08-26)"},{"location":"09-release-notes/#bug-fixes_6","text":"cardinality: Check cardinality with multiple inherited classes (DEV-1189) ( #2164 ) ( f183d7d ) Fuseki doesn't stop after client's timeout (DEV-1190) ( #2175 ) ( 90f86b5 ) v2 test: fix test data collection ( #2174 ) ( 468df8f )","title":"Bug Fixes"},{"location":"09-release-notes/#documentation","text":"update file formats (DEV-1185) ( #2158 ) ( 4fab193 )","title":"Documentation"},{"location":"09-release-notes/#maintenance_4","text":"add codacy coverage reporter ( #2177 ) ( c30390f ) add code coverage ( #2135 ) ( 1a02f49 ) add code coverage ( #2163 ) ( b026442 ) add coverage upload to codecov ( #2179 ) ( 5d4e57e ) feature-toggles: remove remnants of feature toggles (DEV-217) ( #2176 ) ( ed1cbd0 ) remove github action for deploying docs (DEV-824) ( #2155 ) ( a55eef4 ) update dependencies ( #2173 ) ( 79b88d2 )","title":"Maintenance"},{"location":"09-release-notes/#2400-2022-08-08","text":"","title":"24.0.0 (2022-08-08)"},{"location":"09-release-notes/#breaking-changes","text":"add isSequenceOf to knora-base ontology (DEV-745) (#2061)","title":"\u26a0 BREAKING CHANGES"},{"location":"09-release-notes/#bug-fixes_7","text":"sipi: SIPI returns 404 instead of images if cookie is invalid (DEV-1135) ( #2142 ) ( eb797f0 )","title":"Bug Fixes"},{"location":"09-release-notes/#enhancements","text":"add isSequenceOf to knora-base ontology (DEV-745) ( #2061 ) ( 74366d4 )","title":"Enhancements"},{"location":"09-release-notes/#maintenance_5","text":"dependencies: bulk upgrade dependencies ( #2144 ) ( 4602150 ) update dependencies ( 4cd9812 )","title":"Maintenance"},{"location":"09-release-notes/#2303-2022-08-02","text":"","title":"23.0.3 (2022-08-02)"},{"location":"09-release-notes/#bug-fixes_8","text":"triplestore-connector: stack crashes on invalid search (DEV-1154) ( #2140 ) ( e5426dc )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_6","text":"dependencies: update akka-http-cors to 1.1.3 ( #2103 ) ( 5d0d522 ) dependencies: update jwt-spray-json to 9.0.2 ( #2111 ) ( 6e54443 ) dependencies: update Saxon-HE to 11.4 ( #2137 ) ( 08c9f68 ) dependencies: update scalatest to 3.2.13 ( #2138 ) ( a345079 ) dependencies: update spring-security-core to 5.6.6 ( #2130 ) ( c83645d ) dependencies: update spring-security-core to 5.7.2 ( #2139 ) ( 3a12562 ) dependencies: update titanium-json-ld to 1.3.1 ( #2104 ) ( 4850525 )","title":"Maintenance"},{"location":"09-release-notes/#2302-2022-07-29","text":"","title":"23.0.2 (2022-07-29)"},{"location":"09-release-notes/#bug-fixes_9","text":"ontology: link value property is still not editable after updating the property metadata (DEV-1116) ( #2133 ) ( d5b48db ) sipi: cookie parsing can cause an error which leads to 404 for images (DEV-1135) ( #2134 ) ( bd023a5 )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_7","text":"add dependency checking ( #2100 ) ( 8017b1f ) add dependency checking ( #2102 ) ( 856277b ) Improve validation of GUI elements and GUI attributes (DEV-1082) ( #2098 ) ( 5cec8ba ) v3: add role slice (DEV-1010) ( #2099 ) ( 6920716 )","title":"Maintenance"},{"location":"09-release-notes/#2301-2022-07-19","text":"","title":"23.0.1 (2022-07-19)"},{"location":"09-release-notes/#bug-fixes_10","text":"ontology: Don't accept list values without gui attribute (DEV-775) ( #2089 ) ( 74a14e1 )","title":"Bug Fixes"},{"location":"09-release-notes/#2300-2022-07-14","text":"","title":"23.0.0 (2022-07-14)"},{"location":"09-release-notes/#breaking-changes_1","text":"transform valueHasUri values from node to string type (DEV-1047) (#2094)","title":"\u26a0 BREAKING CHANGES"},{"location":"09-release-notes/#bug-fixes_11","text":"authentication: make cookie name unique between environments ( #2095 ) ( 7d420a4 ) ontology: existing cardinalities get duplicated in the triplestore when adding a new cardinality to a class (DEV-937) ( #2092 ) ( 9fa26db ) transform valueHasUri values from node to string type (DEV-1047) ( #2094 ) ( e1d8d95 )","title":"Bug Fixes"},{"location":"09-release-notes/#2201-2022-07-08","text":"","title":"22.0.1 (2022-07-08)"},{"location":"09-release-notes/#bug-fixes_12","text":"authentication: make cookie name unique between environments ( #2091 ) ( 680021e ) value: make impossible to set list root node as a value (DEV-973) ( #2088 ) ( 94d2b46 )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_8","text":"triplestore: ZIO-fying triplestore service (DSP-904) ( #2059 ) ( 9e038ec ) v3: finish user slice (DEV-671) ( #2078 ) ( 48592ad )","title":"Maintenance"},{"location":"09-release-notes/#2200-2022-06-30","text":"","title":"22.0.0 (2022-06-30)"},{"location":"09-release-notes/#breaking-changes_2","text":"add upgrade plugin that fixes invalid date serialisations (#2081)","title":"\u26a0 BREAKING CHANGES"},{"location":"09-release-notes/#bug-fixes_13","text":"add upgrade plugin that fixes invalid date serialisations ( #2081 ) ( 3a0902e ) ontology: link value property is not editable after editing the property metadata (DEV-1037) ( #2084 ) ( 09688f5 )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_9","text":"temporarily ignore KnoraSipiIntegrationV2ITSpec ( #2085 ) ( 59f93b3 )","title":"Maintenance"},{"location":"09-release-notes/#2101-2022-06-23","text":"","title":"21.0.1 (2022-06-23)"},{"location":"09-release-notes/#bug-fixes_14","text":"fix RepositoryUpdater by removing old way of adding plugins ( #2082 ) ( 6599b68 )","title":"Bug Fixes"},{"location":"09-release-notes/#2100-2022-06-23","text":"","title":"21.0.0 (2022-06-23)"},{"location":"09-release-notes/#breaking-changes_3","text":"fix valueHasUri bad values and missing types (DEV-1036) (#2079)","title":"\u26a0 BREAKING CHANGES"},{"location":"09-release-notes/#bug-fixes_15","text":"fix valueHasUri bad values and missing types (DEV-1036) ( #2079 ) ( de1e5a4 )","title":"Bug Fixes"},{"location":"09-release-notes/#2041-2022-06-16","text":"","title":"20.4.1 (2022-06-16)"},{"location":"09-release-notes/#bug-fixes_16","text":"admin: return list labels and comments sorted by language ( #2074 ) ( f3a66cb )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_10","text":"add missing client test data (DEV-979) ( #2072 ) ( 54446bc ) audio: remove not required properties ( #2070 ) ( 96362f4 ) exceptions: Create sbt project \"shared\" and move exceptions (DEV-990) ( #2075 ) ( c09392d ) move value objects to separate project (DEV-615) ( #2069 ) ( b55eb12 ) responder manager as plain case class ( #2073 ) ( 7f55697 ) user: add user project (DEV-586) ( #2063 ) ( 0c5ec03 )","title":"Maintenance"},{"location":"09-release-notes/#2040-2022-05-25","text":"","title":"20.4.0 (2022-05-25)"},{"location":"09-release-notes/#bug-fixes_17","text":"cache: cache does not update correctly when an ontology is modified (DEV-939) ( #2068 ) ( 8541519 )","title":"Bug Fixes"},{"location":"09-release-notes/#enhancements_1","text":"admin: add list child node deletion route (DEV-729) ( #2064 ) ( 179ad19 )","title":"Enhancements"},{"location":"09-release-notes/#2031-2022-05-12","text":"","title":"20.3.1 (2022-05-12)"},{"location":"09-release-notes/#bug-fixes_18","text":"authentication: Add bouncyCastle dependency (DEV-922) ( #2065 ) ( 4ac799d )","title":"Bug Fixes"},{"location":"09-release-notes/#2030-2022-05-12","text":"","title":"20.3.0 (2022-05-12)"},{"location":"09-release-notes/#bug-fixes_19","text":"Problem with updating cache after deleting comments (DEV-508) ( #2060 ) ( a9fda7e )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_11","text":"check that the expected Fuseki version is present (DEV-331) ( #2057 ) ( 2a695ec ) deps: bump ZIO version (DEV-893) ( #2056 ) ( 933f91e )","title":"Maintenance"},{"location":"09-release-notes/#enhancements_2","text":"add Romansh as supported language (DEV-557) ( #2053 ) ( 58971c8 ) gravsearch: improve gravsearch performance by using unions in prequery (DEV-492) ( #2045 ) ( 40354a7 )","title":"Enhancements"},{"location":"09-release-notes/#2021-2022-05-05","text":"","title":"20.2.1 (2022-05-05)"},{"location":"09-release-notes/#bug-fixes_20","text":"projectsADM: fix cache issue in getSingleProjectADM ( #2054 ) ( 77bfadc )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_12","text":"IIIFService: zio-fying iiif service (DEV-801) ( #2044 ) ( 224b664 )","title":"Maintenance"},{"location":"09-release-notes/#2020-2022-04-28","text":"","title":"20.2.0 (2022-04-28)"},{"location":"09-release-notes/#bug-fixes_21","text":"Cleaning sipi tmp folder results in an error when there are lots of files (DEV-316) ( #2052 ) ( 33e6896 )","title":"Bug Fixes"},{"location":"09-release-notes/#enhancements_3","text":"error-handling: return status 504 instead of 500 for triplestore timeout exception (DEV-749) ( #2046 ) ( a47096e ) ontology: allow deleting comments of classes (DEV-804) ( #2048 ) ( eca9206 ) ontology: allow deleting comments of properties (DEV-696) ( #2042 ) ( 985c5fd )","title":"Enhancements"},{"location":"09-release-notes/#maintenance_13","text":"formatting-logging: reformat scala code and change logging policy (DEV-839) ( #2051 ) ( 5e4e914 ) formatting: reformat turtle files (DEV-430) ( #2050 ) ( 0389e52 ) triplestore: remove embedded-jena-tdb related code ( #2043 ) ( a5ea62e )","title":"Maintenance"},{"location":"09-release-notes/#2011-2022-04-14","text":"","title":"20.1.1 (2022-04-14)"},{"location":"09-release-notes/#bug-fixes_22","text":"sipi: extract frames from video even without aspect ratio (DEV-802) ( #2041 ) ( 57d40f7 )","title":"Bug Fixes"},{"location":"09-release-notes/#documentation_1","text":"ingest: Add accepted file formats to documentation (DEV-677) ( #2038 ) ( f72e7a0 )","title":"Documentation"},{"location":"09-release-notes/#maintenance_14","text":"cacheservice: use ZIO (DEV-546) ( #2022 ) ( 521150f ) triplestore: remove graphDB support ( #2037 ) ( bf17bca )","title":"Maintenance"},{"location":"09-release-notes/#2010-2022-04-07","text":"","title":"20.1.0 (2022-04-07)"},{"location":"09-release-notes/#bug-fixes_23","text":"docs/requirements.txt to reduce vulnerabilities ( #2034 ) ( b07600d )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_15","text":"distinguish between compile, runtime and test dependencies ( #2028 ) ( 7cb326f ) inventory and upgrade of dependencies (DEV-478) ( #2033 ) ( 470b77f )","title":"Maintenance"},{"location":"09-release-notes/#documentation_2","text":"replace Bazel and Intellij documentation with SBT and VSCode (DEV-607) ( #2035 ) ( 603efef )","title":"Documentation"},{"location":"09-release-notes/#enhancements_4","text":"ontology: Add support for additional ontologies (DEV-512) ( #2029 ) ( 50e3186 ) sipi: upload video support (DEV-771 / DEV-207) ( #1952 ) ( 47f2e28 )","title":"Enhancements"},{"location":"09-release-notes/#2000-2022-03-31","text":"","title":"20.0.0 (2022-03-31)"},{"location":"09-release-notes/#breaking-changes_4","text":"ontology: make knora-base:lastModificationDate required property (#2018)","title":"\u26a0 BREAKING CHANGES"},{"location":"09-release-notes/#maintenance_16","text":"fix docker containers timezone ( #2027 ) ( 6bbb3fe )","title":"Maintenance"},{"location":"09-release-notes/#enhancements_5","text":"ontology: make knora-base:lastModificationDate required property ( #2018 ) ( 64cdce9 )","title":"Enhancements"},{"location":"09-release-notes/#1900-2022-03-24","text":"","title":"19.0.0 (2022-03-24)"},{"location":"09-release-notes/#breaking-changes_5","text":"authentication: add server specific issuer to JWT token (DEV-555) (#2024)","title":"\u26a0 BREAKING CHANGES"},{"location":"09-release-notes/#bug-fixes_24","text":"authentication: add server specific issuer to JWT token (DEV-555) ( #2024 ) ( 4bd5b2f ) version: fix displayed versions ( #2026 ) ( 566285c )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_17","text":"improve logging (DEV-634) ( #2021 ) ( 85d1057 ) remove warnings (DEV-621) ( #2015 ) ( 70630f1 ) test: get tests to run in vs code (DEV-601) ( #2020 ) ( 747d13d )","title":"Maintenance"},{"location":"09-release-notes/#1800-2022-03-08","text":"","title":"18.0.0 (2022-03-08)"},{"location":"09-release-notes/#breaking-changes_6","text":"standoff: return XML alongside HTML for textValue with custom standoff mapping and default XSL transformation (DEV-201) (#1991)","title":"\u26a0 BREAKING CHANGES"},{"location":"09-release-notes/#bug-fixes_25","text":"Use correct docker image tag after publishing (DEV-614) ( #2016 ) ( 7649515 )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_18","text":"improve code structure (DEV-612) ( #2012 ) ( eac0049 )","title":"Maintenance"},{"location":"09-release-notes/#enhancements_6","text":"standoff: return XML alongside HTML for textValue with custom standoff mapping and default XSL transformation (DEV-201) ( #1991 ) ( 2548b8f )","title":"Enhancements"},{"location":"09-release-notes/#1753-2022-03-04","text":"","title":"17.5.3 (2022-03-04)"},{"location":"09-release-notes/#bug-fixes_26","text":"RepositoryUpdater: make sure temp directories are deleted ( #2010 ) ( 9c9a1bd )","title":"Bug Fixes"},{"location":"09-release-notes/#documentation_3","text":"fix permissions design documentation (DEV-495) ( #1997 ) ( 5154adc )","title":"Documentation"},{"location":"09-release-notes/#maintenance_19","text":"fix docker image name (DEV-574) ( #2007 ) ( 7a186ba ) remove fuseki image creation and change sipi image creation to sbt (DEV-544) ( #2011 ) ( eed2767 ) start on a functional domain design implementation for ontologies (DEV-227) ( #2009 ) ( 54cee7a )","title":"Maintenance"},{"location":"09-release-notes/#1752-2022-02-23","text":"","title":"17.5.2 (2022-02-23)"},{"location":"09-release-notes/#bug-fixes_27","text":"permissions: Update default object access permissions (DEV-514) ( #2004 ) ( 04a8d3d ) timeout: Increase timeouts (DEV-536) ( #2005 ) ( f1f8005 )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_20","text":"BAZEL to SBT migration (DEV-508) ( #2002 ) ( 38faa9e )","title":"Maintenance"},{"location":"09-release-notes/#1751-2022-02-16","text":"","title":"17.5.1 (2022-02-16)"},{"location":"09-release-notes/#maintenance_21","text":"deps: upgrade Jena Fuseki docker image to v2.0.8 ( #2001 ) ( 3e2eccc ) deps: upgrate Jena API to v4.4.0 ( #1999 ) ( 3eecc69 )","title":"Maintenance"},{"location":"09-release-notes/#documentation_4","text":"fix markdown issues in documentation (DEV-504) ( #2003 ) ( ff6b4cf )","title":"Documentation"},{"location":"09-release-notes/#1750-2022-02-11","text":"","title":"17.5.0 (2022-02-11)"},{"location":"09-release-notes/#enhancements_7","text":"ontologies: make comments optional for property and class creation (DEV-342) ( #1996 ) ( a3c286c )","title":"Enhancements"},{"location":"09-release-notes/#1741-2022-02-07","text":"","title":"17.4.1 (2022-02-07)"},{"location":"09-release-notes/#maintenance_22","text":"deps: upgrade Jena to v4.3.2 (DEV-473) ( #1995 ) ( 216dcb4 ) deps: upgrade titanium-json-ld to v1.2.0 & jakarta-json to v2.0.1 (DEV-335) ( #1993 ) ( ad01bf9 )","title":"Maintenance"},{"location":"09-release-notes/#1740-2022-02-04","text":"","title":"17.4.0 (2022-02-04)"},{"location":"09-release-notes/#bug-fixes_28","text":"version-upgrade: add upgrade plugin for ArchiveRepresentation and DeletedResource (DEV-467) ( #1992 ) ( e1566e9 )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_23","text":"add support for building native API and Fuseki Docker images on Apple M1 (DEV-435) ( #1987 ) ( ab80e72 ) refactor test models (DEV-264) ( #1975 ) ( 65952f9 )","title":"Maintenance"},{"location":"09-release-notes/#enhancements_8","text":"resource: add ArchiveRepresentation to API V1 (DEV-393) (DEV-394) ( #1984 ) ( 65b88a2 ) UUID: add IRI validation that allows only to create IRIs using UUID version 4 and 5 (DEV-402) ( #1990 ) ( 74d4344 )","title":"Enhancements"},{"location":"09-release-notes/#1731-2022-01-28","text":"","title":"17.3.1 (2022-01-28)"},{"location":"09-release-notes/#bug-fixes_29","text":"ontology: Sub-properties of link values aren't created correctly (DEV-426) ( #1985 ) ( 70a8b08 )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_24","text":"deps: bump fuseki image to 2.0.7 (DEV-389) ( #1983 ) ( fcbfb1d ) license: update the license (DEV-374) ( #1981 ) ( 044fdc5 )","title":"Maintenance"},{"location":"09-release-notes/#1730-2022-01-17","text":"","title":"17.3.0 (2022-01-17)"},{"location":"09-release-notes/#bug-fixes_30","text":"ontology: DSP-API creates wrong partOfValue property (DEV-216) ( #1978 ) ( 27b5c86 ) resource: return sensible CreationDate for DeletedResource ( #1979 ) ( 1658103 )","title":"Bug Fixes"},{"location":"09-release-notes/#enhancements_9","text":"resource: add support for 7z files in ArchiveRepresentation (DEV-322) ( #1977 ) ( 729689c )","title":"Enhancements"},{"location":"09-release-notes/#maintenance_25","text":"admin: refactor projects & users value objects (DEV-240) ( #1976 ) ( 563d252 ) CI: add disk cache and other cleanup (DEV-388) ( #1982 ) ( e590d12 )","title":"Maintenance"},{"location":"09-release-notes/#1720-2022-01-10","text":"","title":"17.2.0 (2022-01-10)"},{"location":"09-release-notes/#bug-fixes_31","text":"search: Return matching sub-nodes when searching for list label (DEV-158) ( #1973 ) ( 7e8c759 )","title":"Bug Fixes"},{"location":"09-release-notes/#enhancements_10","text":"return a DeletedResource or DeletedValue instead of 404 if a deleted resource or value is requested (DEV-226) ( #1960 ) ( c78e252 )","title":"Enhancements"},{"location":"09-release-notes/#1710-2021-12-20","text":"","title":"17.1.0 (2021-12-20)"},{"location":"09-release-notes/#enhancements_11","text":"listsADM: add canDeleteList route ( #1968 ) ( c276625 )","title":"Enhancements"},{"location":"09-release-notes/#maintenance_26","text":"deps: bump log4j to 2.17.0 and Fuseki to 4.3.2 (DEV-334) ( #1972 ) ( afb6587 )","title":"Maintenance"},{"location":"09-release-notes/#1704-2021-12-17","text":"","title":"17.0.4 (2021-12-17)"},{"location":"09-release-notes/#bug-fixes_32","text":"authentication: delete cookie (in chrome) on logout (DEV-325) ( #1970 ) ( b2c9204 ) candeletecardinalities: return canDoResponse of false instead of throwing an exception for inherited cardinalities (DEV-314) ( #1966 ) ( 55b5d4b ) ontology: cardinality of one can be added to classes as long as not used in data ( #1958 ) ( 2cebac7 )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_27","text":"bump logging libraries (DEV-333) ( #1969 ) ( f680c4f )","title":"Maintenance"},{"location":"09-release-notes/#1703-2021-12-14","text":"","title":"17.0.3 (2021-12-14)"},{"location":"09-release-notes/#maintenance_28","text":"bump Fuseki (log4shell fix) (IT-4) ( #1965 ) ( 86fa251 ) projectMetadataV2: remove projectMetadataV2 implementation ( #1962 ) ( 7b95d66 )","title":"Maintenance"},{"location":"09-release-notes/#1702-2021-12-10","text":"","title":"17.0.2 (2021-12-10)"},{"location":"09-release-notes/#maintenance_29","text":"bump db version (add shiro.ini)(DEV-302)( #1961 ) ( d147bf6 )","title":"Maintenance"},{"location":"09-release-notes/#1701-2021-12-06","text":"","title":"17.0.1 (2021-12-06)"},{"location":"09-release-notes/#maintenance_30","text":"fix issues with fuseki (DEV-277) ( #1953 ) ( 4c1a5f1 )","title":"Maintenance"},{"location":"09-release-notes/#documentation_5","text":"Updated readme ( #1956 ) ( 774b68d )","title":"Documentation"},{"location":"09-release-notes/#1700-2021-11-25","text":"","title":"17.0.0 (2021-11-25)"},{"location":"09-release-notes/#breaking-changes_7","text":"add archive representation to DSP-API (DEV-17) (#1926)","title":"\u26a0 BREAKING CHANGES"},{"location":"09-release-notes/#maintenance_31","text":"bump fuseki base container version ( #1946 ) ( cf8bdec ) bump java and sipi version (only security updates) (DEV-263) ( #1950 ) ( fe6106f )","title":"Maintenance"},{"location":"09-release-notes/#enhancements_12","text":"add archive representation to DSP-API (DEV-17) ( #1926 ) ( 0123a8f )","title":"Enhancements"},{"location":"09-release-notes/#1601-2021-11-22","text":"","title":"16.0.1 (2021-11-22)"},{"location":"09-release-notes/#bug-fixes_33","text":"canDeleteCardinalities: canDeleteCardinalities checks too eagerly (DEV-187) ( #1941 ) ( 298ba47 )","title":"Bug Fixes"},{"location":"09-release-notes/#1600-2021-11-19","text":"","title":"16.0.0 (2021-11-19)"},{"location":"09-release-notes/#breaking-changes_8","text":"listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd )","title":"\u26a0 BREAKING CHANGES"},{"location":"09-release-notes/#bug-fixes_34","text":"projectsADM: clear cache after changing project (DEV-239) ( #1943 ) ( 17c5c09 )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_32","text":"groupsADM: improve value objects implementation (DEV-160) ( #1932 ) ( 24e34dd ) listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd ) release v16.0.0 ( 8e5f494 ) release v16.0.0 ( ba6923d )","title":"Maintenance"},{"location":"09-release-notes/#1513-2021-11-19","text":"","title":"15.1.3 (2021-11-19)"},{"location":"09-release-notes/#breaking-changes_9","text":"listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd )","title":"\u26a0 BREAKING CHANGES"},{"location":"09-release-notes/#bug-fixes_35","text":"projectsADM: clear cache after changing project (DEV-239) ( #1943 ) ( 17c5c09 )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_33","text":"groupsADM: improve value objects implementation (DEV-160) ( #1932 ) ( 24e34dd ) listsADM: remove new lists implementation (DEV-160) ( #1932 ) ( 24e34dd )","title":"Maintenance"},{"location":"09-release-notes/#1512-2021-11-12","text":"","title":"15.1.2 (2021-11-12)"},{"location":"09-release-notes/#maintenance_34","text":"bump bazel ( #1938 ) ( 39417e6 ) improve validation handling (DEV-228) ( #1937 ) ( 94d7d3f )","title":"Maintenance"},{"location":"09-release-notes/#1511-2021-11-09","text":"","title":"15.1.1 (2021-11-09)"},{"location":"09-release-notes/#bug-fixes_36","text":"list: add support for special characters in list update (DEV-200) ( #1934 ) ( 3c2865c )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_35","text":"init-db: init db test data from test server (DEV-198) ( #1936 ) ( 1c24bea )","title":"Maintenance"},{"location":"09-release-notes/#1510-2021-11-03","text":"","title":"15.1.0 (2021-11-03)"},{"location":"09-release-notes/#bug-fixes_37","text":"users: fix bug adding user to group or project (DEV-184) ( #1925 ) ( a24a320 )","title":"Bug Fixes"},{"location":"09-release-notes/#enhancements_13","text":"add value objects to list routes - old and new (DEV-65) ( #1917 ) ( 7752a36 )","title":"Enhancements"},{"location":"09-release-notes/#maintenance_36","text":"bump sipi version (DEV-188) ( #1931 ) ( d302b5e ) change license to Apache 2.0 (DEV-82) ( #1924 ) ( 2d39a1f ) deps: bump mkdocs from 1.1.2 to 1.2.3 in /docs ( #1927 ) ( cbbf1b6 ) fix warnings (DEV-80) ( #1929 ) ( 1368769 )","title":"Maintenance"},{"location":"09-release-notes/#1503-2021-10-21","text":"","title":"15.0.3 (2021-10-21)"},{"location":"09-release-notes/#bug-fixes_38","text":"list: find list labels in full-text search ( #1922 ) ( cc3b06c )","title":"Bug Fixes"},{"location":"09-release-notes/#1502-2021-10-14","text":"","title":"15.0.2 (2021-10-14)"},{"location":"09-release-notes/#bug-fixes_39","text":"authenticator: improve performance ( #1914 ) ( d6a0d27 ) groups: update test data and documentation to use language specific group descriptions (DEV-123) ( #1921 ) ( 0f45b51 ) removing cardinality of a link property (DEV-90) ( #1919 ) ( c79c194 )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_37","text":"groups: refactor groups route using value objects (DEV-66) ( #1913 ) ( 1cd98e6 ) knora-base: fix typo ( #1918 ) ( 720aa65 ) projects: cleaner value objects usage in addProject route (DEV-119) ( #1920 ) ( 32b9e49 )","title":"Maintenance"},{"location":"09-release-notes/#1501-2021-09-29","text":"","title":"15.0.1 (2021-09-29)"},{"location":"09-release-notes/#bug-fixes_40","text":"candeletecardinalities: return correct response on route negative case (DEV-36) ( #1910 ) ( 652c747 ) escape-special-characters: escape special characters in user routes (DSP-1557) ( #1902 ) ( 689d92a )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_38","text":"contributors: remove contributors file (DEV-77) ( #1911 ) ( 7d925b6 ) projects: refactor projects route with value objects (DEV-64) ( #1909 ) ( 172cf77 ) reformatting Scala files (DSP-1897) ( #1908 ) ( 8df70a2 )","title":"Maintenance"},{"location":"09-release-notes/#1500-2021-09-14","text":"","title":"15.0.0 (2021-09-14)"},{"location":"09-release-notes/#breaking-changes_10","text":"ontology: use patch instead of delete for deleting cardinalities (DSP-1700) (#1903)","title":"\u26a0 BREAKING CHANGES"},{"location":"09-release-notes/#documentation_6","text":"add username to changeable attributes (DSP-1895) ( #1904 ) ( 719cd0d )","title":"Documentation"},{"location":"09-release-notes/#maintenance_39","text":"ontology: use patch instead of delete for deleting cardinalities (DSP-1700) ( #1903 ) ( 91ef4ec )","title":"Maintenance"},{"location":"09-release-notes/#1410-2021-08-19","text":"","title":"14.1.0 (2021-08-19)"},{"location":"09-release-notes/#bug-fixes_41","text":"ontology V2: use internal iri when updating a property (DSP-1868) ( #1898 ) ( a746f65 )","title":"Bug Fixes"},{"location":"09-release-notes/#enhancements_14","text":"v2-ontologies: add remove cardinalities from class if property not used in resources (DSP-1700) ( #1869 ) ( a30668b )","title":"Enhancements"},{"location":"09-release-notes/#1401-2021-08-04","text":"","title":"14.0.1 (2021-08-04)"},{"location":"09-release-notes/#bug-fixes_42","text":"add-test-file: add response file for test case (DSP-1841) ( #1894 ) ( 028e685 )","title":"Bug Fixes"},{"location":"09-release-notes/#1400-2021-08-02","text":"","title":"14.0.0 (2021-08-02)"},{"location":"09-release-notes/#breaking-changes_11","text":"projects: Change shortname to xsd:NCName forma, Escape special character in payloads of projects endpoints (DSP-1555 ) (#1886)","title":"\u26a0 BREAKING CHANGES"},{"location":"09-release-notes/#bug-fixes_43","text":"api-v2, api-admin: ontology name and project name should be URL safe (DSP-1749) ( #1889 ) ( 17601a7 ) permissions: reject malformed doap and ap create/update request (DSP-1328) ( #1890 ) ( 3e3a3ce )","title":"Bug Fixes"},{"location":"09-release-notes/#enhancements_15","text":"customIRIs: custom IRIs must contain a UUID (DSP-1763) ( #1884 ) ( 593d9cb ) projects: Change shortname to xsd:NCName forma, Escape special character in payloads of projects endpoints (DSP-1555 ) ( #1886 ) ( b3c2d5f ) resource-metadata: return resource metadata after metadata update request (DSP-1828) ( #1893 ) ( a4e878a ) video: add support for video/mp4 to both v1 and v2 (DSP-1204) ( #1891 ) ( 83fb4b8 )","title":"Enhancements"},{"location":"09-release-notes/#13120-2021-06-24","text":"","title":"13.12.0 (2021-06-24)"},{"location":"09-release-notes/#enhancements_16","text":"resourceHistoryEvents: route for resource history events (DSP-1749) ( #1882 ) ( f86de53 )","title":"Enhancements"},{"location":"09-release-notes/#13110-2021-06-17","text":"","title":"13.11.0 (2021-06-17)"},{"location":"09-release-notes/#enhancements_17","text":"events: update resource last modification date event ( #1877 ) ( d5e70ba )","title":"Enhancements"},{"location":"09-release-notes/#maintenance_40","text":"build: cleanup ( #1880 ) ( 749e8ea ) cache-service: add in-memory implementation ( #1870 ) ( 61531ab ) gh-ci: update docs deployment (DSP-1741) ( #1878 ) ( ff65323 )","title":"Maintenance"},{"location":"09-release-notes/#13100-2021-06-09","text":"","title":"13.10.0 (2021-06-09)"},{"location":"09-release-notes/#enhancements_18","text":"gravsearch: use layer info for topological order permutations (DSP-1389) ( #1872 ) ( b49d5ba )","title":"Enhancements"},{"location":"09-release-notes/#documentation_7","text":"prepare documentation for docs.dasch.swiss (DSP-1721) ( #1873 ) ( 66751a0 )","title":"Documentation"},{"location":"09-release-notes/#1392-2021-06-02","text":"","title":"13.9.2 (2021-06-02)"},{"location":"09-release-notes/#maintenance_41","text":"sipi: add comments ( #1864 ) ( 06e8b0c )","title":"Maintenance"},{"location":"09-release-notes/#documentation_8","text":"ontology: update term ( #1865 ) ( cd37580 )","title":"Documentation"},{"location":"09-release-notes/#1391-2021-05-28","text":"","title":"13.9.1 (2021-05-28)"},{"location":"09-release-notes/#maintenance_42","text":"bazel: bump bazel version ( #1866 ) ( c754cbf )","title":"Maintenance"},{"location":"09-release-notes/#1390-2021-05-25","text":"","title":"13.9.0 (2021-05-25)"},{"location":"09-release-notes/#enhancements_19","text":"api-v2: Add routes for checking whether ontology entities can be changed (DSP-1621) ( #1861 ) ( fdd098f )","title":"Enhancements"},{"location":"09-release-notes/#1380-2021-05-19","text":"","title":"13.8.0 (2021-05-19)"},{"location":"09-release-notes/#bug-fixes_44","text":"api-v2: Update subclasses in ontology cache when base class changes (DSP-1643) ( #1860 ) ( beb951d ) gravsearch: don't move the patterns with resource IRI after topological sorting (DSP-1620) ( #1856 ) ( 6022c91 )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_43","text":"documentation: bug fix in documentation deployment (DSP-1605) ( bb852c9 ) documentation: bug fix in documentation deployment (DSP-1605) ( #1854 ) ( 999a2bb )","title":"Maintenance"},{"location":"09-release-notes/#enhancements_20","text":"api-v2: Change GUI element and attribute of a property (DSP-1600) ( #1855 ) ( ce9ba3a ) api-v2: Generate IIIF manifest (DSP-50) ( #1784 ) ( 74feb2c ) conf: Rule to dump prod data and load locally (DSP-1485) ( #1857 ) ( 161ea31 ) ontology: Allow adding new property to a resource class in use (DSP-1629) ( #1859 ) ( 061875e )","title":"Enhancements"},{"location":"09-release-notes/#1370-2021-05-06","text":"","title":"13.7.0 (2021-05-06)"},{"location":"09-release-notes/#bug-fixes_45","text":"doc: correct remaining incorrect copyright dates ( #1847 ) ( d1473ed ) gravsearch: Keep rdf:type knora-api:Resource when needed. ( #1835 ) ( e561d94 ) lists: Escape special characters in comment, label, and name of a list node (DSP-1529) ( #1846 ) ( f96c069 ) test-data: change webern shortcode in test data (DSP-1520) ( #1843 ) ( 5f06a10 ) values v1 route: fix geoname case (DSP-1487) ( #1839 ) ( 9d0e93e )","title":"Bug Fixes"},{"location":"09-release-notes/#documentation_9","text":"replace knora by dsp or dsp-api in documentation (DSP-1469) ( #1836 ) ( 923abe8 ) v1: improve search docs ( #1848 ) ( 5a81f73 )","title":"Documentation"},{"location":"09-release-notes/#enhancements_21","text":"api-v2: Add route for changing GUI order of cardinalities ( #1850 ) ( d8dbb4f ) api-v2: Return events describing version history of resources and values of a project ordered by data (DSP-1528) ( #1844 ) ( 84f7c14 ) ext search v1: add support for URI values (DSP-1522) ( #1842 ) ( b119757 )","title":"Enhancements"},{"location":"09-release-notes/#maintenance_44","text":"bumb Bazel to version with apple silicon support ( #1852 ) ( 286d289 ) bump scala to 2.13 ( #1851 ) ( 5feb915 ) deps: bump versions (DSP-1569) ( #1849 ) ( f69f008 )","title":"Maintenance"},{"location":"09-release-notes/#1360-2021-03-16","text":"","title":"13.6.0 (2021-03-16)"},{"location":"09-release-notes/#enhancements_22","text":"api-v2: Improve error message when an XSLT transformation file is not found (DSP-1404) ( #1831 ) ( 153a674 )","title":"Enhancements"},{"location":"09-release-notes/#1351-2021-03-11","text":"","title":"13.5.1 (2021-03-11)"},{"location":"09-release-notes/#bug-fixes_46","text":"OntologiesRouteV2: Reject internal ontology names in external schema (DSP-1394) ( #1827 ) ( e392bf1 ) OntologyResponderV2: Fix check when updating ontology label and comment (DSP-1390) ( #1826 ) ( 26cce48 )","title":"Bug Fixes"},{"location":"09-release-notes/#1350-2021-03-08","text":"","title":"13.5.0 (2021-03-08)"},{"location":"09-release-notes/#bug-fixes_47","text":"replaceCardinalities.scala.txt: Fix blank node insertion. ( #1829 ) ( d24c5d2 )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_45","text":"gh-ci: update release please configuration (DSP-1382) ( #1825 ) ( 7ce4b65 )","title":"Maintenance"},{"location":"09-release-notes/#enhancements_23","text":"Add support for audio files (DSP-1343) ( #1818 ) ( 7497023 ) gravsearch: Optimise Gravsearch queries using topological sort (DSP-1327) ( #1813 ) ( efbecee ) store: Return 404 if the triplestore returns 404. ( #1828 ) ( 5250f6d )","title":"Enhancements"},{"location":"09-release-notes/#1340-2021-02-17","text":"","title":"13.4.0 (2021-02-17)"},{"location":"09-release-notes/#bug-fixes_48","text":"Lists: fix bug in shifting the second of two children after deletion of the first one. ( #1820 ) ( d92bb01 )","title":"Bug Fixes"},{"location":"09-release-notes/#enhancements_24","text":"projects: add default set of permissions when creating new project (DSP-1347) ( #1822 ) ( b7c71ca )","title":"Enhancements"},{"location":"09-release-notes/#1331-2021-02-09","text":"","title":"13.3.1 (2021-02-09)"},{"location":"09-release-notes/#bug-fixes_49","text":"Lists: fix bug in deleting the single child of a node (DSP-1355) ( #1816 ) ( 1d06572 )","title":"Bug Fixes"},{"location":"09-release-notes/#1330-2021-02-05","text":"","title":"13.3.0 (2021-02-05)"},{"location":"09-release-notes/#enhancements_25","text":"sipi: add storing of original and sidecar (DSP-1318) ( #1808 ) ( 022ed7e )","title":"Enhancements"},{"location":"09-release-notes/#1320-2021-02-04","text":"","title":"13.2.0 (2021-02-04)"},{"location":"09-release-notes/#bug-fixes_50","text":"api-v1: Optimise SPARQL queries. ( #1814 ) ( 4edc27c ) Lists: Repositioning the node when new position equals length of new parent's children (DSP-1322) ( #1811 ) ( 3fead13 )","title":"Bug Fixes"},{"location":"09-release-notes/#enhancements_26","text":"api-v1: Add support for PDF files (DSP-1267) ( #1797 ) ( c3b2e84 ) api-v2: Allow resubmitting existing class/property lablels/comments. ( #1812 ) ( 6a13852 )","title":"Enhancements"},{"location":"09-release-notes/#maintenance_46","text":"make targets for adding metadata (DSP-1289) ( #1810 ) ( 9c1a70a ) salsah1: delete from repository ( #1805 )(DSP-1294) ( 3251a74 )","title":"Maintenance"},{"location":"09-release-notes/#1311-2021-01-30","text":"","title":"13.1.1 (2021-01-30)"},{"location":"09-release-notes/#maintenance_47","text":"gh-ci: Bring back the client-test-data command to github actions ( #1804 ) ( e6b0fbf ) revert release 13.1.0 ( #1800 ) ( 565e5ac )","title":"Maintenance"},{"location":"09-release-notes/#1310-2021-01-29","text":"","title":"13.1.0 (2021-01-29)"},{"location":"09-release-notes/#bug-fixes_51","text":"api-v1: Optimise link value queries for Fuseki (DSP-1243) ( #1791 ) ( b1e1b9e ) api-v2: Don't allow an invalid cardinality on a boolean property (DSP-1236) ( #1788 ) ( 3d5f802 ) gravsearch: Handle UNION scopes with FILTER correctly (DSP-1240) ( #1790 ) ( 61d2e86 ) HttpTriplestoreConnector: Always parse triplestore responses as UTF-8. ( #1789 ) ( 61d2e86 ) permissions : fix getting builtin groups while creating a permission (DSP-1296 ) ( #1799 ) ( d390014 )","title":"Bug Fixes"},{"location":"09-release-notes/#maintenance_48","text":"gh-ci: fix issue in the release process ( #1782 ) ( afe61b7 ) ghi-ci: google chat release notification ( #1785 ) ( 4718cdc )","title":"Maintenance"},{"location":"09-release-notes/#enhancements_27","text":"permissions: add delete permissions: (DSP-1169) ( #1787 ) ( 3fe8c14 ) store: Return a clearer exception when a triplestore read timeout occurs. ( #1795 ) ( 0eeb3b3 )","title":"Enhancements"},{"location":"09-release-notes/#1300-2021-01-11","text":"","title":"13.0.0 (2021-01-11)"},{"location":"09-release-notes/#breaking-changes_12","text":"New features and refactoring (#1779)","title":"\u26a0 BREAKING CHANGES"},{"location":"09-release-notes/#bug-fixes_52","text":"(dependencies) add the missing dependency ( #1755 ) ( 0e37d21 ) api-v2: Change link value comment ( #1582 ) ( faa2e55 ) api-v2: Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) ( #1749 ) ( 905766f ) api-v2: Fix custom datatypes in knora-api simple ontology ( #1601 ) ( e0cfd4e ) api-v2: Fix generated SPARQL for updating property comment ( #1693 ) ( 7b70339 ) api-v2: Fix ontology deletion ( #1584 ) ( 70b0841 ) api-v2: Fix post-update check for resource with standoff link (DSP-841) ( #1728 ) ( 35d449f ) failing repository upgrade at startup (DSP-654) ( #1712 ) ( 0d6b4ee ) gravsearch: Prevent duplicate results ( #1626 ) ( 9313b88 ) gravsearch: When link property compared in filter, don't compare link value property, too ( #1699 ) ( a3b1665 ) init db scripts (DSP-511) ( #1681 ) ( d4505ce ) loading of data (DSP-445) ( #1669 ) ( 3f8d406 ) OntologyResponderV2: Add a global ontology cache lock ( #1637 ) ( 1853865 ) OntologyResponderV2: Fix ontology cache update when ontology metadata changed ( #1709 ) ( 4f57977 ) server header (DSP-537) ( #1691 ) ( 8d7bee8 ) sipi makefile ( #1616 ) ( 73a0afe ) sipi: Don't expect API v1 status code (DSP-1114) ( #1763 ) ( 3236d25 ) sipi: Improve performance of file value query ( #1697 ) ( 8214877 ) test: Fix typos in IRIs in anything-data.ttl. ( #1625 ) ( 23d51ce ) upgrade: Fix log output. ( #1774 ) ( b43fab0 ) webapi: unique username/email check on change user ( #1561 ) ( 4f26e22 ) rdf-api : Use the Jena RDF API implementation by default (DSP-1153) ( 1772 ) ( 389feb4 )","title":"Bug Fixes"},{"location":"09-release-notes/#documentation_10","text":"api-v2: Document what happens when a resource has a link to a deleted resource ( #1685 ) ( 1c88651 ) fix broken links ( #1688 ) ( 9c0292c ) fix make targets docker-build and docker-publish ( #1694 ) ( d06b6a6 ) Update README (DSP-1142) ( #1771 ) ( 7ba7fc6 ) Update required mkdocs package ( #1725 ) ( 27de65e )","title":"Documentation"},{"location":"09-release-notes/#maintenance_49","text":"api-v2: Delete obsolete files. ( #1634 ) ( e80bf52 ) api-v2: Switch from JSONLD-Java to Titanium ( #1715 ) ( 9e28e5b ) build: Bump testcontainers version. ( #1723 ) ( 24ae1d3 ) build: Update ScalaTest (DSP-919) ( #1745 ) ( bbaeadd ) build: Upgrade Sipi to 3.0.0-rc.8 (DSP-916) ( #1743 ) ( 23395fc ) bump sipi to rc.7 (DSP-733) ( #1721 ) ( b635495 ) gh-ci: Fix gren issue ( #1666 ) ( 2dc5361 ) gh-ci: Publish on release only ( #1662 ) ( 787dca8 ) rdf-api: Use the Jena RDF API implementation by default (DSP-1153) ( #1772 ) ( 389feb4 ) Remove obsolete functions from StringFormatter. ( #1640 ) ( 5fa6de4 ) Update ci workflow release notes ( #1707 ) ( d8e0b39 ) gh-ci CI is failing to test upgrade correctly (DSP-667) ( #1073 ) ( 13cbdab ) bazel Update Bazel maven rules to see if it fixes problems with macOS Big Sur (DSP-1099) ( #1761 ) ( a2c9941 )","title":"Maintenance"},{"location":"09-release-notes/#enhancements_28","text":"Add an RDF processing fa\u00e7ade (2nd iteration) (DSP-1083) ( #1759 ) ( 346873d ) Add feature toggles (DSP-910) ( #1742 ) ( 2e6db2e ) Add time value type ( #1403 ) ( d925c85 ) api-v1: Change API v1 file uploads to work like API v2 (DSP-41, PR 3) ( #1722 ) ( a824bcc ) api-v2: Accept custom new value IRI when updating value ( #1698 ) ( 4d8f867 ) api-v2: Accept custom timestamps in update/delete requests ( #1686 ) ( 0fbe5a8 ) api-v2: Add an RDF processing fa\u00e7ade (DSP-1020) ( #1754 ) ( 9170419 ) api-v2: Add metadata routes (DSP-662) ( #1734 ) ( bf48968 ) api-v2: Add support for text file upload (DSP-44) ( #1664 ) ( a88d20d ) api-v2: Add test data. ( #1704 ) ( de14ab1 ) api-v2: Allow querying for rdfs:label in Gravsearch ( #1649 ) ( d56004b ) api-v2: Control JSON-LD nesting via an HTTP header (DSP-1084) ( #1758 ) ( b13eecf ) api-v2: Make inference optional in Gravsearch ( #1696 ) ( 166a260 ) api-v2: Optionally return file values in full-text search results (DSP-1191) ( #1776 ) ( 01f59bd ) api-v2: Remove client code generation ( #1610 ) ( 6977ab3 ) api-v2: Remove ForbiddenResource ( #1615 ) ( 992596e ) api-v2: Return value UUID on value creation and update ( #1602 ) ( cbed601 ) api-v2: Specify custom IRIs when creating resources/values ( #1646 ) ( 135b039 ) clientapi: Change method signature. ( #1583 ) ( c2a2559 ) gh-ci: Release please and update gh actions (DSP-1168) ( #1777 ) ( 593ffab ) gravsearch: Allow comparing variables representing resource IRIs ( #1713 ) ( f359c8e ) gravsearch: Remove deprecated functions ( #1660 ) ( 5d3af46 ) New features and refactoring ( #1779 ) ( 9a5fb77 ) rdf-api: Add a general-purpose SHACL validation utility (DSP-930) ( #1762 ) ( bfd3192 ) sipi: Improve error message if XSL file not found ( #1590 ) ( bbb42f6 ) triplestores: Support Apache Jena Fuseki ( #1375 ) ( 82f8a55 ) upgrade: Update repository on startup ( #1643 ) ( 0127dca )","title":"Enhancements"},{"location":"09-release-notes/#v1300-rc25-08122020","text":"","title":"v13.0.0-rc.25 (08/12/2020)"},{"location":"09-release-notes/#enhancements_29","text":"#1768 | DSP-1106 Update Permission #1767 | enhancement(triplestore): Use N-Quads instead of TriG for repository upgrade (DSP-1129) #1764 | DSP-1033 Reposition List Nodes #1762 | feat(rdf-api): Add a general-purpose SHACL validation utility (DSP-930) #1759 | feat: Add an RDF processing fa\u00e7ade (2nd iteration) (DSP-1083) #1760 | (DSP-1031) Delete list items #1753 | Edit lists routes (DSP-597 ) #1758 | feat(api-v2): Control JSON-LD nesting via an HTTP header (DSP-1084)","title":"Enhancements"},{"location":"09-release-notes/#bug-fixes_53","text":"#1763 | fix(sipi): Don't expect API v1 status code (DSP-1114)","title":"Bug fixes"},{"location":"09-release-notes/#documentation_11","text":"#1771 | docs: Update README (DSP-1142)","title":"Documentation"},{"location":"09-release-notes/#maintenance_50","text":"#1770 | refactor: Use java.nio.file.Path instead of java.io.File (DSP-1124) #1765 | DSP-1094 Upgrade Swagger version #1766 | style: Add Scalafmt config file #1769 | style: Reformat code with Scalafmt (DSP-1137) #1754 | feat(api-v2): Add an RDF processing fa\u00e7ade (DSP-1020) #1757 | build: bazel workspace cleanup","title":"Maintenance"},{"location":"09-release-notes/#v1300-rc24-13112020","text":"#1756 | DSP-1052 : Migration task to replace empty strings with dummy \"FIXME\"","title":"v13.0.0-rc.24 (13/11/2020)"},{"location":"09-release-notes/#v1300-rc23-09112020","text":"","title":"v13.0.0-rc.23 (09/11/2020)"},{"location":"09-release-notes/#bug-fixes_54","text":"#1755 | DSP-1029: Add the missing dependency","title":"Bug fixes"},{"location":"09-release-notes/#v1300-rc22-09112020","text":"","title":"v13.0.0-rc.22 (09/11/2020)"},{"location":"09-release-notes/#breaking-changes_13","text":"#1724 | test: Collect client test data from E2E tests (DSP-724) #1727 | DSP-740 Update List Name #1722 | feat(api-v1): Change API v1 file uploads to work like API v2 (DSP-41, PR 3) #1233 | feat(api-v1): Change API v1 file uploads to work like API v2 #1708 | Get Project Permissions","title":"Breaking changes"},{"location":"09-release-notes/#enhancements_30","text":"#1403 | feat: Add time value type #1537 | build: Add env var to set triplestore actor pool #1649 | feat(api-v2): Allow querying for rdfs:label in Gravsearch #1742 | feat: Add feature toggles (DSP-910) #1741 | DSP-804: create a child node with a custom IRI #1734 | feat(api-v2): Add metadata routes (DSP-662) #1739 | enhancement(api-v2): Optimise checking isDeleted (DSP-848) #1664 | feat(api-v2): Add support for text file upload (DSP-44) #1652 | DSP-377 Support Islamic calendar #1717 | enhancement(gravsearch): Optimise queries by moving up statements with resource IRIs #1713 | feat(gravsearch): Allow comparing variables representing resource IRIs #1710 | update ontology metadata with a comment #1704 | feat(api-v2): Add test data #1703 | Add comments to ontology metadata #1686 | feat(api-v2): Accept custom timestamps in update/delete requests #1692 | Create Permissions #1696 | feat(api-v2): Make inference optional in Gravsearch #1697 | fix(sipi): Improve performance of file value query #1698 | feat(api-v2): Accept custom new value IRI when updating value #1700 | hierarchically ordered Sequence of base classes #1689 | build: bump SIPI to v3.0.0-rc.5 (DSP-547) #1679 | Gravsearch optimisations #1663 | build: add support for SIPI v3.0.0-rc.3 (DSP-433) #1660 | feat(gravsearch): Remove deprecated functions #1653 | build: dockerize fuseki (dsp-30)","title":"Enhancements"},{"location":"09-release-notes/#bug-fixes_55","text":"#1626 | fix(gravsearch): Prevent duplicate results #1587 | fix (webapi): Add enforcing of restrictions for username and email #1576 | Add missing env var #1571 | fixed date string format #1564 | enable click on save button in case of recoverable error #1751 | DSP-1022 SIPI_EXTERNAL_HOSTNAME doesn't contain the external hostname #1749 | fix(api-v2): Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) #1748 | DSP-756 Tests failing because Knora version header and route are incorrect #1746 | DSP-932: Don't allow missing StringLiteralV2 value if language tag given #1744 | DSP-917 Releases pushed to Dockerhub from DSP-API are \"dirty\" #1733 | DSP-470 Intermittent bind errors #1728 | fix(api-v2): Fix post-update check for resource with standoff link (DSP-841) #1723 | chore(build): Bump testcontainers version (DSP-755) #1706 | Fix of update of list node info and update of project info #1712 | fix: failing repository upgrade at startup (DSP-654) #1709 | fix(OntologyResponderV2): Fix ontology cache update when ontology metadata changed #1701 | reverse change of Permission JSONs #1693 | fix(api-v2): Fix generated SPARQL for updating property comment #1699 | fix(gravsearch): When link property compared in filter, don't compare link value property, too #1691 | fix: server header (DSP-537) #1681 | fix: init db scripts (DSP-511) #1669 | fix: loading of data (DSP-445)","title":"Bug Fixes"},{"location":"09-release-notes/#documentation_12","text":"#1598 | doc: fix sipi docs link #1609 | fix complex schema url #1568 | fixed the URI for the query #1726 | PersmissionsDocs: remove the attribute #1725 | docs: Update required mkdocs package #1711 | update developer and create resource docs #1684 | developer guideline #1685 | docs(api-v2): Document what happens when a resource has a link to a deleted resource #1688 | docs: fix broken links #1694 | docs: fix publishing #1621 | fixing typos for list rendering","title":"Documentation"},{"location":"09-release-notes/#other","text":"#1750 | Update README.md #1747 | DSP-920 Renaming default github branch to \"main\" ; Move to the same base branch #1740 | DSP-877 Upload api-client-test-data to GitHub release #1738 | DSP-877 Upload api-client-test-data to GitHub release #1736 | DSP-877 Upload api-client-test-data to GitHub release #1730 | DSP-816: Generate client test data for health route #1719 | change possibly conflictual env var USERNAME (DSP-706) #1720 | DSP-620 Update release process #1714 | test: fix generation of test data (DSP-665) #1716 | bulid: fix sipi image version (DSP-677) #1718 | DSP-702 Add template for PRs #1715 | chore(api-v2): Switch from JSONLD-Java to Titanium #1707 | chore: Update ci workflow #1702 | Add PR labels (DSP-607) #1695 | refactor(gravsearch): Clarify optimisations #1678 | refactor: first steps towards more independent packages (DSP-513) #1680 | build: bump rules_docker and instructions for installing bazelisk #1674 | build: add mkdocs for documentation generation (DSP-460) #1480 | build: add bazel (DSP-437) #1666 | Fix gren issue in github actions workflow #1662 | Publish on release only #1661 | Automated release notes","title":"Other"},{"location":"09-release-notes/#dependencies","text":"#1721 | chore: bump sipi to rc.7 (DSP-733) #1735 | DSP-496 Bump Apache Jena Fuseki and Apache Jena Libraries to 3.16 #1737 | DSP-842 Bump used Bazel version to newly released 3.7.0 #1743 | chore(build): Upgrade Sipi to 3.0.0-rc.8 (DSP-916) #1745 | chore(build): Update ScalaTest (DSP-919) #1752 | DSP-1017 Upgrade to Sipi v3.0.0-rc.9","title":"Dependencies"},{"location":"09-release-notes/#v1300-rc21-09112020","text":"","title":"v13.0.0-rc.21 (09/11/2020)"},{"location":"09-release-notes/#breaking-changes_14","text":"#1724 | test: Collect client test data from E2E tests (DSP-724) #1727 | DSP-740 Update List Name #1722 | feat(api-v1): Change API v1 file uploads to work like API v2 (DSP-41, PR 3) #1233 | feat(api-v1): Change API v1 file uploads to work like API v2 #1708 | Get Project Permissions","title":"Breaking changes"},{"location":"09-release-notes/#enhancements_31","text":"#1403 | feat: Add time value type #1649 | feat(api-v2): Allow querying for rdfs:label in Gravsearch #1742 | feat: Add feature toggles (DSP-910) #1741 | DSP-804: create a child node with a custom IRI #1734 | feat(api-v2): Add metadata routes (DSP-662) #1739 | enhancement(api-v2): Optimise checking isDeleted (DSP-848) #1664 | feat(api-v2): Add support for text file upload (DSP-44) #1652 | DSP-377 Support Islamic calendar #1717 | enhancement(gravsearch): Optimise queries by moving up statements with resource IRIs #1713 | feat(gravsearch): Allow comparing variables representing resource IRIs #1710 | update ontology metadata with a comment #1704 | feat(api-v2): Add test data #1703 | Add comments to ontology metadata #1686 | feat(api-v2): Accept custom timestamps in update/delete requests #1692 | Create Permissions #1696 | feat(api-v2): Make inference optional in Gravsearch #1697 | fix(sipi): Improve performance of file value query #1698 | feat(api-v2): Accept custom new value IRI when updating value #1700 | hierarchically ordered Sequence of base classes #1689 | build: bump SIPI to v3.0.0-rc.5 (DSP-547) #1679 | Gravsearch optimisations #1663 | build: add support for SIPI v3.0.0-rc.3 (DSP-433) #1660 | feat(gravsearch): Remove deprecated functions #1653 | build: dockerize fuseki (dsp-30)","title":"Enhancements"},{"location":"09-release-notes/#bug-fixes_56","text":"#1626 | fix(gravsearch): Prevent duplicate results #1587 | fix (webapi): Add enforcing of restrictions for username and email #1751 | DSP-1022 SIPI_EXTERNAL_HOSTNAME doesn't contain the external hostname #1749 | fix(api-v2): Don't check file extensions of XSL files and Gravsearch templates (DSP-1005) #1748 | DSP-756 Tests failing because Knora version header and route are incorrect #1746 | DSP-932: Don't allow missing StringLiteralV2 value if language tag given #1744 | DSP-917 Releases pushed to Dockerhub from DSP-API are \"dirty\" #1733 | DSP-470 Intermittent bind errors #1728 | fix(api-v2): Fix post-update check for resource with standoff link (DSP-841) #1723 | chore(build): Bump testcontainers version (DSP-755) #1706 | Fix of update of list node info and update of project info #1712 | fix: failing repository upgrade at startup (DSP-654) #1709 | fix(OntologyResponderV2): Fix ontology cache update when ontology metadata changed #1701 | reverse change of Permission JSONs #1693 | fix(api-v2): Fix generated SPARQL for updating property comment #1699 | fix(gravsearch): When link property compared in filter, don't compare link value property, too #1691 | fix: server header (DSP-537) #1681 | fix: init db scripts (DSP-511) #1669 | fix: loading of data (DSP-445)","title":"Bug Fixes"},{"location":"09-release-notes/#documentation_13","text":"#1598 | doc: fix sipi docs link #1609 | fix complex schema url #1568 | fixed the URI for the query #1726 | PersmissionsDocs: remove the attribute #1725 | docs: Update required mkdocs package #1711 | update developer and create resource docs #1684 | developer guideline #1685 | docs(api-v2): Document what happens when a resource has a link to a deleted resource #1688 | docs: fix broken links #1694 | docs: fix publishing #1621 | fixing typos for list rendering","title":"Documentation"},{"location":"09-release-notes/#other_1","text":"#1750 | Update README.md #1747 | DSP-920 Renaming default github branch to \"main\" ; Move to the same base branch #1740 | DSP-877 Upload api-client-test-data to GitHub release #1738 | DSP-877 Upload api-client-test-data to GitHub release #1736 | DSP-877 Upload api-client-test-data to GitHub release #1730 | DSP-816: Generate client test data for health route #1719 | change possibly conflictual env var USERNAME (DSP-706) #1720 | DSP-620 Update release process #1714 | test: fix generation of test data (DSP-665) #1716 | bulid: fix sipi image version (DSP-677) #1718 | DSP-702 Add template for PRs #1715 | chore(api-v2): Switch from JSONLD-Java to Titanium #1707 | chore: Update ci workflow #1702 | Add PR labels (DSP-607) #1695 | refactor(gravsearch): Clarify optimisations #1678 | refactor: first steps towards more independent packages (DSP-513) #1680 | build: bump rules_docker and instructions for installing bazelisk #1674 | build: add mkdocs for documentation generation (DSP-460) #1480 | build: add bazel (DSP-437) #1666 | Fix gren issue in github actions workflow #1662 | Publish on release only #1661 | Automated release notes","title":"Other"},{"location":"09-release-notes/#v1200-27012020","text":"","title":"v12.0.0 (27/01/2020)"},{"location":"09-release-notes/#breaking-api-changes","text":"#1439 JSON-LD Serialization of an xsd:dateTimeStamp","title":"Breaking API Changes"},{"location":"09-release-notes/#new-features-and-enhancements","text":"#1509 Support lists admin endpoint #1466 Optimise generated SPARQL","title":"New Features and Enhancements"},{"location":"09-release-notes/#bug-fixes_57","text":"#1569 broken ark #1559 Admin lists: createChildNode should send a httpPost request, not httpPut","title":"Bug Fixes"},{"location":"09-release-notes/#v1100-16122019","text":"","title":"v11.0.0 (16/12/2019)"},{"location":"09-release-notes/#breaking-changes_15","text":"#1344 Gravsearch ForbiddenResource result and permissions of linked resources #1202 Implement upload of PDF and text files in API v2. Users with files in Sipi under /server must move them to /images when upgrading.","title":"Breaking Changes"},{"location":"09-release-notes/#bug-fixes_58","text":"#1531 Sipi's mimetype_consistency fails with .bin file #1430 Creating the first resource with an image inside a project fails with Sipi not finding the project folder #924 Get dependent resources Iris","title":"Bug Fixes"},{"location":"09-release-notes/#v1011-27112019","text":"","title":"v10.1.1 (27/11/2019)"},{"location":"09-release-notes/#v1010-27112019","text":"","title":"v10.1.0 (27/11/2019)"},{"location":"09-release-notes/#v1000-22102019","text":"","title":"v10.0.0 (22/10/2019)"},{"location":"09-release-notes/#breaking-changes_16","text":"#1346 Richtext/HTML in page anchor link","title":"Breaking Changes"},{"location":"09-release-notes/#enhancements_32","text":"#1457 Upgrade sipi to 2.0.1","title":"Enhancements"},{"location":"09-release-notes/#bug-fixes_59","text":"#1460 Build banner in README is broken","title":"Bug Fixes"},{"location":"09-release-notes/#documentation_14","text":"#1481 build badge in README has broken link","title":"Documentation"},{"location":"09-release-notes/#other_2","text":"#1449 Add Makefile-based task execution #1401 Enable testing docs generation in Travis","title":"Other"},{"location":"09-release-notes/#v910-26092019","text":"","title":"v9.1.0 (26/09/2019)"},{"location":"09-release-notes/#enhancements_33","text":"#1421 Physically deleting a resource","title":"Enhancements"},{"location":"09-release-notes/#documentation_15","text":"#1407 Document ARK URLs for projects","title":"Documentation"},{"location":"09-release-notes/#v900-29082019","text":"","title":"v9.0.0 (29/08/2019)"},{"location":"09-release-notes/#breaking-changes_17","text":"#1411 Moved /admin/groups/members/GROUP_IRI to /admin/groups/GROUP_IRI/members #1231 Change value permissions #763 refactor splitMainResourcesAndValueRdfData so it uses SparqlExtendedConstructResponse","title":"Breaking Changes"},{"location":"09-release-notes/#enhancements_34","text":"#1373 The startup ends in a thrown exception if the triplestore is not up-to-date #1364 Add support for Redis cache #1360 Build and publish Knora version specific docker images for GraphDB Free and SE #1358 Add admin route to dump project data","title":"Enhancements"},{"location":"09-release-notes/#bug-fixes_60","text":"#1394 Using dockerComposeUp to start the stack, fails to find Redis at startup","title":"Bug Fixes"},{"location":"09-release-notes/#documentation_16","text":"#1386 Add lists admin API documentation","title":"Documentation"},{"location":"09-release-notes/#other_3","text":"#1412 Change release notes to be based on issues","title":"Other"},{"location":"09-release-notes/#v800-14062019","text":"feature(webapi): Add GraphDB-Free startup support (#1351) - @subotic feature(webapi): Add returning of fixed public user information (#1348) - @subotic feat(api-v2): No custom permissions higher than defaults (#1337) - @benjamingeer feat(upgrade): Improve upgrade framework (#1345) - @benjamingeer test(webapi): Add new user authentication (#1201) - @subotic chore(webapi): Add request duration logging (#1347) - @subotic feat(api-v2): Make values citable (#1322) - @benjamingeer Leibniz ontology (#1326) - @SepidehAlassi feature(webapi): add CORS allow header (#1340) - @subotic fix(sipi): Return permissions for a previous version of a file value. (#1339) - @benjamingeer fix(scripts): add admin ontology data to correct graph (#1333) - @subotic fix(sipi): Don't try to read a file value in a deleted resource. (#1329) - @benjamingeer docs(api-v2): Fix sample responses. (#1327) - @benjamingeer fix(api-v2): Fix typo. (#1325) - @benjamingeer Handle List Nodes in Response (#1321) - @tobiasschweizer feat(api-v2): Return standoff markup separately from text values (#1307) - @benjamingeer BEOL: Import comments for Meditationes (#1281) - @tobiasschweizer feat(triplestore): Log SPARQL query if triplestore doesn't respond. (#1292) - @benjamingeer Support list nodes in Gravsearch (#1314) - @tobiasschweizer","title":"v8.0.0 (14/06/2019)"},{"location":"09-release-notes/#v700-03052019","text":"fix(api-v2): Cache base class IRIs correctly when creating/updating class (#1311) - @benjamingeer chore(standoff): Use Base64-encoded UUIDs in standoff tags. (#1301) - @benjamingeer feat(api-v2): Allow a resource to be created as a specified user (#1306) - @benjamingeer feat(admin): Give the admin ontology an external schema (#1291) - @benjamingeer fix(api-v2): Remove INFORMATION SEPARATOR TWO from text in the simple schema. (#1299) - @benjamingeer test: Compare Knora response with its class definition (#1297) - @benjamingeer docs(api-admin): fix description of the change password payload (#1285) - @loicjaouen fix(api-v1): Fix double escaping of newline. (#1296) - @benjamingeer fix (tei beol): fix problems in XSLT (#1260) - @tobiasschweizer refactor(ontology): Make knora-admin a separate ontology (#1263) - @benjamingeer a handfull of changes in documentation and error messages (#1278) - @loicjaouen docs: fix missing username (#1269) - @loicjaouen feat(api-v2): Get resources in a particular class from a project (#1251) - @benjamingeer fix(sipi): Improve error checking of Sipi's knora.json response. (#1279) - @benjamingeer feat(api-v2): Return user's permission on resources and values (#1257) - @benjamingeer fix(api-v1): Escape rdfs:label in bulk import. (#1276) - @benjamingeer chore(webapi): Remove persistent map code (#1254) - @benjamingeer docs (api-v2): Update outdated ARK documentation. (#1252) - @benjamingeer Update build.properties (#1265) - @subotic","title":"v7.0.0 (03/05/2019)"},{"location":"09-release-notes/#v601-22032019","text":"chore: releasing-v6.0.1 (#1270) - @subotic chore(webapi): Add script for loading of a minimal set of data (#1267) - @subotic fix (beolPersonLabel) typo in label of hasBirthPlace (#1248) - @SepidehAlassi fix (webapi): message typo (#1244) - @subotic Unescape standoff string attributes when verifying text value update (#1242) - @benjamingeer docs: fix user admin api (#1237) - @subotic","title":"v6.0.1 (22/03/2019)"},{"location":"09-release-notes/#v600-28022019","text":"","title":"v6.0.0 (28/02/2019)"},{"location":"09-release-notes/#release-notes","text":"MAJOR: Use HTTP POST to mark resources and values as deleted (#1203) MAJOR: Reorganize user and project routes (#1209) FEATURE: Secure routes returning user information (#961) MAJOR: Change all xsd:dateTimeStamp to xsd:dateTime in the triplestore (#1211). Existing data must be updated; see upgrade/1211-datetime for instructions. FIX: Ignore order of attributes when comparing standoff (#1224). FEATURE: Query version history (#1214) FIX: Don't allow conflicting cardinalities (#1229) MAJOR: Remove preview file values (#1230). Existing data must be updated; see upgrade/1230-delete-previews for instructions.","title":"Release Notes"},{"location":"09-release-notes/#v500-05022019","text":"","title":"v5.0.0 (05/02/2019)"},{"location":"09-release-notes/#release-notes_1","text":"MAJOR: Fix property names for incoming links (#1144)) MAJOR: Generate and resolve ARK URLs for resources (#1161). Projects that have resource IRIs that do not conform to the format specified in https://docs.knora.org/paradox/03-endpoints/api-v2/knora-iris.html#iris-for-data must update them. MAJOR: Use project shortcode in IIIF URLs (#1191). If you have file value IRIs containing the substring /reps/ , you must replace /reps/ with /values/ . FEATURE: Update resource metadata in API v2 (#1131) FEATURE: Allow setting resource creation date in bulk import #1151) FEATURE: The v2/authentication route now also initiates cookie creation (the same as v1/authentication ) (#1159) FEATURE: Allow to specify restricted view settings for a project which Sipi will adhere to (#690). FIX: Triplestore connection error when using dockerComposeUp (#1122) FIX: Reject link value properties in Gravsearch queries in the simple schema (#1145) FIX: Fix error-checking when updating cardinalities in ontology API (#1142) FIX: Allow hasRepresentation in an ontology used in a bulk import (#1171) FIX: Set cookie domain to the value specified in application.conf with the setting cookie-domain (#1169) FIX: Fix processing of shared property in bulk import (#1182)","title":"Release Notes"},{"location":"09-release-notes/#v400-12122018","text":"","title":"v4.0.0 (12/12/2018)"},{"location":"09-release-notes/#v400-release-notes","text":"MAJOR CHANGE: mapping creation request and response formats have changed (#1094) MINOR CHANGE: Update technical user docs (#1085) BUGFIX CHANGE: Fix permission checking in API v2 resource creation (#1104)","title":"v4.0.0 Release Notes"},{"location":"09-release-notes/#v300-30112018","text":"","title":"v3.0.0 (30/11/2018)"},{"location":"09-release-notes/#v300-release-notes","text":"[BREAKING ONTOLOGY CHANGE] The property knora-base:username was added and is required for knora-base:User . (#1047) [BREAKING API CHANGE] The /admin/user API has changed due to adding the username property. (#1047) [FIX] Incorrect standoff to XML conversion if empty tag has empty child tag (#1054) [FEATURE] Add default permission caching (#1062) [FIX] Fix unescaping in update check and reading standoff URL (#1074) [FIX] Incorrect standoff to XML conversion if empty tag has empty child tag (#1054) [FEATURE] Create image file values in API v2 (#1011). Requires Sipi with tagged commit v1.4.1-SNAPSHOT or later.","title":"v3.0.0 Release Notes"},{"location":"09-release-notes/#v210-02112018","text":"","title":"v2.1.0 (02/11/2018)"},{"location":"09-release-notes/#new-features","text":"Implement graph query in API v2 (#1009) Expose additional webapi settings as environment variables. Please see the Configuration section in the documentation for more information (#1025)","title":"New features"},{"location":"09-release-notes/#bugfixes","text":"sipi container config / sipi not able to talk to knora (#994)","title":"Bugfixes"},{"location":"09-release-notes/#v210-snapshot-22102018","text":"","title":"v2.1.0-snapshot (22/10/2018)"},{"location":"09-release-notes/#v200-13092018","text":"This is the first release with the new version numbering convention. From now on, if any changes to the existing data are necessary for a release, then this release will have its major number increased. Please see the Release Versioning Convention description.","title":"v2.0.0 (13/09/2018)"},{"location":"09-release-notes/#required-changes-to-existing-data","text":"a knora-base:ListNode must have at least one rdfs:label . (@github #991 )","title":"Required changes to existing data"},{"location":"09-release-notes/#new-features_1","text":"add developer-centric docker-compose.yml for starting the Knora / GraphDB / Sipi / Salsah1 (@github #979 ) configure webapi and salsah1 thorough environment variables (@github #979 ) update for Java 10 (@github #979 ) comment out the generation of fat jars from KnoraBuild.sbt (for now) (@github #979 ) update ehcache (@github #979 ) update sbt to 1.2.1 (@github #979 ) remove Kamon monitoring (for now) since we don't see anything meaningful there. We probably will have to instrument Knora by hand and then use Kamon for access. (@github #979 ) update Dockerfiles for webapi and salsah1 (@github #979 ) follow subClassOf when including ontologies in XML import schemas (@github #991 ) add support for adding list child nodes (@github #991 ) add support for shared ontologies (@github #987 )","title":"New features"},{"location":"09-release-notes/#bugfixes_1","text":"trouble with xml-checker and/or consistency-checker during bulk import (@github #978 ) ontology API error with link values (@github #988 )","title":"Bugfixes"},{"location":"09-release-notes/#v171-29082018","text":"","title":"v1.7.1 (29/08/2018)"},{"location":"09-release-notes/#knora-stack-compatible-versions","text":"Knora v1.7.1 - Salsah v2.1.2 - Sipi v1.4.0 - GraphDB v8.5.0 doc (webapi): add yourkit acknowledgment (#983) Don't allow class with cardinalities on P and on a subproperty of P (#982) doc (webapi): add LHTT project shortcode (#981) feature (webapi): not return or allow changing of built-in users (#975) fix (webapi): startup check does not detect running triplestore (#969) Fix bulk import parsing bug and limit concurrent client connections (#973)","title":"Knora-Stack compatible versions"},{"location":"09-release-notes/#v170-16082018","text":"See the closed tickets on the v1.7.0 milestone .","title":"v1.7.0 (16/08/2018)"},{"location":"09-release-notes/#knora-stack-compatible-versions_1","text":"Knora v1.7.0 - Salsah v2.1.0 - Sipi v1.4.0 - GraphDB v8.5.0","title":"Knora-Stack compatible versions"},{"location":"09-release-notes/#required-changes-to-existing-data_1","text":"To use the inferred Gravsearch predicate knora-api:standoffTagHasStartAncestor , you must recreate your repository with the updated KnoraRules.pie .","title":"Required changes to existing data"},{"location":"09-release-notes/#new-features_2","text":"Gravsearch queries can now match standoff markup (#910). Add Graphdb-Free initialization scripts for local and docker installation (#955). Create temp dirs at startup (#951) Update versions of monitoring tools (#951)","title":"New features"},{"location":"09-release-notes/#bugfixes_2","text":"timeout or java.lang.OutOfMemoryError when using /v1/resources/xmlimportschemas/ for some ontologies (#944) Timeout cleanup (#951) Add separate dispatchers (#945)","title":"Bugfixes"},{"location":"09-release-notes/#v160-29062018","text":"","title":"v1.6.0 (29/06/2018)"},{"location":"09-release-notes/#v160-release-notes","text":"See the release and closed tickets on the v1.6.0 milestone on Github.","title":"v1.6.0 Release Notes"},{"location":"09-release-notes/#required-changes-to-existing-data_2","text":"A project is now required to have at least one description, so potentially a description will need to be added to those projects that don't have one.","title":"Required changes to existing data"},{"location":"09-release-notes/#new-features_3","text":"General: Added a /health endpoint KnoraService waits on startup for a triplestore before trying to load the ontologies Gravsearch enhancements: Accept queries in POST requests (@github #650 ). Allow a Gravsearch query to specify the IRI of the main resource (@github #871 ) (by allowing BIND ). Allow lang to be used with != . A UNION or OPTIONAL can now be nested in an OPTIONAL (@github #882 ). Gravsearch now does type inference (@github #884 ). The Knora API v2 complex schema can now be used in Gravsearch, making it possible to search for list nodes (@github #899 ). Admin API: Make project description required (@github #875 ). Conversion to TEI: Conversion of standard standoff entities to TEI Custom conversion of project specific standoff entities and metadata to TEI Sipi integration: The Knora specific Sipi configuration and scripts can now be found under the sipi/ directory (@github #404 ). Documentation on how Sipi can be started changed (@github #404 ).","title":"New features"},{"location":"09-release-notes/#bugfixes_3","text":"Allow a class or property definition to have more than one object for rdf:type (@github #885 ). Exclude list values from v2 fulltext search (@github #906 ). Gravsearch fixes: Allow the lang function to be used in a comparison inside AND/OR (@github #846 ). Fix the processing of resources with multiple incoming links that use the same property (@github #878 ). Fix the parsing of a FILTER inside an OPTIONAL (@github #879 ). Require the match function to be the top-level expression in a FILTER .","title":"Bugfixes"},{"location":"09-release-notes/#v150-31052018","text":"See v1.5.0 milestone for a full list of closed tickets.","title":"v1.5.0 (31/05/2018)"},{"location":"09-release-notes/#new-features_4","text":"Resources can be returned in the simple ontology schema (#833). Text values can specify the language of the text (#819). Responses can be returned in Turtle and RDF/XML (#851).","title":"New features"},{"location":"09-release-notes/#bugfixes_4","text":"Incorrect representation of IRI object values in JSON-LD (#835) GenerateContributorsFile broken (#797)","title":"Bugfixes"},{"location":"09-release-notes/#v140-30042018","text":"","title":"v1.4.0 (30/04/2018)"},{"location":"09-release-notes/#required-changes-to-existing-data_3","text":"Every ontology must now have the property knora-base:attachedToProject , which points to the IRI of the project that is responsible for the ontology. This must be added to each project-specific ontology in existing repositories. All built-in ontologies have been updated to have this property, and must, therefore, be reloaded into existing repositories. The property knora-base:projectOntology has been removed, and must be removed from project definitions in existing repositories. Every project now needs to have the property knora-base:projectShortcode set.","title":"Required changes to existing data"},{"location":"09-release-notes/#new-features_5","text":"Added OpenAPI / Swagger API documentation route The Knora API server now checks the validity of ontologies on startup. The property knora-base:projectShortcode is now a required property (was optional).","title":"New features"},{"location":"09-release-notes/#bugfixes_5","text":"API v1 extended search was not properly handling multiple conditions on list values (issue #800) Fix image orientation in SALSAH 1 (issue #726)","title":"Bugfixes"},{"location":"09-release-notes/#v131-06042018","text":"","title":"v1.3.1 (06/04/2018)"},{"location":"09-release-notes/#v130-28032018","text":"","title":"v1.3.0 (28/03/2018)"},{"location":"09-release-notes/#required-changes-to-existing-data_4","text":"","title":"Required changes to existing data"},{"location":"09-release-notes/#1-replace-salsah-gui-ontology","text":"You must replace the salsah-gui ontology that you have in the triplestore with the one in salsah-gui.ttl .","title":"1. Replace salsah-gui ontology"},{"location":"09-release-notes/#new-features_6","text":"More support for salsah-gui elements and attributes in ontologies Serve the salsah-gui ontology in API v2 in the default schema. Show salsah-gui:guiElement and salsah-gui:guiAttribute when serving ontologies in API v2 in the default schema. Allow salsah-gui:guiElement and salsah-gui:guiAttribute to be included in new property definitions created via API v2. Change salsah-gui so that GraphDB's consistency checker can check the use of guiElement and guiAttribute . Changes to application.conf . The sipi and web-api sections have received a big update, adding separate settings for internal and external host settings: app { knora-api { // relevant for direct communication inside the knora stack internal-host = \"0.0.0.0\" internal-port = 3333 // relevant for the client, i.e. browser external-protocol = \"http\" // optional ssl termination needs to be done by the proxy external-host = \"0.0.0.0\" external-port = 3333 } sipi { // relevant for direct communication inside the knora stack internal-protocol = \"http\" internal-host = \"localhost\" internal-port = 1024 // relevant for the client, i.e. browser external-protocol = \"http\" external-host = \"localhost\" external-port = 1024 prefix = \"knora\" file-server-path = \"server\" path-conversion-route = \"convert_from_binaries\" file-conversion-route = \"convert_from_file\" image-mime-types = [\"image/tiff\", \"image/jpeg\", \"image/png\", \"image/jp2\"] movie-mime-types = [] sound-mime-types = [] } salsah1 { base-url = \"http://localhost:3335/\" project-icons-basepath = \"project-icons/\" } }","title":"New features"},{"location":"09-release-notes/#bugfixes_6","text":"When API v2 served knora-api (default schema), salsah-gui:guiElement and salsah-gui:guiAttribute were not shown in properties in that ontology. The predicate salsah-gui:guiOrder was not accepted when creating a property via API v2.","title":"Bugfixes"},{"location":"architecture/","text":"C4 Model and ADRs Installation $ brew install adr-tools Usage Run the following command from the root directory to start the C4 model browser: $ make structurizer","title":"C4 Model and ADRs"},{"location":"architecture/#c4-model-and-adrs","text":"","title":"C4 Model and ADRs"},{"location":"architecture/#installation","text":"$ brew install adr-tools","title":"Installation"},{"location":"architecture/#usage","text":"Run the following command from the root directory to start the C4 model browser: $ make structurizer","title":"Usage"},{"location":"architecture/docs/http-request-flow-with-events/","text":"Example for an HTTP Request Flow with Events Create a User sequenceDiagram autonumber user ->> userRoute: \"sends HTTP request\" userRoute ->> userRoute: \"validates input (payload) and creates value objects\" userRoute ->> userHandler: \"sends value objects\" userHandler ->> userRepo: \"reserves username\" userRepo ->> eventStoreService: \"reserves username\" eventStoreService ->> eventStoreService: \"checks if username exists\" eventStoreService ->> eventStoreService: \"reserves username\" userHandler ->> userDomain: \"calls User.make() with value objects\" userDomain ->> userDomain: \"creates userDomainEntity + userCreatedEvent(who, what)\" userDomain ->> userHandler: \"returns (userDomainEntity + userCreatedEvent)\" userHandler ->> userRepo: \"storeUser(userDomainEntity + userCreatedEvent)\" userRepo ->> eventStoreService: \"storeUser(userDomainEntity + userCreatedEvent)\" eventStoreService ->> eventStoreService: \"store event(s), userCreatedEvent(who, what, when(!))\" eventStoreService ->> eventListener: \"publishEvent(userCreatedEvent)\" eventListener ->> triplestoreService: \"writeToTsService(E)\" triplestoreService ->> triplestoreService: \"SPARQL update - write user to triplestore\" eventListener ->> arkService: \"writeToArkService(E)\" arkService ->> arkService: \"create ARK(URL)\" eventListener ->> elasticSearchService: \"writeToEsService(E)\" elasticSearchService ->> elasticSearchService: \"write\"","title":"Http request flow with events"},{"location":"architecture/docs/http-request-flow-with-events/#example-for-an-http-request-flow-with-events","text":"","title":"Example for an HTTP Request Flow with Events"},{"location":"architecture/docs/http-request-flow-with-events/#create-a-user","text":"sequenceDiagram autonumber user ->> userRoute: \"sends HTTP request\" userRoute ->> userRoute: \"validates input (payload) and creates value objects\" userRoute ->> userHandler: \"sends value objects\" userHandler ->> userRepo: \"reserves username\" userRepo ->> eventStoreService: \"reserves username\" eventStoreService ->> eventStoreService: \"checks if username exists\" eventStoreService ->> eventStoreService: \"reserves username\" userHandler ->> userDomain: \"calls User.make() with value objects\" userDomain ->> userDomain: \"creates userDomainEntity + userCreatedEvent(who, what)\" userDomain ->> userHandler: \"returns (userDomainEntity + userCreatedEvent)\" userHandler ->> userRepo: \"storeUser(userDomainEntity + userCreatedEvent)\" userRepo ->> eventStoreService: \"storeUser(userDomainEntity + userCreatedEvent)\" eventStoreService ->> eventStoreService: \"store event(s), userCreatedEvent(who, what, when(!))\" eventStoreService ->> eventListener: \"publishEvent(userCreatedEvent)\" eventListener ->> triplestoreService: \"writeToTsService(E)\" triplestoreService ->> triplestoreService: \"SPARQL update - write user to triplestore\" eventListener ->> arkService: \"writeToArkService(E)\" arkService ->> arkService: \"create ARK(URL)\" eventListener ->> elasticSearchService: \"writeToEsService(E)\" elasticSearchService ->> elasticSearchService: \"write\"","title":"Create a User"},{"location":"architecture/docs/http-request-flow/","text":"HTTP Request Flow V2 vs. V3 V1 / V2 / admin: sequenceDiagram autonumber client ->> route: send http request route ->> authenticator: authenticate user authenticator ->> route: user authenticated route ->> application actor: send message application actor ->> responder manager: forward message responder manager ->> responder: forward message responder ->> responder manager: return result responder manager ->> application actor: forward result application actor ->> route: forward result route ->> client: send http response V3: sequenceDiagram autonumber client ->> route: send http request route ->> authenticator: authenticate user authenticator ->> route: user authenticated route ->> handler: call handler method handler ->> route: return result route ->> client: send result as http response","title":"Http request flow"},{"location":"architecture/docs/http-request-flow/#http-request-flow-v2-vs-v3","text":"V1 / V2 / admin: sequenceDiagram autonumber client ->> route: send http request route ->> authenticator: authenticate user authenticator ->> route: user authenticated route ->> application actor: send message application actor ->> responder manager: forward message responder manager ->> responder: forward message responder ->> responder manager: return result responder manager ->> application actor: forward result application actor ->> route: forward result route ->> client: send http response V3: sequenceDiagram autonumber client ->> route: send http request route ->> authenticator: authenticate user authenticator ->> route: user authenticated route ->> handler: call handler method handler ->> route: return result route ->> client: send result as http response","title":"HTTP Request Flow V2 vs. V3"}]}